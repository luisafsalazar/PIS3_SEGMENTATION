Epoch [17/30] Training [16/488] Loss: 0.30150
Epoch [17/30] Training [17/488] Loss: 0.28723
Epoch [17/30] Training [18/488] Loss: 0.28966
Epoch [17/30] Training [19/488] Loss: 0.35148
Epoch [17/30] Training [20/488] Loss: 0.37249
Epoch [17/30] Training [21/488] Loss: 0.30385
Epoch [17/30] Training [22/488] Loss: 0.18480
Epoch [17/30] Training [23/488] Loss: 0.17824
Epoch [17/30] Training [24/488] Loss: 0.27777
Epoch [17/30] Training [25/488] Loss: 0.33138
Epoch [17/30] Training [26/488] Loss: 0.20517
Epoch [17/30] Training [27/488] Loss: 0.31952
Epoch [17/30] Training [28/488] Loss: 0.21951
Epoch [17/30] Training [29/488] Loss: 0.27124
Epoch [17/30] Training [30/488] Loss: 0.26023
Epoch [17/30] Training [31/488] Loss: 0.23122
Epoch [17/30] Training [32/488] Loss: 0.55317
Epoch [17/30] Training [33/488] Loss: 0.22947
Epoch [17/30] Training [34/488] Loss: 0.20340
Epoch [17/30] Training [35/488] Loss: 0.27354
Epoch [17/30] Training [36/488] Loss: 0.28490
Epoch [17/30] Training [37/488] Loss: 0.24134
Epoch [17/30] Training [38/488] Loss: 0.34237
Epoch [17/30] Training [39/488] Loss: 0.15279
Epoch [17/30] Training [40/488] Loss: 0.29277
Epoch [17/30] Training [41/488] Loss: 0.54929
Epoch [17/30] Training [42/488] Loss: 0.18751
Epoch [17/30] Training [43/488] Loss: 0.20573
Epoch [17/30] Training [44/488] Loss: 0.31272
Epoch [17/30] Training [45/488] Loss: 0.19069
Epoch [17/30] Training [46/488] Loss: 0.26047
Epoch [17/30] Training [47/488] Loss: 0.24158
Epoch [17/30] Training [48/488] Loss: 0.29625
Epoch [17/30] Training [49/488] Loss: 0.30212
Epoch [17/30] Training [50/488] Loss: 0.44796
Epoch [17/30] Training [51/488] Loss: 0.23910
Epoch [17/30] Training [52/488] Loss: 0.41211
Epoch [17/30] Training [53/488] Loss: 0.24036
Epoch [17/30] Training [54/488] Loss: 0.33716
Epoch [17/30] Training [55/488] Loss: 0.20434
Epoch [17/30] Training [56/488] Loss: 0.25221
Epoch [17/30] Training [57/488] Loss: 0.15795
Epoch [17/30] Training [58/488] Loss: 0.23306
Epoch [17/30] Training [59/488] Loss: 0.19619
Epoch [17/30] Training [60/488] Loss: 0.20768
Epoch [17/30] Training [61/488] Loss: 0.20689
Epoch [17/30] Training [62/488] Loss: 0.27111
Epoch [17/30] Training [63/488] Loss: 0.42773
Epoch [17/30] Training [64/488] Loss: 0.14468
Epoch [17/30] Training [65/488] Loss: 0.14463
Epoch [17/30] Training [66/488] Loss: 0.15830
Epoch [17/30] Training [67/488] Loss: 0.20348
Epoch [17/30] Training [68/488] Loss: 0.50238
Epoch [17/30] Training [69/488] Loss: 0.18547
Epoch [17/30] Training [70/488] Loss: 0.30503
Epoch [17/30] Training [71/488] Loss: 0.72975
Epoch [17/30] Training [72/488] Loss: 0.22813
Epoch [17/30] Training [73/488] Loss: 0.48965
Epoch [17/30] Training [74/488] Loss: 0.16089
Epoch [17/30] Training [75/488] Loss: 0.43027
Epoch [17/30] Training [76/488] Loss: 0.31942
Epoch [17/30] Training [77/488] Loss: 0.76657
Epoch [17/30] Training [78/488] Loss: 0.54128
Epoch [17/30] Training [79/488] Loss: 0.25131
Epoch [17/30] Training [80/488] Loss: 0.22138
Epoch [17/30] Training [81/488] Loss: 0.27299
Epoch [17/30] Training [82/488] Loss: 0.19713
Epoch [17/30] Training [83/488] Loss: 0.17213
Epoch [17/30] Training [84/488] Loss: 0.36669
Epoch [17/30] Training [85/488] Loss: 0.18898
Epoch [17/30] Training [86/488] Loss: 0.21441
Epoch [17/30] Training [87/488] Loss: 0.23612
Epoch [17/30] Training [88/488] Loss: 0.20325
Epoch [17/30] Training [89/488] Loss: 0.14360
Epoch [17/30] Training [90/488] Loss: 0.47840
Epoch [17/30] Training [91/488] Loss: 0.21445
Epoch [17/30] Training [92/488] Loss: 0.24800
Epoch [17/30] Training [93/488] Loss: 0.35122
Epoch [17/30] Training [94/488] Loss: 0.20313
Epoch [17/30] Training [95/488] Loss: 0.17703
Epoch [17/30] Training [96/488] Loss: 0.25021
Epoch [17/30] Training [97/488] Loss: 0.48121
Epoch [17/30] Training [98/488] Loss: 0.25418
Epoch [17/30] Training [99/488] Loss: 0.23796
Epoch [17/30] Training [100/488] Loss: 0.31660
Epoch [17/30] Training [101/488] Loss: 0.44894
Epoch [17/30] Training [102/488] Loss: 0.14151
Epoch [17/30] Training [103/488] Loss: 0.28605
Epoch [17/30] Training [104/488] Loss: 0.19899
Epoch [17/30] Training [105/488] Loss: 0.30888
Epoch [17/30] Training [106/488] Loss: 0.32058
Epoch [17/30] Training [107/488] Loss: 0.20900
Epoch [17/30] Training [108/488] Loss: 0.23570
Epoch [17/30] Training [109/488] Loss: 0.41907
Epoch [17/30] Training [110/488] Loss: 0.14946
Epoch [17/30] Training [111/488] Loss: 0.26933
Epoch [17/30] Training [112/488] Loss: 0.15836
Epoch [17/30] Training [113/488] Loss: 0.32577
Epoch [17/30] Training [114/488] Loss: 0.27111
Epoch [17/30] Training [115/488] Loss: 0.19113
Epoch [17/30] Training [116/488] Loss: 0.25639
Epoch [17/30] Training [117/488] Loss: 0.39586
Epoch [17/30] Training [118/488] Loss: 0.23649
Epoch [17/30] Training [119/488] Loss: 0.28033
Epoch [17/30] Training [120/488] Loss: 0.14865
Epoch [17/30] Training [121/488] Loss: 0.29934
Epoch [17/30] Training [122/488] Loss: 0.27475
Epoch [17/30] Training [123/488] Loss: 0.22107
Epoch [17/30] Training [124/488] Loss: 0.17290
Epoch [17/30] Training [125/488] Loss: 0.24293
Epoch [17/30] Training [126/488] Loss: 0.29846
Epoch [17/30] Training [127/488] Loss: 0.20733
Epoch [17/30] Training [128/488] Loss: 0.18038
Epoch [17/30] Training [129/488] Loss: 0.42579
Epoch [17/30] Training [130/488] Loss: 0.28962
Epoch [17/30] Training [131/488] Loss: 0.32756
Epoch [17/30] Training [132/488] Loss: 0.17720
Epoch [17/30] Training [133/488] Loss: 0.34907
Epoch [17/30] Training [134/488] Loss: 0.16865
Epoch [17/30] Training [135/488] Loss: 0.20900
Epoch [17/30] Training [136/488] Loss: 0.26535
Epoch [17/30] Training [137/488] Loss: 0.26241
Epoch [17/30] Training [138/488] Loss: 0.48822
Epoch [17/30] Training [139/488] Loss: 0.16249
Epoch [17/30] Training [140/488] Loss: 0.29924
Epoch [17/30] Training [141/488] Loss: 0.16960
Epoch [17/30] Training [142/488] Loss: 0.21220
Epoch [17/30] Training [143/488] Loss: 0.38370
Epoch [17/30] Training [144/488] Loss: 0.28380
Epoch [17/30] Training [145/488] Loss: 0.26079
Epoch [17/30] Training [146/488] Loss: 0.16995
Epoch [17/30] Training [147/488] Loss: 0.13700
Epoch [17/30] Training [148/488] Loss: 0.54830
Epoch [17/30] Training [149/488] Loss: 0.27357
Epoch [17/30] Training [150/488] Loss: 0.31190
Epoch [17/30] Training [151/488] Loss: 0.21341
Epoch [17/30] Training [152/488] Loss: 0.19406
Epoch [17/30] Training [153/488] Loss: 0.23617
Epoch [17/30] Training [154/488] Loss: 0.19779
Epoch [17/30] Training [155/488] Loss: 0.18854
Epoch [17/30] Training [156/488] Loss: 0.34786
Epoch [17/30] Training [157/488] Loss: 0.30041
Epoch [17/30] Training [158/488] Loss: 0.20350
Epoch [17/30] Training [159/488] Loss: 0.46731
Epoch [17/30] Training [160/488] Loss: 0.35735
Epoch [17/30] Training [161/488] Loss: 0.17803
Epoch [17/30] Training [162/488] Loss: 0.19985
Epoch [17/30] Training [163/488] Loss: 0.23392
Epoch [17/30] Training [164/488] Loss: 0.18044
Epoch [17/30] Training [165/488] Loss: 0.25810
Epoch [17/30] Training [166/488] Loss: 0.27844
Epoch [17/30] Training [167/488] Loss: 0.25776
Epoch [17/30] Training [168/488] Loss: 0.27151
Epoch [17/30] Training [169/488] Loss: 0.27687
Epoch [17/30] Training [170/488] Loss: 0.23022
Epoch [17/30] Training [171/488] Loss: 0.14466
Epoch [17/30] Training [172/488] Loss: 0.29428
Epoch [17/30] Training [173/488] Loss: 0.23006
Epoch [17/30] Training [174/488] Loss: 0.32938
Epoch [17/30] Training [175/488] Loss: 0.17026
Epoch [17/30] Training [176/488] Loss: 0.47424
Epoch [17/30] Training [177/488] Loss: 0.20213
Epoch [17/30] Training [178/488] Loss: 0.26258
Epoch [17/30] Training [179/488] Loss: 0.63694
Epoch [17/30] Training [180/488] Loss: 0.44015
Epoch [17/30] Training [181/488] Loss: 0.17809
Epoch [17/30] Training [182/488] Loss: 0.21254
Epoch [17/30] Training [183/488] Loss: 0.19602
Epoch [17/30] Training [184/488] Loss: 0.18554
Epoch [17/30] Training [185/488] Loss: 0.49430
Epoch [17/30] Training [186/488] Loss: 0.35355
Epoch [17/30] Training [187/488] Loss: 0.21678
Epoch [17/30] Training [188/488] Loss: 0.39352
Epoch [17/30] Training [189/488] Loss: 0.14564
Epoch [17/30] Training [190/488] Loss: 0.33357
Epoch [17/30] Training [191/488] Loss: 0.43019
Epoch [17/30] Training [192/488] Loss: 0.22818
Epoch [17/30] Training [193/488] Loss: 0.13209
Epoch [17/30] Training [194/488] Loss: 0.25669
Epoch [17/30] Training [195/488] Loss: 0.18655
Epoch [17/30] Training [196/488] Loss: 0.21383
Epoch [17/30] Training [197/488] Loss: 0.24101
Epoch [17/30] Training [198/488] Loss: 0.55187
Epoch [17/30] Training [199/488] Loss: 0.14526
Epoch [17/30] Training [200/488] Loss: 0.24410
Epoch [17/30] Training [201/488] Loss: 0.17727
Epoch [17/30] Training [202/488] Loss: 0.17814
Epoch [17/30] Training [203/488] Loss: 0.25512
Epoch [17/30] Training [204/488] Loss: 0.15923
Epoch [17/30] Training [205/488] Loss: 0.26920
Epoch [17/30] Training [206/488] Loss: 0.14395
Epoch [17/30] Training [207/488] Loss: 0.15154
Epoch [17/30] Training [208/488] Loss: 0.54532
Epoch [17/30] Training [209/488] Loss: 0.31436
Epoch [17/30] Training [210/488] Loss: 0.36565
Epoch [17/30] Training [211/488] Loss: 0.37277
Epoch [17/30] Training [212/488] Loss: 0.35607
Epoch [17/30] Training [213/488] Loss: 0.17240
Epoch [17/30] Training [214/488] Loss: 0.33641
Epoch [17/30] Training [215/488] Loss: 0.22042
Epoch [17/30] Training [216/488] Loss: 0.35798
Epoch [17/30] Training [217/488] Loss: 0.35147
Epoch [17/30] Training [218/488] Loss: 0.44460
Epoch [17/30] Training [219/488] Loss: 0.41873
Epoch [17/30] Training [220/488] Loss: 0.19866
Epoch [17/30] Training [221/488] Loss: 0.30346
Epoch [17/30] Training [222/488] Loss: 0.17597
Epoch [17/30] Training [223/488] Loss: 0.19605
Epoch [17/30] Training [224/488] Loss: 0.23078
Epoch [17/30] Training [225/488] Loss: 0.60839
Epoch [17/30] Training [226/488] Loss: 0.80492
Epoch [17/30] Training [227/488] Loss: 0.29208
Epoch [17/30] Training [228/488] Loss: 0.21494
Epoch [17/30] Training [229/488] Loss: 0.29468
Epoch [17/30] Training [230/488] Loss: 0.20137
Epoch [17/30] Training [231/488] Loss: 0.73731
Epoch [17/30] Training [232/488] Loss: 0.40887
Epoch [17/30] Training [233/488] Loss: 0.15229
Epoch [17/30] Training [234/488] Loss: 0.29521
Epoch [17/30] Training [235/488] Loss: 0.27275
Epoch [17/30] Training [236/488] Loss: 0.33942
Epoch [17/30] Training [237/488] Loss: 0.15890
Epoch [17/30] Training [238/488] Loss: 0.25339
Epoch [17/30] Training [239/488] Loss: 0.19996
Epoch [17/30] Training [240/488] Loss: 0.17621
Epoch [17/30] Training [241/488] Loss: 0.21528
Epoch [17/30] Training [242/488] Loss: 0.30328
Epoch [17/30] Training [243/488] Loss: 0.54480
Epoch [17/30] Training [244/488] Loss: 0.29804
Epoch [17/30] Training [245/488] Loss: 0.36687
Epoch [17/30] Training [246/488] Loss: 0.17717
Epoch [17/30] Training [247/488] Loss: 0.70257
Epoch [17/30] Training [248/488] Loss: 0.30307
Epoch [17/30] Training [249/488] Loss: 0.15256
Epoch [17/30] Training [250/488] Loss: 0.38873
Epoch [17/30] Training [251/488] Loss: 0.19985
Epoch [17/30] Training [252/488] Loss: 0.16486
Epoch [17/30] Training [253/488] Loss: 0.22859
Epoch [17/30] Training [254/488] Loss: 0.35008
Epoch [17/30] Training [255/488] Loss: 0.40387
Epoch [17/30] Training [256/488] Loss: 0.24498
Epoch [17/30] Training [257/488] Loss: 0.35464
Epoch [17/30] Training [258/488] Loss: 0.24021
Epoch [17/30] Training [259/488] Loss: 0.24819
Epoch [17/30] Training [260/488] Loss: 0.49877
Epoch [17/30] Training [261/488] Loss: 0.48553
Epoch [17/30] Training [262/488] Loss: 0.42980
Epoch [17/30] Training [263/488] Loss: 0.20020
Epoch [17/30] Training [264/488] Loss: 0.15214
Epoch [17/30] Training [265/488] Loss: 0.23298
Epoch [17/30] Training [266/488] Loss: 0.16158
Epoch [17/30] Training [267/488] Loss: 0.21004
Epoch [17/30] Training [268/488] Loss: 0.24083
Epoch [17/30] Training [269/488] Loss: 0.55364
Epoch [17/30] Training [270/488] Loss: 0.21751
Epoch [17/30] Training [271/488] Loss: 0.23613
Epoch [17/30] Training [272/488] Loss: 0.20960
Epoch [17/30] Training [273/488] Loss: 0.19318
Epoch [17/30] Training [274/488] Loss: 0.26872
Epoch [17/30] Training [275/488] Loss: 0.21977
Epoch [17/30] Training [276/488] Loss: 0.14094
Epoch [17/30] Training [277/488] Loss: 0.24634
Epoch [17/30] Training [278/488] Loss: 0.51718
Epoch [17/30] Training [279/488] Loss: 0.29226
Epoch [17/30] Training [280/488] Loss: 0.25090
Epoch [17/30] Training [281/488] Loss: 0.24862
Epoch [17/30] Training [282/488] Loss: 0.15520
Epoch [17/30] Training [283/488] Loss: 0.15377
Epoch [17/30] Training [284/488] Loss: 0.17500
Epoch [17/30] Training [285/488] Loss: 0.18304
Epoch [17/30] Training [286/488] Loss: 0.25016
Epoch [17/30] Training [287/488] Loss: 0.37534
Epoch [17/30] Training [288/488] Loss: 0.21571
Epoch [17/30] Training [289/488] Loss: 0.18774
Epoch [17/30] Training [290/488] Loss: 0.17610
Epoch [17/30] Training [291/488] Loss: 0.28413
Epoch [17/30] Training [292/488] Loss: 0.22248
Epoch [17/30] Training [293/488] Loss: 0.24430
Epoch [17/30] Training [294/488] Loss: 0.25815
Epoch [17/30] Training [295/488] Loss: 0.18504
Epoch [17/30] Training [296/488] Loss: 0.20510
Epoch [17/30] Training [297/488] Loss: 0.22654
Epoch [17/30] Training [298/488] Loss: 0.23261
Epoch [17/30] Training [299/488] Loss: 0.42331
Epoch [17/30] Training [300/488] Loss: 0.40982
Epoch [17/30] Training [301/488] Loss: 0.25431
Epoch [17/30] Training [302/488] Loss: 0.16690
Epoch [17/30] Training [303/488] Loss: 0.41819
Epoch [17/30] Training [304/488] Loss: 0.16821
Epoch [17/30] Training [305/488] Loss: 0.39251
Epoch [17/30] Training [306/488] Loss: 0.19349
Epoch [17/30] Training [307/488] Loss: 0.18339
Epoch [17/30] Training [308/488] Loss: 0.74350
Epoch [17/30] Training [309/488] Loss: 0.29473
Epoch [17/30] Training [310/488] Loss: 0.19992
Epoch [17/30] Training [311/488] Loss: 0.15999
Epoch [17/30] Training [312/488] Loss: 0.19728
Epoch [17/30] Training [313/488] Loss: 0.27094
Epoch [17/30] Training [314/488] Loss: 0.42103
Epoch [17/30] Training [315/488] Loss: 0.32843
Epoch [17/30] Training [316/488] Loss: 0.28291
Epoch [17/30] Training [317/488] Loss: 0.54415
Epoch [17/30] Training [318/488] Loss: 0.19021
Epoch [17/30] Training [319/488] Loss: 0.23751
Epoch [17/30] Training [320/488] Loss: 0.35856
Epoch [17/30] Training [321/488] Loss: 0.42210
Epoch [17/30] Training [322/488] Loss: 0.20190
Epoch [17/30] Training [323/488] Loss: 0.37215
Epoch [17/30] Training [324/488] Loss: 0.41585
Epoch [17/30] Training [325/488] Loss: 0.18328
Epoch [17/30] Training [326/488] Loss: 0.16816
Epoch [17/30] Training [327/488] Loss: 0.19327
Epoch [17/30] Training [328/488] Loss: 0.17735
Epoch [17/30] Training [329/488] Loss: 0.19039
Epoch [17/30] Training [330/488] Loss: 0.18123
Epoch [17/30] Training [331/488] Loss: 0.20475
Epoch [17/30] Training [332/488] Loss: 0.27032
Epoch [17/30] Training [333/488] Loss: 0.21819
Epoch [17/30] Training [334/488] Loss: 0.17217
Epoch [17/30] Training [335/488] Loss: 0.22881
Epoch [17/30] Training [336/488] Loss: 0.13495
Epoch [17/30] Training [337/488] Loss: 0.20467
Epoch [17/30] Training [338/488] Loss: 0.67020
Epoch [17/30] Training [339/488] Loss: 0.21754
Epoch [17/30] Training [340/488] Loss: 0.17480
Epoch [17/30] Training [341/488] Loss: 0.21792
Epoch [17/30] Training [342/488] Loss: 0.25495
Epoch [17/30] Training [343/488] Loss: 0.33563
Epoch [17/30] Training [344/488] Loss: 0.53255
Epoch [17/30] Training [345/488] Loss: 0.24910
Epoch [17/30] Training [346/488] Loss: 0.54349
Epoch [17/30] Training [347/488] Loss: 0.21320
Epoch [17/30] Training [348/488] Loss: 0.45556
Epoch [17/30] Training [349/488] Loss: 0.43478
Epoch [17/30] Training [350/488] Loss: 0.25985
Epoch [17/30] Training [351/488] Loss: 0.19116
Epoch [17/30] Training [352/488] Loss: 0.16780
Epoch [17/30] Training [353/488] Loss: 0.19586
Epoch [17/30] Training [354/488] Loss: 0.22282
Epoch [17/30] Training [355/488] Loss: 0.25826
Epoch [17/30] Training [356/488] Loss: 0.17068
Epoch [17/30] Training [357/488] Loss: 0.34856
Epoch [17/30] Training [358/488] Loss: 0.14381
Epoch [17/30] Training [359/488] Loss: 0.18525
Epoch [17/30] Training [360/488] Loss: 0.18199
Epoch [17/30] Training [361/488] Loss: 0.27462
Epoch [17/30] Training [362/488] Loss: 0.29635
Epoch [17/30] Training [363/488] Loss: 0.14937
Epoch [17/30] Training [364/488] Loss: 0.17930
Epoch [17/30] Training [365/488] Loss: 0.16232
Epoch [17/30] Training [366/488] Loss: 0.35172
Epoch [17/30] Training [367/488] Loss: 0.17323
Epoch [17/30] Training [368/488] Loss: 0.27805
Epoch [17/30] Training [369/488] Loss: 0.29656
Epoch [17/30] Training [370/488] Loss: 0.14696
Epoch [17/30] Training [371/488] Loss: 0.15506
Epoch [17/30] Training [372/488] Loss: 0.16022
Epoch [17/30] Training [373/488] Loss: 0.17907
Epoch [17/30] Training [374/488] Loss: 0.16576
Epoch [17/30] Training [375/488] Loss: 0.20088
Epoch [17/30] Training [376/488] Loss: 0.18791
Epoch [17/30] Training [377/488] Loss: 0.17296
Epoch [17/30] Training [378/488] Loss: 0.19557
Epoch [17/30] Training [379/488] Loss: 0.57103
Epoch [17/30] Training [380/488] Loss: 0.34638
Epoch [17/30] Training [381/488] Loss: 0.26075
Epoch [17/30] Training [382/488] Loss: 0.32816
Epoch [17/30] Training [383/488] Loss: 0.28146
Epoch [17/30] Training [384/488] Loss: 0.14403
Epoch [17/30] Training [385/488] Loss: 0.21505
Epoch [17/30] Training [386/488] Loss: 0.32910
Epoch [17/30] Training [387/488] Loss: 0.16548
Epoch [17/30] Training [388/488] Loss: 0.17409
Epoch [17/30] Training [389/488] Loss: 0.21661
Epoch [17/30] Training [390/488] Loss: 0.41606
Epoch [17/30] Training [391/488] Loss: 0.14237
Epoch [17/30] Training [392/488] Loss: 0.23160
Epoch [17/30] Training [393/488] Loss: 0.19454
Epoch [17/30] Training [394/488] Loss: 0.17124
Epoch [17/30] Training [395/488] Loss: 0.27392
Epoch [17/30] Training [396/488] Loss: 0.16034
Epoch [17/30] Training [397/488] Loss: 0.12914
Epoch [17/30] Training [398/488] Loss: 0.20521
Epoch [17/30] Training [399/488] Loss: 0.20928
Epoch [17/30] Training [400/488] Loss: 0.25478
Epoch [17/30] Training [401/488] Loss: 0.15697
Epoch [17/30] Training [402/488] Loss: 0.19986
Epoch [17/30] Training [403/488] Loss: 0.23751
Epoch [17/30] Training [404/488] Loss: 0.40648
Epoch [17/30] Training [405/488] Loss: 0.14118
Epoch [17/30] Training [406/488] Loss: 0.26905
Epoch [17/30] Training [407/488] Loss: 0.23494
Epoch [17/30] Training [408/488] Loss: 0.32744
Epoch [17/30] Training [409/488] Loss: 0.38159
Epoch [17/30] Training [410/488] Loss: 0.12426
Epoch [17/30] Training [411/488] Loss: 0.22867
Epoch [17/30] Training [412/488] Loss: 0.16371
Epoch [17/30] Training [413/488] Loss: 0.18747
Epoch [17/30] Training [414/488] Loss: 0.44842
Epoch [17/30] Training [415/488] Loss: 0.29129
Epoch [17/30] Training [416/488] Loss: 0.23627
Epoch [17/30] Training [417/488] Loss: 0.17962
Epoch [17/30] Training [418/488] Loss: 0.17304
Epoch [17/30] Training [419/488] Loss: 0.42858
Epoch [17/30] Training [420/488] Loss: 0.26468
Epoch [17/30] Training [421/488] Loss: 0.14806
Epoch [17/30] Training [422/488] Loss: 0.16103
Epoch [17/30] Training [423/488] Loss: 0.20996
Epoch [17/30] Training [424/488] Loss: 0.15444
Epoch [17/30] Training [425/488] Loss: 0.32947
Epoch [17/30] Training [426/488] Loss: 0.18039
Epoch [17/30] Training [427/488] Loss: 0.43098
Epoch [17/30] Training [428/488] Loss: 0.14370
Epoch [17/30] Training [429/488] Loss: 0.15988
Epoch [17/30] Training [430/488] Loss: 0.20848
Epoch [17/30] Training [431/488] Loss: 0.34285
Epoch [17/30] Training [432/488] Loss: 0.28761
Epoch [17/30] Training [433/488] Loss: 0.38025
Epoch [17/30] Training [434/488] Loss: 0.17814
Epoch [17/30] Training [435/488] Loss: 0.19840
Epoch [17/30] Training [436/488] Loss: 0.13272
Epoch [17/30] Training [437/488] Loss: 0.30454
Epoch [17/30] Training [438/488] Loss: 0.16530
Epoch [17/30] Training [439/488] Loss: 0.19998
Epoch [17/30] Training [440/488] Loss: 0.24921
Epoch [17/30] Training [441/488] Loss: 0.18491
Epoch [17/30] Training [442/488] Loss: 0.16014
Epoch [17/30] Training [443/488] Loss: 0.14357
Epoch [17/30] Training [444/488] Loss: 0.15687
Epoch [17/30] Training [445/488] Loss: 0.22507
Epoch [17/30] Training [446/488] Loss: 0.16178
Epoch [17/30] Training [447/488] Loss: 0.16317
Epoch [17/30] Training [448/488] Loss: 0.23696
Epoch [17/30] Training [449/488] Loss: 0.16789
Epoch [17/30] Training [450/488] Loss: 0.76230
Epoch [17/30] Training [451/488] Loss: 0.17013
Epoch [17/30] Training [452/488] Loss: 0.23943
Epoch [17/30] Training [453/488] Loss: 0.46208
Epoch [17/30] Training [454/488] Loss: 0.19876
Epoch [17/30] Training [455/488] Loss: 0.21166
Epoch [17/30] Training [456/488] Loss: 0.16359
Epoch [17/30] Training [457/488] Loss: 0.24277
Epoch [17/30] Training [458/488] Loss: 0.66359
Epoch [17/30] Training [459/488] Loss: 0.44100
Epoch [17/30] Training [460/488] Loss: 0.43276
Epoch [17/30] Training [461/488] Loss: 0.15115
Epoch [17/30] Training [462/488] Loss: 0.26167
Epoch [17/30] Training [463/488] Loss: 0.45521
Epoch [17/30] Training [464/488] Loss: 0.14678
Epoch [17/30] Training [465/488] Loss: 0.28408
Epoch [17/30] Training [466/488] Loss: 0.27633
Epoch [17/30] Training [467/488] Loss: 0.22219
Epoch [17/30] Training [468/488] Loss: 0.26834
Epoch [17/30] Training [469/488] Loss: 0.20383
Epoch [17/30] Training [470/488] Loss: 0.33262
Epoch [17/30] Training [471/488] Loss: 0.46192
Epoch [17/30] Training [472/488] Loss: 0.16390
Epoch [17/30] Training [473/488] Loss: 0.17407
Epoch [17/30] Training [474/488] Loss: 0.19964
Epoch [17/30] Training [475/488] Loss: 0.23017
Epoch [17/30] Training [476/488] Loss: 0.28932
Epoch [17/30] Training [477/488] Loss: 0.20278
Epoch [17/30] Training [478/488] Loss: 0.13369
Epoch [17/30] Training [479/488] Loss: 0.55126
Epoch [17/30] Training [480/488] Loss: 0.15363
Epoch [17/30] Training [481/488] Loss: 0.21989
Epoch [17/30] Training [482/488] Loss: 0.32790
Epoch [17/30] Training [483/488] Loss: 0.18082
Epoch [17/30] Training [484/488] Loss: 0.16760
Epoch [17/30] Training [485/488] Loss: 0.16100
Epoch [17/30] Training [486/488] Loss: 0.17174
Epoch [17/30] Training [487/488] Loss: 0.23126
Epoch [17/30] Training [488/488] Loss: 0.18498
Epoch [17/30] Training metric {'Train/mean dice_metric': 0.8694271445274353, 'Train/TC dice_metric': 0.8837080001831055, 'Train/WT dice_metric': 0.9233759045600891, 'Train/ET dice_metric': 0.8011974096298218}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [17/30] Validation [1/123] Loss: 0.24234  focal_loss 0.00209  dice_loss 0.24025
Epoch [17/30] Validation [2/123] Loss: 0.42220  focal_loss 0.00136  dice_loss 0.42084
Epoch [17/30] Validation [3/123] Loss: 0.23128  focal_loss 0.00197  dice_loss 0.22931
Epoch [17/30] Validation [4/123] Loss: 0.31698  focal_loss 0.00155  dice_loss 0.31543
Epoch [17/30] Validation [5/123] Loss: 0.31757  focal_loss 0.00730  dice_loss 0.31027
Epoch [17/30] Validation [6/123] Loss: 0.37070  focal_loss 0.00131  dice_loss 0.36939
Epoch [17/30] Validation [7/123] Loss: 0.44002  focal_loss 0.00195  dice_loss 0.43807
Epoch [17/30] Validation [8/123] Loss: 0.39342  focal_loss 0.00158  dice_loss 0.39184
Epoch [17/30] Validation [9/123] Loss: 0.30996  focal_loss 0.00187  dice_loss 0.30809
Epoch [17/30] Validation [10/123] Loss: 0.49046  focal_loss 0.00244  dice_loss 0.48801
Epoch [17/30] Validation [11/123] Loss: 0.51418  focal_loss 0.00383  dice_loss 0.51036
Epoch [17/30] Validation [12/123] Loss: 0.25313  focal_loss 0.00174  dice_loss 0.25138
Epoch [17/30] Validation [13/123] Loss: 0.22318  focal_loss 0.00301  dice_loss 0.22017
Epoch [17/30] Validation [14/123] Loss: 0.30293  focal_loss 0.00241  dice_loss 0.30052
Epoch [17/30] Validation [15/123] Loss: 0.40442  focal_loss 0.00154  dice_loss 0.40287
Epoch [17/30] Validation [16/123] Loss: 0.48547  focal_loss 0.00215  dice_loss 0.48331
Epoch [17/30] Validation [17/123] Loss: 0.53423  focal_loss 0.00144  dice_loss 0.53279
Epoch [17/30] Validation [18/123] Loss: 0.40021  focal_loss 0.00483  dice_loss 0.39538
Epoch [17/30] Validation [19/123] Loss: 0.36461  focal_loss 0.01019  dice_loss 0.35442
Epoch [17/30] Validation [20/123] Loss: 0.53540  focal_loss 0.00140  dice_loss 0.53400
Epoch [17/30] Validation [21/123] Loss: 0.38307  focal_loss 0.00096  dice_loss 0.38211
Epoch [17/30] Validation [22/123] Loss: 0.65765  focal_loss 0.00836  dice_loss 0.64929
Epoch [17/30] Validation [23/123] Loss: 0.25538  focal_loss 0.00181  dice_loss 0.25357
Epoch [17/30] Validation [24/123] Loss: 0.33228  focal_loss 0.00198  dice_loss 0.33030
Epoch [17/30] Validation [25/123] Loss: 0.35016  focal_loss 0.00148  dice_loss 0.34868
Epoch [17/30] Validation [26/123] Loss: 0.25202  focal_loss 0.00176  dice_loss 0.25026
Epoch [17/30] Validation [27/123] Loss: 0.31543  focal_loss 0.00827  dice_loss 0.30716
Epoch [17/30] Validation [28/123] Loss: 0.55042  focal_loss 0.00430  dice_loss 0.54612
Epoch [17/30] Validation [29/123] Loss: 0.48745  focal_loss 0.00870  dice_loss 0.47875
Epoch [17/30] Validation [30/123] Loss: 0.27969  focal_loss 0.00358  dice_loss 0.27611
Epoch [17/30] Validation [31/123] Loss: 0.23544  focal_loss 0.00158  dice_loss 0.23386
Epoch [17/30] Validation [32/123] Loss: 0.34408  focal_loss 0.00282  dice_loss 0.34126
Epoch [17/30] Validation [33/123] Loss: 0.39055  focal_loss 0.00185  dice_loss 0.38869
Epoch [17/30] Validation [34/123] Loss: 0.38285  focal_loss 0.00475  dice_loss 0.37810
Epoch [17/30] Validation [35/123] Loss: 0.28697  focal_loss 0.00139  dice_loss 0.28558
Epoch [17/30] Validation [36/123] Loss: 0.30299  focal_loss 0.00097  dice_loss 0.30202
Epoch [17/30] Validation [37/123] Loss: 0.44902  focal_loss 0.00872  dice_loss 0.44030
Epoch [17/30] Validation [38/123] Loss: 0.26993  focal_loss 0.00155  dice_loss 0.26838
Epoch [17/30] Validation [39/123] Loss: 0.24789  focal_loss 0.00134  dice_loss 0.24655
Epoch [17/30] Validation [40/123] Loss: 0.35938  focal_loss 0.00086  dice_loss 0.35852
Epoch [17/30] Validation [41/123] Loss: 0.24945  focal_loss 0.00146  dice_loss 0.24800
Epoch [17/30] Validation [42/123] Loss: 0.24630  focal_loss 0.00183  dice_loss 0.24448
Epoch [17/30] Validation [43/123] Loss: 0.32021  focal_loss 0.01327  dice_loss 0.30693
Epoch [17/30] Validation [44/123] Loss: 0.63354  focal_loss 0.01674  dice_loss 0.61681
Epoch [17/30] Validation [45/123] Loss: 0.34736  focal_loss 0.00160  dice_loss 0.34577
Epoch [17/30] Validation [46/123] Loss: 0.40979  focal_loss 0.00499  dice_loss 0.40480
Epoch [17/30] Validation [47/123] Loss: 0.34291  focal_loss 0.00132  dice_loss 0.34159
Epoch [17/30] Validation [48/123] Loss: 0.43138  focal_loss 0.00282  dice_loss 0.42855
Epoch [17/30] Validation [49/123] Loss: 0.29668  focal_loss 0.00955  dice_loss 0.28713
Epoch [17/30] Validation [50/123] Loss: 0.24487  focal_loss 0.00179  dice_loss 0.24308
Epoch [17/30] Validation [51/123] Loss: 0.38799  focal_loss 0.00456  dice_loss 0.38343
Epoch [17/30] Validation [52/123] Loss: 0.27046  focal_loss 0.00088  dice_loss 0.26958
Epoch [17/30] Validation [53/123] Loss: 0.33153  focal_loss 0.00092  dice_loss 0.33062
Epoch [17/30] Validation [54/123] Loss: 0.36776  focal_loss 0.00097  dice_loss 0.36679
Epoch [17/30] Validation [55/123] Loss: 0.32129  focal_loss 0.00126  dice_loss 0.32003
Epoch [17/30] Validation [56/123] Loss: 0.26665  focal_loss 0.00208  dice_loss 0.26457
Epoch [17/30] Validation [57/123] Loss: 0.35677  focal_loss 0.00567  dice_loss 0.35110
Epoch [17/30] Validation [58/123] Loss: 0.30823  focal_loss 0.00280  dice_loss 0.30543
Epoch [17/30] Validation [59/123] Loss: 0.68449  focal_loss 0.01747  dice_loss 0.66702
Epoch [17/30] Validation [60/123] Loss: 0.31273  focal_loss 0.00496  dice_loss 0.30777
Epoch [17/30] Validation [61/123] Loss: 0.73648  focal_loss 0.00976  dice_loss 0.72672
Epoch [17/30] Validation [62/123] Loss: 0.55877  focal_loss 0.01271  dice_loss 0.54606
Epoch [17/30] Validation [63/123] Loss: 0.44555  focal_loss 0.00124  dice_loss 0.44431
Epoch [17/30] Validation [64/123] Loss: 0.42041  focal_loss 0.00953  dice_loss 0.41088
Epoch [17/30] Validation [65/123] Loss: 0.28118  focal_loss 0.00116  dice_loss 0.28002
Epoch [17/30] Validation [66/123] Loss: 0.29139  focal_loss 0.00118  dice_loss 0.29021
Epoch [17/30] Validation [67/123] Loss: 0.43123  focal_loss 0.00593  dice_loss 0.42530
Epoch [17/30] Validation [68/123] Loss: 0.40618  focal_loss 0.00080  dice_loss 0.40538
Epoch [17/30] Validation [69/123] Loss: 0.39805  focal_loss 0.00520  dice_loss 0.39285
Epoch [17/30] Validation [70/123] Loss: 0.35585  focal_loss 0.00150  dice_loss 0.35435
Epoch [17/30] Validation [71/123] Loss: 0.28137  focal_loss 0.00094  dice_loss 0.28043
Epoch [17/30] Validation [72/123] Loss: 0.25738  focal_loss 0.00162  dice_loss 0.25576
Epoch [17/30] Validation [73/123] Loss: 0.38835  focal_loss 0.00713  dice_loss 0.38122
Epoch [17/30] Validation [74/123] Loss: 0.36480  focal_loss 0.00286  dice_loss 0.36194
Epoch [17/30] Validation [75/123] Loss: 0.32437  focal_loss 0.00173  dice_loss 0.32264
Epoch [17/30] Validation [76/123] Loss: 0.56268  focal_loss 0.00536  dice_loss 0.55733
Epoch [17/30] Validation [77/123] Loss: 0.41817  focal_loss 0.00102  dice_loss 0.41715
Epoch [17/30] Validation [78/123] Loss: 0.30867  focal_loss 0.00147  dice_loss 0.30720
Epoch [17/30] Validation [79/123] Loss: 0.36729  focal_loss 0.00170  dice_loss 0.36558
Epoch [17/30] Validation [80/123] Loss: 0.25978  focal_loss 0.00230  dice_loss 0.25748
Epoch [17/30] Validation [81/123] Loss: 0.31078  focal_loss 0.00157  dice_loss 0.30922
Epoch [17/30] Validation [82/123] Loss: 0.26457  focal_loss 0.00133  dice_loss 0.26324
Epoch [17/30] Validation [83/123] Loss: 0.39245  focal_loss 0.00769  dice_loss 0.38476
Epoch [17/30] Validation [84/123] Loss: 0.30593  focal_loss 0.00128  dice_loss 0.30465
Epoch [17/30] Validation [85/123] Loss: 0.39391  focal_loss 0.00999  dice_loss 0.38392
Epoch [17/30] Validation [86/123] Loss: 0.28860  focal_loss 0.00359  dice_loss 0.28500
Epoch [17/30] Validation [87/123] Loss: 0.25248  focal_loss 0.00436  dice_loss 0.24812
Epoch [17/30] Validation [88/123] Loss: 0.29505  focal_loss 0.00271  dice_loss 0.29234
Epoch [17/30] Validation [89/123] Loss: 0.23877  focal_loss 0.00202  dice_loss 0.23675
Epoch [17/30] Validation [90/123] Loss: 0.35053  focal_loss 0.00189  dice_loss 0.34864
Epoch [17/30] Validation [91/123] Loss: 0.27815  focal_loss 0.00115  dice_loss 0.27700
Epoch [17/30] Validation [92/123] Loss: 0.23846  focal_loss 0.00153  dice_loss 0.23693
Epoch [17/30] Validation [93/123] Loss: 0.26472  focal_loss 0.00199  dice_loss 0.26273
Epoch [17/30] Validation [94/123] Loss: 0.38462  focal_loss 0.00163  dice_loss 0.38299
Epoch [17/30] Validation [95/123] Loss: 0.32005  focal_loss 0.00389  dice_loss 0.31616
Epoch [17/30] Validation [96/123] Loss: 0.37807  focal_loss 0.00215  dice_loss 0.37593
Epoch [17/30] Validation [97/123] Loss: 0.56587  focal_loss 0.00443  dice_loss 0.56144
Epoch [17/30] Validation [98/123] Loss: 0.35957  focal_loss 0.00085  dice_loss 0.35871
Epoch [17/30] Validation [99/123] Loss: 0.37056  focal_loss 0.00070  dice_loss 0.36986
Epoch [17/30] Validation [100/123] Loss: 0.40972  focal_loss 0.00179  dice_loss 0.40794
Epoch [17/30] Validation [101/123] Loss: 0.33765  focal_loss 0.00126  dice_loss 0.33638
Epoch [17/30] Validation [102/123] Loss: 0.40070  focal_loss 0.00096  dice_loss 0.39974
Epoch [17/30] Validation [103/123] Loss: 0.47817  focal_loss 0.00091  dice_loss 0.47726
Epoch [17/30] Validation [104/123] Loss: 0.46634  focal_loss 0.00483  dice_loss 0.46152
Epoch [17/30] Validation [105/123] Loss: 0.26044  focal_loss 0.00439  dice_loss 0.25605
Epoch [17/30] Validation [106/123] Loss: 0.29148  focal_loss 0.00115  dice_loss 0.29032
Epoch [17/30] Validation [107/123] Loss: 0.61744  focal_loss 0.00615  dice_loss 0.61129
Epoch [17/30] Validation [108/123] Loss: 0.27118  focal_loss 0.00064  dice_loss 0.27054
Epoch [17/30] Validation [109/123] Loss: 0.24232  focal_loss 0.00441  dice_loss 0.23791
Epoch [17/30] Validation [110/123] Loss: 0.41477  focal_loss 0.00349  dice_loss 0.41127
Epoch [17/30] Validation [111/123] Loss: 0.42482  focal_loss 0.00433  dice_loss 0.42049
Epoch [17/30] Validation [112/123] Loss: 0.39845  focal_loss 0.00229  dice_loss 0.39617
Epoch [17/30] Validation [113/123] Loss: 0.30092  focal_loss 0.00137  dice_loss 0.29955
Epoch [17/30] Validation [114/123] Loss: 0.41636  focal_loss 0.00838  dice_loss 0.40798
Epoch [17/30] Validation [115/123] Loss: 0.37781  focal_loss 0.01015  dice_loss 0.36766
Epoch [17/30] Validation [116/123] Loss: 0.30738  focal_loss 0.00060  dice_loss 0.30678
Epoch [17/30] Validation [117/123] Loss: 0.31398  focal_loss 0.00143  dice_loss 0.31254
Epoch [17/30] Validation [118/123] Loss: 0.21860  focal_loss 0.00187  dice_loss 0.21673
Epoch [17/30] Validation [119/123] Loss: 0.25024  focal_loss 0.00132  dice_loss 0.24892
Epoch [17/30] Validation [120/123] Loss: 0.29148  focal_loss 0.00224  dice_loss 0.28924
Epoch [17/30] Validation [121/123] Loss: 0.63558  focal_loss 0.01099  dice_loss 0.62459
Epoch [17/30] Validation [122/123] Loss: 0.69434  focal_loss 0.00138  dice_loss 0.69296
Epoch [17/30] Validation [123/123] Loss: 0.27714  focal_loss 0.00178  dice_loss 0.27536
Epoch [17/30] Validation metric {'Val/mean dice_metric': 0.8692505359649658, 'Val/TC dice_metric': 0.8838886618614197, 'Val/WT dice_metric': 0.921278178691864, 'Val/ET dice_metric': 0.802584707736969}
Epoch [17/30] lr = [0.0005936906572928624, 0.0005936906572928624] best acc: tensor([0.8580], device='cuda:0'), mean acc: tensor([0.8693], device='cuda:0'), mean class: tensor([0.8839, 0.9213, 0.8026], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [18/30] Training [1/488] Loss: 0.21631
Epoch [18/30] Training [2/488] Loss: 0.23115
Epoch [18/30] Training [3/488] Loss: 0.26325
Epoch [18/30] Training [4/488] Loss: 0.20929
Epoch [18/30] Training [5/488] Loss: 0.22705
Epoch [18/30] Training [6/488] Loss: 0.52331
Epoch [18/30] Training [7/488] Loss: 0.29564
Epoch [18/30] Training [8/488] Loss: 0.18671
Epoch [18/30] Training [9/488] Loss: 0.18564
Epoch [18/30] Training [10/488] Loss: 0.15314
Epoch [18/30] Training [11/488] Loss: 0.34842
Epoch [18/30] Training [12/488] Loss: 0.27239
Epoch [18/30] Training [13/488] Loss: 0.17312
Epoch [18/30] Training [14/488] Loss: 0.22089
Epoch [18/30] Training [15/488] Loss: 0.20477
Epoch [18/30] Training [16/488] Loss: 0.54701
Epoch [18/30] Training [17/488] Loss: 0.21305
Epoch [18/30] Training [18/488] Loss: 0.17086
Epoch [18/30] Training [19/488] Loss: 0.20690
Epoch [18/30] Training [20/488] Loss: 0.22379
Epoch [18/30] Training [21/488] Loss: 0.17710
Epoch [18/30] Training [22/488] Loss: 0.29486
Epoch [18/30] Training [23/488] Loss: 0.20285
Epoch [18/30] Training [24/488] Loss: 0.42421
Epoch [18/30] Training [25/488] Loss: 0.39680
Epoch [18/30] Training [26/488] Loss: 0.37123
Epoch [18/30] Training [27/488] Loss: 0.11764
Epoch [18/30] Training [28/488] Loss: 0.20469
Epoch [18/30] Training [29/488] Loss: 0.14750
Epoch [18/30] Training [30/488] Loss: 0.14905
Epoch [18/30] Training [31/488] Loss: 0.34662
Epoch [18/30] Training [32/488] Loss: 0.31752
Epoch [18/30] Training [33/488] Loss: 0.20264
Epoch [18/30] Training [34/488] Loss: 0.52299
Epoch [18/30] Training [35/488] Loss: 0.15860
Epoch [18/30] Training [36/488] Loss: 0.22333
Epoch [18/30] Training [37/488] Loss: 0.18440
Epoch [18/30] Training [38/488] Loss: 0.37705
Epoch [18/30] Training [39/488] Loss: 0.15657
Epoch [18/30] Training [40/488] Loss: 0.35129
Epoch [18/30] Training [41/488] Loss: 0.18232
Epoch [18/30] Training [42/488] Loss: 0.19791
Epoch [18/30] Training [43/488] Loss: 0.39531
Epoch [18/30] Training [44/488] Loss: 0.20038
Epoch [18/30] Training [45/488] Loss: 0.27065
Epoch [18/30] Training [46/488] Loss: 0.13624
Epoch [18/30] Training [47/488] Loss: 0.18098
Epoch [18/30] Training [48/488] Loss: 0.21547
Epoch [18/30] Training [49/488] Loss: 0.33676
Epoch [18/30] Training [50/488] Loss: 0.18048
Epoch [18/30] Training [51/488] Loss: 0.40089
Epoch [18/30] Training [52/488] Loss: 0.19124
Epoch [18/30] Training [53/488] Loss: 0.23429
Epoch [18/30] Training [54/488] Loss: 0.31365
Epoch [18/30] Training [55/488] Loss: 0.20165
Epoch [18/30] Training [56/488] Loss: 0.17700
Epoch [18/30] Training [57/488] Loss: 0.22649
Epoch [18/30] Training [58/488] Loss: 0.33568
Epoch [18/30] Training [59/488] Loss: 0.21352
Epoch [18/30] Training [60/488] Loss: 0.16516
Epoch [18/30] Training [61/488] Loss: 0.15367
Epoch [18/30] Training [62/488] Loss: 0.53610
Epoch [18/30] Training [63/488] Loss: 0.16206
Epoch [18/30] Training [64/488] Loss: 0.16803
Epoch [18/30] Training [65/488] Loss: 0.27600
Epoch [18/30] Training [66/488] Loss: 0.19805
Epoch [18/30] Training [67/488] Loss: 0.33524
Epoch [18/30] Training [68/488] Loss: 0.27644
Epoch [18/30] Training [69/488] Loss: 0.18899
Epoch [18/30] Training [70/488] Loss: 0.29242
Epoch [18/30] Training [71/488] Loss: 0.16415
Epoch [18/30] Training [72/488] Loss: 0.20736
Epoch [18/30] Training [73/488] Loss: 0.26239
Epoch [18/30] Training [74/488] Loss: 0.13365
Epoch [18/30] Training [75/488] Loss: 0.19047
Epoch [18/30] Training [76/488] Loss: 0.27949
Epoch [18/30] Training [77/488] Loss: 0.24524
Epoch [18/30] Training [78/488] Loss: 0.15202
Epoch [18/30] Training [79/488] Loss: 0.32757
Epoch [18/30] Training [80/488] Loss: 0.22699
Epoch [18/30] Training [81/488] Loss: 0.19848
Epoch [18/30] Training [82/488] Loss: 0.12371
Epoch [18/30] Training [83/488] Loss: 0.33826
Epoch [18/30] Training [84/488] Loss: 0.19560
Epoch [18/30] Training [85/488] Loss: 0.19381
Epoch [18/30] Training [86/488] Loss: 0.17624
Epoch [18/30] Training [87/488] Loss: 0.14798
Epoch [18/30] Training [88/488] Loss: 0.24434
Epoch [18/30] Training [89/488] Loss: 0.16980
Epoch [18/30] Training [90/488] Loss: 0.19153
Epoch [18/30] Training [91/488] Loss: 0.19125
Epoch [18/30] Training [92/488] Loss: 0.12017
Epoch [18/30] Training [93/488] Loss: 0.20243
Epoch [18/30] Training [94/488] Loss: 0.16174
Epoch [18/30] Training [95/488] Loss: 0.18290
Epoch [18/30] Training [96/488] Loss: 0.21655
Epoch [18/30] Training [97/488] Loss: 0.19883
Epoch [18/30] Training [98/488] Loss: 0.17110
Epoch [18/30] Training [99/488] Loss: 0.16367
Epoch [18/30] Training [100/488] Loss: 0.22772
Epoch [18/30] Training [101/488] Loss: 0.19666
Epoch [18/30] Training [102/488] Loss: 0.16952
Epoch [18/30] Training [103/488] Loss: 0.22457
Epoch [18/30] Training [104/488] Loss: 0.37298
Epoch [18/30] Training [105/488] Loss: 0.14931
Epoch [18/30] Training [106/488] Loss: 0.17122
Epoch [18/30] Training [107/488] Loss: 0.36891
Epoch [18/30] Training [108/488] Loss: 0.33861
Epoch [18/30] Training [109/488] Loss: 0.16344
Epoch [18/30] Training [110/488] Loss: 0.16601
Epoch [18/30] Training [111/488] Loss: 0.42548
Epoch [18/30] Training [112/488] Loss: 0.53221
Epoch [18/30] Training [113/488] Loss: 0.21811
Epoch [18/30] Training [114/488] Loss: 0.15926
Epoch [18/30] Training [115/488] Loss: 0.18904
Epoch [18/30] Training [116/488] Loss: 0.24620
Epoch [18/30] Training [117/488] Loss: 0.13200
Epoch [18/30] Training [118/488] Loss: 0.23030
Epoch [18/30] Training [119/488] Loss: 0.22805
Epoch [18/30] Training [120/488] Loss: 0.22965
Epoch [18/30] Training [121/488] Loss: 0.20352
Epoch [18/30] Training [122/488] Loss: 0.17087
Epoch [18/30] Training [123/488] Loss: 0.18720
Epoch [18/30] Training [124/488] Loss: 0.18367
Epoch [18/30] Training [125/488] Loss: 0.35326
Epoch [18/30] Training [126/488] Loss: 0.33278
Epoch [18/30] Training [127/488] Loss: 0.49852
Epoch [18/30] Training [128/488] Loss: 0.17164
Epoch [18/30] Training [129/488] Loss: 0.29974
Epoch [18/30] Training [130/488] Loss: 0.37714
Epoch [18/30] Training [131/488] Loss: 0.13971
Epoch [18/30] Training [132/488] Loss: 0.15309
Epoch [18/30] Training [133/488] Loss: 0.16802
Epoch [18/30] Training [134/488] Loss: 0.18406
Epoch [18/30] Training [135/488] Loss: 0.16911
Epoch [18/30] Training [136/488] Loss: 0.14740
Epoch [18/30] Training [137/488] Loss: 0.23215
Epoch [18/30] Training [138/488] Loss: 0.15752
Epoch [18/30] Training [139/488] Loss: 0.53357
Epoch [18/30] Training [140/488] Loss: 0.47713
Epoch [18/30] Training [141/488] Loss: 0.41380
Epoch [18/30] Training [142/488] Loss: 0.16595
Epoch [18/30] Training [143/488] Loss: 0.22851
Epoch [18/30] Training [144/488] Loss: 0.15281
Epoch [18/30] Training [145/488] Loss: 0.28735
Epoch [18/30] Training [146/488] Loss: 0.51538
Epoch [18/30] Training [147/488] Loss: 0.34456
Epoch [18/30] Training [148/488] Loss: 0.22682
Epoch [18/30] Training [149/488] Loss: 0.15492
Epoch [18/30] Training [150/488] Loss: 0.24387
Epoch [18/30] Training [151/488] Loss: 0.13869
Epoch [18/30] Training [152/488] Loss: 0.26269
Epoch [18/30] Training [153/488] Loss: 0.19024
Epoch [18/30] Training [154/488] Loss: 0.16971
Epoch [18/30] Training [155/488] Loss: 0.26143
Epoch [18/30] Training [156/488] Loss: 0.16880
Epoch [18/30] Training [157/488] Loss: 0.18190
Epoch [18/30] Training [158/488] Loss: 0.23253
Epoch [18/30] Training [159/488] Loss: 0.23001
Epoch [18/30] Training [160/488] Loss: 0.15999
Epoch [18/30] Training [161/488] Loss: 0.14376
Epoch [18/30] Training [162/488] Loss: 0.26538
Epoch [18/30] Training [163/488] Loss: 0.16171
Epoch [18/30] Training [164/488] Loss: 0.16832
Epoch [18/30] Training [165/488] Loss: 0.36849
Epoch [18/30] Training [166/488] Loss: 0.17831
Epoch [18/30] Training [167/488] Loss: 0.17382
Epoch [18/30] Training [168/488] Loss: 0.26093
Epoch [18/30] Training [169/488] Loss: 0.28457
Epoch [18/30] Training [170/488] Loss: 0.19185
Epoch [18/30] Training [171/488] Loss: 0.34761
Epoch [18/30] Training [172/488] Loss: 0.16072
Epoch [18/30] Training [173/488] Loss: 0.15585
Epoch [18/30] Training [174/488] Loss: 0.20587
Epoch [18/30] Training [175/488] Loss: 0.35897
Epoch [18/30] Training [176/488] Loss: 0.15310
Epoch [18/30] Training [177/488] Loss: 0.24766
Epoch [18/30] Training [178/488] Loss: 0.16305
Epoch [18/30] Training [179/488] Loss: 0.13241
Epoch [18/30] Training [180/488] Loss: 0.26402
Epoch [18/30] Training [181/488] Loss: 0.41895
Epoch [18/30] Training [182/488] Loss: 0.14953
Epoch [18/30] Training [183/488] Loss: 0.34495
Epoch [18/30] Training [184/488] Loss: 0.19206
Epoch [18/30] Training [185/488] Loss: 0.18779
Epoch [18/30] Training [186/488] Loss: 0.46147
Epoch [18/30] Training [187/488] Loss: 0.13189
Epoch [18/30] Training [188/488] Loss: 0.26342
Epoch [18/30] Training [189/488] Loss: 0.23021
Epoch [18/30] Training [190/488] Loss: 0.25675
Epoch [18/30] Training [191/488] Loss: 0.27935
Epoch [18/30] Training [192/488] Loss: 0.27189
Epoch [18/30] Training [193/488] Loss: 0.18122
Epoch [18/30] Training [194/488] Loss: 0.24705
Epoch [18/30] Training [195/488] Loss: 0.35859
Epoch [18/30] Training [196/488] Loss: 0.13131
Epoch [18/30] Training [197/488] Loss: 0.19075
Epoch [18/30] Training [198/488] Loss: 0.12299
Epoch [18/30] Training [199/488] Loss: 0.27670
Epoch [18/30] Training [200/488] Loss: 0.60220
Epoch [18/30] Training [201/488] Loss: 0.17101
Epoch [18/30] Training [202/488] Loss: 0.15718
Epoch [18/30] Training [203/488] Loss: 0.16897
Epoch [18/30] Training [204/488] Loss: 0.21443
Epoch [18/30] Training [205/488] Loss: 0.25344
Epoch [18/30] Training [206/488] Loss: 0.36417
Epoch [18/30] Training [207/488] Loss: 0.32503
Epoch [18/30] Training [208/488] Loss: 0.19264
Epoch [18/30] Training [209/488] Loss: 0.17634
Epoch [18/30] Training [210/488] Loss: 0.31084
Epoch [18/30] Training [211/488] Loss: 0.75353
Epoch [18/30] Training [212/488] Loss: 0.26075
Epoch [18/30] Training [213/488] Loss: 0.40998
Epoch [18/30] Training [214/488] Loss: 0.27949
Epoch [18/30] Training [215/488] Loss: 0.23366
Epoch [18/30] Training [216/488] Loss: 0.23590
Epoch [18/30] Training [217/488] Loss: 0.28032
Epoch [18/30] Training [218/488] Loss: 0.12673
Epoch [18/30] Training [219/488] Loss: 0.32267
Epoch [18/30] Training [220/488] Loss: 0.27759
Epoch [18/30] Training [221/488] Loss: 0.25235
Epoch [18/30] Training [222/488] Loss: 0.13798
Epoch [18/30] Training [223/488] Loss: 0.22254
Epoch [18/30] Training [224/488] Loss: 0.12716
Epoch [18/30] Training [225/488] Loss: 0.19500
Epoch [18/30] Training [226/488] Loss: 0.41094
Epoch [18/30] Training [227/488] Loss: 0.16694
Epoch [18/30] Training [228/488] Loss: 0.22770
Epoch [18/30] Training [229/488] Loss: 0.16363
Epoch [18/30] Training [230/488] Loss: 0.19949
Epoch [18/30] Training [231/488] Loss: 0.22427
Epoch [18/30] Training [232/488] Loss: 0.22461
Epoch [18/30] Training [233/488] Loss: 0.57064
Epoch [18/30] Training [234/488] Loss: 0.33047
Epoch [18/30] Training [235/488] Loss: 0.16482
Epoch [18/30] Training [236/488] Loss: 0.53025
Epoch [18/30] Training [237/488] Loss: 0.27644
Epoch [18/30] Training [238/488] Loss: 0.16313
Epoch [18/30] Training [239/488] Loss: 0.26774
Epoch [18/30] Training [240/488] Loss: 0.15319
Epoch [18/30] Training [241/488] Loss: 0.25565
Epoch [18/30] Training [242/488] Loss: 0.23603
Epoch [18/30] Training [243/488] Loss: 0.24805
Epoch [18/30] Training [244/488] Loss: 0.18801
Epoch [18/30] Training [245/488] Loss: 0.19907
Epoch [18/30] Training [246/488] Loss: 0.33126
Epoch [18/30] Training [247/488] Loss: 0.13262
Epoch [18/30] Training [248/488] Loss: 0.15822
Epoch [18/30] Training [249/488] Loss: 0.27981
Epoch [18/30] Training [250/488] Loss: 0.26878
Epoch [18/30] Training [251/488] Loss: 0.25963
Epoch [18/30] Training [252/488] Loss: 0.44596
Epoch [18/30] Training [253/488] Loss: 0.14672
Epoch [18/30] Training [254/488] Loss: 0.51590
Epoch [18/30] Training [255/488] Loss: 0.37137
Epoch [18/30] Training [256/488] Loss: 0.18218
Epoch [18/30] Training [257/488] Loss: 0.14401
Epoch [18/30] Training [258/488] Loss: 0.87266
Epoch [18/30] Training [259/488] Loss: 0.19697
Epoch [18/30] Training [260/488] Loss: 0.36950
Epoch [18/30] Training [261/488] Loss: 0.37517
Epoch [18/30] Training [262/488] Loss: 0.12939
Epoch [18/30] Training [263/488] Loss: 0.65465
Epoch [18/30] Training [264/488] Loss: 0.44839
Epoch [18/30] Training [265/488] Loss: 0.20106
Epoch [18/30] Training [266/488] Loss: 0.16764
Epoch [18/30] Training [267/488] Loss: 0.31930
Epoch [18/30] Training [268/488] Loss: 0.34951
Epoch [18/30] Training [269/488] Loss: 0.22887
Epoch [18/30] Training [270/488] Loss: 0.18751
Epoch [18/30] Training [271/488] Loss: 0.16365
Epoch [18/30] Training [272/488] Loss: 0.24153
Epoch [18/30] Training [273/488] Loss: 0.57270
Epoch [18/30] Training [274/488] Loss: 0.15896
Epoch [18/30] Training [275/488] Loss: 0.18233
Epoch [18/30] Training [276/488] Loss: 0.35468
Epoch [18/30] Training [277/488] Loss: 0.17141
Epoch [18/30] Training [278/488] Loss: 0.18415
Epoch [18/30] Training [279/488] Loss: 0.20049
Epoch [18/30] Training [280/488] Loss: 0.13959
Epoch [18/30] Training [281/488] Loss: 0.28743
Epoch [18/30] Training [282/488] Loss: 0.14102
Epoch [18/30] Training [283/488] Loss: 0.25674
Epoch [18/30] Training [284/488] Loss: 0.24544
Epoch [18/30] Training [285/488] Loss: 0.20513
Epoch [18/30] Training [286/488] Loss: 0.14405
Epoch [18/30] Training [287/488] Loss: 0.21767
Epoch [18/30] Training [288/488] Loss: 0.30893
Epoch [18/30] Training [289/488] Loss: 0.15856
Epoch [18/30] Training [290/488] Loss: 0.20262
Epoch [18/30] Training [291/488] Loss: 0.27253
Epoch [18/30] Training [292/488] Loss: 0.14688
Epoch [18/30] Training [293/488] Loss: 0.20528
Epoch [18/30] Training [294/488] Loss: 0.46365
Epoch [18/30] Training [295/488] Loss: 0.19384
Epoch [18/30] Training [296/488] Loss: 0.15171
Epoch [18/30] Training [297/488] Loss: 0.25984
Epoch [18/30] Training [298/488] Loss: 0.18604
Epoch [18/30] Training [299/488] Loss: 0.15551
Epoch [18/30] Training [300/488] Loss: 0.26280
Epoch [18/30] Training [301/488] Loss: 0.22473
Epoch [18/30] Training [302/488] Loss: 0.26575
Epoch [18/30] Training [303/488] Loss: 0.15843
Epoch [18/30] Training [304/488] Loss: 0.24832
Epoch [18/30] Training [305/488] Loss: 0.36714
Epoch [18/30] Training [306/488] Loss: 0.17382
Epoch [18/30] Training [307/488] Loss: 0.29844
Epoch [18/30] Training [308/488] Loss: 0.17409
Epoch [18/30] Training [309/488] Loss: 0.20519
Epoch [18/30] Training [310/488] Loss: 0.92140
Epoch [18/30] Training [311/488] Loss: 0.15273
Epoch [18/30] Training [312/488] Loss: 0.70790
Epoch [18/30] Training [313/488] Loss: 0.32402
Epoch [18/30] Training [314/488] Loss: 0.16871
Epoch [18/30] Training [315/488] Loss: 0.42164
Epoch [18/30] Training [316/488] Loss: 0.22684
Epoch [18/30] Training [317/488] Loss: 0.16597
Epoch [18/30] Training [318/488] Loss: 0.42373
Epoch [18/30] Training [319/488] Loss: 0.32395
Epoch [18/30] Training [320/488] Loss: 0.17749
Epoch [18/30] Training [321/488] Loss: 0.38474
Epoch [18/30] Training [322/488] Loss: 0.25993
Epoch [18/30] Training [323/488] Loss: 0.18294
Epoch [18/30] Training [324/488] Loss: 0.21263
Epoch [18/30] Training [325/488] Loss: 0.13692
Epoch [18/30] Training [326/488] Loss: 0.17128
Epoch [18/30] Training [327/488] Loss: 0.43145
Epoch [18/30] Training [328/488] Loss: 0.20700
Epoch [18/30] Training [329/488] Loss: 0.16413
Epoch [18/30] Training [330/488] Loss: 0.16241
Epoch [18/30] Training [331/488] Loss: 0.24770
Epoch [18/30] Training [332/488] Loss: 0.19052
Epoch [18/30] Training [333/488] Loss: 0.23968
Epoch [18/30] Training [334/488] Loss: 0.26145
Epoch [18/30] Training [335/488] Loss: 0.25055
Epoch [18/30] Training [336/488] Loss: 0.17124
Epoch [18/30] Training [337/488] Loss: 0.18358
Epoch [18/30] Training [338/488] Loss: 0.22880
Epoch [18/30] Training [339/488] Loss: 0.21555
Epoch [18/30] Training [340/488] Loss: 0.21760
Epoch [18/30] Training [341/488] Loss: 0.22350
Epoch [18/30] Training [342/488] Loss: 0.21311
Epoch [18/30] Training [343/488] Loss: 0.36117
Epoch [18/30] Training [344/488] Loss: 0.17611
Epoch [18/30] Training [345/488] Loss: 0.13188
Epoch [18/30] Training [346/488] Loss: 0.14941
Epoch [18/30] Training [347/488] Loss: 0.38839
Epoch [18/30] Training [348/488] Loss: 0.18485
Epoch [18/30] Training [349/488] Loss: 0.30342
Epoch [18/30] Training [350/488] Loss: 0.20933
Epoch [18/30] Training [351/488] Loss: 0.11491
Epoch [18/30] Training [352/488] Loss: 0.26251
Epoch [18/30] Training [353/488] Loss: 0.17648
Epoch [18/30] Training [354/488] Loss: 0.19917
Epoch [18/30] Training [355/488] Loss: 0.16638
Epoch [18/30] Training [356/488] Loss: 0.23592
Epoch [18/30] Training [357/488] Loss: 0.17087
Epoch [18/30] Training [358/488] Loss: 0.25548
Epoch [18/30] Training [359/488] Loss: 0.11815
Epoch [18/30] Training [360/488] Loss: 0.21816
Epoch [18/30] Training [361/488] Loss: 0.54445
Epoch [18/30] Training [362/488] Loss: 0.80855
Epoch [18/30] Training [363/488] Loss: 0.26495
Epoch [18/30] Training [364/488] Loss: 0.13663
Epoch [18/30] Training [365/488] Loss: 0.38844
Epoch [18/30] Training [366/488] Loss: 0.40784
Epoch [18/30] Training [367/488] Loss: 0.14836
Epoch [18/30] Training [368/488] Loss: 0.20379
Epoch [18/30] Training [369/488] Loss: 0.23004
Epoch [18/30] Training [370/488] Loss: 0.23519
Epoch [18/30] Training [371/488] Loss: 0.19859
Epoch [18/30] Training [372/488] Loss: 0.16724
Epoch [18/30] Training [373/488] Loss: 0.13186
Epoch [18/30] Training [374/488] Loss: 0.33242
Epoch [18/30] Training [375/488] Loss: 0.13541
Epoch [18/30] Training [376/488] Loss: 0.17815
Epoch [18/30] Training [377/488] Loss: 0.19323
Epoch [18/30] Training [378/488] Loss: 0.24388
Epoch [18/30] Training [379/488] Loss: 0.21287
Epoch [18/30] Training [380/488] Loss: 0.20327
Epoch [18/30] Training [381/488] Loss: 0.33476
Epoch [18/30] Training [382/488] Loss: 0.20935
Epoch [18/30] Training [383/488] Loss: 0.17723
Epoch [18/30] Training [384/488] Loss: 0.32417
Epoch [18/30] Training [385/488] Loss: 0.15961
Epoch [18/30] Training [386/488] Loss: 0.71601
Epoch [18/30] Training [387/488] Loss: 0.18702
Epoch [18/30] Training [388/488] Loss: 0.45541
Epoch [18/30] Training [389/488] Loss: 0.20182
Epoch [18/30] Training [390/488] Loss: 0.16791
Epoch [18/30] Training [391/488] Loss: 0.22428
Epoch [18/30] Training [392/488] Loss: 0.23414
Epoch [18/30] Training [393/488] Loss: 0.16119
Epoch [18/30] Training [394/488] Loss: 0.28313
Epoch [18/30] Training [395/488] Loss: 0.22054
Epoch [18/30] Training [396/488] Loss: 0.14121
Epoch [18/30] Training [397/488] Loss: 0.37988
Epoch [18/30] Training [398/488] Loss: 0.22286
Epoch [18/30] Training [399/488] Loss: 0.28261
Epoch [18/30] Training [400/488] Loss: 0.30155
Epoch [18/30] Training [401/488] Loss: 0.21716
Epoch [18/30] Training [402/488] Loss: 0.14646
Epoch [18/30] Training [403/488] Loss: 0.14808
Epoch [18/30] Training [404/488] Loss: 0.20751
Epoch [18/30] Training [405/488] Loss: 0.19241
Epoch [18/30] Training [406/488] Loss: 0.42867
Epoch [18/30] Training [407/488] Loss: 0.20310
Epoch [18/30] Training [408/488] Loss: 0.13669
Epoch [18/30] Training [409/488] Loss: 0.12476
Epoch [18/30] Training [410/488] Loss: 0.34082
Epoch [18/30] Training [411/488] Loss: 0.26748
Epoch [18/30] Training [412/488] Loss: 0.22461
Epoch [18/30] Training [413/488] Loss: 0.19463
Epoch [18/30] Training [414/488] Loss: 0.27418
Epoch [18/30] Training [415/488] Loss: 0.28318
Epoch [18/30] Training [416/488] Loss: 0.29255
Epoch [18/30] Training [417/488] Loss: 0.17622
Epoch [18/30] Training [418/488] Loss: 0.13646
Epoch [18/30] Training [419/488] Loss: 0.24073
Epoch [18/30] Training [420/488] Loss: 0.65122
Epoch [18/30] Training [421/488] Loss: 0.40928
Epoch [18/30] Training [422/488] Loss: 0.12833
Epoch [18/30] Training [423/488] Loss: 0.16206
Epoch [18/30] Training [424/488] Loss: 0.14829
Epoch [18/30] Training [425/488] Loss: 0.28135
Epoch [18/30] Training [426/488] Loss: 0.15760
Epoch [18/30] Training [427/488] Loss: 0.29468
Epoch [18/30] Training [428/488] Loss: 0.26043
Epoch [18/30] Training [429/488] Loss: 0.12501
Epoch [18/30] Training [430/488] Loss: 0.49979
Epoch [18/30] Training [431/488] Loss: 0.11795
Epoch [18/30] Training [432/488] Loss: 0.39900
Epoch [18/30] Training [433/488] Loss: 0.44893
Epoch [18/30] Training [434/488] Loss: 0.26394
Epoch [18/30] Training [435/488] Loss: 0.11166
Epoch [18/30] Training [436/488] Loss: 0.66296
Epoch [18/30] Training [437/488] Loss: 0.22617
Epoch [18/30] Training [438/488] Loss: 0.36371
Epoch [18/30] Training [439/488] Loss: 0.15638
Epoch [18/30] Training [440/488] Loss: 0.39174
Epoch [18/30] Training [441/488] Loss: 0.13723
Epoch [18/30] Training [442/488] Loss: 0.63332
Epoch [18/30] Training [443/488] Loss: 0.17485
Epoch [18/30] Training [444/488] Loss: 0.16577
Epoch [18/30] Training [445/488] Loss: 0.16183
Epoch [18/30] Training [446/488] Loss: 0.52942
Epoch [18/30] Training [447/488] Loss: 0.19931
Epoch [18/30] Training [448/488] Loss: 0.12881
Epoch [18/30] Training [449/488] Loss: 0.21595
Epoch [18/30] Training [450/488] Loss: 0.48839
Epoch [18/30] Training [451/488] Loss: 0.41291
Epoch [18/30] Training [452/488] Loss: 0.36257
Epoch [18/30] Training [453/488] Loss: 0.14411
Epoch [18/30] Training [454/488] Loss: 0.14688
Epoch [18/30] Training [455/488] Loss: 0.14071
Epoch [18/30] Training [456/488] Loss: 0.12496
Epoch [18/30] Training [457/488] Loss: 0.20076
Epoch [18/30] Training [458/488] Loss: 0.23053
Epoch [18/30] Training [459/488] Loss: 0.19438
Epoch [18/30] Training [460/488] Loss: 0.16961
Epoch [18/30] Training [461/488] Loss: 0.23104
Epoch [18/30] Training [462/488] Loss: 0.65681
Epoch [18/30] Training [463/488] Loss: 0.13537
Epoch [18/30] Training [464/488] Loss: 0.24632
Epoch [18/30] Training [465/488] Loss: 0.74375
Epoch [18/30] Training [466/488] Loss: 0.46036
Epoch [18/30] Training [467/488] Loss: 0.15670
Epoch [18/30] Training [468/488] Loss: 0.30543
Epoch [18/30] Training [469/488] Loss: 0.30699
Epoch [18/30] Training [470/488] Loss: 0.13889
Epoch [18/30] Training [471/488] Loss: 0.31041
Epoch [18/30] Training [472/488] Loss: 0.41471
Epoch [18/30] Training [473/488] Loss: 0.21526
Epoch [18/30] Training [474/488] Loss: 0.15239
Epoch [18/30] Training [475/488] Loss: 0.34215
Epoch [18/30] Training [476/488] Loss: 0.17913
Epoch [18/30] Training [477/488] Loss: 0.13368
Epoch [18/30] Training [478/488] Loss: 0.14815
Epoch [18/30] Training [479/488] Loss: 0.14203
Epoch [18/30] Training [480/488] Loss: 0.12667
Epoch [18/30] Training [481/488] Loss: 0.26312
Epoch [18/30] Training [482/488] Loss: 0.14790
Epoch [18/30] Training [483/488] Loss: 0.15361
Epoch [18/30] Training [484/488] Loss: 0.17843
Epoch [18/30] Training [485/488] Loss: 0.14446
Epoch [18/30] Training [486/488] Loss: 0.15003
Epoch [18/30] Training [487/488] Loss: 0.15253
Epoch [18/30] Training [488/488] Loss: 0.15048
Epoch [18/30] Training metric {'Train/mean dice_metric': 0.8732511401176453, 'Train/TC dice_metric': 0.8861085176467896, 'Train/WT dice_metric': 0.9246307015419006, 'Train/ET dice_metric': 0.809014081954956}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [18/30] Validation [1/123] Loss: 0.21809  focal_loss 0.00189  dice_loss 0.21620
Epoch [18/30] Validation [2/123] Loss: 0.41700  focal_loss 0.00280  dice_loss 0.41420
Epoch [18/30] Validation [3/123] Loss: 0.20216  focal_loss 0.00176  dice_loss 0.20040
Epoch [18/30] Validation [4/123] Loss: 0.30015  focal_loss 0.00261  dice_loss 0.29754
Epoch [18/30] Validation [5/123] Loss: 0.32608  focal_loss 0.00813  dice_loss 0.31795
Epoch [18/30] Validation [6/123] Loss: 0.39568  focal_loss 0.00351  dice_loss 0.39217
Epoch [18/30] Validation [7/123] Loss: 0.46360  focal_loss 0.00781  dice_loss 0.45579
Epoch [18/30] Validation [8/123] Loss: 0.36900  focal_loss 0.00191  dice_loss 0.36708
Epoch [18/30] Validation [9/123] Loss: 0.30520  focal_loss 0.00224  dice_loss 0.30296
Epoch [18/30] Validation [10/123] Loss: 0.56713  focal_loss 0.00908  dice_loss 0.55805
Epoch [18/30] Validation [11/123] Loss: 0.51088  focal_loss 0.00370  dice_loss 0.50718
Epoch [18/30] Validation [12/123] Loss: 0.24546  focal_loss 0.00285  dice_loss 0.24261
Epoch [18/30] Validation [13/123] Loss: 0.20895  focal_loss 0.00265  dice_loss 0.20630
Epoch [18/30] Validation [14/123] Loss: 0.26532  focal_loss 0.00145  dice_loss 0.26387
Epoch [18/30] Validation [15/123] Loss: 0.44672  focal_loss 0.00427  dice_loss 0.44245
Epoch [18/30] Validation [16/123] Loss: 0.50068  focal_loss 0.00378  dice_loss 0.49691
Epoch [18/30] Validation [17/123] Loss: 0.52105  focal_loss 0.00214  dice_loss 0.51891
Epoch [18/30] Validation [18/123] Loss: 0.41429  focal_loss 0.00775  dice_loss 0.40654
Epoch [18/30] Validation [19/123] Loss: 0.36877  focal_loss 0.01823  dice_loss 0.35053
Epoch [18/30] Validation [20/123] Loss: 0.51718  focal_loss 0.00231  dice_loss 0.51486
Epoch [18/30] Validation [21/123] Loss: 0.46398  focal_loss 0.00591  dice_loss 0.45807
Epoch [18/30] Validation [22/123] Loss: 0.66369  focal_loss 0.01543  dice_loss 0.64825
Epoch [18/30] Validation [23/123] Loss: 0.22930  focal_loss 0.00180  dice_loss 0.22750
Epoch [18/30] Validation [24/123] Loss: 0.35757  focal_loss 0.00626  dice_loss 0.35131
Epoch [18/30] Validation [25/123] Loss: 0.44967  focal_loss 0.00833  dice_loss 0.44135
Epoch [18/30] Validation [26/123] Loss: 0.21467  focal_loss 0.00108  dice_loss 0.21358
Epoch [18/30] Validation [27/123] Loss: 0.35842  focal_loss 0.02143  dice_loss 0.33699
Epoch [18/30] Validation [28/123] Loss: 0.57209  focal_loss 0.00954  dice_loss 0.56255
Epoch [18/30] Validation [29/123] Loss: 0.52106  focal_loss 0.01858  dice_loss 0.50248
Epoch [18/30] Validation [30/123] Loss: 0.25176  focal_loss 0.00276  dice_loss 0.24900
Epoch [18/30] Validation [31/123] Loss: 0.20574  focal_loss 0.00125  dice_loss 0.20449
Epoch [18/30] Validation [32/123] Loss: 0.33865  focal_loss 0.00502  dice_loss 0.33362
Epoch [18/30] Validation [33/123] Loss: 0.38120  focal_loss 0.00302  dice_loss 0.37818
Epoch [18/30] Validation [34/123] Loss: 0.50558  focal_loss 0.01629  dice_loss 0.48929
Epoch [18/30] Validation [35/123] Loss: 0.26539  focal_loss 0.00179  dice_loss 0.26360
Epoch [18/30] Validation [36/123] Loss: 0.27528  focal_loss 0.00090  dice_loss 0.27437
Epoch [18/30] Validation [37/123] Loss: 0.44577  focal_loss 0.01256  dice_loss 0.43321
Epoch [18/30] Validation [38/123] Loss: 0.23892  focal_loss 0.00178  dice_loss 0.23714
Epoch [18/30] Validation [39/123] Loss: 0.22405  focal_loss 0.00161  dice_loss 0.22244
Epoch [18/30] Validation [40/123] Loss: 0.33285  focal_loss 0.00102  dice_loss 0.33183
Epoch [18/30] Validation [41/123] Loss: 0.22787  focal_loss 0.00232  dice_loss 0.22555
Epoch [18/30] Validation [42/123] Loss: 0.22856  focal_loss 0.00208  dice_loss 0.22648
Epoch [18/30] Validation [43/123] Loss: 0.36193  focal_loss 0.03020  dice_loss 0.33174
Epoch [18/30] Validation [44/123] Loss: 0.79902  focal_loss 0.04605  dice_loss 0.75297
Epoch [18/30] Validation [45/123] Loss: 0.32136  focal_loss 0.00167  dice_loss 0.31968
Epoch [18/30] Validation [46/123] Loss: 0.37391  focal_loss 0.00347  dice_loss 0.37044
Epoch [18/30] Validation [47/123] Loss: 0.32838  focal_loss 0.00212  dice_loss 0.32626
Epoch [18/30] Validation [48/123] Loss: 0.48155  focal_loss 0.00732  dice_loss 0.47422
Epoch [18/30] Validation [49/123] Loss: 0.27980  focal_loss 0.01777  dice_loss 0.26202
Epoch [18/30] Validation [50/123] Loss: 0.22859  focal_loss 0.00227  dice_loss 0.22632
Epoch [18/30] Validation [51/123] Loss: 0.38419  focal_loss 0.00776  dice_loss 0.37643
Epoch [18/30] Validation [52/123] Loss: 0.24696  focal_loss 0.00119  dice_loss 0.24577
Epoch [18/30] Validation [53/123] Loss: 0.31293  focal_loss 0.00155  dice_loss 0.31138
Epoch [18/30] Validation [54/123] Loss: 0.37058  focal_loss 0.00212  dice_loss 0.36846
Epoch [18/30] Validation [55/123] Loss: 0.30813  focal_loss 0.00183  dice_loss 0.30630
Epoch [18/30] Validation [56/123] Loss: 0.26394  focal_loss 0.00553  dice_loss 0.25841
Epoch [18/30] Validation [57/123] Loss: 0.34387  focal_loss 0.00917  dice_loss 0.33470
Epoch [18/30] Validation [58/123] Loss: 0.27373  focal_loss 0.00220  dice_loss 0.27154
Epoch [18/30] Validation [59/123] Loss: 0.86783  focal_loss 0.04953  dice_loss 0.81830
Epoch [18/30] Validation [60/123] Loss: 0.29783  focal_loss 0.00690  dice_loss 0.29094
Epoch [18/30] Validation [61/123] Loss: 0.72749  focal_loss 0.01461  dice_loss 0.71289
Epoch [18/30] Validation [62/123] Loss: 0.59298  focal_loss 0.02492  dice_loss 0.56806
Epoch [18/30] Validation [63/123] Loss: 0.43830  focal_loss 0.00324  dice_loss 0.43506
Epoch [18/30] Validation [64/123] Loss: 0.44487  focal_loss 0.01738  dice_loss 0.42749
Epoch [18/30] Validation [65/123] Loss: 0.25137  focal_loss 0.00099  dice_loss 0.25038
Epoch [18/30] Validation [66/123] Loss: 0.27685  focal_loss 0.00222  dice_loss 0.27463
Epoch [18/30] Validation [67/123] Loss: 0.42692  focal_loss 0.00826  dice_loss 0.41866
Epoch [18/30] Validation [68/123] Loss: 0.38582  focal_loss 0.00122  dice_loss 0.38460
Epoch [18/30] Validation [69/123] Loss: 0.39272  focal_loss 0.00551  dice_loss 0.38721
Epoch [18/30] Validation [70/123] Loss: 0.35666  focal_loss 0.00289  dice_loss 0.35378
Epoch [18/30] Validation [71/123] Loss: 0.25272  focal_loss 0.00121  dice_loss 0.25151
Epoch [18/30] Validation [72/123] Loss: 0.22811  focal_loss 0.00194  dice_loss 0.22617
Epoch [18/30] Validation [73/123] Loss: 0.37647  focal_loss 0.01002  dice_loss 0.36645
Epoch [18/30] Validation [74/123] Loss: 0.40468  focal_loss 0.00927  dice_loss 0.39541
Epoch [18/30] Validation [75/123] Loss: 0.31880  focal_loss 0.00371  dice_loss 0.31508
Epoch [18/30] Validation [76/123] Loss: 0.54857  focal_loss 0.00907  dice_loss 0.53949
Epoch [18/30] Validation [77/123] Loss: 0.41168  focal_loss 0.00230  dice_loss 0.40937
Epoch [18/30] Validation [78/123] Loss: 0.29270  focal_loss 0.00208  dice_loss 0.29062
Epoch [18/30] Validation [79/123] Loss: 0.35096  focal_loss 0.00228  dice_loss 0.34868
Epoch [18/30] Validation [80/123] Loss: 0.23333  focal_loss 0.00216  dice_loss 0.23117
Epoch [18/30] Validation [81/123] Loss: 0.27875  focal_loss 0.00189  dice_loss 0.27686
Epoch [18/30] Validation [82/123] Loss: 0.22478  focal_loss 0.00077  dice_loss 0.22400
Epoch [18/30] Validation [83/123] Loss: 0.41457  focal_loss 0.01221  dice_loss 0.40237
Epoch [18/30] Validation [84/123] Loss: 0.28089  focal_loss 0.00176  dice_loss 0.27913
Epoch [18/30] Validation [85/123] Loss: 0.44959  focal_loss 0.02047  dice_loss 0.42912
Epoch [18/30] Validation [86/123] Loss: 0.28876  focal_loss 0.00958  dice_loss 0.27918
Epoch [18/30] Validation [87/123] Loss: 0.23179  focal_loss 0.00377  dice_loss 0.22802
Epoch [18/30] Validation [88/123] Loss: 0.27862  focal_loss 0.00454  dice_loss 0.27408
Epoch [18/30] Validation [89/123] Loss: 0.21448  focal_loss 0.00176  dice_loss 0.21271
Epoch [18/30] Validation [90/123] Loss: 0.33005  focal_loss 0.00307  dice_loss 0.32698
Epoch [18/30] Validation [91/123] Loss: 0.26484  focal_loss 0.00207  dice_loss 0.26277
Epoch [18/30] Validation [92/123] Loss: 0.20829  focal_loss 0.00115  dice_loss 0.20714
Epoch [18/30] Validation [93/123] Loss: 0.24208  focal_loss 0.00268  dice_loss 0.23940
Epoch [18/30] Validation [94/123] Loss: 0.37970  focal_loss 0.00304  dice_loss 0.37665
Epoch [18/30] Validation [95/123] Loss: 0.27524  focal_loss 0.00259  dice_loss 0.27266
Epoch [18/30] Validation [96/123] Loss: 0.35151  focal_loss 0.00228  dice_loss 0.34922
Epoch [18/30] Validation [97/123] Loss: 0.56931  focal_loss 0.00993  dice_loss 0.55938
Epoch [18/30] Validation [98/123] Loss: 0.35867  focal_loss 0.00200  dice_loss 0.35668
Epoch [18/30] Validation [99/123] Loss: 0.34364  focal_loss 0.00096  dice_loss 0.34268
Epoch [18/30] Validation [100/123] Loss: 0.37965  focal_loss 0.00179  dice_loss 0.37786
Epoch [18/30] Validation [101/123] Loss: 0.32386  focal_loss 0.00191  dice_loss 0.32195
Epoch [18/30] Validation [102/123] Loss: 0.37447  focal_loss 0.00120  dice_loss 0.37327
Epoch [18/30] Validation [103/123] Loss: 0.53652  focal_loss 0.00276  dice_loss 0.53376
Epoch [18/30] Validation [104/123] Loss: 0.46649  focal_loss 0.01023  dice_loss 0.45626
Epoch [18/30] Validation [105/123] Loss: 0.22698  focal_loss 0.00319  dice_loss 0.22379
Epoch [18/30] Validation [106/123] Loss: 0.26047  focal_loss 0.00117  dice_loss 0.25930
Epoch [18/30] Validation [107/123] Loss: 0.57281  focal_loss 0.00473  dice_loss 0.56808
Epoch [18/30] Validation [108/123] Loss: 0.23794  focal_loss 0.00052  dice_loss 0.23742
Epoch [18/30] Validation [109/123] Loss: 0.21377  focal_loss 0.00321  dice_loss 0.21056
Epoch [18/30] Validation [110/123] Loss: 0.47122  focal_loss 0.00732  dice_loss 0.46390
Epoch [18/30] Validation [111/123] Loss: 0.40581  focal_loss 0.00427  dice_loss 0.40154
Epoch [18/30] Validation [112/123] Loss: 0.34214  focal_loss 0.00115  dice_loss 0.34100
Epoch [18/30] Validation [113/123] Loss: 0.28443  focal_loss 0.00197  dice_loss 0.28246
Epoch [18/30] Validation [114/123] Loss: 0.37682  focal_loss 0.00636  dice_loss 0.37046
Epoch [18/30] Validation [115/123] Loss: 0.33555  focal_loss 0.00782  dice_loss 0.32773
Epoch [18/30] Validation [116/123] Loss: 0.27716  focal_loss 0.00068  dice_loss 0.27649
Epoch [18/30] Validation [117/123] Loss: 0.29410  focal_loss 0.00183  dice_loss 0.29227
Epoch [18/30] Validation [118/123] Loss: 0.19376  focal_loss 0.00179  dice_loss 0.19197
Epoch [18/30] Validation [119/123] Loss: 0.22902  focal_loss 0.00166  dice_loss 0.22736
Epoch [18/30] Validation [120/123] Loss: 0.25986  focal_loss 0.00191  dice_loss 0.25795
Epoch [18/30] Validation [121/123] Loss: 0.70437  focal_loss 0.02735  dice_loss 0.67703
Epoch [18/30] Validation [122/123] Loss: 0.66678  focal_loss 0.00198  dice_loss 0.66481
Epoch [18/30] Validation [123/123] Loss: 0.25122  focal_loss 0.00150  dice_loss 0.24972
Epoch [18/30] Validation metric {'Val/mean dice_metric': 0.8698452711105347, 'Val/TC dice_metric': 0.8832144737243652, 'Val/WT dice_metric': 0.9185714721679688, 'Val/ET dice_metric': 0.8077497482299805}
Epoch [18/30] lr = [0.0005313952597646568, 0.0005313952597646568] best acc: tensor([0.8693], device='cuda:0'), mean acc: tensor([0.8698], device='cuda:0'), mean class: tensor([0.8832, 0.9186, 0.8077], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [19/30] Training [1/488] Loss: 0.31412
Epoch [19/30] Training [2/488] Loss: 0.25238
Epoch [19/30] Training [3/488] Loss: 0.21136
Epoch [19/30] Training [4/488] Loss: 0.21472
Epoch [19/30] Training [5/488] Loss: 0.19417
Epoch [19/30] Training [6/488] Loss: 0.21465
Epoch [19/30] Training [7/488] Loss: 0.13268
Epoch [19/30] Training [8/488] Loss: 0.51736
Epoch [19/30] Training [9/488] Loss: 0.21270
Epoch [19/30] Training [10/488] Loss: 0.20781
Epoch [19/30] Training [11/488] Loss: 0.15399
Epoch [19/30] Training [12/488] Loss: 0.25610
Epoch [19/30] Training [13/488] Loss: 0.24190
Epoch [19/30] Training [14/488] Loss: 0.33710
Epoch [19/30] Training [15/488] Loss: 0.46034
Epoch [19/30] Training [16/488] Loss: 0.17969
Epoch [19/30] Training [17/488] Loss: 0.24672
Epoch [19/30] Training [18/488] Loss: 0.52769
Epoch [19/30] Training [19/488] Loss: 0.14077
Epoch [19/30] Training [20/488] Loss: 0.34117
Epoch [19/30] Training [21/488] Loss: 0.25870
Epoch [19/30] Training [22/488] Loss: 0.13968
Epoch [19/30] Training [23/488] Loss: 0.24776
Epoch [19/30] Training [24/488] Loss: 0.14764
Epoch [19/30] Training [25/488] Loss: 0.16073
Epoch [19/30] Training [26/488] Loss: 0.18325
Epoch [19/30] Training [27/488] Loss: 0.27283
Epoch [19/30] Training [28/488] Loss: 0.22082
Epoch [19/30] Training [29/488] Loss: 0.24872
Epoch [19/30] Training [30/488] Loss: 0.15222
Epoch [19/30] Training [31/488] Loss: 0.14504
Epoch [19/30] Training [32/488] Loss: 0.20916
Epoch [19/30] Training [33/488] Loss: 0.52794
Epoch [19/30] Training [34/488] Loss: 0.27376
Epoch [19/30] Training [35/488] Loss: 0.14096
Epoch [19/30] Training [36/488] Loss: 0.13048
Epoch [19/30] Training [37/488] Loss: 0.29864
Epoch [19/30] Training [38/488] Loss: 0.27785
Epoch [19/30] Training [39/488] Loss: 0.17507
Epoch [19/30] Training [40/488] Loss: 0.18089
Epoch [19/30] Training [41/488] Loss: 0.31851
Epoch [19/30] Training [42/488] Loss: 0.30072
Epoch [19/30] Training [43/488] Loss: 0.23454
Epoch [19/30] Training [44/488] Loss: 0.15979
Epoch [19/30] Training [45/488] Loss: 0.33549
Epoch [19/30] Training [46/488] Loss: 0.16493
Epoch [19/30] Training [47/488] Loss: 0.18357
Epoch [19/30] Training [48/488] Loss: 0.18429
Epoch [19/30] Training [49/488] Loss: 0.17728
Epoch [19/30] Training [50/488] Loss: 0.25262
Epoch [19/30] Training [51/488] Loss: 0.14567
Epoch [19/30] Training [52/488] Loss: 0.30765
Epoch [19/30] Training [53/488] Loss: 0.16227
Epoch [19/30] Training [54/488] Loss: 0.34400
Epoch [19/30] Training [55/488] Loss: 0.15460
Epoch [19/30] Training [56/488] Loss: 0.17972
Epoch [19/30] Training [57/488] Loss: 0.41373
Epoch [19/30] Training [58/488] Loss: 0.13416
Epoch [19/30] Training [59/488] Loss: 0.29459
Epoch [19/30] Training [60/488] Loss: 0.21721
Epoch [19/30] Training [61/488] Loss: 0.17810
Epoch [19/30] Training [62/488] Loss: 0.23936
Epoch [19/30] Training [63/488] Loss: 0.38463
Epoch [19/30] Training [64/488] Loss: 0.21427
Epoch [19/30] Training [65/488] Loss: 0.21278
Epoch [19/30] Training [66/488] Loss: 0.65217
Epoch [19/30] Training [67/488] Loss: 0.14395
Epoch [19/30] Training [68/488] Loss: 0.65845
Epoch [19/30] Training [69/488] Loss: 0.13918
Epoch [19/30] Training [70/488] Loss: 0.26439
Epoch [19/30] Training [71/488] Loss: 0.46049
Epoch [19/30] Training [72/488] Loss: 0.23656
Epoch [19/30] Training [73/488] Loss: 0.17692
Epoch [19/30] Training [74/488] Loss: 0.43150
Epoch [19/30] Training [75/488] Loss: 0.20100
Epoch [19/30] Training [76/488] Loss: 0.38574
Epoch [19/30] Training [77/488] Loss: 0.32193
Epoch [19/30] Training [78/488] Loss: 0.13353
Epoch [19/30] Training [79/488] Loss: 0.14264
Epoch [19/30] Training [80/488] Loss: 0.18297
Epoch [19/30] Training [81/488] Loss: 0.15514
Epoch [19/30] Training [82/488] Loss: 0.32113
Epoch [19/30] Training [83/488] Loss: 0.19048
Epoch [19/30] Training [84/488] Loss: 0.18170
Epoch [19/30] Training [85/488] Loss: 0.11252
Epoch [19/30] Training [86/488] Loss: 0.40925
Epoch [19/30] Training [87/488] Loss: 0.20171
Epoch [19/30] Training [88/488] Loss: 0.29611
Epoch [19/30] Training [89/488] Loss: 0.17931
Epoch [19/30] Training [90/488] Loss: 0.23204
Epoch [19/30] Training [91/488] Loss: 0.15139
Epoch [19/30] Training [92/488] Loss: 0.16343
Epoch [19/30] Training [93/488] Loss: 0.25513
Epoch [19/30] Training [94/488] Loss: 0.15694
Epoch [19/30] Training [95/488] Loss: 0.12915
Epoch [19/30] Training [96/488] Loss: 0.14944
Epoch [19/30] Training [97/488] Loss: 0.21892
Epoch [19/30] Training [98/488] Loss: 0.20414
Epoch [19/30] Training [99/488] Loss: 0.47819
Epoch [19/30] Training [100/488] Loss: 0.14949
Epoch [19/30] Training [101/488] Loss: 0.15413
Epoch [19/30] Training [102/488] Loss: 0.16087
Epoch [19/30] Training [103/488] Loss: 0.14651
Epoch [19/30] Training [104/488] Loss: 0.30548
Epoch [19/30] Training [105/488] Loss: 0.15686
Epoch [19/30] Training [106/488] Loss: 0.19628
Epoch [19/30] Training [107/488] Loss: 0.21207
Epoch [19/30] Training [108/488] Loss: 0.17497
Epoch [19/30] Training [109/488] Loss: 0.13807
Epoch [19/30] Training [110/488] Loss: 0.43698
Epoch [19/30] Training [111/488] Loss: 0.18209
Epoch [19/30] Training [112/488] Loss: 0.17911
Epoch [19/30] Training [113/488] Loss: 0.14736
Epoch [19/30] Training [114/488] Loss: 0.15117
Epoch [19/30] Training [115/488] Loss: 0.16320
Epoch [19/30] Training [116/488] Loss: 0.20679
Epoch [19/30] Training [117/488] Loss: 0.19554
Epoch [19/30] Training [118/488] Loss: 0.34527
Epoch [19/30] Training [119/488] Loss: 0.14401
Epoch [19/30] Training [120/488] Loss: 0.19292
Epoch [19/30] Training [121/488] Loss: 0.17417
Epoch [19/30] Training [122/488] Loss: 0.21313
Epoch [19/30] Training [123/488] Loss: 0.32436
Epoch [19/30] Training [124/488] Loss: 0.58894
Epoch [19/30] Training [125/488] Loss: 0.14113
Epoch [19/30] Training [126/488] Loss: 0.12408
Epoch [19/30] Training [127/488] Loss: 0.11029
Epoch [19/30] Training [128/488] Loss: 0.23050
Epoch [19/30] Training [129/488] Loss: 0.12850
Epoch [19/30] Training [130/488] Loss: 0.15523
Epoch [19/30] Training [131/488] Loss: 0.15248
Epoch [19/30] Training [132/488] Loss: 0.17706
Epoch [19/30] Training [133/488] Loss: 0.21859
Epoch [19/30] Training [134/488] Loss: 0.13725
Epoch [19/30] Training [135/488] Loss: 0.26179
Epoch [19/30] Training [136/488] Loss: 0.37008
Epoch [19/30] Training [137/488] Loss: 0.27132
Epoch [19/30] Training [138/488] Loss: 0.44492
Epoch [19/30] Training [139/488] Loss: 0.11845
Epoch [19/30] Training [140/488] Loss: 0.32331
Epoch [19/30] Training [141/488] Loss: 0.40599
Epoch [19/30] Training [142/488] Loss: 0.13779
Epoch [19/30] Training [143/488] Loss: 0.31813
Epoch [19/30] Training [144/488] Loss: 0.15974
Epoch [19/30] Training [145/488] Loss: 0.20165
Epoch [19/30] Training [146/488] Loss: 0.30611
Epoch [19/30] Training [147/488] Loss: 0.69687
Epoch [19/30] Training [148/488] Loss: 0.19899
Epoch [19/30] Training [149/488] Loss: 0.27513
Epoch [19/30] Training [150/488] Loss: 0.13741
Epoch [19/30] Training [151/488] Loss: 0.14122
Epoch [19/30] Training [152/488] Loss: 0.31619
Epoch [19/30] Training [153/488] Loss: 0.13621
Epoch [19/30] Training [154/488] Loss: 0.23435
Epoch [19/30] Training [155/488] Loss: 0.19005
Epoch [19/30] Training [156/488] Loss: 0.15845
Epoch [19/30] Training [157/488] Loss: 0.38520
Epoch [19/30] Training [158/488] Loss: 0.13451
Epoch [19/30] Training [159/488] Loss: 0.19349
Epoch [19/30] Training [160/488] Loss: 0.13927
Epoch [19/30] Training [161/488] Loss: 0.16262
Epoch [19/30] Training [162/488] Loss: 0.16686
Epoch [19/30] Training [163/488] Loss: 0.19315
Epoch [19/30] Training [164/488] Loss: 0.12421
Epoch [19/30] Training [165/488] Loss: 0.15843
Epoch [19/30] Training [166/488] Loss: 0.14532
Epoch [19/30] Training [167/488] Loss: 0.22275
Epoch [19/30] Training [168/488] Loss: 0.21076
Epoch [19/30] Training [169/488] Loss: 0.14609
Epoch [19/30] Training [170/488] Loss: 0.25261
Epoch [19/30] Training [171/488] Loss: 0.52951
Epoch [19/30] Training [172/488] Loss: 0.21076
Epoch [19/30] Training [173/488] Loss: 0.25509
Epoch [19/30] Training [174/488] Loss: 0.23251
Epoch [19/30] Training [175/488] Loss: 0.12898
Epoch [19/30] Training [176/488] Loss: 0.23999
Epoch [19/30] Training [177/488] Loss: 0.17584
Epoch [19/30] Training [178/488] Loss: 0.16064
Epoch [19/30] Training [179/488] Loss: 0.16692
Epoch [19/30] Training [180/488] Loss: 0.30027
Epoch [19/30] Training [181/488] Loss: 0.11727
Epoch [19/30] Training [182/488] Loss: 0.14894
Epoch [19/30] Training [183/488] Loss: 0.18038
Epoch [19/30] Training [184/488] Loss: 0.29420
Epoch [19/30] Training [185/488] Loss: 0.15361
Epoch [19/30] Training [186/488] Loss: 0.11450
Epoch [19/30] Training [187/488] Loss: 0.12662
Epoch [19/30] Training [188/488] Loss: 0.15080
Epoch [19/30] Training [189/488] Loss: 0.23056
Epoch [19/30] Training [190/488] Loss: 0.16227
Epoch [19/30] Training [191/488] Loss: 0.15974
Epoch [19/30] Training [192/488] Loss: 0.15832
Epoch [19/30] Training [193/488] Loss: 0.22846
Epoch [19/30] Training [194/488] Loss: 0.11747
Epoch [19/30] Training [195/488] Loss: 0.16762
Epoch [19/30] Training [196/488] Loss: 0.20181
Epoch [19/30] Training [197/488] Loss: 0.21634
Epoch [19/30] Training [198/488] Loss: 0.15445
Epoch [19/30] Training [199/488] Loss: 0.23245
Epoch [19/30] Training [200/488] Loss: 0.26179
Epoch [19/30] Training [201/488] Loss: 0.27318
Epoch [19/30] Training [202/488] Loss: 0.13065
Epoch [19/30] Training [203/488] Loss: 0.14986
Epoch [19/30] Training [204/488] Loss: 0.12080
Epoch [19/30] Training [205/488] Loss: 0.37265
Epoch [19/30] Training [206/488] Loss: 0.22133
Epoch [19/30] Training [207/488] Loss: 0.15501
Epoch [19/30] Training [208/488] Loss: 0.15856
Epoch [19/30] Training [209/488] Loss: 0.44640
Epoch [19/30] Training [210/488] Loss: 0.12298
Epoch [19/30] Training [211/488] Loss: 0.14286
Epoch [19/30] Training [212/488] Loss: 0.47863
Epoch [19/30] Training [213/488] Loss: 0.18910
Epoch [19/30] Training [214/488] Loss: 0.16487
Epoch [19/30] Training [215/488] Loss: 0.16573
Epoch [19/30] Training [216/488] Loss: 0.30442
Epoch [19/30] Training [217/488] Loss: 0.17210
Epoch [19/30] Training [218/488] Loss: 0.14459
Epoch [19/30] Training [219/488] Loss: 0.15414
Epoch [19/30] Training [220/488] Loss: 0.16451
Epoch [19/30] Training [221/488] Loss: 0.14226
Epoch [19/30] Training [222/488] Loss: 0.21175
Epoch [19/30] Training [223/488] Loss: 0.13937
Epoch [19/30] Training [224/488] Loss: 0.25498
Epoch [19/30] Training [225/488] Loss: 0.24549
Epoch [19/30] Training [226/488] Loss: 0.23788
Epoch [19/30] Training [227/488] Loss: 0.11606
Epoch [19/30] Training [228/488] Loss: 0.24297
Epoch [19/30] Training [229/488] Loss: 0.28924
Epoch [19/30] Training [230/488] Loss: 0.31603
Epoch [19/30] Training [231/488] Loss: 0.17516
Epoch [19/30] Training [232/488] Loss: 0.47285
Epoch [19/30] Training [233/488] Loss: 0.17607
Epoch [19/30] Training [234/488] Loss: 0.40045
Epoch [19/30] Training [235/488] Loss: 0.70840
Epoch [19/30] Training [236/488] Loss: 0.23682
Epoch [19/30] Training [237/488] Loss: 0.20135
Epoch [19/30] Training [238/488] Loss: 0.11703
Epoch [19/30] Training [239/488] Loss: 0.25080
Epoch [19/30] Training [240/488] Loss: 0.23018
Epoch [19/30] Training [241/488] Loss: 0.17079
Epoch [19/30] Training [242/488] Loss: 0.23148
Epoch [19/30] Training [243/488] Loss: 0.25722
Epoch [19/30] Training [244/488] Loss: 0.36262
Epoch [19/30] Training [245/488] Loss: 0.16223
Epoch [19/30] Training [246/488] Loss: 0.26266
Epoch [19/30] Training [247/488] Loss: 0.45174
Epoch [19/30] Training [248/488] Loss: 0.45660
Epoch [19/30] Training [249/488] Loss: 0.16525
Epoch [19/30] Training [250/488] Loss: 0.26529
Epoch [19/30] Training [251/488] Loss: 0.18016
Epoch [19/30] Training [252/488] Loss: 0.13795
Epoch [19/30] Training [253/488] Loss: 0.14721
Epoch [19/30] Training [254/488] Loss: 0.16683
Epoch [19/30] Training [255/488] Loss: 0.20087
Epoch [19/30] Training [256/488] Loss: 0.49858
Epoch [19/30] Training [257/488] Loss: 0.27777
Epoch [19/30] Training [258/488] Loss: 0.32406
Epoch [19/30] Training [259/488] Loss: 0.19211
Epoch [19/30] Training [260/488] Loss: 0.12357
Epoch [19/30] Training [261/488] Loss: 0.16851
Epoch [19/30] Training [262/488] Loss: 0.12246
Epoch [19/30] Training [263/488] Loss: 0.14984
Epoch [19/30] Training [264/488] Loss: 0.12546
Epoch [19/30] Training [265/488] Loss: 0.22006
Epoch [19/30] Training [266/488] Loss: 0.12678
Epoch [19/30] Training [267/488] Loss: 0.13579
Epoch [19/30] Training [268/488] Loss: 0.35067
Epoch [19/30] Training [269/488] Loss: 0.48218
Epoch [19/30] Training [270/488] Loss: 0.41067
Epoch [19/30] Training [271/488] Loss: 0.22266
Epoch [19/30] Training [272/488] Loss: 0.46506
Epoch [19/30] Training [273/488] Loss: 0.46346
Epoch [19/30] Training [274/488] Loss: 0.17340
Epoch [19/30] Training [275/488] Loss: 0.18516
Epoch [19/30] Training [276/488] Loss: 0.29590
Epoch [19/30] Training [277/488] Loss: 0.12012
Epoch [19/30] Training [278/488] Loss: 0.19227
Epoch [19/30] Training [279/488] Loss: 0.14052
Epoch [19/30] Training [280/488] Loss: 0.20890
Epoch [19/30] Training [281/488] Loss: 0.11710
Epoch [19/30] Training [282/488] Loss: 0.20468
Epoch [19/30] Training [283/488] Loss: 0.15043
Epoch [19/30] Training [284/488] Loss: 0.13606
Epoch [19/30] Training [285/488] Loss: 0.35463
Epoch [19/30] Training [286/488] Loss: 0.68353
Epoch [19/30] Training [287/488] Loss: 0.23115
Epoch [19/30] Training [288/488] Loss: 0.10976
Epoch [19/30] Training [289/488] Loss: 0.73736
Epoch [19/30] Training [290/488] Loss: 0.21010
Epoch [19/30] Training [291/488] Loss: 0.17827
Epoch [19/30] Training [292/488] Loss: 0.20519
Epoch [19/30] Training [293/488] Loss: 0.37185
Epoch [19/30] Training [294/488] Loss: 0.21228
Epoch [19/30] Training [295/488] Loss: 0.17052
Epoch [19/30] Training [296/488] Loss: 0.21542
Epoch [19/30] Training [297/488] Loss: 0.29878
Epoch [19/30] Training [298/488] Loss: 0.15746
Epoch [19/30] Training [299/488] Loss: 0.14001
Epoch [19/30] Training [300/488] Loss: 0.29062
Epoch [19/30] Training [301/488] Loss: 0.16347
Epoch [19/30] Training [302/488] Loss: 0.23591
Epoch [19/30] Training [303/488] Loss: 0.11964
Epoch [19/30] Training [304/488] Loss: 0.31574
Epoch [19/30] Training [305/488] Loss: 0.13739
Epoch [19/30] Training [306/488] Loss: 0.21404
Epoch [19/30] Training [307/488] Loss: 0.13619
Epoch [19/30] Training [308/488] Loss: 0.47289
Epoch [19/30] Training [309/488] Loss: 0.12863
Epoch [19/30] Training [310/488] Loss: 0.17019
Epoch [19/30] Training [311/488] Loss: 0.21106
Epoch [19/30] Training [312/488] Loss: 0.13794
Epoch [19/30] Training [313/488] Loss: 0.17443
Epoch [19/30] Training [314/488] Loss: 0.14754
Epoch [19/30] Training [315/488] Loss: 0.18431
Epoch [19/30] Training [316/488] Loss: 0.14552
Epoch [19/30] Training [317/488] Loss: 0.37611
Epoch [19/30] Training [318/488] Loss: 0.10368
Epoch [19/30] Training [319/488] Loss: 0.11501
Epoch [19/30] Training [320/488] Loss: 0.48951
Epoch [19/30] Training [321/488] Loss: 0.71396
Epoch [19/30] Training [322/488] Loss: 0.15609
Epoch [19/30] Training [323/488] Loss: 0.35171
Epoch [19/30] Training [324/488] Loss: 0.51987
Epoch [19/30] Training [325/488] Loss: 0.36236
Epoch [19/30] Training [326/488] Loss: 0.73353
Epoch [19/30] Training [327/488] Loss: 0.34097
Epoch [19/30] Training [328/488] Loss: 0.18216
Epoch [19/30] Training [329/488] Loss: 0.17527
Epoch [19/30] Training [330/488] Loss: 0.98005
Epoch [19/30] Training [331/488] Loss: 0.16145
Epoch [19/30] Training [332/488] Loss: 0.24990
Epoch [19/30] Training [333/488] Loss: 0.15748
Epoch [19/30] Training [334/488] Loss: 0.23864
Epoch [19/30] Training [335/488] Loss: 0.19215
Epoch [19/30] Training [336/488] Loss: 0.70872
Epoch [19/30] Training [337/488] Loss: 0.19883
Epoch [19/30] Training [338/488] Loss: 0.50610
Epoch [19/30] Training [339/488] Loss: 0.38200
Epoch [19/30] Training [340/488] Loss: 0.21123
Epoch [19/30] Training [341/488] Loss: 0.23581
Epoch [19/30] Training [342/488] Loss: 0.19289
Epoch [19/30] Training [343/488] Loss: 0.15841
Epoch [19/30] Training [344/488] Loss: 0.15062
Epoch [19/30] Training [345/488] Loss: 0.16148
Epoch [19/30] Training [346/488] Loss: 0.19526
Epoch [19/30] Training [347/488] Loss: 0.25892
Epoch [19/30] Training [348/488] Loss: 0.30775
Epoch [19/30] Training [349/488] Loss: 0.22185
Epoch [19/30] Training [350/488] Loss: 0.21596
Epoch [19/30] Training [351/488] Loss: 0.14147
Epoch [19/30] Training [352/488] Loss: 0.15409
Epoch [19/30] Training [353/488] Loss: 0.23534
Epoch [19/30] Training [354/488] Loss: 0.16838
Epoch [19/30] Training [355/488] Loss: 0.20964
Epoch [19/30] Training [356/488] Loss: 0.15089
Epoch [19/30] Training [357/488] Loss: 0.12712
Epoch [19/30] Training [358/488] Loss: 0.18647
Epoch [19/30] Training [359/488] Loss: 0.22586
Epoch [19/30] Training [360/488] Loss: 0.54384
Epoch [19/30] Training [361/488] Loss: 0.24633
Epoch [19/30] Training [362/488] Loss: 0.15235
Epoch [19/30] Training [363/488] Loss: 0.33754
Epoch [19/30] Training [364/488] Loss: 0.20974
Epoch [19/30] Training [365/488] Loss: 0.16273
Epoch [19/30] Training [366/488] Loss: 0.47664
Epoch [19/30] Training [367/488] Loss: 0.23219
Epoch [19/30] Training [368/488] Loss: 0.26289
Epoch [19/30] Training [369/488] Loss: 0.20590
Epoch [19/30] Training [370/488] Loss: 0.25304
Epoch [19/30] Training [371/488] Loss: 0.12187
Epoch [19/30] Training [372/488] Loss: 0.18008
Epoch [19/30] Training [373/488] Loss: 0.18393
Epoch [19/30] Training [374/488] Loss: 0.32197
Epoch [19/30] Training [375/488] Loss: 0.29476
Epoch [19/30] Training [376/488] Loss: 0.18590
Epoch [19/30] Training [377/488] Loss: 0.31201
Epoch [19/30] Training [378/488] Loss: 0.13769
Epoch [19/30] Training [379/488] Loss: 0.20543
Epoch [19/30] Training [380/488] Loss: 0.13856
Epoch [19/30] Training [381/488] Loss: 0.15744
Epoch [19/30] Training [382/488] Loss: 0.13232
Epoch [19/30] Training [383/488] Loss: 0.19119
Epoch [19/30] Training [384/488] Loss: 0.18647
Epoch [19/30] Training [385/488] Loss: 0.16399
Epoch [19/30] Training [386/488] Loss: 0.13741
Epoch [19/30] Training [387/488] Loss: 0.35008
Epoch [19/30] Training [388/488] Loss: 0.13790
Epoch [19/30] Training [389/488] Loss: 0.15737
Epoch [19/30] Training [390/488] Loss: 0.28608
Epoch [19/30] Training [391/488] Loss: 0.17647
Epoch [19/30] Training [392/488] Loss: 0.19053
Epoch [19/30] Training [393/488] Loss: 0.23143
Epoch [19/30] Training [394/488] Loss: 0.13765
Epoch [19/30] Training [395/488] Loss: 0.34636
Epoch [19/30] Training [396/488] Loss: 0.10520
Epoch [19/30] Training [397/488] Loss: 0.12226
Epoch [19/30] Training [398/488] Loss: 0.17611
Epoch [19/30] Training [399/488] Loss: 0.24230
Epoch [19/30] Training [400/488] Loss: 0.20646
Epoch [19/30] Training [401/488] Loss: 0.49766
Epoch [19/30] Training [402/488] Loss: 0.16509
Epoch [19/30] Training [403/488] Loss: 0.23010
Epoch [19/30] Training [404/488] Loss: 0.16754
Epoch [19/30] Training [405/488] Loss: 0.20505
Epoch [19/30] Training [406/488] Loss: 0.23979
Epoch [19/30] Training [407/488] Loss: 0.18137
Epoch [19/30] Training [408/488] Loss: 0.17242
Epoch [19/30] Training [409/488] Loss: 0.25203
Epoch [19/30] Training [410/488] Loss: 0.24695
Epoch [19/30] Training [411/488] Loss: 0.13224
Epoch [19/30] Training [412/488] Loss: 0.13753
Epoch [19/30] Training [413/488] Loss: 0.13184
Epoch [19/30] Training [414/488] Loss: 0.39963
Epoch [19/30] Training [415/488] Loss: 0.32250
Epoch [19/30] Training [416/488] Loss: 0.20373
Epoch [19/30] Training [417/488] Loss: 0.13579
Epoch [19/30] Training [418/488] Loss: 0.30879
Epoch [19/30] Training [419/488] Loss: 0.14605
Epoch [19/30] Training [420/488] Loss: 0.17268
Epoch [19/30] Training [421/488] Loss: 0.50477
Epoch [19/30] Training [422/488] Loss: 0.47709
Epoch [19/30] Training [423/488] Loss: 0.58787
Epoch [19/30] Training [424/488] Loss: 0.24533
Epoch [19/30] Training [425/488] Loss: 0.39740
Epoch [19/30] Training [426/488] Loss: 0.13748
Epoch [19/30] Training [427/488] Loss: 0.12268
Epoch [19/30] Training [428/488] Loss: 0.29065
Epoch [19/30] Training [429/488] Loss: 0.12263
Epoch [19/30] Training [430/488] Loss: 0.30776
Epoch [19/30] Training [431/488] Loss: 0.23037
Epoch [19/30] Training [432/488] Loss: 0.17187
Epoch [19/30] Training [433/488] Loss: 0.17852
Epoch [19/30] Training [434/488] Loss: 0.17660
Epoch [19/30] Training [435/488] Loss: 0.20053
Epoch [19/30] Training [436/488] Loss: 0.11170
Epoch [19/30] Training [437/488] Loss: 0.29040
Epoch [19/30] Training [438/488] Loss: 0.14662
Epoch [19/30] Training [439/488] Loss: 0.18791
Epoch [19/30] Training [440/488] Loss: 0.12442
Epoch [19/30] Training [441/488] Loss: 0.42014
Epoch [19/30] Training [442/488] Loss: 0.16899
Epoch [19/30] Training [443/488] Loss: 0.19369
Epoch [19/30] Training [444/488] Loss: 0.19510
Epoch [19/30] Training [445/488] Loss: 0.35136
Epoch [19/30] Training [446/488] Loss: 0.34153
Epoch [19/30] Training [447/488] Loss: 0.19891
Epoch [19/30] Training [448/488] Loss: 0.14739
Epoch [19/30] Training [449/488] Loss: 0.18186
Epoch [19/30] Training [450/488] Loss: 0.23276
Epoch [19/30] Training [451/488] Loss: 0.22029
Epoch [19/30] Training [452/488] Loss: 0.18692
Epoch [19/30] Training [453/488] Loss: 0.18629
Epoch [19/30] Training [454/488] Loss: 0.39774
Epoch [19/30] Training [455/488] Loss: 0.16772
Epoch [19/30] Training [456/488] Loss: 0.18160
Epoch [19/30] Training [457/488] Loss: 0.14191
Epoch [19/30] Training [458/488] Loss: 0.16261
Epoch [19/30] Training [459/488] Loss: 0.14886
Epoch [19/30] Training [460/488] Loss: 0.31954
Epoch [19/30] Training [461/488] Loss: 0.15729
Epoch [19/30] Training [462/488] Loss: 0.43417
Epoch [19/30] Training [463/488] Loss: 0.16360
Epoch [19/30] Training [464/488] Loss: 0.15459
Epoch [19/30] Training [465/488] Loss: 0.12247
Epoch [19/30] Training [466/488] Loss: 0.25312
Epoch [19/30] Training [467/488] Loss: 0.19384
Epoch [19/30] Training [468/488] Loss: 0.21241
Epoch [19/30] Training [469/488] Loss: 0.14476
Epoch [19/30] Training [470/488] Loss: 0.14984
Epoch [19/30] Training [471/488] Loss: 0.11962
Epoch [19/30] Training [472/488] Loss: 0.12488
Epoch [19/30] Training [473/488] Loss: 0.10735
Epoch [19/30] Training [474/488] Loss: 0.13812
Epoch [19/30] Training [475/488] Loss: 0.09981
Epoch [19/30] Training [476/488] Loss: 0.16796
Epoch [19/30] Training [477/488] Loss: 0.38919
Epoch [19/30] Training [478/488] Loss: 0.15986
Epoch [19/30] Training [479/488] Loss: 0.20273
Epoch [19/30] Training [480/488] Loss: 0.15336
Epoch [19/30] Training [481/488] Loss: 0.28876
Epoch [19/30] Training [482/488] Loss: 0.13694
Epoch [19/30] Training [483/488] Loss: 0.12248
Epoch [19/30] Training [484/488] Loss: 0.17707
Epoch [19/30] Training [485/488] Loss: 0.23860
Epoch [19/30] Training [486/488] Loss: 0.45057
Epoch [19/30] Training [487/488] Loss: 0.21344
Epoch [19/30] Training [488/488] Loss: 0.13890
Epoch [19/30] Training metric {'Train/mean dice_metric': 0.8768715262413025, 'Train/TC dice_metric': 0.8904305696487427, 'Train/WT dice_metric': 0.9260491728782654, 'Train/ET dice_metric': 0.8141348361968994}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [19/30] Validation [1/123] Loss: 0.20207  focal_loss 0.00196  dice_loss 0.20010
Epoch [19/30] Validation [2/123] Loss: 0.37431  focal_loss 0.00149  dice_loss 0.37282
Epoch [19/30] Validation [3/123] Loss: 0.18272  focal_loss 0.00168  dice_loss 0.18104
Epoch [19/30] Validation [4/123] Loss: 0.26838  focal_loss 0.00160  dice_loss 0.26678
Epoch [19/30] Validation [5/123] Loss: 0.34846  focal_loss 0.01068  dice_loss 0.33778
Epoch [19/30] Validation [6/123] Loss: 0.39455  focal_loss 0.00356  dice_loss 0.39098
Epoch [19/30] Validation [7/123] Loss: 0.35336  focal_loss 0.00062  dice_loss 0.35273
Epoch [19/30] Validation [8/123] Loss: 0.34298  focal_loss 0.00124  dice_loss 0.34174
Epoch [19/30] Validation [9/123] Loss: 0.26972  focal_loss 0.00181  dice_loss 0.26791
Epoch [19/30] Validation [10/123] Loss: 0.49750  focal_loss 0.00373  dice_loss 0.49377
Epoch [19/30] Validation [11/123] Loss: 0.56124  focal_loss 0.00358  dice_loss 0.55767
Epoch [19/30] Validation [12/123] Loss: 0.20884  focal_loss 0.00180  dice_loss 0.20704
Epoch [19/30] Validation [13/123] Loss: 0.19035  focal_loss 0.00262  dice_loss 0.18773
Epoch [19/30] Validation [14/123] Loss: 0.23375  focal_loss 0.00109  dice_loss 0.23267
Epoch [19/30] Validation [15/123] Loss: 0.37149  focal_loss 0.00182  dice_loss 0.36968
Epoch [19/30] Validation [16/123] Loss: 0.48346  focal_loss 0.00263  dice_loss 0.48083
Epoch [19/30] Validation [17/123] Loss: 0.50671  focal_loss 0.00218  dice_loss 0.50453
Epoch [19/30] Validation [18/123] Loss: 0.36843  focal_loss 0.00374  dice_loss 0.36469
Epoch [19/30] Validation [19/123] Loss: 0.29976  focal_loss 0.00700  dice_loss 0.29276
Epoch [19/30] Validation [20/123] Loss: 0.48582  focal_loss 0.00140  dice_loss 0.48442
Epoch [19/30] Validation [21/123] Loss: 0.33145  focal_loss 0.00094  dice_loss 0.33050
Epoch [19/30] Validation [22/123] Loss: 0.59617  focal_loss 0.00763  dice_loss 0.58854
Epoch [19/30] Validation [23/123] Loss: 0.19546  focal_loss 0.00145  dice_loss 0.19401
Epoch [19/30] Validation [24/123] Loss: 0.30013  focal_loss 0.00284  dice_loss 0.29729
Epoch [19/30] Validation [25/123] Loss: 0.31122  focal_loss 0.00203  dice_loss 0.30919
Epoch [19/30] Validation [26/123] Loss: 0.19997  focal_loss 0.00130  dice_loss 0.19867
Epoch [19/30] Validation [27/123] Loss: 0.23867  focal_loss 0.00222  dice_loss 0.23645
Epoch [19/30] Validation [28/123] Loss: 0.57893  focal_loss 0.00562  dice_loss 0.57330
Epoch [19/30] Validation [29/123] Loss: 0.37348  focal_loss 0.00333  dice_loss 0.37016
Epoch [19/30] Validation [30/123] Loss: 0.23571  focal_loss 0.00292  dice_loss 0.23278
Epoch [19/30] Validation [31/123] Loss: 0.18825  focal_loss 0.00130  dice_loss 0.18695
Epoch [19/30] Validation [32/123] Loss: 0.31400  focal_loss 0.00378  dice_loss 0.31022
Epoch [19/30] Validation [33/123] Loss: 0.35691  focal_loss 0.00189  dice_loss 0.35502
Epoch [19/30] Validation [34/123] Loss: 0.33581  focal_loss 0.00290  dice_loss 0.33291
Epoch [19/30] Validation [35/123] Loss: 0.23074  focal_loss 0.00138  dice_loss 0.22936
Epoch [19/30] Validation [36/123] Loss: 0.25420  focal_loss 0.00087  dice_loss 0.25333
Epoch [19/30] Validation [37/123] Loss: 0.39595  focal_loss 0.00912  dice_loss 0.38683
Epoch [19/30] Validation [38/123] Loss: 0.21180  focal_loss 0.00141  dice_loss 0.21038
Epoch [19/30] Validation [39/123] Loss: 0.20217  focal_loss 0.00119  dice_loss 0.20098
Epoch [19/30] Validation [40/123] Loss: 0.31099  focal_loss 0.00089  dice_loss 0.31009
Epoch [19/30] Validation [41/123] Loss: 0.19954  focal_loss 0.00137  dice_loss 0.19817
Epoch [19/30] Validation [42/123] Loss: 0.18799  focal_loss 0.00119  dice_loss 0.18680
Epoch [19/30] Validation [43/123] Loss: 0.28337  focal_loss 0.01157  dice_loss 0.27181
Epoch [19/30] Validation [44/123] Loss: 0.64034  focal_loss 0.01081  dice_loss 0.62953
Epoch [19/30] Validation [45/123] Loss: 0.30045  focal_loss 0.00170  dice_loss 0.29875
Epoch [19/30] Validation [46/123] Loss: 0.37322  focal_loss 0.00352  dice_loss 0.36970
Epoch [19/30] Validation [47/123] Loss: 0.29969  focal_loss 0.00158  dice_loss 0.29811
Epoch [19/30] Validation [48/123] Loss: 0.45946  focal_loss 0.00618  dice_loss 0.45328
Epoch [19/30] Validation [49/123] Loss: 0.22361  focal_loss 0.00458  dice_loss 0.21903
Epoch [19/30] Validation [50/123] Loss: 0.20452  focal_loss 0.00183  dice_loss 0.20269
Epoch [19/30] Validation [51/123] Loss: 0.38988  focal_loss 0.00898  dice_loss 0.38090
Epoch [19/30] Validation [52/123] Loss: 0.22241  focal_loss 0.00081  dice_loss 0.22159
Epoch [19/30] Validation [53/123] Loss: 0.28025  focal_loss 0.00084  dice_loss 0.27942
Epoch [19/30] Validation [54/123] Loss: 0.33581  focal_loss 0.00135  dice_loss 0.33447
Epoch [19/30] Validation [55/123] Loss: 0.28075  focal_loss 0.00129  dice_loss 0.27946
Epoch [19/30] Validation [56/123] Loss: 0.23172  focal_loss 0.00298  dice_loss 0.22874
Epoch [19/30] Validation [57/123] Loss: 0.30281  focal_loss 0.00526  dice_loss 0.29755
Epoch [19/30] Validation [58/123] Loss: 0.25054  focal_loss 0.00186  dice_loss 0.24867
Epoch [19/30] Validation [59/123] Loss: 0.72204  focal_loss 0.01688  dice_loss 0.70516
Epoch [19/30] Validation [60/123] Loss: 0.24924  focal_loss 0.00245  dice_loss 0.24678
Epoch [19/30] Validation [61/123] Loss: 0.59598  focal_loss 0.00203  dice_loss 0.59396
Epoch [19/30] Validation [62/123] Loss: 0.54486  focal_loss 0.01488  dice_loss 0.52997
Epoch [19/30] Validation [63/123] Loss: 0.39565  focal_loss 0.00168  dice_loss 0.39397
Epoch [19/30] Validation [64/123] Loss: 0.41471  focal_loss 0.01232  dice_loss 0.40238
Epoch [19/30] Validation [65/123] Loss: 0.22927  focal_loss 0.00094  dice_loss 0.22832
Epoch [19/30] Validation [66/123] Loss: 0.23454  focal_loss 0.00102  dice_loss 0.23352
Epoch [19/30] Validation [67/123] Loss: 0.36773  focal_loss 0.00369  dice_loss 0.36403
Epoch [19/30] Validation [68/123] Loss: 0.36399  focal_loss 0.00104  dice_loss 0.36295
Epoch [19/30] Validation [69/123] Loss: 0.38469  focal_loss 0.00550  dice_loss 0.37919
Epoch [19/30] Validation [70/123] Loss: 0.35622  focal_loss 0.00298  dice_loss 0.35324
Epoch [19/30] Validation [71/123] Loss: 0.22340  focal_loss 0.00091  dice_loss 0.22248
Epoch [19/30] Validation [72/123] Loss: 0.20302  focal_loss 0.00135  dice_loss 0.20168
Epoch [19/30] Validation [73/123] Loss: 0.32838  focal_loss 0.00456  dice_loss 0.32382
Epoch [19/30] Validation [74/123] Loss: 0.33476  focal_loss 0.00274  dice_loss 0.33201
Epoch [19/30] Validation [75/123] Loss: 0.26212  focal_loss 0.00128  dice_loss 0.26085
Epoch [19/30] Validation [76/123] Loss: 0.51337  focal_loss 0.00518  dice_loss 0.50819
Epoch [19/30] Validation [77/123] Loss: 0.37146  focal_loss 0.00099  dice_loss 0.37047
Epoch [19/30] Validation [78/123] Loss: 0.27166  focal_loss 0.00172  dice_loss 0.26995
Epoch [19/30] Validation [79/123] Loss: 0.31339  focal_loss 0.00155  dice_loss 0.31185
Epoch [19/30] Validation [80/123] Loss: 0.21105  focal_loss 0.00187  dice_loss 0.20918
Epoch [19/30] Validation [81/123] Loss: 0.26583  focal_loss 0.00204  dice_loss 0.26378
Epoch [19/30] Validation [82/123] Loss: 0.20578  focal_loss 0.00087  dice_loss 0.20491
Epoch [19/30] Validation [83/123] Loss: 0.45706  focal_loss 0.01473  dice_loss 0.44234
Epoch [19/30] Validation [84/123] Loss: 0.25342  focal_loss 0.00120  dice_loss 0.25222
Epoch [19/30] Validation [85/123] Loss: 0.38247  focal_loss 0.00962  dice_loss 0.37285
Epoch [19/30] Validation [86/123] Loss: 0.23814  focal_loss 0.00252  dice_loss 0.23562
Epoch [19/30] Validation [87/123] Loss: 0.22167  focal_loss 0.00494  dice_loss 0.21672
Epoch [19/30] Validation [88/123] Loss: 0.24457  focal_loss 0.00259  dice_loss 0.24199
Epoch [19/30] Validation [89/123] Loss: 0.19878  focal_loss 0.00174  dice_loss 0.19704
Epoch [19/30] Validation [90/123] Loss: 0.30190  focal_loss 0.00214  dice_loss 0.29976
Epoch [19/30] Validation [91/123] Loss: 0.24159  focal_loss 0.00143  dice_loss 0.24016
Epoch [19/30] Validation [92/123] Loss: 0.19507  focal_loss 0.00134  dice_loss 0.19374
Epoch [19/30] Validation [93/123] Loss: 0.20879  focal_loss 0.00164  dice_loss 0.20715
Epoch [19/30] Validation [94/123] Loss: 0.34587  focal_loss 0.00201  dice_loss 0.34387
Epoch [19/30] Validation [95/123] Loss: 0.25473  focal_loss 0.00254  dice_loss 0.25219
Epoch [19/30] Validation [96/123] Loss: 0.31345  focal_loss 0.00167  dice_loss 0.31178
Epoch [19/30] Validation [97/123] Loss: 0.60662  focal_loss 0.00820  dice_loss 0.59842
Epoch [19/30] Validation [98/123] Loss: 0.32943  focal_loss 0.00136  dice_loss 0.32807
Epoch [19/30] Validation [99/123] Loss: 0.31835  focal_loss 0.00076  dice_loss 0.31759
Epoch [19/30] Validation [100/123] Loss: 0.35761  focal_loss 0.00173  dice_loss 0.35588
Epoch [19/30] Validation [101/123] Loss: 0.29945  focal_loss 0.00154  dice_loss 0.29791
Epoch [19/30] Validation [102/123] Loss: 0.35100  focal_loss 0.00103  dice_loss 0.34997
Epoch [19/30] Validation [103/123] Loss: 0.49483  focal_loss 0.00135  dice_loss 0.49349
Epoch [19/30] Validation [104/123] Loss: 0.41819  focal_loss 0.00467  dice_loss 0.41351
Epoch [19/30] Validation [105/123] Loss: 0.21124  focal_loss 0.00312  dice_loss 0.20812
Epoch [19/30] Validation [106/123] Loss: 0.22971  focal_loss 0.00098  dice_loss 0.22873
Epoch [19/30] Validation [107/123] Loss: 0.54930  focal_loss 0.00429  dice_loss 0.54501
Epoch [19/30] Validation [108/123] Loss: 0.22126  focal_loss 0.00061  dice_loss 0.22065
Epoch [19/30] Validation [109/123] Loss: 0.20576  focal_loss 0.00397  dice_loss 0.20180
Epoch [19/30] Validation [110/123] Loss: 0.37997  focal_loss 0.00343  dice_loss 0.37653
Epoch [19/30] Validation [111/123] Loss: 0.37748  focal_loss 0.00356  dice_loss 0.37393
Epoch [19/30] Validation [112/123] Loss: 0.31015  focal_loss 0.00083  dice_loss 0.30932
Epoch [19/30] Validation [113/123] Loss: 0.25415  focal_loss 0.00138  dice_loss 0.25277
Epoch [19/30] Validation [114/123] Loss: 0.34461  focal_loss 0.00508  dice_loss 0.33953
Epoch [19/30] Validation [115/123] Loss: 0.29627  focal_loss 0.00579  dice_loss 0.29048
Epoch [19/30] Validation [116/123] Loss: 0.25542  focal_loss 0.00061  dice_loss 0.25481
Epoch [19/30] Validation [117/123] Loss: 0.26742  focal_loss 0.00125  dice_loss 0.26617
Epoch [19/30] Validation [118/123] Loss: 0.17699  focal_loss 0.00174  dice_loss 0.17525
Epoch [19/30] Validation [119/123] Loss: 0.20295  focal_loss 0.00122  dice_loss 0.20173
Epoch [19/30] Validation [120/123] Loss: 0.23832  focal_loss 0.00174  dice_loss 0.23658
Epoch [19/30] Validation [121/123] Loss: 0.66244  focal_loss 0.02222  dice_loss 0.64022
Epoch [19/30] Validation [122/123] Loss: 0.56157  focal_loss 0.00051  dice_loss 0.56107
Epoch [19/30] Validation [123/123] Loss: 0.22982  focal_loss 0.00148  dice_loss 0.22834
Epoch [19/30] Validation metric {'Val/mean dice_metric': 0.8753013610839844, 'Val/TC dice_metric': 0.8873782157897949, 'Val/WT dice_metric': 0.9254361391067505, 'Val/ET dice_metric': 0.8130895495414734}
Epoch [19/30] lr = [0.0004686047402353433, 0.0004686047402353433] best acc: tensor([0.8698], device='cuda:0'), mean acc: tensor([0.8753], device='cuda:0'), mean class: tensor([0.8874, 0.9254, 0.8131], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [20/30] Training [1/488] Loss: 0.13107
Epoch [20/30] Training [2/488] Loss: 0.30150
Epoch [20/30] Training [3/488] Loss: 0.19849
Epoch [20/30] Training [4/488] Loss: 0.53135
Epoch [20/30] Training [5/488] Loss: 0.14277
Epoch [20/30] Training [6/488] Loss: 0.12799
Epoch [20/30] Training [7/488] Loss: 0.31092
Epoch [20/30] Training [8/488] Loss: 0.23181
Epoch [20/30] Training [9/488] Loss: 0.21002
Epoch [20/30] Training [10/488] Loss: 0.22669
Epoch [20/30] Training [11/488] Loss: 0.11426
Epoch [20/30] Training [12/488] Loss: 0.27305
Epoch [20/30] Training [13/488] Loss: 0.11243
Epoch [20/30] Training [14/488] Loss: 0.20340
Epoch [20/30] Training [15/488] Loss: 0.15970
Epoch [20/30] Training [16/488] Loss: 0.16172
Epoch [20/30] Training [17/488] Loss: 0.26676
Epoch [20/30] Training [18/488] Loss: 0.16573
Epoch [20/30] Training [19/488] Loss: 0.29058
Epoch [20/30] Training [20/488] Loss: 0.14625
Epoch [20/30] Training [21/488] Loss: 0.25639
Epoch [20/30] Training [22/488] Loss: 0.10158
Epoch [20/30] Training [23/488] Loss: 0.24191
Epoch [20/30] Training [24/488] Loss: 0.12017
Epoch [20/30] Training [25/488] Loss: 0.14649
Epoch [20/30] Training [26/488] Loss: 0.11554
Epoch [20/30] Training [27/488] Loss: 0.13518
Epoch [20/30] Training [28/488] Loss: 0.13305
Epoch [20/30] Training [29/488] Loss: 0.14820
Epoch [20/30] Training [30/488] Loss: 0.12263
Epoch [20/30] Training [31/488] Loss: 0.30052
Epoch [20/30] Training [32/488] Loss: 0.14448
Epoch [20/30] Training [33/488] Loss: 0.14805
Epoch [20/30] Training [34/488] Loss: 0.32970
Epoch [20/30] Training [35/488] Loss: 0.12333
Epoch [20/30] Training [36/488] Loss: 0.16769
Epoch [20/30] Training [37/488] Loss: 0.19759
Epoch [20/30] Training [38/488] Loss: 0.10159
Epoch [20/30] Training [39/488] Loss: 0.17969
Epoch [20/30] Training [40/488] Loss: 0.49664
Epoch [20/30] Training [41/488] Loss: 0.15729
Epoch [20/30] Training [42/488] Loss: 0.13422
Epoch [20/30] Training [43/488] Loss: 0.15146
Epoch [20/30] Training [44/488] Loss: 0.14944
Epoch [20/30] Training [45/488] Loss: 0.23120
Epoch [20/30] Training [46/488] Loss: 0.29933
Epoch [20/30] Training [47/488] Loss: 0.16508
Epoch [20/30] Training [48/488] Loss: 0.11692
Epoch [20/30] Training [49/488] Loss: 0.35934
Epoch [20/30] Training [50/488] Loss: 0.14582
Epoch [20/30] Training [51/488] Loss: 0.23098
Epoch [20/30] Training [52/488] Loss: 0.24660
Epoch [20/30] Training [53/488] Loss: 0.40186
Epoch [20/30] Training [54/488] Loss: 0.14724
Epoch [20/30] Training [55/488] Loss: 0.40098
Epoch [20/30] Training [56/488] Loss: 0.12278
Epoch [20/30] Training [57/488] Loss: 0.17898
Epoch [20/30] Training [58/488] Loss: 0.11901
Epoch [20/30] Training [59/488] Loss: 0.12782
Epoch [20/30] Training [60/488] Loss: 0.27379
Epoch [20/30] Training [61/488] Loss: 0.63410
Epoch [20/30] Training [62/488] Loss: 0.19314
Epoch [20/30] Training [63/488] Loss: 0.11814
Epoch [20/30] Training [64/488] Loss: 0.21172
Epoch [20/30] Training [65/488] Loss: 0.19187
Epoch [20/30] Training [66/488] Loss: 0.15168
Epoch [20/30] Training [67/488] Loss: 0.13528
Epoch [20/30] Training [68/488] Loss: 0.31411
Epoch [20/30] Training [69/488] Loss: 0.23350
Epoch [20/30] Training [70/488] Loss: 0.29465
Epoch [20/30] Training [71/488] Loss: 0.43499
Epoch [20/30] Training [72/488] Loss: 0.42793
Epoch [20/30] Training [73/488] Loss: 0.37161
Epoch [20/30] Training [74/488] Loss: 0.21982
Epoch [20/30] Training [75/488] Loss: 0.25007
Epoch [20/30] Training [76/488] Loss: 0.33031
Epoch [20/30] Training [77/488] Loss: 0.20783
Epoch [20/30] Training [78/488] Loss: 0.12532
Epoch [20/30] Training [79/488] Loss: 0.23091
Epoch [20/30] Training [80/488] Loss: 0.15840
Epoch [20/30] Training [81/488] Loss: 0.14638
Epoch [20/30] Training [82/488] Loss: 0.31153
Epoch [20/30] Training [83/488] Loss: 0.12420
Epoch [20/30] Training [84/488] Loss: 0.40201
Epoch [20/30] Training [85/488] Loss: 0.63690
Epoch [20/30] Training [86/488] Loss: 0.25534
Epoch [20/30] Training [87/488] Loss: 0.28608
Epoch [20/30] Training [88/488] Loss: 0.19190
Epoch [20/30] Training [89/488] Loss: 0.10719
Epoch [20/30] Training [90/488] Loss: 0.24578
Epoch [20/30] Training [91/488] Loss: 0.21441
Epoch [20/30] Training [92/488] Loss: 0.13635
Epoch [20/30] Training [93/488] Loss: 0.23308
Epoch [20/30] Training [94/488] Loss: 0.43747
Epoch [20/30] Training [95/488] Loss: 0.27091
Epoch [20/30] Training [96/488] Loss: 0.24289
Epoch [20/30] Training [97/488] Loss: 0.29596
Epoch [20/30] Training [98/488] Loss: 0.20021
Epoch [20/30] Training [99/488] Loss: 0.23783
Epoch [20/30] Training [100/488] Loss: 0.19924
Epoch [20/30] Training [101/488] Loss: 0.24715
Epoch [20/30] Training [102/488] Loss: 0.17197
Epoch [20/30] Training [103/488] Loss: 0.19917
Epoch [20/30] Training [104/488] Loss: 0.17455
Epoch [20/30] Training [105/488] Loss: 0.09865
Epoch [20/30] Training [106/488] Loss: 0.22133
Epoch [20/30] Training [107/488] Loss: 0.20775
Epoch [20/30] Training [108/488] Loss: 0.28710
Epoch [20/30] Training [109/488] Loss: 0.41454
Epoch [20/30] Training [110/488] Loss: 0.17484
Epoch [20/30] Training [111/488] Loss: 0.15426
Epoch [20/30] Training [112/488] Loss: 0.13940
Epoch [20/30] Training [113/488] Loss: 0.39144
Epoch [20/30] Training [114/488] Loss: 0.34485
Epoch [20/30] Training [115/488] Loss: 0.39661
Epoch [20/30] Training [116/488] Loss: 0.15300
Epoch [20/30] Training [117/488] Loss: 0.18185
Epoch [20/30] Training [118/488] Loss: 0.23625
Epoch [20/30] Training [119/488] Loss: 0.19710
Epoch [20/30] Training [120/488] Loss: 0.16243
Epoch [20/30] Training [121/488] Loss: 0.13375
Epoch [20/30] Training [122/488] Loss: 0.22430
Epoch [20/30] Training [123/488] Loss: 0.48820
Epoch [20/30] Training [124/488] Loss: 0.24581
Epoch [20/30] Training [125/488] Loss: 0.23651
Epoch [20/30] Training [126/488] Loss: 0.12341
Epoch [20/30] Training [127/488] Loss: 0.13262
Epoch [20/30] Training [128/488] Loss: 0.18598
Epoch [20/30] Training [129/488] Loss: 0.15798
Epoch [20/30] Training [130/488] Loss: 0.22094
Epoch [20/30] Training [131/488] Loss: 0.17904
Epoch [20/30] Training [132/488] Loss: 0.28170
Epoch [20/30] Training [133/488] Loss: 0.63625
Epoch [20/30] Training [134/488] Loss: 0.15843
Epoch [20/30] Training [135/488] Loss: 0.22970
Epoch [20/30] Training [136/488] Loss: 0.44378
Epoch [20/30] Training [137/488] Loss: 0.16469
Epoch [20/30] Training [138/488] Loss: 0.32135
Epoch [20/30] Training [139/488] Loss: 0.16323
Epoch [20/30] Training [140/488] Loss: 0.11678
Epoch [20/30] Training [141/488] Loss: 0.22114
Epoch [20/30] Training [142/488] Loss: 0.14475
Epoch [20/30] Training [143/488] Loss: 0.10480
Epoch [20/30] Training [144/488] Loss: 0.19532
Epoch [20/30] Training [145/488] Loss: 0.22332
Epoch [20/30] Training [146/488] Loss: 0.15838
Epoch [20/30] Training [147/488] Loss: 0.13977
Epoch [20/30] Training [148/488] Loss: 0.13604
Epoch [20/30] Training [149/488] Loss: 0.19325
Epoch [20/30] Training [150/488] Loss: 0.20304
Epoch [20/30] Training [151/488] Loss: 0.23399
Epoch [20/30] Training [152/488] Loss: 0.25972
Epoch [20/30] Training [153/488] Loss: 0.12888
Epoch [20/30] Training [154/488] Loss: 0.21143
Epoch [20/30] Training [155/488] Loss: 0.14544
Epoch [20/30] Training [156/488] Loss: 0.13597
Epoch [20/30] Training [157/488] Loss: 0.35008
Epoch [20/30] Training [158/488] Loss: 0.15079
Epoch [20/30] Training [159/488] Loss: 0.13920
Epoch [20/30] Training [160/488] Loss: 0.45089
Epoch [20/30] Training [161/488] Loss: 0.14692
Epoch [20/30] Training [162/488] Loss: 0.15631
Epoch [20/30] Training [163/488] Loss: 0.17921
Epoch [20/30] Training [164/488] Loss: 0.22728
Epoch [20/30] Training [165/488] Loss: 0.17045
Epoch [20/30] Training [166/488] Loss: 0.17477
Epoch [20/30] Training [167/488] Loss: 0.30279
Epoch [20/30] Training [168/488] Loss: 0.17064
Epoch [20/30] Training [169/488] Loss: 0.21986
Epoch [20/30] Training [170/488] Loss: 0.24918
Epoch [20/30] Training [171/488] Loss: 0.16735
Epoch [20/30] Training [172/488] Loss: 0.19604
Epoch [20/30] Training [173/488] Loss: 0.20420
Epoch [20/30] Training [174/488] Loss: 0.20147
Epoch [20/30] Training [175/488] Loss: 0.28318
Epoch [20/30] Training [176/488] Loss: 0.17113
Epoch [20/30] Training [177/488] Loss: 0.11782
Epoch [20/30] Training [178/488] Loss: 0.16667
Epoch [20/30] Training [179/488] Loss: 0.53231
Epoch [20/30] Training [180/488] Loss: 0.22096
Epoch [20/30] Training [181/488] Loss: 0.17256
Epoch [20/30] Training [182/488] Loss: 0.19402
Epoch [20/30] Training [183/488] Loss: 0.12371
Epoch [20/30] Training [184/488] Loss: 0.14641
Epoch [20/30] Training [185/488] Loss: 0.28778
Epoch [20/30] Training [186/488] Loss: 0.16684
Epoch [20/30] Training [187/488] Loss: 0.11006
Epoch [20/30] Training [188/488] Loss: 0.10337
Epoch [20/30] Training [189/488] Loss: 0.18019
Epoch [20/30] Training [190/488] Loss: 0.13162
Epoch [20/30] Training [191/488] Loss: 0.13869
Epoch [20/30] Training [192/488] Loss: 0.17898
Epoch [20/30] Training [193/488] Loss: 0.15730
Epoch [20/30] Training [194/488] Loss: 0.10857
Epoch [20/30] Training [195/488] Loss: 0.10393
Epoch [20/30] Training [196/488] Loss: 0.34742
Epoch [20/30] Training [197/488] Loss: 0.13462
Epoch [20/30] Training [198/488] Loss: 0.39077
Epoch [20/30] Training [199/488] Loss: 0.21988
Epoch [20/30] Training [200/488] Loss: 0.15244
Epoch [20/30] Training [201/488] Loss: 0.12935
Epoch [20/30] Training [202/488] Loss: 0.14166
Epoch [20/30] Training [203/488] Loss: 0.28336
Epoch [20/30] Training [204/488] Loss: 0.15946
Epoch [20/30] Training [205/488] Loss: 0.27230
Epoch [20/30] Training [206/488] Loss: 0.23545
Epoch [20/30] Training [207/488] Loss: 0.15309
Epoch [20/30] Training [208/488] Loss: 0.59951
Epoch [20/30] Training [209/488] Loss: 0.14523
Epoch [20/30] Training [210/488] Loss: 0.18540
Epoch [20/30] Training [211/488] Loss: 0.27904
Epoch [20/30] Training [212/488] Loss: 0.17818
Epoch [20/30] Training [213/488] Loss: 0.38581
Epoch [20/30] Training [214/488] Loss: 0.17727
Epoch [20/30] Training [215/488] Loss: 0.15427
Epoch [20/30] Training [216/488] Loss: 0.13256
Epoch [20/30] Training [217/488] Loss: 0.16641
Epoch [20/30] Training [218/488] Loss: 0.35812
Epoch [20/30] Training [219/488] Loss: 0.18052
Epoch [20/30] Training [220/488] Loss: 0.12719
Epoch [20/30] Training [221/488] Loss: 0.15209
Epoch [20/30] Training [222/488] Loss: 0.17557
Epoch [20/30] Training [223/488] Loss: 0.22278
Epoch [20/30] Training [224/488] Loss: 0.23110
Epoch [20/30] Training [225/488] Loss: 0.13024
Epoch [20/30] Training [226/488] Loss: 0.16162
Epoch [20/30] Training [227/488] Loss: 0.18861
Epoch [20/30] Training [228/488] Loss: 0.22962
Epoch [20/30] Training [229/488] Loss: 0.21408
Epoch [20/30] Training [230/488] Loss: 0.27323
Epoch [20/30] Training [231/488] Loss: 0.13559
Epoch [20/30] Training [232/488] Loss: 0.23093
Epoch [20/30] Training [233/488] Loss: 0.10594
Epoch [20/30] Training [234/488] Loss: 0.13999
Epoch [20/30] Training [235/488] Loss: 0.19940
Epoch [20/30] Training [236/488] Loss: 0.18359
Epoch [20/30] Training [237/488] Loss: 0.12762
Epoch [20/30] Training [238/488] Loss: 0.10869
Epoch [20/30] Training [239/488] Loss: 0.17836
Epoch [20/30] Training [240/488] Loss: 0.41858
Epoch [20/30] Training [241/488] Loss: 0.18904
Epoch [20/30] Training [242/488] Loss: 0.16846
Epoch [20/30] Training [243/488] Loss: 0.51735
Epoch [20/30] Training [244/488] Loss: 0.16528
Epoch [20/30] Training [245/488] Loss: 0.32388
Epoch [20/30] Training [246/488] Loss: 0.14837
Epoch [20/30] Training [247/488] Loss: 0.24646
Epoch [20/30] Training [248/488] Loss: 0.18572
Epoch [20/30] Training [249/488] Loss: 0.22682
Epoch [20/30] Training [250/488] Loss: 0.11313
Epoch [20/30] Training [251/488] Loss: 0.39736
Epoch [20/30] Training [252/488] Loss: 0.15212
Epoch [20/30] Training [253/488] Loss: 0.26583
Epoch [20/30] Training [254/488] Loss: 0.32243
Epoch [20/30] Training [255/488] Loss: 0.17397
Epoch [20/30] Training [256/488] Loss: 0.24531
Epoch [20/30] Training [257/488] Loss: 0.46673
Epoch [20/30] Training [258/488] Loss: 0.30810
Epoch [20/30] Training [259/488] Loss: 0.15053
Epoch [20/30] Training [260/488] Loss: 0.15116
Epoch [20/30] Training [261/488] Loss: 0.34108
Epoch [20/30] Training [262/488] Loss: 0.15183
Epoch [20/30] Training [263/488] Loss: 0.35747
Epoch [20/30] Training [264/488] Loss: 0.27987
Epoch [20/30] Training [265/488] Loss: 0.37165
Epoch [20/30] Training [266/488] Loss: 0.21987
Epoch [20/30] Training [267/488] Loss: 0.12587
Epoch [20/30] Training [268/488] Loss: 0.61592
Epoch [20/30] Training [269/488] Loss: 0.16474
Epoch [20/30] Training [270/488] Loss: 0.14682
Epoch [20/30] Training [271/488] Loss: 0.19560
Epoch [20/30] Training [272/488] Loss: 0.27033
Epoch [20/30] Training [273/488] Loss: 0.31661
Epoch [20/30] Training [274/488] Loss: 0.12875
Epoch [20/30] Training [275/488] Loss: 0.46201
Epoch [20/30] Training [276/488] Loss: 0.15157
Epoch [20/30] Training [277/488] Loss: 0.12036
Epoch [20/30] Training [278/488] Loss: 0.17225
Epoch [20/30] Training [279/488] Loss: 0.18423
Epoch [20/30] Training [280/488] Loss: 0.13625
Epoch [20/30] Training [281/488] Loss: 0.15137
Epoch [20/30] Training [282/488] Loss: 0.18461
Epoch [20/30] Training [283/488] Loss: 0.19017
Epoch [20/30] Training [284/488] Loss: 0.11381
Epoch [20/30] Training [285/488] Loss: 0.35814
Epoch [20/30] Training [286/488] Loss: 0.11613
Epoch [20/30] Training [287/488] Loss: 0.10746
Epoch [20/30] Training [288/488] Loss: 0.13294
Epoch [20/30] Training [289/488] Loss: 0.16280
Epoch [20/30] Training [290/488] Loss: 0.15993
Epoch [20/30] Training [291/488] Loss: 0.33627
Epoch [20/30] Training [292/488] Loss: 0.19868
Epoch [20/30] Training [293/488] Loss: 0.48104
Epoch [20/30] Training [294/488] Loss: 0.15867
Epoch [20/30] Training [295/488] Loss: 0.21794
Epoch [20/30] Training [296/488] Loss: 0.15716
Epoch [20/30] Training [297/488] Loss: 0.13395
Epoch [20/30] Training [298/488] Loss: 0.13761
Epoch [20/30] Training [299/488] Loss: 0.26792
Epoch [20/30] Training [300/488] Loss: 0.21214
Epoch [20/30] Training [301/488] Loss: 0.22051
Epoch [20/30] Training [302/488] Loss: 0.88460
Epoch [20/30] Training [303/488] Loss: 0.12809
Epoch [20/30] Training [304/488] Loss: 0.29801
Epoch [20/30] Training [305/488] Loss: 0.29705
Epoch [20/30] Training [306/488] Loss: 0.12782
Epoch [20/30] Training [307/488] Loss: 0.21116
Epoch [20/30] Training [308/488] Loss: 0.11977
Epoch [20/30] Training [309/488] Loss: 0.15971
Epoch [20/30] Training [310/488] Loss: 0.11767
Epoch [20/30] Training [311/488] Loss: 0.23164
Epoch [20/30] Training [312/488] Loss: 0.16578
Epoch [20/30] Training [313/488] Loss: 0.26851
Epoch [20/30] Training [314/488] Loss: 0.12989
Epoch [20/30] Training [315/488] Loss: 0.21067
Epoch [20/30] Training [316/488] Loss: 0.23116
Epoch [20/30] Training [317/488] Loss: 0.20693
Epoch [20/30] Training [318/488] Loss: 0.20118
Epoch [20/30] Training [319/488] Loss: 0.13075
Epoch [20/30] Training [320/488] Loss: 0.15159
Epoch [20/30] Training [321/488] Loss: 0.17547
Epoch [20/30] Training [322/488] Loss: 0.14206
Epoch [20/30] Training [323/488] Loss: 0.17240
Epoch [20/30] Training [324/488] Loss: 0.16606
Epoch [20/30] Training [325/488] Loss: 0.40217
Epoch [20/30] Training [326/488] Loss: 0.23195
Epoch [20/30] Training [327/488] Loss: 0.17972
Epoch [20/30] Training [328/488] Loss: 0.23548
Epoch [20/30] Training [329/488] Loss: 0.13142
Epoch [20/30] Training [330/488] Loss: 0.22673
Epoch [20/30] Training [331/488] Loss: 0.17868
Epoch [20/30] Training [332/488] Loss: 0.36126
Epoch [20/30] Training [333/488] Loss: 0.13561
Epoch [20/30] Training [334/488] Loss: 0.17158
Epoch [20/30] Training [335/488] Loss: 0.18749
Epoch [20/30] Training [336/488] Loss: 0.37393
Epoch [20/30] Training [337/488] Loss: 0.16342
Epoch [20/30] Training [338/488] Loss: 0.14883
Epoch [20/30] Training [339/488] Loss: 0.12374
Epoch [20/30] Training [340/488] Loss: 0.14062
Epoch [20/30] Training [341/488] Loss: 0.17751
Epoch [20/30] Training [342/488] Loss: 0.13258
Epoch [20/30] Training [343/488] Loss: 0.18421
Epoch [20/30] Training [344/488] Loss: 0.12499
Epoch [20/30] Training [345/488] Loss: 0.10913
Epoch [20/30] Training [346/488] Loss: 0.13845
Epoch [20/30] Training [347/488] Loss: 0.32272
Epoch [20/30] Training [348/488] Loss: 0.13873
Epoch [20/30] Training [349/488] Loss: 0.19435
Epoch [20/30] Training [350/488] Loss: 0.24722
Epoch [20/30] Training [351/488] Loss: 0.12758
Epoch [20/30] Training [352/488] Loss: 0.12074
Epoch [20/30] Training [353/488] Loss: 0.14741
Epoch [20/30] Training [354/488] Loss: 0.13590
Epoch [20/30] Training [355/488] Loss: 0.24246
Epoch [20/30] Training [356/488] Loss: 0.11686
Epoch [20/30] Training [357/488] Loss: 0.13598
Epoch [20/30] Training [358/488] Loss: 0.21849
Epoch [20/30] Training [359/488] Loss: 0.29555
Epoch [20/30] Training [360/488] Loss: 0.11988
Epoch [20/30] Training [361/488] Loss: 0.12897
Epoch [20/30] Training [362/488] Loss: 0.15448
Epoch [20/30] Training [363/488] Loss: 0.11325
Epoch [20/30] Training [364/488] Loss: 0.11818
Epoch [20/30] Training [365/488] Loss: 0.11200
Epoch [20/30] Training [366/488] Loss: 0.32105
Epoch [20/30] Training [367/488] Loss: 0.11359
Epoch [20/30] Training [368/488] Loss: 0.13991
Epoch [20/30] Training [369/488] Loss: 0.11117
Epoch [20/30] Training [370/488] Loss: 0.13965
Epoch [20/30] Training [371/488] Loss: 0.21627
Epoch [20/30] Training [372/488] Loss: 0.20900
Epoch [20/30] Training [373/488] Loss: 0.13860
Epoch [20/30] Training [374/488] Loss: 0.14317
Epoch [20/30] Training [375/488] Loss: 0.13039
Epoch [20/30] Training [376/488] Loss: 0.18067
Epoch [20/30] Training [377/488] Loss: 0.27602
Epoch [20/30] Training [378/488] Loss: 0.15651
Epoch [20/30] Training [379/488] Loss: 0.13806
Epoch [20/30] Training [380/488] Loss: 0.15096
Epoch [20/30] Training [381/488] Loss: 0.16078
Epoch [20/30] Training [382/488] Loss: 0.11914
Epoch [20/30] Training [383/488] Loss: 0.13980
Epoch [20/30] Training [384/488] Loss: 0.09169
Epoch [20/30] Training [385/488] Loss: 0.31983
Epoch [20/30] Training [386/488] Loss: 0.26620
Epoch [20/30] Training [387/488] Loss: 0.14870
Epoch [20/30] Training [388/488] Loss: 0.38556
Epoch [20/30] Training [389/488] Loss: 0.21322
Epoch [20/30] Training [390/488] Loss: 0.15307
Epoch [20/30] Training [391/488] Loss: 0.48370
Epoch [20/30] Training [392/488] Loss: 0.13343
Epoch [20/30] Training [393/488] Loss: 0.13701
Epoch [20/30] Training [394/488] Loss: 0.17744
Epoch [20/30] Training [395/488] Loss: 0.11114
Epoch [20/30] Training [396/488] Loss: 0.18179
Epoch [20/30] Training [397/488] Loss: 0.12285
Epoch [20/30] Training [398/488] Loss: 0.12382
Epoch [20/30] Training [399/488] Loss: 0.12842
Epoch [20/30] Training [400/488] Loss: 0.20257
Epoch [20/30] Training [401/488] Loss: 0.12406
Epoch [20/30] Training [402/488] Loss: 0.11114
Epoch [20/30] Training [403/488] Loss: 0.11970
Epoch [20/30] Training [404/488] Loss: 0.12553
Epoch [20/30] Training [405/488] Loss: 0.16915
Epoch [20/30] Training [406/488] Loss: 0.10350
Epoch [20/30] Training [407/488] Loss: 0.32569
Epoch [20/30] Training [408/488] Loss: 0.14307
Epoch [20/30] Training [409/488] Loss: 0.10980
Epoch [20/30] Training [410/488] Loss: 0.27339
Epoch [20/30] Training [411/488] Loss: 0.19161
Epoch [20/30] Training [412/488] Loss: 0.16042
Epoch [20/30] Training [413/488] Loss: 0.16881
Epoch [20/30] Training [414/488] Loss: 0.17236
Epoch [20/30] Training [415/488] Loss: 0.17340
Epoch [20/30] Training [416/488] Loss: 0.72169
Epoch [20/30] Training [417/488] Loss: 0.19904
Epoch [20/30] Training [418/488] Loss: 0.15909
Epoch [20/30] Training [419/488] Loss: 0.13000
Epoch [20/30] Training [420/488] Loss: 0.27938
Epoch [20/30] Training [421/488] Loss: 0.13975
Epoch [20/30] Training [422/488] Loss: 0.35636
Epoch [20/30] Training [423/488] Loss: 0.33131
Epoch [20/30] Training [424/488] Loss: 0.19194
Epoch [20/30] Training [425/488] Loss: 0.36141
Epoch [20/30] Training [426/488] Loss: 0.12722
Epoch [20/30] Training [427/488] Loss: 0.12836
Epoch [20/30] Training [428/488] Loss: 0.19791
Epoch [20/30] Training [429/488] Loss: 0.15934
Epoch [20/30] Training [430/488] Loss: 0.25124
Epoch [20/30] Training [431/488] Loss: 0.71826
Epoch [20/30] Training [432/488] Loss: 0.28367
Epoch [20/30] Training [433/488] Loss: 0.16165
Epoch [20/30] Training [434/488] Loss: 0.16902
Epoch [20/30] Training [435/488] Loss: 0.19934
Epoch [20/30] Training [436/488] Loss: 0.15395
Epoch [20/30] Training [437/488] Loss: 0.15631
Epoch [20/30] Training [438/488] Loss: 0.14631
Epoch [20/30] Training [439/488] Loss: 0.21678
Epoch [20/30] Training [440/488] Loss: 0.19151
Epoch [20/30] Training [441/488] Loss: 0.42982
Epoch [20/30] Training [442/488] Loss: 0.21712
Epoch [20/30] Training [443/488] Loss: 0.12351
Epoch [20/30] Training [444/488] Loss: 0.10711
Epoch [20/30] Training [445/488] Loss: 0.11500
Epoch [20/30] Training [446/488] Loss: 0.39318
Epoch [20/30] Training [447/488] Loss: 0.39129
Epoch [20/30] Training [448/488] Loss: 0.17472
Epoch [20/30] Training [449/488] Loss: 0.13075
Epoch [20/30] Training [450/488] Loss: 0.11496
Epoch [20/30] Training [451/488] Loss: 0.11375
Epoch [20/30] Training [452/488] Loss: 0.72244
Epoch [20/30] Training [453/488] Loss: 0.40827
Epoch [20/30] Training [454/488] Loss: 0.29154
Epoch [20/30] Training [455/488] Loss: 0.11962
Epoch [20/30] Training [456/488] Loss: 0.18861
Epoch [20/30] Training [457/488] Loss: 0.20673
Epoch [20/30] Training [458/488] Loss: 0.82640
Epoch [20/30] Training [459/488] Loss: 0.22975
Epoch [20/30] Training [460/488] Loss: 0.13975
Epoch [20/30] Training [461/488] Loss: 0.50768
Epoch [20/30] Training [462/488] Loss: 0.37971
Epoch [20/30] Training [463/488] Loss: 0.17167
Epoch [20/30] Training [464/488] Loss: 0.12725
Epoch [20/30] Training [465/488] Loss: 0.20894
Epoch [20/30] Training [466/488] Loss: 0.71103
Epoch [20/30] Training [467/488] Loss: 0.11112
Epoch [20/30] Training [468/488] Loss: 0.17420
Epoch [20/30] Training [469/488] Loss: 0.17671
Epoch [20/30] Training [470/488] Loss: 0.12671
Epoch [20/30] Training [471/488] Loss: 0.11418
Epoch [20/30] Training [472/488] Loss: 0.16818
Epoch [20/30] Training [473/488] Loss: 0.14921
Epoch [20/30] Training [474/488] Loss: 0.15302
Epoch [20/30] Training [475/488] Loss: 0.18490
Epoch [20/30] Training [476/488] Loss: 0.15070
Epoch [20/30] Training [477/488] Loss: 0.64550
Epoch [20/30] Training [478/488] Loss: 0.11816
Epoch [20/30] Training [479/488] Loss: 0.15821
Epoch [20/30] Training [480/488] Loss: 0.14724
Epoch [20/30] Training [481/488] Loss: 0.14629
Epoch [20/30] Training [482/488] Loss: 0.12882
Epoch [20/30] Training [483/488] Loss: 0.23167
Epoch [20/30] Training [484/488] Loss: 0.12711
Epoch [20/30] Training [485/488] Loss: 0.38793
Epoch [20/30] Training [486/488] Loss: 0.11487
Epoch [20/30] Training [487/488] Loss: 0.12797
Epoch [20/30] Training [488/488] Loss: 0.13295
Epoch [20/30] Training metric {'Train/mean dice_metric': 0.8853263258934021, 'Train/TC dice_metric': 0.9000460505485535, 'Train/WT dice_metric': 0.9318640828132629, 'Train/ET dice_metric': 0.8240687251091003}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [20/30] Validation [1/123] Loss: 0.18918  focal_loss 0.00196  dice_loss 0.18722
Epoch [20/30] Validation [2/123] Loss: 0.34861  focal_loss 0.00117  dice_loss 0.34743
Epoch [20/30] Validation [3/123] Loss: 0.17012  focal_loss 0.00169  dice_loss 0.16843
Epoch [20/30] Validation [4/123] Loss: 0.24405  focal_loss 0.00137  dice_loss 0.24268
Epoch [20/30] Validation [5/123] Loss: 0.33311  focal_loss 0.00967  dice_loss 0.32344
Epoch [20/30] Validation [6/123] Loss: 0.30992  focal_loss 0.00152  dice_loss 0.30840
Epoch [20/30] Validation [7/123] Loss: 0.33191  focal_loss 0.00063  dice_loss 0.33129
Epoch [20/30] Validation [8/123] Loss: 0.35465  focal_loss 0.00168  dice_loss 0.35297
Epoch [20/30] Validation [9/123] Loss: 0.25304  focal_loss 0.00158  dice_loss 0.25146
Epoch [20/30] Validation [10/123] Loss: 0.42754  focal_loss 0.00206  dice_loss 0.42548
Epoch [20/30] Validation [11/123] Loss: 0.45962  focal_loss 0.00181  dice_loss 0.45780
Epoch [20/30] Validation [12/123] Loss: 0.19634  focal_loss 0.00167  dice_loss 0.19466
Epoch [20/30] Validation [13/123] Loss: 0.18491  focal_loss 0.00298  dice_loss 0.18193
Epoch [20/30] Validation [14/123] Loss: 0.20656  focal_loss 0.00082  dice_loss 0.20574
Epoch [20/30] Validation [15/123] Loss: 0.34155  focal_loss 0.00135  dice_loss 0.34020
Epoch [20/30] Validation [16/123] Loss: 0.45163  focal_loss 0.00184  dice_loss 0.44979
Epoch [20/30] Validation [17/123] Loss: 0.46145  focal_loss 0.00140  dice_loss 0.46005
Epoch [20/30] Validation [18/123] Loss: 0.35492  focal_loss 0.00373  dice_loss 0.35119
Epoch [20/30] Validation [19/123] Loss: 0.28577  focal_loss 0.00643  dice_loss 0.27934
Epoch [20/30] Validation [20/123] Loss: 0.42545  focal_loss 0.00092  dice_loss 0.42453
Epoch [20/30] Validation [21/123] Loss: 0.30567  focal_loss 0.00070  dice_loss 0.30497
Epoch [20/30] Validation [22/123] Loss: 0.71826  focal_loss 0.00681  dice_loss 0.71145
Epoch [20/30] Validation [23/123] Loss: 0.18329  focal_loss 0.00153  dice_loss 0.18175
Epoch [20/30] Validation [24/123] Loss: 0.26866  focal_loss 0.00229  dice_loss 0.26638
Epoch [20/30] Validation [25/123] Loss: 0.37792  focal_loss 0.00617  dice_loss 0.37174
Epoch [20/30] Validation [26/123] Loss: 0.18802  focal_loss 0.00159  dice_loss 0.18643
Epoch [20/30] Validation [27/123] Loss: 0.22401  focal_loss 0.00228  dice_loss 0.22173
Epoch [20/30] Validation [28/123] Loss: 0.44905  focal_loss 0.00330  dice_loss 0.44575
Epoch [20/30] Validation [29/123] Loss: 0.32358  focal_loss 0.00182  dice_loss 0.32176
Epoch [20/30] Validation [30/123] Loss: 0.23813  focal_loss 0.00375  dice_loss 0.23439
Epoch [20/30] Validation [31/123] Loss: 0.17775  focal_loss 0.00144  dice_loss 0.17630
Epoch [20/30] Validation [32/123] Loss: 0.27409  focal_loss 0.00267  dice_loss 0.27142
Epoch [20/30] Validation [33/123] Loss: 0.32575  focal_loss 0.00144  dice_loss 0.32430
Epoch [20/30] Validation [34/123] Loss: 0.25273  focal_loss 0.00076  dice_loss 0.25198
Epoch [20/30] Validation [35/123] Loss: 0.21478  focal_loss 0.00168  dice_loss 0.21310
Epoch [20/30] Validation [36/123] Loss: 0.24261  focal_loss 0.00105  dice_loss 0.24156
Epoch [20/30] Validation [37/123] Loss: 0.32490  focal_loss 0.00163  dice_loss 0.32326
Epoch [20/30] Validation [38/123] Loss: 0.19484  focal_loss 0.00148  dice_loss 0.19335
Epoch [20/30] Validation [39/123] Loss: 0.19263  focal_loss 0.00142  dice_loss 0.19121
Epoch [20/30] Validation [40/123] Loss: 0.28847  focal_loss 0.00072  dice_loss 0.28775
Epoch [20/30] Validation [41/123] Loss: 0.21298  focal_loss 0.00464  dice_loss 0.20834
Epoch [20/30] Validation [42/123] Loss: 0.18106  focal_loss 0.00131  dice_loss 0.17975
Epoch [20/30] Validation [43/123] Loss: 0.27986  focal_loss 0.02285  dice_loss 0.25701
Epoch [20/30] Validation [44/123] Loss: 0.55427  focal_loss 0.00951  dice_loss 0.54475
Epoch [20/30] Validation [45/123] Loss: 0.29933  focal_loss 0.00256  dice_loss 0.29677
Epoch [20/30] Validation [46/123] Loss: 0.32336  focal_loss 0.00263  dice_loss 0.32074
Epoch [20/30] Validation [47/123] Loss: 0.27109  focal_loss 0.00110  dice_loss 0.27000
Epoch [20/30] Validation [48/123] Loss: 0.38236  focal_loss 0.00341  dice_loss 0.37895
Epoch [20/30] Validation [49/123] Loss: 0.20338  focal_loss 0.00360  dice_loss 0.19978
Epoch [20/30] Validation [50/123] Loss: 0.19299  focal_loss 0.00205  dice_loss 0.19095
Epoch [20/30] Validation [51/123] Loss: 0.37448  focal_loss 0.00919  dice_loss 0.36529
Epoch [20/30] Validation [52/123] Loss: 0.20519  focal_loss 0.00077  dice_loss 0.20442
Epoch [20/30] Validation [53/123] Loss: 0.25904  focal_loss 0.00078  dice_loss 0.25826
Epoch [20/30] Validation [54/123] Loss: 0.30058  focal_loss 0.00084  dice_loss 0.29974
Epoch [20/30] Validation [55/123] Loss: 0.26442  focal_loss 0.00115  dice_loss 0.26326
Epoch [20/30] Validation [56/123] Loss: 0.20058  focal_loss 0.00239  dice_loss 0.19819
Epoch [20/30] Validation [57/123] Loss: 0.27670  focal_loss 0.00211  dice_loss 0.27459
Epoch [20/30] Validation [58/123] Loss: 0.23490  focal_loss 0.00183  dice_loss 0.23307
Epoch [20/30] Validation [59/123] Loss: 0.61518  focal_loss 0.01442  dice_loss 0.60076
Epoch [20/30] Validation [60/123] Loss: 0.23290  focal_loss 0.00263  dice_loss 0.23027
Epoch [20/30] Validation [61/123] Loss: 0.58639  focal_loss 0.00102  dice_loss 0.58537
Epoch [20/30] Validation [62/123] Loss: 0.45754  focal_loss 0.00683  dice_loss 0.45071
Epoch [20/30] Validation [63/123] Loss: 0.34518  focal_loss 0.00104  dice_loss 0.34414
Epoch [20/30] Validation [64/123] Loss: 0.37256  focal_loss 0.00461  dice_loss 0.36796
Epoch [20/30] Validation [65/123] Loss: 0.21638  focal_loss 0.00111  dice_loss 0.21527
Epoch [20/30] Validation [66/123] Loss: 0.22105  focal_loss 0.00110  dice_loss 0.21995
Epoch [20/30] Validation [67/123] Loss: 0.36621  focal_loss 0.00536  dice_loss 0.36084
Epoch [20/30] Validation [68/123] Loss: 0.33042  focal_loss 0.00068  dice_loss 0.32975
Epoch [20/30] Validation [69/123] Loss: 0.37926  focal_loss 0.00493  dice_loss 0.37432
Epoch [20/30] Validation [70/123] Loss: 0.30154  focal_loss 0.00175  dice_loss 0.29979
Epoch [20/30] Validation [71/123] Loss: 0.20492  focal_loss 0.00090  dice_loss 0.20402
Epoch [20/30] Validation [72/123] Loss: 0.19480  focal_loss 0.00167  dice_loss 0.19313
Epoch [20/30] Validation [73/123] Loss: 0.30310  focal_loss 0.00323  dice_loss 0.29987
Epoch [20/30] Validation [74/123] Loss: 0.28815  focal_loss 0.00234  dice_loss 0.28581
Epoch [20/30] Validation [75/123] Loss: 0.23246  focal_loss 0.00118  dice_loss 0.23128
Epoch [20/30] Validation [76/123] Loss: 0.52588  focal_loss 0.00424  dice_loss 0.52164
Epoch [20/30] Validation [77/123] Loss: 0.34414  focal_loss 0.00074  dice_loss 0.34340
Epoch [20/30] Validation [78/123] Loss: 0.25280  focal_loss 0.00138  dice_loss 0.25142
Epoch [20/30] Validation [79/123] Loss: 0.28034  focal_loss 0.00098  dice_loss 0.27936
Epoch [20/30] Validation [80/123] Loss: 0.20938  focal_loss 0.00274  dice_loss 0.20664
Epoch [20/30] Validation [81/123] Loss: 0.23487  focal_loss 0.00140  dice_loss 0.23346
Epoch [20/30] Validation [82/123] Loss: 0.19643  focal_loss 0.00115  dice_loss 0.19528
Epoch [20/30] Validation [83/123] Loss: 0.37595  focal_loss 0.01114  dice_loss 0.36481
Epoch [20/30] Validation [84/123] Loss: 0.23520  focal_loss 0.00114  dice_loss 0.23406
Epoch [20/30] Validation [85/123] Loss: 0.35408  focal_loss 0.00647  dice_loss 0.34760
Epoch [20/30] Validation [86/123] Loss: 0.20858  focal_loss 0.00116  dice_loss 0.20742
Epoch [20/30] Validation [87/123] Loss: 0.21013  focal_loss 0.00269  dice_loss 0.20744
Epoch [20/30] Validation [88/123] Loss: 0.22138  focal_loss 0.00154  dice_loss 0.21985
Epoch [20/30] Validation [89/123] Loss: 0.19078  focal_loss 0.00192  dice_loss 0.18885
Epoch [20/30] Validation [90/123] Loss: 0.26932  focal_loss 0.00150  dice_loss 0.26782
Epoch [20/30] Validation [91/123] Loss: 0.22835  focal_loss 0.00154  dice_loss 0.22680
Epoch [20/30] Validation [92/123] Loss: 0.17616  focal_loss 0.00123  dice_loss 0.17493
Epoch [20/30] Validation [93/123] Loss: 0.19476  focal_loss 0.00156  dice_loss 0.19319
Epoch [20/30] Validation [94/123] Loss: 0.32838  focal_loss 0.00162  dice_loss 0.32677
Epoch [20/30] Validation [95/123] Loss: 0.23750  focal_loss 0.00204  dice_loss 0.23545
Epoch [20/30] Validation [96/123] Loss: 0.28957  focal_loss 0.00153  dice_loss 0.28804
Epoch [20/30] Validation [97/123] Loss: 0.52359  focal_loss 0.00407  dice_loss 0.51952
Epoch [20/30] Validation [98/123] Loss: 0.29294  focal_loss 0.00096  dice_loss 0.29198
Epoch [20/30] Validation [99/123] Loss: 0.28935  focal_loss 0.00057  dice_loss 0.28878
Epoch [20/30] Validation [100/123] Loss: 0.31173  focal_loss 0.00089  dice_loss 0.31085
Epoch [20/30] Validation [101/123] Loss: 0.27142  focal_loss 0.00097  dice_loss 0.27045
Epoch [20/30] Validation [102/123] Loss: 0.32909  focal_loss 0.00104  dice_loss 0.32805
Epoch [20/30] Validation [103/123] Loss: 0.41883  focal_loss 0.00071  dice_loss 0.41812
Epoch [20/30] Validation [104/123] Loss: 0.39816  focal_loss 0.00344  dice_loss 0.39471
Epoch [20/30] Validation [105/123] Loss: 0.20291  focal_loss 0.00326  dice_loss 0.19965
Epoch [20/30] Validation [106/123] Loss: 0.20947  focal_loss 0.00083  dice_loss 0.20864
Epoch [20/30] Validation [107/123] Loss: 0.48849  focal_loss 0.00239  dice_loss 0.48609
Epoch [20/30] Validation [108/123] Loss: 0.21121  focal_loss 0.00091  dice_loss 0.21029
Epoch [20/30] Validation [109/123] Loss: 0.20422  focal_loss 0.00455  dice_loss 0.19967
Epoch [20/30] Validation [110/123] Loss: 0.33702  focal_loss 0.00259  dice_loss 0.33442
Epoch [20/30] Validation [111/123] Loss: 0.34618  focal_loss 0.00231  dice_loss 0.34387
Epoch [20/30] Validation [112/123] Loss: 0.28700  focal_loss 0.00076  dice_loss 0.28623
Epoch [20/30] Validation [113/123] Loss: 0.23693  focal_loss 0.00124  dice_loss 0.23569
Epoch [20/30] Validation [114/123] Loss: 0.32218  focal_loss 0.00512  dice_loss 0.31706
Epoch [20/30] Validation [115/123] Loss: 0.29330  focal_loss 0.00627  dice_loss 0.28703
Epoch [20/30] Validation [116/123] Loss: 0.23734  focal_loss 0.00069  dice_loss 0.23665
Epoch [20/30] Validation [117/123] Loss: 0.25169  focal_loss 0.00111  dice_loss 0.25058
Epoch [20/30] Validation [118/123] Loss: 0.16698  focal_loss 0.00181  dice_loss 0.16518
Epoch [20/30] Validation [119/123] Loss: 0.18908  focal_loss 0.00130  dice_loss 0.18778
Epoch [20/30] Validation [120/123] Loss: 0.22246  focal_loss 0.00164  dice_loss 0.22082
Epoch [20/30] Validation [121/123] Loss: 0.61598  focal_loss 0.01405  dice_loss 0.60193
Epoch [20/30] Validation [122/123] Loss: 0.53329  focal_loss 0.00044  dice_loss 0.53285
Epoch [20/30] Validation [123/123] Loss: 0.21879  focal_loss 0.00156  dice_loss 0.21724
Epoch [20/30] Validation metric {'Val/mean dice_metric': 0.8848370313644409, 'Val/TC dice_metric': 0.8985941410064697, 'Val/WT dice_metric': 0.9311317205429077, 'Val/ET dice_metric': 0.824785053730011}
Epoch [20/30] lr = [0.0004063093427071377, 0.0004063093427071377] best acc: tensor([0.8753], device='cuda:0'), mean acc: tensor([0.8848], device='cuda:0'), mean class: tensor([0.8986, 0.9311, 0.8248], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [21/30] Training [1/488] Loss: 0.25541
Epoch [21/30] Training [2/488] Loss: 0.14532
Epoch [21/30] Training [3/488] Loss: 0.17133
Epoch [21/30] Training [4/488] Loss: 0.19094
Epoch [21/30] Training [5/488] Loss: 0.12999
Epoch [21/30] Training [6/488] Loss: 0.13773
Epoch [21/30] Training [7/488] Loss: 0.11237
Epoch [21/30] Training [8/488] Loss: 0.13036
Epoch [21/30] Training [9/488] Loss: 0.12172
Epoch [21/30] Training [10/488] Loss: 0.26883
Epoch [21/30] Training [11/488] Loss: 0.16541
Epoch [21/30] Training [12/488] Loss: 0.19742
Epoch [21/30] Training [13/488] Loss: 0.20520
Epoch [21/30] Training [14/488] Loss: 0.10253
Epoch [21/30] Training [15/488] Loss: 0.14012
Epoch [21/30] Training [16/488] Loss: 0.22853
Epoch [21/30] Training [17/488] Loss: 0.29280
Epoch [21/30] Training [18/488] Loss: 0.20957
Epoch [21/30] Training [19/488] Loss: 0.21008
Epoch [21/30] Training [20/488] Loss: 0.10846
Epoch [21/30] Training [21/488] Loss: 0.12001
Epoch [21/30] Training [22/488] Loss: 0.27937
Epoch [21/30] Training [23/488] Loss: 0.29806
Epoch [21/30] Training [24/488] Loss: 0.24990
Epoch [21/30] Training [25/488] Loss: 0.28522
Epoch [21/30] Training [26/488] Loss: 0.27733
Epoch [21/30] Training [27/488] Loss: 0.20268
Epoch [21/30] Training [28/488] Loss: 0.12545
Epoch [21/30] Training [29/488] Loss: 0.12597
Epoch [21/30] Training [30/488] Loss: 0.19512
Epoch [21/30] Training [31/488] Loss: 0.18140
Epoch [21/30] Training [32/488] Loss: 0.12175
Epoch [21/30] Training [33/488] Loss: 0.11624
Epoch [21/30] Training [34/488] Loss: 0.56456
Epoch [21/30] Training [35/488] Loss: 0.12131
Epoch [21/30] Training [36/488] Loss: 0.19088
Epoch [21/30] Training [37/488] Loss: 0.16815
Epoch [21/30] Training [38/488] Loss: 0.10360
Epoch [21/30] Training [39/488] Loss: 0.18348
Epoch [21/30] Training [40/488] Loss: 0.24315
Epoch [21/30] Training [41/488] Loss: 0.13035
Epoch [21/30] Training [42/488] Loss: 0.13514
Epoch [21/30] Training [43/488] Loss: 0.10348
Epoch [21/30] Training [44/488] Loss: 0.15251
Epoch [21/30] Training [45/488] Loss: 0.28050
Epoch [21/30] Training [46/488] Loss: 0.23024
Epoch [21/30] Training [47/488] Loss: 0.12267
Epoch [21/30] Training [48/488] Loss: 0.28153
Epoch [21/30] Training [49/488] Loss: 0.12606
Epoch [21/30] Training [50/488] Loss: 0.12389
Epoch [21/30] Training [51/488] Loss: 0.39349
Epoch [21/30] Training [52/488] Loss: 0.11670
Epoch [21/30] Training [53/488] Loss: 0.19592
Epoch [21/30] Training [54/488] Loss: 0.35895
Epoch [21/30] Training [55/488] Loss: 0.15664
Epoch [21/30] Training [56/488] Loss: 0.15429
Epoch [21/30] Training [57/488] Loss: 0.17526
Epoch [21/30] Training [58/488] Loss: 0.17360
Epoch [21/30] Training [59/488] Loss: 0.33361
Epoch [21/30] Training [60/488] Loss: 0.11955
Epoch [21/30] Training [61/488] Loss: 0.30790
Epoch [21/30] Training [62/488] Loss: 0.14236
Epoch [21/30] Training [63/488] Loss: 0.12904
Epoch [21/30] Training [64/488] Loss: 0.17150
Epoch [21/30] Training [65/488] Loss: 0.36954
Epoch [21/30] Training [66/488] Loss: 0.14391
Epoch [21/30] Training [67/488] Loss: 0.18360
Epoch [21/30] Training [68/488] Loss: 0.27381
Epoch [21/30] Training [69/488] Loss: 0.10736
Epoch [21/30] Training [70/488] Loss: 0.18532
Epoch [21/30] Training [71/488] Loss: 0.14381
Epoch [21/30] Training [72/488] Loss: 0.20889
Epoch [21/30] Training [73/488] Loss: 0.11828
Epoch [21/30] Training [74/488] Loss: 0.32129
Epoch [21/30] Training [75/488] Loss: 0.13155
Epoch [21/30] Training [76/488] Loss: 0.26200
Epoch [21/30] Training [77/488] Loss: 0.20834
Epoch [21/30] Training [78/488] Loss: 0.11149
Epoch [21/30] Training [79/488] Loss: 0.47610
Epoch [21/30] Training [80/488] Loss: 0.14492
Epoch [21/30] Training [81/488] Loss: 0.15622
Epoch [21/30] Training [82/488] Loss: 0.10418
Epoch [21/30] Training [83/488] Loss: 0.14693
Epoch [21/30] Training [84/488] Loss: 0.28613
Epoch [21/30] Training [85/488] Loss: 0.18487
Epoch [21/30] Training [86/488] Loss: 0.29430
Epoch [21/30] Training [87/488] Loss: 0.39630
Epoch [21/30] Training [88/488] Loss: 0.42635
Epoch [21/30] Training [89/488] Loss: 0.30355
Epoch [21/30] Training [90/488] Loss: 0.13448
Epoch [21/30] Training [91/488] Loss: 0.12758
Epoch [21/30] Training [92/488] Loss: 0.19434
Epoch [21/30] Training [93/488] Loss: 0.43086
Epoch [21/30] Training [94/488] Loss: 0.10657
Epoch [21/30] Training [95/488] Loss: 0.15673
Epoch [21/30] Training [96/488] Loss: 0.18117
Epoch [21/30] Training [97/488] Loss: 0.12414
Epoch [21/30] Training [98/488] Loss: 0.13152
Epoch [21/30] Training [99/488] Loss: 0.11761
Epoch [21/30] Training [100/488] Loss: 0.11610
Epoch [21/30] Training [101/488] Loss: 0.12984
Epoch [21/30] Training [102/488] Loss: 0.14370
Epoch [21/30] Training [103/488] Loss: 0.15787
Epoch [21/30] Training [104/488] Loss: 0.21185
Epoch [21/30] Training [105/488] Loss: 0.13606
Epoch [21/30] Training [106/488] Loss: 0.24253
Epoch [21/30] Training [107/488] Loss: 0.11418
Epoch [21/30] Training [108/488] Loss: 0.21651
Epoch [21/30] Training [109/488] Loss: 0.12221
Epoch [21/30] Training [110/488] Loss: 0.16605
Epoch [21/30] Training [111/488] Loss: 0.12064
Epoch [21/30] Training [112/488] Loss: 0.22258
Epoch [21/30] Training [113/488] Loss: 0.21526
Epoch [21/30] Training [114/488] Loss: 0.42118
Epoch [21/30] Training [115/488] Loss: 0.76609
Epoch [21/30] Training [116/488] Loss: 0.14242
Epoch [21/30] Training [117/488] Loss: 0.13995
Epoch [21/30] Training [118/488] Loss: 0.17012
Epoch [21/30] Training [119/488] Loss: 0.13741
Epoch [21/30] Training [120/488] Loss: 0.14031
Epoch [21/30] Training [121/488] Loss: 0.14167
Epoch [21/30] Training [122/488] Loss: 0.11984
Epoch [21/30] Training [123/488] Loss: 0.14976
Epoch [21/30] Training [124/488] Loss: 0.28258
Epoch [21/30] Training [125/488] Loss: 0.12092
Epoch [21/30] Training [126/488] Loss: 0.35355
Epoch [21/30] Training [127/488] Loss: 0.22439
Epoch [21/30] Training [128/488] Loss: 0.29251
Epoch [21/30] Training [129/488] Loss: 0.14252
Epoch [21/30] Training [130/488] Loss: 0.45951
Epoch [21/30] Training [131/488] Loss: 0.16121
Epoch [21/30] Training [132/488] Loss: 0.16901
Epoch [21/30] Training [133/488] Loss: 0.22792
Epoch [21/30] Training [134/488] Loss: 0.14874
Epoch [21/30] Training [135/488] Loss: 0.33895
Epoch [21/30] Training [136/488] Loss: 0.14799
Epoch [21/30] Training [137/488] Loss: 0.13811
Epoch [21/30] Training [138/488] Loss: 0.23786
Epoch [21/30] Training [139/488] Loss: 0.20068
Epoch [21/30] Training [140/488] Loss: 0.21780
Epoch [21/30] Training [141/488] Loss: 0.25157
Epoch [21/30] Training [142/488] Loss: 0.11424
Epoch [21/30] Training [143/488] Loss: 0.18583
Epoch [21/30] Training [144/488] Loss: 0.20322
Epoch [21/30] Training [145/488] Loss: 0.17758
Epoch [21/30] Training [146/488] Loss: 0.20837
Epoch [21/30] Training [147/488] Loss: 0.09426
Epoch [21/30] Training [148/488] Loss: 0.11049
Epoch [21/30] Training [149/488] Loss: 0.39305
Epoch [21/30] Training [150/488] Loss: 0.11580
Epoch [21/30] Training [151/488] Loss: 0.31376
Epoch [21/30] Training [152/488] Loss: 0.29774
Epoch [21/30] Training [153/488] Loss: 0.36357
Epoch [21/30] Training [154/488] Loss: 0.24599
Epoch [21/30] Training [155/488] Loss: 0.21885
Epoch [21/30] Training [156/488] Loss: 0.35874
Epoch [21/30] Training [157/488] Loss: 0.46373
Epoch [21/30] Training [158/488] Loss: 0.65135
Epoch [21/30] Training [159/488] Loss: 0.14442
Epoch [21/30] Training [160/488] Loss: 0.27342
Epoch [21/30] Training [161/488] Loss: 0.13908
Epoch [21/30] Training [162/488] Loss: 0.09542
Epoch [21/30] Training [163/488] Loss: 0.17465
Epoch [21/30] Training [164/488] Loss: 0.16634
Epoch [21/30] Training [165/488] Loss: 0.15519
Epoch [21/30] Training [166/488] Loss: 0.17389
Epoch [21/30] Training [167/488] Loss: 0.16031
Epoch [21/30] Training [168/488] Loss: 0.11501
Epoch [21/30] Training [169/488] Loss: 0.25015
Epoch [21/30] Training [170/488] Loss: 0.14667
Epoch [21/30] Training [171/488] Loss: 0.48353
Epoch [21/30] Training [172/488] Loss: 0.13521
Epoch [21/30] Training [173/488] Loss: 0.59282
Epoch [21/30] Training [174/488] Loss: 0.13101
Epoch [21/30] Training [175/488] Loss: 0.18275
Epoch [21/30] Training [176/488] Loss: 0.16219
Epoch [21/30] Training [177/488] Loss: 0.36810
Epoch [21/30] Training [178/488] Loss: 0.15162
Epoch [21/30] Training [179/488] Loss: 0.13672
Epoch [21/30] Training [180/488] Loss: 0.10881
Epoch [21/30] Training [181/488] Loss: 0.23220
Epoch [21/30] Training [182/488] Loss: 0.18224
Epoch [21/30] Training [183/488] Loss: 0.25631
Epoch [21/30] Training [184/488] Loss: 0.12191
Epoch [21/30] Training [185/488] Loss: 0.17451
Epoch [21/30] Training [186/488] Loss: 0.08961
Epoch [21/30] Training [187/488] Loss: 0.10298
Epoch [21/30] Training [188/488] Loss: 0.16781
Epoch [21/30] Training [189/488] Loss: 0.19112
Epoch [21/30] Training [190/488] Loss: 0.17547
Epoch [21/30] Training [191/488] Loss: 0.13306
Epoch [21/30] Training [192/488] Loss: 0.13693
Epoch [21/30] Training [193/488] Loss: 0.20067
Epoch [21/30] Training [194/488] Loss: 0.40909
Epoch [21/30] Training [195/488] Loss: 0.13816
Epoch [21/30] Training [196/488] Loss: 0.12054
Epoch [21/30] Training [197/488] Loss: 0.72136
Epoch [21/30] Training [198/488] Loss: 0.12908
Epoch [21/30] Training [199/488] Loss: 0.20750
Epoch [21/30] Training [200/488] Loss: 0.20449
Epoch [21/30] Training [201/488] Loss: 0.17018
Epoch [21/30] Training [202/488] Loss: 0.15896
Epoch [21/30] Training [203/488] Loss: 0.13341
Epoch [21/30] Training [204/488] Loss: 0.19223
Epoch [21/30] Training [205/488] Loss: 0.20881
Epoch [21/30] Training [206/488] Loss: 0.15365
Epoch [21/30] Training [207/488] Loss: 0.16907
Epoch [21/30] Training [208/488] Loss: 0.12066
Epoch [21/30] Training [209/488] Loss: 0.13060
Epoch [21/30] Training [210/488] Loss: 0.42421
Epoch [21/30] Training [211/488] Loss: 0.17251
Epoch [21/30] Training [212/488] Loss: 0.50235
Epoch [21/30] Training [213/488] Loss: 0.17310
Epoch [21/30] Training [214/488] Loss: 0.15285
Epoch [21/30] Training [215/488] Loss: 0.26056
Epoch [21/30] Training [216/488] Loss: 0.28638
Epoch [21/30] Training [217/488] Loss: 0.22220
Epoch [21/30] Training [218/488] Loss: 0.25369
Epoch [21/30] Training [219/488] Loss: 0.14086
Epoch [21/30] Training [220/488] Loss: 0.24799
Epoch [21/30] Training [221/488] Loss: 0.12901
Epoch [21/30] Training [222/488] Loss: 0.11652
Epoch [21/30] Training [223/488] Loss: 0.14674
Epoch [21/30] Training [224/488] Loss: 0.16241
Epoch [21/30] Training [225/488] Loss: 0.14572
Epoch [21/30] Training [226/488] Loss: 0.12121
Epoch [21/30] Training [227/488] Loss: 0.16167
Epoch [21/30] Training [228/488] Loss: 0.27308
Epoch [21/30] Training [229/488] Loss: 0.17025
Epoch [21/30] Training [230/488] Loss: 0.11979
Epoch [21/30] Training [231/488] Loss: 0.10857
Epoch [21/30] Training [232/488] Loss: 0.40082
Epoch [21/30] Training [233/488] Loss: 0.30545
Epoch [21/30] Training [234/488] Loss: 0.21459
Epoch [21/30] Training [235/488] Loss: 0.18082
Epoch [21/30] Training [236/488] Loss: 0.10804
Epoch [21/30] Training [237/488] Loss: 0.15114
Epoch [21/30] Training [238/488] Loss: 0.13125
Epoch [21/30] Training [239/488] Loss: 0.17497
Epoch [21/30] Training [240/488] Loss: 0.17972
Epoch [21/30] Training [241/488] Loss: 0.13142
Epoch [21/30] Training [242/488] Loss: 0.12149
Epoch [21/30] Training [243/488] Loss: 0.11620
Epoch [21/30] Training [244/488] Loss: 0.12217
Epoch [21/30] Training [245/488] Loss: 0.09857
Epoch [21/30] Training [246/488] Loss: 0.20283
Epoch [21/30] Training [247/488] Loss: 0.15299
Epoch [21/30] Training [248/488] Loss: 0.15295
Epoch [21/30] Training [249/488] Loss: 0.25456
Epoch [21/30] Training [250/488] Loss: 0.09228
Epoch [21/30] Training [251/488] Loss: 0.15892
Epoch [21/30] Training [252/488] Loss: 0.14742
Epoch [21/30] Training [253/488] Loss: 0.13939
Epoch [21/30] Training [254/488] Loss: 0.37578
Epoch [21/30] Training [255/488] Loss: 0.51442
Epoch [21/30] Training [256/488] Loss: 0.17542
Epoch [21/30] Training [257/488] Loss: 0.12503
Epoch [21/30] Training [258/488] Loss: 0.13679
Epoch [21/30] Training [259/488] Loss: 0.12321
Epoch [21/30] Training [260/488] Loss: 0.10315
Epoch [21/30] Training [261/488] Loss: 0.33813
Epoch [21/30] Training [262/488] Loss: 0.19181
Epoch [21/30] Training [263/488] Loss: 0.19693
Epoch [21/30] Training [264/488] Loss: 0.13874
Epoch [21/30] Training [265/488] Loss: 0.14654
Epoch [21/30] Training [266/488] Loss: 0.14949
Epoch [21/30] Training [267/488] Loss: 0.15786
Epoch [21/30] Training [268/488] Loss: 0.13458
Epoch [21/30] Training [269/488] Loss: 0.12784
Epoch [21/30] Training [270/488] Loss: 0.60301
Epoch [21/30] Training [271/488] Loss: 0.19996
Epoch [21/30] Training [272/488] Loss: 0.11136
Epoch [21/30] Training [273/488] Loss: 0.15522
Epoch [21/30] Training [274/488] Loss: 0.15715
Epoch [21/30] Training [275/488] Loss: 0.10974
Epoch [21/30] Training [276/488] Loss: 0.17695
Epoch [21/30] Training [277/488] Loss: 0.11855
Epoch [21/30] Training [278/488] Loss: 0.20889
Epoch [21/30] Training [279/488] Loss: 0.38794
Epoch [21/30] Training [280/488] Loss: 0.11828
Epoch [21/30] Training [281/488] Loss: 0.18397
Epoch [21/30] Training [282/488] Loss: 0.18625
Epoch [21/30] Training [283/488] Loss: 0.15534
Epoch [21/30] Training [284/488] Loss: 0.72291
Epoch [21/30] Training [285/488] Loss: 0.12069
Epoch [21/30] Training [286/488] Loss: 0.13972
Epoch [21/30] Training [287/488] Loss: 0.16917
Epoch [21/30] Training [288/488] Loss: 0.73601
Epoch [21/30] Training [289/488] Loss: 0.11877
Epoch [21/30] Training [290/488] Loss: 0.11031
Epoch [21/30] Training [291/488] Loss: 0.10982
Epoch [21/30] Training [292/488] Loss: 0.13814
Epoch [21/30] Training [293/488] Loss: 0.10258
Epoch [21/30] Training [294/488] Loss: 0.15374
Epoch [21/30] Training [295/488] Loss: 0.46950
Epoch [21/30] Training [296/488] Loss: 0.15205
Epoch [21/30] Training [297/488] Loss: 0.14098
Epoch [21/30] Training [298/488] Loss: 0.14802
Epoch [21/30] Training [299/488] Loss: 0.15963
Epoch [21/30] Training [300/488] Loss: 0.13630
Epoch [21/30] Training [301/488] Loss: 0.31837
Epoch [21/30] Training [302/488] Loss: 0.25738
Epoch [21/30] Training [303/488] Loss: 0.15947
Epoch [21/30] Training [304/488] Loss: 0.11910
Epoch [21/30] Training [305/488] Loss: 0.21932
Epoch [21/30] Training [306/488] Loss: 0.13180
Epoch [21/30] Training [307/488] Loss: 0.19178
Epoch [21/30] Training [308/488] Loss: 0.43945
Epoch [21/30] Training [309/488] Loss: 0.22503
Epoch [21/30] Training [310/488] Loss: 0.35690
Epoch [21/30] Training [311/488] Loss: 0.11104
Epoch [21/30] Training [312/488] Loss: 0.26305
Epoch [21/30] Training [313/488] Loss: 0.12606
Epoch [21/30] Training [314/488] Loss: 0.12559
Epoch [21/30] Training [315/488] Loss: 0.26596
Epoch [21/30] Training [316/488] Loss: 0.18054
Epoch [21/30] Training [317/488] Loss: 0.08526
Epoch [21/30] Training [318/488] Loss: 0.20018
Epoch [21/30] Training [319/488] Loss: 0.18596
Epoch [21/30] Training [320/488] Loss: 0.26391
Epoch [21/30] Training [321/488] Loss: 0.13215
Epoch [21/30] Training [322/488] Loss: 0.15287
Epoch [21/30] Training [323/488] Loss: 0.18034
Epoch [21/30] Training [324/488] Loss: 0.29794
Epoch [21/30] Training [325/488] Loss: 0.20067
Epoch [21/30] Training [326/488] Loss: 0.17431
Epoch [21/30] Training [327/488] Loss: 0.45824
Epoch [21/30] Training [328/488] Loss: 0.28104
Epoch [21/30] Training [329/488] Loss: 0.10131
Epoch [21/30] Training [330/488] Loss: 0.18448
Epoch [21/30] Training [331/488] Loss: 0.15468
Epoch [21/30] Training [332/488] Loss: 0.20855
Epoch [21/30] Training [333/488] Loss: 0.16322
Epoch [21/30] Training [334/488] Loss: 0.25298
Epoch [21/30] Training [335/488] Loss: 0.39391
Epoch [21/30] Training [336/488] Loss: 0.30496
Epoch [21/30] Training [337/488] Loss: 0.30581
Epoch [21/30] Training [338/488] Loss: 0.71797
Epoch [21/30] Training [339/488] Loss: 0.25931
Epoch [21/30] Training [340/488] Loss: 0.11840
Epoch [21/30] Training [341/488] Loss: 0.19527
Epoch [21/30] Training [342/488] Loss: 0.16065
Epoch [21/30] Training [343/488] Loss: 0.10813
Epoch [21/30] Training [344/488] Loss: 0.12378
Epoch [21/30] Training [345/488] Loss: 0.20823
Epoch [21/30] Training [346/488] Loss: 0.26710
Epoch [21/30] Training [347/488] Loss: 0.20224
Epoch [21/30] Training [348/488] Loss: 0.20745
Epoch [21/30] Training [349/488] Loss: 0.10858
Epoch [21/30] Training [350/488] Loss: 0.31038
Epoch [21/30] Training [351/488] Loss: 0.12364
Epoch [21/30] Training [352/488] Loss: 0.17249
Epoch [21/30] Training [353/488] Loss: 0.16935
Epoch [21/30] Training [354/488] Loss: 0.15563
Epoch [21/30] Training [355/488] Loss: 0.15289
Epoch [21/30] Training [356/488] Loss: 0.12519
Epoch [21/30] Training [357/488] Loss: 0.15590
Epoch [21/30] Training [358/488] Loss: 0.11746
Epoch [21/30] Training [359/488] Loss: 0.25044
Epoch [21/30] Training [360/488] Loss: 0.16249
Epoch [21/30] Training [361/488] Loss: 0.35357
Epoch [21/30] Training [362/488] Loss: 0.11144
Epoch [21/30] Training [363/488] Loss: 0.32772
Epoch [21/30] Training [364/488] Loss: 0.10277
Epoch [21/30] Training [365/488] Loss: 0.18126
Epoch [21/30] Training [366/488] Loss: 0.11860
Epoch [21/30] Training [367/488] Loss: 0.10557
Epoch [21/30] Training [368/488] Loss: 0.11583
Epoch [21/30] Training [369/488] Loss: 0.11537
Epoch [21/30] Training [370/488] Loss: 0.11829
Epoch [21/30] Training [371/488] Loss: 0.12170
Epoch [21/30] Training [372/488] Loss: 0.14661
Epoch [21/30] Training [373/488] Loss: 0.38398
Epoch [21/30] Training [374/488] Loss: 0.33653
Epoch [21/30] Training [375/488] Loss: 0.35330
Epoch [21/30] Training [376/488] Loss: 0.16612
Epoch [21/30] Training [377/488] Loss: 0.24247
Epoch [21/30] Training [378/488] Loss: 0.11961
Epoch [21/30] Training [379/488] Loss: 0.10173
Epoch [21/30] Training [380/488] Loss: 0.10863
Epoch [21/30] Training [381/488] Loss: 0.15352
Epoch [21/30] Training [382/488] Loss: 0.09955
Epoch [21/30] Training [383/488] Loss: 0.28045
Epoch [21/30] Training [384/488] Loss: 0.21284
Epoch [21/30] Training [385/488] Loss: 0.11435
Epoch [21/30] Training [386/488] Loss: 0.24879
Epoch [21/30] Training [387/488] Loss: 0.91181
Epoch [21/30] Training [388/488] Loss: 0.16715
Epoch [21/30] Training [389/488] Loss: 0.17253
Epoch [21/30] Training [390/488] Loss: 0.33624
Epoch [21/30] Training [391/488] Loss: 0.09676
Epoch [21/30] Training [392/488] Loss: 0.11659
Epoch [21/30] Training [393/488] Loss: 0.14042
Epoch [21/30] Training [394/488] Loss: 0.14719
Epoch [21/30] Training [395/488] Loss: 0.27183
Epoch [21/30] Training [396/488] Loss: 0.49442
Epoch [21/30] Training [397/488] Loss: 0.12117
Epoch [21/30] Training [398/488] Loss: 0.15626
Epoch [21/30] Training [399/488] Loss: 0.19012
Epoch [21/30] Training [400/488] Loss: 0.48822
Epoch [21/30] Training [401/488] Loss: 0.09169
Epoch [21/30] Training [402/488] Loss: 0.16273
Epoch [21/30] Training [403/488] Loss: 0.14759
Epoch [21/30] Training [404/488] Loss: 0.13348
Epoch [21/30] Training [405/488] Loss: 0.10153
Epoch [21/30] Training [406/488] Loss: 0.56300
Epoch [21/30] Training [407/488] Loss: 0.11262
Epoch [21/30] Training [408/488] Loss: 0.11062
Epoch [21/30] Training [409/488] Loss: 0.17914
Epoch [21/30] Training [410/488] Loss: 0.12779
Epoch [21/30] Training [411/488] Loss: 0.32168
Epoch [21/30] Training [412/488] Loss: 0.15309
Epoch [21/30] Training [413/488] Loss: 0.20882
Epoch [21/30] Training [414/488] Loss: 0.12849
Epoch [21/30] Training [415/488] Loss: 0.10853
Epoch [21/30] Training [416/488] Loss: 0.11548
Epoch [21/30] Training [417/488] Loss: 0.17223
Epoch [21/30] Training [418/488] Loss: 0.09369
Epoch [21/30] Training [419/488] Loss: 0.12481
Epoch [21/30] Training [420/488] Loss: 0.12740
Epoch [21/30] Training [421/488] Loss: 0.10861
Epoch [21/30] Training [422/488] Loss: 0.18890
Epoch [21/30] Training [423/488] Loss: 0.20910
Epoch [21/30] Training [424/488] Loss: 0.31778
Epoch [21/30] Training [425/488] Loss: 0.28800
Epoch [21/30] Training [426/488] Loss: 0.14644
Epoch [21/30] Training [427/488] Loss: 0.16346
Epoch [21/30] Training [428/488] Loss: 0.18900
Epoch [21/30] Training [429/488] Loss: 0.16765
Epoch [21/30] Training [430/488] Loss: 0.26339
Epoch [21/30] Training [431/488] Loss: 0.20553
Epoch [21/30] Training [432/488] Loss: 0.10124
Epoch [21/30] Training [433/488] Loss: 0.19612
Epoch [21/30] Training [434/488] Loss: 0.22296
Epoch [21/30] Training [435/488] Loss: 0.15512
Epoch [21/30] Training [436/488] Loss: 0.13285
Epoch [21/30] Training [437/488] Loss: 0.12345
Epoch [21/30] Training [438/488] Loss: 0.12805
Epoch [21/30] Training [439/488] Loss: 0.24740
Epoch [21/30] Training [440/488] Loss: 0.51938
Epoch [21/30] Training [441/488] Loss: 0.28271
Epoch [21/30] Training [442/488] Loss: 0.19604
Epoch [21/30] Training [443/488] Loss: 0.11500
Epoch [21/30] Training [444/488] Loss: 0.14164
Epoch [21/30] Training [445/488] Loss: 0.15852
Epoch [21/30] Training [446/488] Loss: 0.13254
Epoch [21/30] Training [447/488] Loss: 0.14332
Epoch [21/30] Training [448/488] Loss: 0.25563
Epoch [21/30] Training [449/488] Loss: 0.11396
Epoch [21/30] Training [450/488] Loss: 0.12515
Epoch [21/30] Training [451/488] Loss: 0.30539
Epoch [21/30] Training [452/488] Loss: 0.29424
Epoch [21/30] Training [453/488] Loss: 0.11786
Epoch [21/30] Training [454/488] Loss: 0.38582
Epoch [21/30] Training [455/488] Loss: 0.25977
Epoch [21/30] Training [456/488] Loss: 0.12096
Epoch [21/30] Training [457/488] Loss: 0.16334
Epoch [21/30] Training [458/488] Loss: 0.17114
Epoch [21/30] Training [459/488] Loss: 0.33032
Epoch [21/30] Training [460/488] Loss: 0.11235
Epoch [21/30] Training [461/488] Loss: 0.15745
Epoch [21/30] Training [462/488] Loss: 0.11857
Epoch [21/30] Training [463/488] Loss: 0.20759
Epoch [21/30] Training [464/488] Loss: 0.19210
Epoch [21/30] Training [465/488] Loss: 0.11081
Epoch [21/30] Training [466/488] Loss: 0.16367
Epoch [21/30] Training [467/488] Loss: 0.11447
Epoch [21/30] Training [468/488] Loss: 0.16423
Epoch [21/30] Training [469/488] Loss: 0.10839
Epoch [21/30] Training [470/488] Loss: 0.15243
Epoch [21/30] Training [471/488] Loss: 0.25200
Epoch [21/30] Training [472/488] Loss: 0.14754
Epoch [21/30] Training [473/488] Loss: 0.12438
Epoch [21/30] Training [474/488] Loss: 0.17898
Epoch [21/30] Training [475/488] Loss: 0.17313
Epoch [21/30] Training [476/488] Loss: 0.20751
Epoch [21/30] Training [477/488] Loss: 0.12907
Epoch [21/30] Training [478/488] Loss: 0.08699
Epoch [21/30] Training [479/488] Loss: 0.17646
Epoch [21/30] Training [480/488] Loss: 0.18729
Epoch [21/30] Training [481/488] Loss: 0.14372
Epoch [21/30] Training [482/488] Loss: 0.30580
Epoch [21/30] Training [483/488] Loss: 0.18226
Epoch [21/30] Training [484/488] Loss: 0.39946
Epoch [21/30] Training [485/488] Loss: 0.53171
Epoch [21/30] Training [486/488] Loss: 0.18400
Epoch [21/30] Training [487/488] Loss: 0.37808
Epoch [21/30] Training [488/488] Loss: 0.15734
Epoch [21/30] Training metric {'Train/mean dice_metric': 0.8894773721694946, 'Train/TC dice_metric': 0.904562771320343, 'Train/WT dice_metric': 0.9324343204498291, 'Train/ET dice_metric': 0.8314349055290222}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [21/30] Validation [1/123] Loss: 0.18539  focal_loss 0.00240  dice_loss 0.18299
Epoch [21/30] Validation [2/123] Loss: 0.34169  focal_loss 0.00116  dice_loss 0.34054
Epoch [21/30] Validation [3/123] Loss: 0.15857  focal_loss 0.00182  dice_loss 0.15675
Epoch [21/30] Validation [4/123] Loss: 0.23094  focal_loss 0.00136  dice_loss 0.22958
Epoch [21/30] Validation [5/123] Loss: 0.29939  focal_loss 0.01060  dice_loss 0.28879
Epoch [21/30] Validation [6/123] Loss: 0.28899  focal_loss 0.00127  dice_loss 0.28772
Epoch [21/30] Validation [7/123] Loss: 0.32115  focal_loss 0.00067  dice_loss 0.32048
Epoch [21/30] Validation [8/123] Loss: 0.34321  focal_loss 0.00167  dice_loss 0.34154
Epoch [21/30] Validation [9/123] Loss: 0.24057  focal_loss 0.00157  dice_loss 0.23900
Epoch [21/30] Validation [10/123] Loss: 0.44834  focal_loss 0.00284  dice_loss 0.44551
Epoch [21/30] Validation [11/123] Loss: 0.44528  focal_loss 0.00165  dice_loss 0.44363
Epoch [21/30] Validation [12/123] Loss: 0.20842  focal_loss 0.00214  dice_loss 0.20628
Epoch [21/30] Validation [13/123] Loss: 0.18856  focal_loss 0.00393  dice_loss 0.18463
Epoch [21/30] Validation [14/123] Loss: 0.19190  focal_loss 0.00090  dice_loss 0.19099
Epoch [21/30] Validation [15/123] Loss: 0.31880  focal_loss 0.00117  dice_loss 0.31764
Epoch [21/30] Validation [16/123] Loss: 0.47189  focal_loss 0.00216  dice_loss 0.46973
Epoch [21/30] Validation [17/123] Loss: 0.45606  focal_loss 0.00192  dice_loss 0.45414
Epoch [21/30] Validation [18/123] Loss: 0.37824  focal_loss 0.00916  dice_loss 0.36908
Epoch [21/30] Validation [19/123] Loss: 0.27353  focal_loss 0.00705  dice_loss 0.26648
Epoch [21/30] Validation [20/123] Loss: 0.40316  focal_loss 0.00060  dice_loss 0.40256
Epoch [21/30] Validation [21/123] Loss: 0.29800  focal_loss 0.00075  dice_loss 0.29725
Epoch [21/30] Validation [22/123] Loss: 0.55808  focal_loss 0.00589  dice_loss 0.55219
Epoch [21/30] Validation [23/123] Loss: 0.20752  focal_loss 0.00275  dice_loss 0.20477
Epoch [21/30] Validation [24/123] Loss: 0.26101  focal_loss 0.00215  dice_loss 0.25886
Epoch [21/30] Validation [25/123] Loss: 0.34518  focal_loss 0.00561  dice_loss 0.33957
Epoch [21/30] Validation [26/123] Loss: 0.18087  focal_loss 0.00186  dice_loss 0.17902
Epoch [21/30] Validation [27/123] Loss: 0.21753  focal_loss 0.00206  dice_loss 0.21548
Epoch [21/30] Validation [28/123] Loss: 0.45948  focal_loss 0.00393  dice_loss 0.45556
Epoch [21/30] Validation [29/123] Loss: 0.31032  focal_loss 0.00181  dice_loss 0.30851
Epoch [21/30] Validation [30/123] Loss: 0.24846  focal_loss 0.00564  dice_loss 0.24282
Epoch [21/30] Validation [31/123] Loss: 0.16875  focal_loss 0.00184  dice_loss 0.16691
Epoch [21/30] Validation [32/123] Loss: 0.26340  focal_loss 0.00280  dice_loss 0.26061
Epoch [21/30] Validation [33/123] Loss: 0.32720  focal_loss 0.00173  dice_loss 0.32547
Epoch [21/30] Validation [34/123] Loss: 0.23605  focal_loss 0.00074  dice_loss 0.23531
Epoch [21/30] Validation [35/123] Loss: 0.22086  focal_loss 0.00203  dice_loss 0.21882
Epoch [21/30] Validation [36/123] Loss: 0.23171  focal_loss 0.00120  dice_loss 0.23051
Epoch [21/30] Validation [37/123] Loss: 0.34764  focal_loss 0.00550  dice_loss 0.34215
Epoch [21/30] Validation [38/123] Loss: 0.18449  focal_loss 0.00173  dice_loss 0.18276
Epoch [21/30] Validation [39/123] Loss: 0.17630  focal_loss 0.00126  dice_loss 0.17504
Epoch [21/30] Validation [40/123] Loss: 0.27952  focal_loss 0.00087  dice_loss 0.27866
Epoch [21/30] Validation [41/123] Loss: 0.17898  focal_loss 0.00178  dice_loss 0.17720
Epoch [21/30] Validation [42/123] Loss: 0.19840  focal_loss 0.00282  dice_loss 0.19558
Epoch [21/30] Validation [43/123] Loss: 0.25170  focal_loss 0.01696  dice_loss 0.23475
Epoch [21/30] Validation [44/123] Loss: 0.46490  focal_loss 0.00431  dice_loss 0.46059
Epoch [21/30] Validation [45/123] Loss: 0.27663  focal_loss 0.00204  dice_loss 0.27458
Epoch [21/30] Validation [46/123] Loss: 0.32077  focal_loss 0.00347  dice_loss 0.31730
Epoch [21/30] Validation [47/123] Loss: 0.25867  focal_loss 0.00118  dice_loss 0.25749
Epoch [21/30] Validation [48/123] Loss: 0.34951  focal_loss 0.00253  dice_loss 0.34697
Epoch [21/30] Validation [49/123] Loss: 0.20231  focal_loss 0.00613  dice_loss 0.19618
Epoch [21/30] Validation [50/123] Loss: 0.18962  focal_loss 0.00249  dice_loss 0.18712
Epoch [21/30] Validation [51/123] Loss: 0.35890  focal_loss 0.00943  dice_loss 0.34946
Epoch [21/30] Validation [52/123] Loss: 0.19520  focal_loss 0.00086  dice_loss 0.19435
Epoch [21/30] Validation [53/123] Loss: 0.24819  focal_loss 0.00079  dice_loss 0.24740
Epoch [21/30] Validation [54/123] Loss: 0.29630  focal_loss 0.00102  dice_loss 0.29528
Epoch [21/30] Validation [55/123] Loss: 0.25883  focal_loss 0.00132  dice_loss 0.25751
Epoch [21/30] Validation [56/123] Loss: 0.20004  focal_loss 0.00276  dice_loss 0.19728
Epoch [21/30] Validation [57/123] Loss: 0.28588  focal_loss 0.00658  dice_loss 0.27930
Epoch [21/30] Validation [58/123] Loss: 0.23817  focal_loss 0.00243  dice_loss 0.23574
Epoch [21/30] Validation [59/123] Loss: 0.55203  focal_loss 0.00788  dice_loss 0.54415
Epoch [21/30] Validation [60/123] Loss: 0.22105  focal_loss 0.00241  dice_loss 0.21864
Epoch [21/30] Validation [61/123] Loss: 0.57092  focal_loss 0.00163  dice_loss 0.56929
Epoch [21/30] Validation [62/123] Loss: 0.48298  focal_loss 0.01313  dice_loss 0.46985
Epoch [21/30] Validation [63/123] Loss: 0.32793  focal_loss 0.00096  dice_loss 0.32697
Epoch [21/30] Validation [64/123] Loss: 0.36511  focal_loss 0.00947  dice_loss 0.35563
Epoch [21/30] Validation [65/123] Loss: 0.20729  focal_loss 0.00114  dice_loss 0.20615
Epoch [21/30] Validation [66/123] Loss: 0.20430  focal_loss 0.00106  dice_loss 0.20323
Epoch [21/30] Validation [67/123] Loss: 0.41359  focal_loss 0.01486  dice_loss 0.39873
Epoch [21/30] Validation [68/123] Loss: 0.32273  focal_loss 0.00079  dice_loss 0.32195
Epoch [21/30] Validation [69/123] Loss: 0.37317  focal_loss 0.00565  dice_loss 0.36752
Epoch [21/30] Validation [70/123] Loss: 0.29879  focal_loss 0.00174  dice_loss 0.29705
Epoch [21/30] Validation [71/123] Loss: 0.19579  focal_loss 0.00124  dice_loss 0.19455
Epoch [21/30] Validation [72/123] Loss: 0.19181  focal_loss 0.00216  dice_loss 0.18965
Epoch [21/30] Validation [73/123] Loss: 0.28267  focal_loss 0.00313  dice_loss 0.27954
Epoch [21/30] Validation [74/123] Loss: 0.25792  focal_loss 0.00142  dice_loss 0.25650
Epoch [21/30] Validation [75/123] Loss: 0.21857  focal_loss 0.00117  dice_loss 0.21741
Epoch [21/30] Validation [76/123] Loss: 0.46337  focal_loss 0.00393  dice_loss 0.45945
Epoch [21/30] Validation [77/123] Loss: 0.33569  focal_loss 0.00075  dice_loss 0.33494
Epoch [21/30] Validation [78/123] Loss: 0.23784  focal_loss 0.00129  dice_loss 0.23655
Epoch [21/30] Validation [79/123] Loss: 0.27062  focal_loss 0.00128  dice_loss 0.26934
Epoch [21/30] Validation [80/123] Loss: 0.20035  focal_loss 0.00288  dice_loss 0.19747
Epoch [21/30] Validation [81/123] Loss: 0.21628  focal_loss 0.00141  dice_loss 0.21487
Epoch [21/30] Validation [82/123] Loss: 0.18602  focal_loss 0.00132  dice_loss 0.18469
Epoch [21/30] Validation [83/123] Loss: 0.38310  focal_loss 0.01286  dice_loss 0.37024
Epoch [21/30] Validation [84/123] Loss: 0.22862  focal_loss 0.00156  dice_loss 0.22706
Epoch [21/30] Validation [85/123] Loss: 0.29478  focal_loss 0.00344  dice_loss 0.29135
Epoch [21/30] Validation [86/123] Loss: 0.19997  focal_loss 0.00135  dice_loss 0.19862
Epoch [21/30] Validation [87/123] Loss: 0.20023  focal_loss 0.00308  dice_loss 0.19715
Epoch [21/30] Validation [88/123] Loss: 0.21773  focal_loss 0.00276  dice_loss 0.21496
Epoch [21/30] Validation [89/123] Loss: 0.18107  focal_loss 0.00230  dice_loss 0.17877
Epoch [21/30] Validation [90/123] Loss: 0.25266  focal_loss 0.00152  dice_loss 0.25113
Epoch [21/30] Validation [91/123] Loss: 0.21919  focal_loss 0.00185  dice_loss 0.21734
Epoch [21/30] Validation [92/123] Loss: 0.17550  focal_loss 0.00176  dice_loss 0.17374
Epoch [21/30] Validation [93/123] Loss: 0.20375  focal_loss 0.00283  dice_loss 0.20092
Epoch [21/30] Validation [94/123] Loss: 0.31700  focal_loss 0.00167  dice_loss 0.31533
Epoch [21/30] Validation [95/123] Loss: 0.23111  focal_loss 0.00238  dice_loss 0.22873
Epoch [21/30] Validation [96/123] Loss: 0.27686  focal_loss 0.00141  dice_loss 0.27546
Epoch [21/30] Validation [97/123] Loss: 0.51808  focal_loss 0.00456  dice_loss 0.51352
Epoch [21/30] Validation [98/123] Loss: 0.27583  focal_loss 0.00075  dice_loss 0.27508
Epoch [21/30] Validation [99/123] Loss: 0.27545  focal_loss 0.00064  dice_loss 0.27481
Epoch [21/30] Validation [100/123] Loss: 0.30770  focal_loss 0.00126  dice_loss 0.30644
Epoch [21/30] Validation [101/123] Loss: 0.25904  focal_loss 0.00094  dice_loss 0.25810
Epoch [21/30] Validation [102/123] Loss: 0.30298  focal_loss 0.00069  dice_loss 0.30229
Epoch [21/30] Validation [103/123] Loss: 0.45744  focal_loss 0.00088  dice_loss 0.45656
Epoch [21/30] Validation [104/123] Loss: 0.38101  focal_loss 0.00381  dice_loss 0.37720
Epoch [21/30] Validation [105/123] Loss: 0.18604  focal_loss 0.00329  dice_loss 0.18275
Epoch [21/30] Validation [106/123] Loss: 0.19876  focal_loss 0.00100  dice_loss 0.19776
Epoch [21/30] Validation [107/123] Loss: 0.46245  focal_loss 0.00148  dice_loss 0.46097
Epoch [21/30] Validation [108/123] Loss: 0.19873  focal_loss 0.00091  dice_loss 0.19782
Epoch [21/30] Validation [109/123] Loss: 0.19325  focal_loss 0.00499  dice_loss 0.18826
Epoch [21/30] Validation [110/123] Loss: 0.35639  focal_loss 0.00564  dice_loss 0.35075
Epoch [21/30] Validation [111/123] Loss: 0.34824  focal_loss 0.00356  dice_loss 0.34467
Epoch [21/30] Validation [112/123] Loss: 0.28151  focal_loss 0.00100  dice_loss 0.28051
Epoch [21/30] Validation [113/123] Loss: 0.24462  focal_loss 0.00177  dice_loss 0.24285
Epoch [21/30] Validation [114/123] Loss: 0.30695  focal_loss 0.00495  dice_loss 0.30199
Epoch [21/30] Validation [115/123] Loss: 0.27974  focal_loss 0.00643  dice_loss 0.27331
Epoch [21/30] Validation [116/123] Loss: 0.22133  focal_loss 0.00062  dice_loss 0.22071
Epoch [21/30] Validation [117/123] Loss: 0.23818  focal_loss 0.00116  dice_loss 0.23702
Epoch [21/30] Validation [118/123] Loss: 0.15896  focal_loss 0.00203  dice_loss 0.15692
Epoch [21/30] Validation [119/123] Loss: 0.20485  focal_loss 0.00204  dice_loss 0.20281
Epoch [21/30] Validation [120/123] Loss: 0.21614  focal_loss 0.00199  dice_loss 0.21415
Epoch [21/30] Validation [121/123] Loss: 0.60789  focal_loss 0.01509  dice_loss 0.59280
Epoch [21/30] Validation [122/123] Loss: 0.50464  focal_loss 0.00038  dice_loss 0.50426
Epoch [21/30] Validation [123/123] Loss: 0.21224  focal_loss 0.00175  dice_loss 0.21049
Epoch [21/30] Validation metric {'Val/mean dice_metric': 0.8889507055282593, 'Val/TC dice_metric': 0.9026414752006531, 'Val/WT dice_metric': 0.931804895401001, 'Val/ET dice_metric': 0.8324057459831238}
Epoch [21/30] lr = [0.00034549150281252644, 0.00034549150281252644] best acc: tensor([0.8848], device='cuda:0'), mean acc: tensor([0.8890], device='cuda:0'), mean class: tensor([0.9026, 0.9318, 0.8324], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [22/30] Training [1/488] Loss: 0.10245
Epoch [22/30] Training [2/488] Loss: 0.23998
Epoch [22/30] Training [3/488] Loss: 0.14099
Epoch [22/30] Training [4/488] Loss: 0.12469
Epoch [22/30] Training [5/488] Loss: 0.13789
Epoch [22/30] Training [6/488] Loss: 0.71127
Epoch [22/30] Training [7/488] Loss: 0.13898
Epoch [22/30] Training [8/488] Loss: 0.32563
Epoch [22/30] Training [9/488] Loss: 0.13444
Epoch [22/30] Training [10/488] Loss: 0.11684
Epoch [22/30] Training [11/488] Loss: 0.13133
Epoch [22/30] Training [12/488] Loss: 0.28653
Epoch [22/30] Training [13/488] Loss: 0.30976
Epoch [22/30] Training [14/488] Loss: 0.31130
Epoch [22/30] Training [15/488] Loss: 0.32625
Epoch [22/30] Training [16/488] Loss: 0.40029
Epoch [22/30] Training [17/488] Loss: 0.10851
Epoch [22/30] Training [18/488] Loss: 0.16041
Epoch [22/30] Training [19/488] Loss: 0.16481
Epoch [22/30] Training [20/488] Loss: 0.28571
Epoch [22/30] Training [21/488] Loss: 0.29046
Epoch [22/30] Training [22/488] Loss: 0.15487
Epoch [22/30] Training [23/488] Loss: 0.10974
Epoch [22/30] Training [24/488] Loss: 0.10185
Epoch [22/30] Training [25/488] Loss: 0.32397
Epoch [22/30] Training [26/488] Loss: 0.12672
Epoch [22/30] Training [27/488] Loss: 0.11707
Epoch [22/30] Training [28/488] Loss: 0.34092
Epoch [22/30] Training [29/488] Loss: 0.19314
Epoch [22/30] Training [30/488] Loss: 0.18690
Epoch [22/30] Training [31/488] Loss: 0.11681
Epoch [22/30] Training [32/488] Loss: 0.21620
Epoch [22/30] Training [33/488] Loss: 0.37015
Epoch [22/30] Training [34/488] Loss: 0.63053
Epoch [22/30] Training [35/488] Loss: 0.14496
Epoch [22/30] Training [36/488] Loss: 0.11252
Epoch [22/30] Training [37/488] Loss: 0.23573
Epoch [22/30] Training [38/488] Loss: 0.17761
Epoch [22/30] Training [39/488] Loss: 0.15524
Epoch [22/30] Training [40/488] Loss: 0.15844
Epoch [22/30] Training [41/488] Loss: 0.14501
Epoch [22/30] Training [42/488] Loss: 0.18933
Epoch [22/30] Training [43/488] Loss: 0.52263
Epoch [22/30] Training [44/488] Loss: 0.45190
Epoch [22/30] Training [45/488] Loss: 0.28565
Epoch [22/30] Training [46/488] Loss: 0.20578
Epoch [22/30] Training [47/488] Loss: 0.21882
Epoch [22/30] Training [48/488] Loss: 0.14150
Epoch [22/30] Training [49/488] Loss: 0.23488
Epoch [22/30] Training [50/488] Loss: 0.19485
Epoch [22/30] Training [51/488] Loss: 0.15070
Epoch [22/30] Training [52/488] Loss: 0.15575
Epoch [22/30] Training [53/488] Loss: 0.33804
Epoch [22/30] Training [54/488] Loss: 0.13662
Epoch [22/30] Training [55/488] Loss: 0.19038
Epoch [22/30] Training [56/488] Loss: 0.13830
Epoch [22/30] Training [57/488] Loss: 0.25183
Epoch [22/30] Training [58/488] Loss: 0.16378
Epoch [22/30] Training [59/488] Loss: 0.17011
Epoch [22/30] Training [60/488] Loss: 0.18826
Epoch [22/30] Training [61/488] Loss: 0.13645
Epoch [22/30] Training [62/488] Loss: 0.13260
Epoch [22/30] Training [63/488] Loss: 0.16454
Epoch [22/30] Training [64/488] Loss: 0.16105
Epoch [22/30] Training [65/488] Loss: 0.69609
Epoch [22/30] Training [66/488] Loss: 0.16629
Epoch [22/30] Training [67/488] Loss: 0.12108
Epoch [22/30] Training [68/488] Loss: 0.27634
Epoch [22/30] Training [69/488] Loss: 0.11685
Epoch [22/30] Training [70/488] Loss: 0.51562
Epoch [22/30] Training [71/488] Loss: 0.34584
Epoch [22/30] Training [72/488] Loss: 0.36739
Epoch [22/30] Training [73/488] Loss: 0.10851
Epoch [22/30] Training [74/488] Loss: 0.10191
Epoch [22/30] Training [75/488] Loss: 0.17096
Epoch [22/30] Training [76/488] Loss: 0.13589
Epoch [22/30] Training [77/488] Loss: 0.15349
Epoch [22/30] Training [78/488] Loss: 0.38451
Epoch [22/30] Training [79/488] Loss: 0.10841
Epoch [22/30] Training [80/488] Loss: 0.16870
Epoch [22/30] Training [81/488] Loss: 0.10980
Epoch [22/30] Training [82/488] Loss: 0.15561
Epoch [22/30] Training [83/488] Loss: 0.13283
Epoch [22/30] Training [84/488] Loss: 0.20042
Epoch [22/30] Training [85/488] Loss: 0.11015
Epoch [22/30] Training [86/488] Loss: 0.13970
Epoch [22/30] Training [87/488] Loss: 0.51424
Epoch [22/30] Training [88/488] Loss: 0.12794
Epoch [22/30] Training [89/488] Loss: 0.21236
Epoch [22/30] Training [90/488] Loss: 0.16886
Epoch [22/30] Training [91/488] Loss: 0.10668
Epoch [22/30] Training [92/488] Loss: 0.14114
Epoch [22/30] Training [93/488] Loss: 0.13025
Epoch [22/30] Training [94/488] Loss: 0.08394
Epoch [22/30] Training [95/488] Loss: 0.25981
Epoch [22/30] Training [96/488] Loss: 0.25691
Epoch [22/30] Training [97/488] Loss: 0.13448
Epoch [22/30] Training [98/488] Loss: 0.29480
Epoch [22/30] Training [99/488] Loss: 0.11558
Epoch [22/30] Training [100/488] Loss: 0.14679
Epoch [22/30] Training [101/488] Loss: 0.11185
Epoch [22/30] Training [102/488] Loss: 0.18565
Epoch [22/30] Training [103/488] Loss: 0.14516
Epoch [22/30] Training [104/488] Loss: 0.14170
Epoch [22/30] Training [105/488] Loss: 0.12437
Epoch [22/30] Training [106/488] Loss: 0.12090
Epoch [22/30] Training [107/488] Loss: 0.16367
Epoch [22/30] Training [108/488] Loss: 0.38245
Epoch [22/30] Training [109/488] Loss: 0.18866
Epoch [22/30] Training [110/488] Loss: 0.09136
Epoch [22/30] Training [111/488] Loss: 0.12971
Epoch [22/30] Training [112/488] Loss: 0.42884
Epoch [22/30] Training [113/488] Loss: 0.11152
Epoch [22/30] Training [114/488] Loss: 0.50203
Epoch [22/30] Training [115/488] Loss: 0.15646
Epoch [22/30] Training [116/488] Loss: 0.16004
Epoch [22/30] Training [117/488] Loss: 0.21600
Epoch [22/30] Training [118/488] Loss: 0.19620
Epoch [22/30] Training [119/488] Loss: 0.09879
Epoch [22/30] Training [120/488] Loss: 0.15393
Epoch [22/30] Training [121/488] Loss: 0.16162
Epoch [22/30] Training [122/488] Loss: 0.11037
Epoch [22/30] Training [123/488] Loss: 0.20294
Epoch [22/30] Training [124/488] Loss: 0.12796
Epoch [22/30] Training [125/488] Loss: 0.15895
Epoch [22/30] Training [126/488] Loss: 0.70009
Epoch [22/30] Training [127/488] Loss: 0.27630
Epoch [22/30] Training [128/488] Loss: 0.10946
Epoch [22/30] Training [129/488] Loss: 0.10354
Epoch [22/30] Training [130/488] Loss: 0.13669
Epoch [22/30] Training [131/488] Loss: 0.12688
Epoch [22/30] Training [132/488] Loss: 0.14540
Epoch [22/30] Training [133/488] Loss: 0.19549
Epoch [22/30] Training [134/488] Loss: 0.19603
Epoch [22/30] Training [135/488] Loss: 0.15742
Epoch [22/30] Training [136/488] Loss: 0.08511
Epoch [22/30] Training [137/488] Loss: 0.14537
Epoch [22/30] Training [138/488] Loss: 0.17794
Epoch [22/30] Training [139/488] Loss: 0.11382
Epoch [22/30] Training [140/488] Loss: 0.21574
Epoch [22/30] Training [141/488] Loss: 0.26809
Epoch [22/30] Training [142/488] Loss: 0.17629
Epoch [22/30] Training [143/488] Loss: 0.19561
Epoch [22/30] Training [144/488] Loss: 0.14384
Epoch [22/30] Training [145/488] Loss: 0.17134
Epoch [22/30] Training [146/488] Loss: 0.11049
Epoch [22/30] Training [147/488] Loss: 0.35161
Epoch [22/30] Training [148/488] Loss: 0.09301
Epoch [22/30] Training [149/488] Loss: 0.30264
Epoch [22/30] Training [150/488] Loss: 0.14409
Epoch [22/30] Training [151/488] Loss: 0.24768
Epoch [22/30] Training [152/488] Loss: 0.11312
Epoch [22/30] Training [153/488] Loss: 0.17909
Epoch [22/30] Training [154/488] Loss: 0.09790
Epoch [22/30] Training [155/488] Loss: 0.20499
Epoch [22/30] Training [156/488] Loss: 0.64110
Epoch [22/30] Training [157/488] Loss: 0.15138
Epoch [22/30] Training [158/488] Loss: 0.33888
Epoch [22/30] Training [159/488] Loss: 0.11308
Epoch [22/30] Training [160/488] Loss: 0.48556
Epoch [22/30] Training [161/488] Loss: 0.12790
Epoch [22/30] Training [162/488] Loss: 0.15116
Epoch [22/30] Training [163/488] Loss: 0.13701
Epoch [22/30] Training [164/488] Loss: 0.16975
Epoch [22/30] Training [165/488] Loss: 0.30995
Epoch [22/30] Training [166/488] Loss: 0.13540
Epoch [22/30] Training [167/488] Loss: 0.19530
Epoch [22/30] Training [168/488] Loss: 0.24173
Epoch [22/30] Training [169/488] Loss: 0.13842
Epoch [22/30] Training [170/488] Loss: 0.11839
Epoch [22/30] Training [171/488] Loss: 0.13849
Epoch [22/30] Training [172/488] Loss: 0.13101
Epoch [22/30] Training [173/488] Loss: 0.12450
Epoch [22/30] Training [174/488] Loss: 0.37639
Epoch [22/30] Training [175/488] Loss: 0.09958
Epoch [22/30] Training [176/488] Loss: 0.15530
Epoch [22/30] Training [177/488] Loss: 0.33132
Epoch [22/30] Training [178/488] Loss: 0.15032
Epoch [22/30] Training [179/488] Loss: 0.12820
Epoch [22/30] Training [180/488] Loss: 0.09561
Epoch [22/30] Training [181/488] Loss: 0.17835
Epoch [22/30] Training [182/488] Loss: 0.14532
Epoch [22/30] Training [183/488] Loss: 0.42169
Epoch [22/30] Training [184/488] Loss: 0.12558
Epoch [22/30] Training [185/488] Loss: 0.12546
Epoch [22/30] Training [186/488] Loss: 0.14751
Epoch [22/30] Training [187/488] Loss: 0.17281
Epoch [22/30] Training [188/488] Loss: 0.18927
Epoch [22/30] Training [189/488] Loss: 0.17072
Epoch [22/30] Training [190/488] Loss: 0.14936
Epoch [22/30] Training [191/488] Loss: 0.19753
Epoch [22/30] Training [192/488] Loss: 0.33191
Epoch [22/30] Training [193/488] Loss: 0.43878
Epoch [22/30] Training [194/488] Loss: 0.16916
Epoch [22/30] Training [195/488] Loss: 0.13985
Epoch [22/30] Training [196/488] Loss: 0.12576
Epoch [22/30] Training [197/488] Loss: 0.14089
Epoch [22/30] Training [198/488] Loss: 0.17628
Epoch [22/30] Training [199/488] Loss: 0.15980
Epoch [22/30] Training [200/488] Loss: 0.10403
Epoch [22/30] Training [201/488] Loss: 0.14295
Epoch [22/30] Training [202/488] Loss: 0.12287
Epoch [22/30] Training [203/488] Loss: 0.17803
Epoch [22/30] Training [204/488] Loss: 0.16989
Epoch [22/30] Training [205/488] Loss: 0.15123
Epoch [22/30] Training [206/488] Loss: 0.26551
Epoch [22/30] Training [207/488] Loss: 0.20559
Epoch [22/30] Training [208/488] Loss: 0.15717
Epoch [22/30] Training [209/488] Loss: 0.25533
Epoch [22/30] Training [210/488] Loss: 0.14935
Epoch [22/30] Training [211/488] Loss: 0.23178
Epoch [22/30] Training [212/488] Loss: 0.79045
Epoch [22/30] Training [213/488] Loss: 0.12791
Epoch [22/30] Training [214/488] Loss: 0.38183
Epoch [22/30] Training [215/488] Loss: 0.10113
Epoch [22/30] Training [216/488] Loss: 0.25459
Epoch [22/30] Training [217/488] Loss: 0.12444
Epoch [22/30] Training [218/488] Loss: 0.11122
Epoch [22/30] Training [219/488] Loss: 0.13543
Epoch [22/30] Training [220/488] Loss: 0.51442
Epoch [22/30] Training [221/488] Loss: 0.15292
Epoch [22/30] Training [222/488] Loss: 0.11362
Epoch [22/30] Training [223/488] Loss: 0.30525
Epoch [22/30] Training [224/488] Loss: 0.09436
Epoch [22/30] Training [225/488] Loss: 0.12659
Epoch [22/30] Training [226/488] Loss: 0.10425
Epoch [22/30] Training [227/488] Loss: 0.16867
Epoch [22/30] Training [228/488] Loss: 0.15138
Epoch [22/30] Training [229/488] Loss: 0.11442
Epoch [22/30] Training [230/488] Loss: 0.12746
Epoch [22/30] Training [231/488] Loss: 0.12115
Epoch [22/30] Training [232/488] Loss: 0.16704
Epoch [22/30] Training [233/488] Loss: 0.13631
Epoch [22/30] Training [234/488] Loss: 0.14677
Epoch [22/30] Training [235/488] Loss: 0.13127
Epoch [22/30] Training [236/488] Loss: 0.13604
Epoch [22/30] Training [237/488] Loss: 0.12837
Epoch [22/30] Training [238/488] Loss: 0.11029
Epoch [22/30] Training [239/488] Loss: 0.14375
Epoch [22/30] Training [240/488] Loss: 0.12183
Epoch [22/30] Training [241/488] Loss: 0.14407
Epoch [22/30] Training [242/488] Loss: 0.12028
Epoch [22/30] Training [243/488] Loss: 0.15027
Epoch [22/30] Training [244/488] Loss: 0.12763
Epoch [22/30] Training [245/488] Loss: 0.13997
Epoch [22/30] Training [246/488] Loss: 0.33016
Epoch [22/30] Training [247/488] Loss: 0.20053
Epoch [22/30] Training [248/488] Loss: 0.15947
Epoch [22/30] Training [249/488] Loss: 0.11266
Epoch [22/30] Training [250/488] Loss: 0.24635
Epoch [22/30] Training [251/488] Loss: 0.36789
Epoch [22/30] Training [252/488] Loss: 0.13556
Epoch [22/30] Training [253/488] Loss: 0.11292
Epoch [22/30] Training [254/488] Loss: 0.11141
Epoch [22/30] Training [255/488] Loss: 0.08634
Epoch [22/30] Training [256/488] Loss: 0.24671
Epoch [22/30] Training [257/488] Loss: 0.12706
Epoch [22/30] Training [258/488] Loss: 0.11851
Epoch [22/30] Training [259/488] Loss: 0.10760
Epoch [22/30] Training [260/488] Loss: 0.15126
Epoch [22/30] Training [261/488] Loss: 0.10559
Epoch [22/30] Training [262/488] Loss: 0.14237
Epoch [22/30] Training [263/488] Loss: 0.19417
Epoch [22/30] Training [264/488] Loss: 0.17101
Epoch [22/30] Training [265/488] Loss: 0.09055
Epoch [22/30] Training [266/488] Loss: 0.27972
Epoch [22/30] Training [267/488] Loss: 0.17564
Epoch [22/30] Training [268/488] Loss: 0.19558
Epoch [22/30] Training [269/488] Loss: 0.11187
Epoch [22/30] Training [270/488] Loss: 0.21191
Epoch [22/30] Training [271/488] Loss: 0.26841
Epoch [22/30] Training [272/488] Loss: 0.20535
Epoch [22/30] Training [273/488] Loss: 0.10262
Epoch [22/30] Training [274/488] Loss: 0.31305
Epoch [22/30] Training [275/488] Loss: 0.10496
Epoch [22/30] Training [276/488] Loss: 0.16825
Epoch [22/30] Training [277/488] Loss: 0.11130
Epoch [22/30] Training [278/488] Loss: 0.17186
Epoch [22/30] Training [279/488] Loss: 0.18297
Epoch [22/30] Training [280/488] Loss: 0.24531
Epoch [22/30] Training [281/488] Loss: 0.17334
Epoch [22/30] Training [282/488] Loss: 0.17011
Epoch [22/30] Training [283/488] Loss: 0.13066
Epoch [22/30] Training [284/488] Loss: 0.13159
Epoch [22/30] Training [285/488] Loss: 0.34529
Epoch [22/30] Training [286/488] Loss: 0.11442
Epoch [22/30] Training [287/488] Loss: 0.12964
Epoch [22/30] Training [288/488] Loss: 0.09903
Epoch [22/30] Training [289/488] Loss: 0.12371
Epoch [22/30] Training [290/488] Loss: 0.15942
Epoch [22/30] Training [291/488] Loss: 0.29565
Epoch [22/30] Training [292/488] Loss: 0.12612
Epoch [22/30] Training [293/488] Loss: 0.17188
Epoch [22/30] Training [294/488] Loss: 0.13117
Epoch [22/30] Training [295/488] Loss: 0.11923
Epoch [22/30] Training [296/488] Loss: 0.11781
Epoch [22/30] Training [297/488] Loss: 0.14383
Epoch [22/30] Training [298/488] Loss: 0.21542
Epoch [22/30] Training [299/488] Loss: 0.12061
Epoch [22/30] Training [300/488] Loss: 0.24120
Epoch [22/30] Training [301/488] Loss: 0.11330
Epoch [22/30] Training [302/488] Loss: 0.19797
Epoch [22/30] Training [303/488] Loss: 0.11912
Epoch [22/30] Training [304/488] Loss: 0.14293
Epoch [22/30] Training [305/488] Loss: 0.21022
Epoch [22/30] Training [306/488] Loss: 0.23238
Epoch [22/30] Training [307/488] Loss: 0.11010
Epoch [22/30] Training [308/488] Loss: 0.12480
Epoch [22/30] Training [309/488] Loss: 0.20939
Epoch [22/30] Training [310/488] Loss: 0.13173
Epoch [22/30] Training [311/488] Loss: 0.19447
Epoch [22/30] Training [312/488] Loss: 0.42050
Epoch [22/30] Training [313/488] Loss: 0.16781
Epoch [22/30] Training [314/488] Loss: 0.16047
Epoch [22/30] Training [315/488] Loss: 0.50152
Epoch [22/30] Training [316/488] Loss: 0.16162
Epoch [22/30] Training [317/488] Loss: 0.15633
Epoch [22/30] Training [318/488] Loss: 0.26446
Epoch [22/30] Training [319/488] Loss: 0.10546
Epoch [22/30] Training [320/488] Loss: 0.10764
Epoch [22/30] Training [321/488] Loss: 0.08982
Epoch [22/30] Training [322/488] Loss: 0.20241
Epoch [22/30] Training [323/488] Loss: 0.10218
Epoch [22/30] Training [324/488] Loss: 0.21976
Epoch [22/30] Training [325/488] Loss: 0.12997
Epoch [22/30] Training [326/488] Loss: 0.19323
Epoch [22/30] Training [327/488] Loss: 0.28725
Epoch [22/30] Training [328/488] Loss: 0.15328
Epoch [22/30] Training [329/488] Loss: 0.19491
Epoch [22/30] Training [330/488] Loss: 0.29288
Epoch [22/30] Training [331/488] Loss: 0.14213
Epoch [22/30] Training [332/488] Loss: 0.11850
Epoch [22/30] Training [333/488] Loss: 0.25699
Epoch [22/30] Training [334/488] Loss: 0.28533
Epoch [22/30] Training [335/488] Loss: 0.11012
Epoch [22/30] Training [336/488] Loss: 0.26822
Epoch [22/30] Training [337/488] Loss: 0.45871
Epoch [22/30] Training [338/488] Loss: 0.10680
Epoch [22/30] Training [339/488] Loss: 0.29758
Epoch [22/30] Training [340/488] Loss: 0.08413
Epoch [22/30] Training [341/488] Loss: 0.10370
Epoch [22/30] Training [342/488] Loss: 0.08227
Epoch [22/30] Training [343/488] Loss: 0.72280
Epoch [22/30] Training [344/488] Loss: 0.37332
Epoch [22/30] Training [345/488] Loss: 0.29028
Epoch [22/30] Training [346/488] Loss: 0.11259
Epoch [22/30] Training [347/488] Loss: 0.19940
Epoch [22/30] Training [348/488] Loss: 0.20128
Epoch [22/30] Training [349/488] Loss: 0.17866
Epoch [22/30] Training [350/488] Loss: 0.11135
Epoch [22/30] Training [351/488] Loss: 0.10804
Epoch [22/30] Training [352/488] Loss: 0.09218
Epoch [22/30] Training [353/488] Loss: 0.15252
Epoch [22/30] Training [354/488] Loss: 0.18669
Epoch [22/30] Training [355/488] Loss: 0.15036
Epoch [22/30] Training [356/488] Loss: 0.15808
Epoch [22/30] Training [357/488] Loss: 0.26335
Epoch [22/30] Training [358/488] Loss: 0.13345
Epoch [22/30] Training [359/488] Loss: 0.11389
Epoch [22/30] Training [360/488] Loss: 0.10414
Epoch [22/30] Training [361/488] Loss: 0.36698
Epoch [22/30] Training [362/488] Loss: 0.22445
Epoch [22/30] Training [363/488] Loss: 0.26672
Epoch [22/30] Training [364/488] Loss: 0.13251
Epoch [22/30] Training [365/488] Loss: 0.10063
Epoch [22/30] Training [366/488] Loss: 0.10801
Epoch [22/30] Training [367/488] Loss: 0.38500
Epoch [22/30] Training [368/488] Loss: 0.10393
Epoch [22/30] Training [369/488] Loss: 0.10249
Epoch [22/30] Training [370/488] Loss: 0.38606
Epoch [22/30] Training [371/488] Loss: 0.19358
Epoch [22/30] Training [372/488] Loss: 0.14604
Epoch [22/30] Training [373/488] Loss: 0.26325
Epoch [22/30] Training [374/488] Loss: 0.23764
Epoch [22/30] Training [375/488] Loss: 0.23297
Epoch [22/30] Training [376/488] Loss: 0.10734
Epoch [22/30] Training [377/488] Loss: 0.09732
Epoch [22/30] Training [378/488] Loss: 0.18961
Epoch [22/30] Training [379/488] Loss: 0.10405
Epoch [22/30] Training [380/488] Loss: 0.12131
Epoch [22/30] Training [381/488] Loss: 0.10909
Epoch [22/30] Training [382/488] Loss: 0.12392
Epoch [22/30] Training [383/488] Loss: 0.12974
Epoch [22/30] Training [384/488] Loss: 0.20228
Epoch [22/30] Training [385/488] Loss: 0.11992
Epoch [22/30] Training [386/488] Loss: 0.11402
Epoch [22/30] Training [387/488] Loss: 0.09880
Epoch [22/30] Training [388/488] Loss: 0.10418
Epoch [22/30] Training [389/488] Loss: 0.13785
Epoch [22/30] Training [390/488] Loss: 0.18740
Epoch [22/30] Training [391/488] Loss: 0.10545
Epoch [22/30] Training [392/488] Loss: 0.26246
Epoch [22/30] Training [393/488] Loss: 0.11082
Epoch [22/30] Training [394/488] Loss: 0.16848
Epoch [22/30] Training [395/488] Loss: 0.82274
Epoch [22/30] Training [396/488] Loss: 0.11410
Epoch [22/30] Training [397/488] Loss: 0.15125
Epoch [22/30] Training [398/488] Loss: 0.17771
Epoch [22/30] Training [399/488] Loss: 0.11162
Epoch [22/30] Training [400/488] Loss: 0.13834
Epoch [22/30] Training [401/488] Loss: 0.13826
Epoch [22/30] Training [402/488] Loss: 0.19016
Epoch [22/30] Training [403/488] Loss: 0.15558
Epoch [22/30] Training [404/488] Loss: 0.18487
Epoch [22/30] Training [405/488] Loss: 0.20043
Epoch [22/30] Training [406/488] Loss: 0.23640
Epoch [22/30] Training [407/488] Loss: 0.16444
Epoch [22/30] Training [408/488] Loss: 0.16523
Epoch [22/30] Training [409/488] Loss: 0.21466
Epoch [22/30] Training [410/488] Loss: 0.24088
Epoch [22/30] Training [411/488] Loss: 0.12880
Epoch [22/30] Training [412/488] Loss: 0.10799
Epoch [22/30] Training [413/488] Loss: 0.09618
Epoch [22/30] Training [414/488] Loss: 0.17424
Epoch [22/30] Training [415/488] Loss: 0.12024
Epoch [22/30] Training [416/488] Loss: 0.40273
Epoch [22/30] Training [417/488] Loss: 0.23123
Epoch [22/30] Training [418/488] Loss: 0.14399
Epoch [22/30] Training [419/488] Loss: 0.14024
Epoch [22/30] Training [420/488] Loss: 0.15081
Epoch [22/30] Training [421/488] Loss: 0.14394
Epoch [22/30] Training [422/488] Loss: 0.20193
Epoch [22/30] Training [423/488] Loss: 0.09766
Epoch [22/30] Training [424/488] Loss: 0.18056
Epoch [22/30] Training [425/488] Loss: 0.14638
Epoch [22/30] Training [426/488] Loss: 0.14617
Epoch [22/30] Training [427/488] Loss: 0.20497
Epoch [22/30] Training [428/488] Loss: 0.11232
Epoch [22/30] Training [429/488] Loss: 0.70599
Epoch [22/30] Training [430/488] Loss: 0.08453
Epoch [22/30] Training [431/488] Loss: 0.15692
Epoch [22/30] Training [432/488] Loss: 0.35160
Epoch [22/30] Training [433/488] Loss: 0.09823
Epoch [22/30] Training [434/488] Loss: 0.11834
Epoch [22/30] Training [435/488] Loss: 0.14965
Epoch [22/30] Training [436/488] Loss: 0.46576
Epoch [22/30] Training [437/488] Loss: 0.33206
Epoch [22/30] Training [438/488] Loss: 0.39220
Epoch [22/30] Training [439/488] Loss: 0.25168
Epoch [22/30] Training [440/488] Loss: 0.56299
Epoch [22/30] Training [441/488] Loss: 0.38059
Epoch [22/30] Training [442/488] Loss: 0.11782
Epoch [22/30] Training [443/488] Loss: 0.16934
Epoch [22/30] Training [444/488] Loss: 0.26061
Epoch [22/30] Training [445/488] Loss: 0.11117
Epoch [22/30] Training [446/488] Loss: 0.11301
Epoch [22/30] Training [447/488] Loss: 0.30492
Epoch [22/30] Training [448/488] Loss: 0.12753
Epoch [22/30] Training [449/488] Loss: 0.25285
Epoch [22/30] Training [450/488] Loss: 0.16579
Epoch [22/30] Training [451/488] Loss: 0.20691
Epoch [22/30] Training [452/488] Loss: 0.23661
Epoch [22/30] Training [453/488] Loss: 0.16788
Epoch [22/30] Training [454/488] Loss: 0.25279
Epoch [22/30] Training [455/488] Loss: 0.12210
Epoch [22/30] Training [456/488] Loss: 0.17479
Epoch [22/30] Training [457/488] Loss: 0.11740
Epoch [22/30] Training [458/488] Loss: 0.12287
Epoch [22/30] Training [459/488] Loss: 0.11511
Epoch [22/30] Training [460/488] Loss: 0.28298
Epoch [22/30] Training [461/488] Loss: 0.31347
Epoch [22/30] Training [462/488] Loss: 0.17878
Epoch [22/30] Training [463/488] Loss: 0.10828
Epoch [22/30] Training [464/488] Loss: 0.17171
Epoch [22/30] Training [465/488] Loss: 0.27297
Epoch [22/30] Training [466/488] Loss: 0.13832
Epoch [22/30] Training [467/488] Loss: 0.11134
Epoch [22/30] Training [468/488] Loss: 0.10903
Epoch [22/30] Training [469/488] Loss: 0.14194
Epoch [22/30] Training [470/488] Loss: 0.10976
Epoch [22/30] Training [471/488] Loss: 0.11774
Epoch [22/30] Training [472/488] Loss: 0.11438
Epoch [22/30] Training [473/488] Loss: 0.18057
Epoch [22/30] Training [474/488] Loss: 0.14438
Epoch [22/30] Training [475/488] Loss: 0.12401
Epoch [22/30] Training [476/488] Loss: 0.13695
Epoch [22/30] Training [477/488] Loss: 0.10179
Epoch [22/30] Training [478/488] Loss: 0.44376
Epoch [22/30] Training [479/488] Loss: 0.08952
Epoch [22/30] Training [480/488] Loss: 0.14841
Epoch [22/30] Training [481/488] Loss: 0.18400
Epoch [22/30] Training [482/488] Loss: 0.11819
Epoch [22/30] Training [483/488] Loss: 0.38273
Epoch [22/30] Training [484/488] Loss: 0.14438
Epoch [22/30] Training [485/488] Loss: 0.18405
Epoch [22/30] Training [486/488] Loss: 0.12717
Epoch [22/30] Training [487/488] Loss: 0.19150
Epoch [22/30] Training [488/488] Loss: 0.68079
Epoch [22/30] Training metric {'Train/mean dice_metric': 0.8921152353286743, 'Train/TC dice_metric': 0.9048317074775696, 'Train/WT dice_metric': 0.9335772395133972, 'Train/ET dice_metric': 0.837936520576477}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [22/30] Validation [1/123] Loss: 0.17260  focal_loss 0.00241  dice_loss 0.17018
Epoch [22/30] Validation [2/123] Loss: 0.33331  focal_loss 0.00120  dice_loss 0.33211
Epoch [22/30] Validation [3/123] Loss: 0.15156  focal_loss 0.00194  dice_loss 0.14963
Epoch [22/30] Validation [4/123] Loss: 0.22096  focal_loss 0.00129  dice_loss 0.21967
Epoch [22/30] Validation [5/123] Loss: 0.26468  focal_loss 0.00752  dice_loss 0.25716
Epoch [22/30] Validation [6/123] Loss: 0.26735  focal_loss 0.00105  dice_loss 0.26630
Epoch [22/30] Validation [7/123] Loss: 0.32048  focal_loss 0.00085  dice_loss 0.31963
Epoch [22/30] Validation [8/123] Loss: 0.33816  focal_loss 0.00183  dice_loss 0.33633
Epoch [22/30] Validation [9/123] Loss: 0.23606  focal_loss 0.00178  dice_loss 0.23427
Epoch [22/30] Validation [10/123] Loss: 0.41761  focal_loss 0.00227  dice_loss 0.41535
Epoch [22/30] Validation [11/123] Loss: 0.43483  focal_loss 0.00220  dice_loss 0.43262
Epoch [22/30] Validation [12/123] Loss: 0.17754  focal_loss 0.00218  dice_loss 0.17536
Epoch [22/30] Validation [13/123] Loss: 0.17459  focal_loss 0.00424  dice_loss 0.17035
Epoch [22/30] Validation [14/123] Loss: 0.17856  focal_loss 0.00078  dice_loss 0.17778
Epoch [22/30] Validation [15/123] Loss: 0.32649  focal_loss 0.00164  dice_loss 0.32485
Epoch [22/30] Validation [16/123] Loss: 0.40763  focal_loss 0.00212  dice_loss 0.40551
Epoch [22/30] Validation [17/123] Loss: 0.44367  focal_loss 0.00193  dice_loss 0.44175
Epoch [22/30] Validation [18/123] Loss: 0.26717  focal_loss 0.00208  dice_loss 0.26509
Epoch [22/30] Validation [19/123] Loss: 0.28657  focal_loss 0.01336  dice_loss 0.27321
Epoch [22/30] Validation [20/123] Loss: 0.40490  focal_loss 0.00073  dice_loss 0.40417
Epoch [22/30] Validation [21/123] Loss: 0.29575  focal_loss 0.00102  dice_loss 0.29474
Epoch [22/30] Validation [22/123] Loss: 0.57546  focal_loss 0.00942  dice_loss 0.56604
Epoch [22/30] Validation [23/123] Loss: 0.16531  focal_loss 0.00231  dice_loss 0.16300
Epoch [22/30] Validation [24/123] Loss: 0.25065  focal_loss 0.00293  dice_loss 0.24772
Epoch [22/30] Validation [25/123] Loss: 0.30772  focal_loss 0.00391  dice_loss 0.30381
Epoch [22/30] Validation [26/123] Loss: 0.17635  focal_loss 0.00221  dice_loss 0.17414
Epoch [22/30] Validation [27/123] Loss: 0.20587  focal_loss 0.00197  dice_loss 0.20389
Epoch [22/30] Validation [28/123] Loss: 0.47695  focal_loss 0.00591  dice_loss 0.47104
Epoch [22/30] Validation [29/123] Loss: 0.32322  focal_loss 0.00398  dice_loss 0.31924
Epoch [22/30] Validation [30/123] Loss: 0.21473  focal_loss 0.00446  dice_loss 0.21027
Epoch [22/30] Validation [31/123] Loss: 0.16001  focal_loss 0.00206  dice_loss 0.15795
Epoch [22/30] Validation [32/123] Loss: 0.25052  focal_loss 0.00265  dice_loss 0.24786
Epoch [22/30] Validation [33/123] Loss: 0.30340  focal_loss 0.00123  dice_loss 0.30217
Epoch [22/30] Validation [34/123] Loss: 0.22858  focal_loss 0.00081  dice_loss 0.22777
Epoch [22/30] Validation [35/123] Loss: 0.19291  focal_loss 0.00192  dice_loss 0.19099
Epoch [22/30] Validation [36/123] Loss: 0.22334  focal_loss 0.00134  dice_loss 0.22200
Epoch [22/30] Validation [37/123] Loss: 0.34703  focal_loss 0.00758  dice_loss 0.33945
Epoch [22/30] Validation [38/123] Loss: 0.16969  focal_loss 0.00140  dice_loss 0.16829
Epoch [22/30] Validation [39/123] Loss: 0.17098  focal_loss 0.00131  dice_loss 0.16967
Epoch [22/30] Validation [40/123] Loss: 0.26663  focal_loss 0.00081  dice_loss 0.26582
Epoch [22/30] Validation [41/123] Loss: 0.16298  focal_loss 0.00143  dice_loss 0.16154
Epoch [22/30] Validation [42/123] Loss: 0.16143  focal_loss 0.00214  dice_loss 0.15929
Epoch [22/30] Validation [43/123] Loss: 0.23648  focal_loss 0.01741  dice_loss 0.21907
Epoch [22/30] Validation [44/123] Loss: 0.41813  focal_loss 0.00262  dice_loss 0.41551
Epoch [22/30] Validation [45/123] Loss: 0.27231  focal_loss 0.00244  dice_loss 0.26987
Epoch [22/30] Validation [46/123] Loss: 0.29089  focal_loss 0.00274  dice_loss 0.28815
Epoch [22/30] Validation [47/123] Loss: 0.24577  focal_loss 0.00114  dice_loss 0.24464
Epoch [22/30] Validation [48/123] Loss: 0.33989  focal_loss 0.00257  dice_loss 0.33732
Epoch [22/30] Validation [49/123] Loss: 0.19250  focal_loss 0.00616  dice_loss 0.18635
Epoch [22/30] Validation [50/123] Loss: 0.17744  focal_loss 0.00251  dice_loss 0.17493
Epoch [22/30] Validation [51/123] Loss: 0.31518  focal_loss 0.00547  dice_loss 0.30972
Epoch [22/30] Validation [52/123] Loss: 0.18481  focal_loss 0.00087  dice_loss 0.18394
Epoch [22/30] Validation [53/123] Loss: 0.23609  focal_loss 0.00086  dice_loss 0.23523
Epoch [22/30] Validation [54/123] Loss: 0.26596  focal_loss 0.00063  dice_loss 0.26533
Epoch [22/30] Validation [55/123] Loss: 0.25227  focal_loss 0.00144  dice_loss 0.25084
Epoch [22/30] Validation [56/123] Loss: 0.17992  focal_loss 0.00309  dice_loss 0.17683
Epoch [22/30] Validation [57/123] Loss: 0.27116  focal_loss 0.00760  dice_loss 0.26356
Epoch [22/30] Validation [58/123] Loss: 0.24916  focal_loss 0.00322  dice_loss 0.24594
Epoch [22/30] Validation [59/123] Loss: 0.55674  focal_loss 0.00519  dice_loss 0.55156
Epoch [22/30] Validation [60/123] Loss: 0.21114  focal_loss 0.00286  dice_loss 0.20828
Epoch [22/30] Validation [61/123] Loss: 0.58634  focal_loss 0.00420  dice_loss 0.58214
Epoch [22/30] Validation [62/123] Loss: 0.50093  focal_loss 0.01970  dice_loss 0.48123
Epoch [22/30] Validation [63/123] Loss: 0.33321  focal_loss 0.00164  dice_loss 0.33158
Epoch [22/30] Validation [64/123] Loss: 0.46440  focal_loss 0.01278  dice_loss 0.45162
Epoch [22/30] Validation [65/123] Loss: 0.19703  focal_loss 0.00120  dice_loss 0.19583
Epoch [22/30] Validation [66/123] Loss: 0.19883  focal_loss 0.00132  dice_loss 0.19751
Epoch [22/30] Validation [67/123] Loss: 0.27788  focal_loss 0.00228  dice_loss 0.27560
Epoch [22/30] Validation [68/123] Loss: 0.31361  focal_loss 0.00087  dice_loss 0.31274
Epoch [22/30] Validation [69/123] Loss: 0.37314  focal_loss 0.00534  dice_loss 0.36779
Epoch [22/30] Validation [70/123] Loss: 0.27305  focal_loss 0.00159  dice_loss 0.27146
Epoch [22/30] Validation [71/123] Loss: 0.17822  focal_loss 0.00090  dice_loss 0.17732
Epoch [22/30] Validation [72/123] Loss: 0.17430  focal_loss 0.00178  dice_loss 0.17253
Epoch [22/30] Validation [73/123] Loss: 0.27212  focal_loss 0.00282  dice_loss 0.26930
Epoch [22/30] Validation [74/123] Loss: 0.26954  focal_loss 0.00436  dice_loss 0.26518
Epoch [22/30] Validation [75/123] Loss: 0.23111  focal_loss 0.00238  dice_loss 0.22873
Epoch [22/30] Validation [76/123] Loss: 0.54730  focal_loss 0.00673  dice_loss 0.54057
Epoch [22/30] Validation [77/123] Loss: 0.32555  focal_loss 0.00078  dice_loss 0.32478
Epoch [22/30] Validation [78/123] Loss: 0.22884  focal_loss 0.00136  dice_loss 0.22748
Epoch [22/30] Validation [79/123] Loss: 0.25259  focal_loss 0.00103  dice_loss 0.25156
Epoch [22/30] Validation [80/123] Loss: 0.20725  focal_loss 0.00403  dice_loss 0.20322
Epoch [22/30] Validation [81/123] Loss: 0.20423  focal_loss 0.00142  dice_loss 0.20281
Epoch [22/30] Validation [82/123] Loss: 0.17520  focal_loss 0.00129  dice_loss 0.17392
Epoch [22/30] Validation [83/123] Loss: 0.44866  focal_loss 0.01860  dice_loss 0.43005
Epoch [22/30] Validation [84/123] Loss: 0.21911  focal_loss 0.00178  dice_loss 0.21733
Epoch [22/30] Validation [85/123] Loss: 0.22696  focal_loss 0.00155  dice_loss 0.22542
Epoch [22/30] Validation [86/123] Loss: 0.19135  focal_loss 0.00211  dice_loss 0.18924
Epoch [22/30] Validation [87/123] Loss: 0.20287  focal_loss 0.00416  dice_loss 0.19871
Epoch [22/30] Validation [88/123] Loss: 0.20575  focal_loss 0.00230  dice_loss 0.20345
Epoch [22/30] Validation [89/123] Loss: 0.17877  focal_loss 0.00254  dice_loss 0.17624
Epoch [22/30] Validation [90/123] Loss: 0.24389  focal_loss 0.00191  dice_loss 0.24198
Epoch [22/30] Validation [91/123] Loss: 0.18421  focal_loss 0.00110  dice_loss 0.18311
Epoch [22/30] Validation [92/123] Loss: 0.16142  focal_loss 0.00155  dice_loss 0.15987
Epoch [22/30] Validation [93/123] Loss: 0.16957  focal_loss 0.00181  dice_loss 0.16776
Epoch [22/30] Validation [94/123] Loss: 0.29956  focal_loss 0.00146  dice_loss 0.29811
Epoch [22/30] Validation [95/123] Loss: 0.22794  focal_loss 0.00274  dice_loss 0.22520
Epoch [22/30] Validation [96/123] Loss: 0.25770  focal_loss 0.00111  dice_loss 0.25659
Epoch [22/30] Validation [97/123] Loss: 0.50373  focal_loss 0.00419  dice_loss 0.49955
Epoch [22/30] Validation [98/123] Loss: 0.26369  focal_loss 0.00074  dice_loss 0.26295
Epoch [22/30] Validation [99/123] Loss: 0.26326  focal_loss 0.00058  dice_loss 0.26268
Epoch [22/30] Validation [100/123] Loss: 0.28965  focal_loss 0.00099  dice_loss 0.28866
Epoch [22/30] Validation [101/123] Loss: 0.24883  focal_loss 0.00097  dice_loss 0.24787
Epoch [22/30] Validation [102/123] Loss: 0.28224  focal_loss 0.00049  dice_loss 0.28174
Epoch [22/30] Validation [103/123] Loss: 0.39854  focal_loss 0.00074  dice_loss 0.39779
Epoch [22/30] Validation [104/123] Loss: 0.39030  focal_loss 0.00546  dice_loss 0.38484
Epoch [22/30] Validation [105/123] Loss: 0.20387  focal_loss 0.00463  dice_loss 0.19924
Epoch [22/30] Validation [106/123] Loss: 0.18382  focal_loss 0.00095  dice_loss 0.18287
Epoch [22/30] Validation [107/123] Loss: 0.46345  focal_loss 0.00163  dice_loss 0.46181
Epoch [22/30] Validation [108/123] Loss: 0.18708  focal_loss 0.00082  dice_loss 0.18627
Epoch [22/30] Validation [109/123] Loss: 0.20188  focal_loss 0.00659  dice_loss 0.19529
Epoch [22/30] Validation [110/123] Loss: 0.28620  focal_loss 0.00197  dice_loss 0.28423
Epoch [22/30] Validation [111/123] Loss: 0.33523  focal_loss 0.00320  dice_loss 0.33203
Epoch [22/30] Validation [112/123] Loss: 0.26656  focal_loss 0.00092  dice_loss 0.26563
Epoch [22/30] Validation [113/123] Loss: 0.20922  focal_loss 0.00117  dice_loss 0.20805
Epoch [22/30] Validation [114/123] Loss: 0.37575  focal_loss 0.01148  dice_loss 0.36427
Epoch [22/30] Validation [115/123] Loss: 0.33096  focal_loss 0.01294  dice_loss 0.31802
Epoch [22/30] Validation [116/123] Loss: 0.20796  focal_loss 0.00053  dice_loss 0.20743
Epoch [22/30] Validation [117/123] Loss: 0.22734  focal_loss 0.00119  dice_loss 0.22615
Epoch [22/30] Validation [118/123] Loss: 0.15411  focal_loss 0.00236  dice_loss 0.15174
Epoch [22/30] Validation [119/123] Loss: 0.17433  focal_loss 0.00170  dice_loss 0.17264
Epoch [22/30] Validation [120/123] Loss: 0.20934  focal_loss 0.00234  dice_loss 0.20700
Epoch [22/30] Validation [121/123] Loss: 0.57812  focal_loss 0.01087  dice_loss 0.56725
Epoch [22/30] Validation [122/123] Loss: 0.52219  focal_loss 0.00064  dice_loss 0.52155
Epoch [22/30] Validation [123/123] Loss: 0.23478  focal_loss 0.00301  dice_loss 0.23177
Epoch [22/30] Validation metric {'Val/mean dice_metric': 0.8917149901390076, 'Val/TC dice_metric': 0.904470682144165, 'Val/WT dice_metric': 0.9318354725837708, 'Val/ET dice_metric': 0.8388387560844421}
Epoch [22/30] lr = [0.00028711035421746366, 0.00028711035421746366] best acc: tensor([0.8890], device='cuda:0'), mean acc: tensor([0.8917], device='cuda:0'), mean class: tensor([0.9045, 0.9318, 0.8388], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [23/30] Training [1/488] Loss: 0.32794
Epoch [23/30] Training [2/488] Loss: 0.10761
Epoch [23/30] Training [3/488] Loss: 0.11200
Epoch [23/30] Training [4/488] Loss: 0.44251
Epoch [23/30] Training [5/488] Loss: 0.11617
Epoch [23/30] Training [6/488] Loss: 0.11669
Epoch [23/30] Training [7/488] Loss: 0.14426
Epoch [23/30] Training [8/488] Loss: 0.12267
Epoch [23/30] Training [9/488] Loss: 0.18299
Epoch [23/30] Training [10/488] Loss: 0.10533
Epoch [23/30] Training [11/488] Loss: 0.09463
Epoch [23/30] Training [12/488] Loss: 0.14406
Epoch [23/30] Training [13/488] Loss: 0.11026
Epoch [23/30] Training [14/488] Loss: 0.11398
Epoch [23/30] Training [15/488] Loss: 0.12929
Epoch [23/30] Training [16/488] Loss: 0.11269
Epoch [23/30] Training [17/488] Loss: 0.15706
Epoch [23/30] Training [18/488] Loss: 0.44475
Epoch [23/30] Training [19/488] Loss: 0.10654
Epoch [23/30] Training [20/488] Loss: 0.10023
Epoch [23/30] Training [21/488] Loss: 0.09259
Epoch [23/30] Training [22/488] Loss: 0.10963
Epoch [23/30] Training [23/488] Loss: 0.09971
Epoch [23/30] Training [24/488] Loss: 0.25336
Epoch [23/30] Training [25/488] Loss: 0.27368
Epoch [23/30] Training [26/488] Loss: 0.37142
Epoch [23/30] Training [27/488] Loss: 0.12589
Epoch [23/30] Training [28/488] Loss: 0.10716
Epoch [23/30] Training [29/488] Loss: 0.11989
Epoch [23/30] Training [30/488] Loss: 0.12125
Epoch [23/30] Training [31/488] Loss: 0.16830
Epoch [23/30] Training [32/488] Loss: 0.16748
Epoch [23/30] Training [33/488] Loss: 0.14096
Epoch [23/30] Training [34/488] Loss: 0.14390
Epoch [23/30] Training [35/488] Loss: 0.09313
Epoch [23/30] Training [36/488] Loss: 0.17168
Epoch [23/30] Training [37/488] Loss: 0.12487
Epoch [23/30] Training [38/488] Loss: 0.22036
Epoch [23/30] Training [39/488] Loss: 0.13001
Epoch [23/30] Training [40/488] Loss: 0.11565
Epoch [23/30] Training [41/488] Loss: 0.14455
Epoch [23/30] Training [42/488] Loss: 0.09682
Epoch [23/30] Training [43/488] Loss: 0.18031
Epoch [23/30] Training [44/488] Loss: 0.10953
Epoch [23/30] Training [45/488] Loss: 0.13204
Epoch [23/30] Training [46/488] Loss: 0.18269
Epoch [23/30] Training [47/488] Loss: 0.14192
Epoch [23/30] Training [48/488] Loss: 0.12250
Epoch [23/30] Training [49/488] Loss: 0.15225
Epoch [23/30] Training [50/488] Loss: 0.13787
Epoch [23/30] Training [51/488] Loss: 0.15454
Epoch [23/30] Training [52/488] Loss: 0.07906
Epoch [23/30] Training [53/488] Loss: 0.19073
Epoch [23/30] Training [54/488] Loss: 0.17026
Epoch [23/30] Training [55/488] Loss: 0.12597
Epoch [23/30] Training [56/488] Loss: 0.18382
Epoch [23/30] Training [57/488] Loss: 0.11766
Epoch [23/30] Training [58/488] Loss: 0.13937
Epoch [23/30] Training [59/488] Loss: 0.11886
Epoch [23/30] Training [60/488] Loss: 0.11064
Epoch [23/30] Training [61/488] Loss: 0.27974
Epoch [23/30] Training [62/488] Loss: 0.21717
Epoch [23/30] Training [63/488] Loss: 0.12572
Epoch [23/30] Training [64/488] Loss: 0.13044
Epoch [23/30] Training [65/488] Loss: 0.11933
Epoch [23/30] Training [66/488] Loss: 0.32367
Epoch [23/30] Training [67/488] Loss: 0.31399
Epoch [23/30] Training [68/488] Loss: 0.18096
Epoch [23/30] Training [69/488] Loss: 0.20281
Epoch [23/30] Training [70/488] Loss: 0.17024
Epoch [23/30] Training [71/488] Loss: 0.10688
Epoch [23/30] Training [72/488] Loss: 0.37143
Epoch [23/30] Training [73/488] Loss: 0.12514
Epoch [23/30] Training [74/488] Loss: 0.13456
Epoch [23/30] Training [75/488] Loss: 0.28844
Epoch [23/30] Training [76/488] Loss: 0.11411
Epoch [23/30] Training [77/488] Loss: 0.44587
Epoch [23/30] Training [78/488] Loss: 0.09887
Epoch [23/30] Training [79/488] Loss: 0.10618
Epoch [23/30] Training [80/488] Loss: 0.15425
Epoch [23/30] Training [81/488] Loss: 0.19353
Epoch [23/30] Training [82/488] Loss: 0.13594
Epoch [23/30] Training [83/488] Loss: 0.08373
Epoch [23/30] Training [84/488] Loss: 0.08941
Epoch [23/30] Training [85/488] Loss: 0.14837
Epoch [23/30] Training [86/488] Loss: 0.18202
Epoch [23/30] Training [87/488] Loss: 0.11106
Epoch [23/30] Training [88/488] Loss: 0.12672
Epoch [23/30] Training [89/488] Loss: 0.11182
Epoch [23/30] Training [90/488] Loss: 0.13523
Epoch [23/30] Training [91/488] Loss: 0.22389
Epoch [23/30] Training [92/488] Loss: 0.11114
Epoch [23/30] Training [93/488] Loss: 0.24659
Epoch [23/30] Training [94/488] Loss: 0.10621
Epoch [23/30] Training [95/488] Loss: 0.10881
Epoch [23/30] Training [96/488] Loss: 0.10141
Epoch [23/30] Training [97/488] Loss: 0.57487
Epoch [23/30] Training [98/488] Loss: 0.16363
Epoch [23/30] Training [99/488] Loss: 0.13522
Epoch [23/30] Training [100/488] Loss: 0.15757
Epoch [23/30] Training [101/488] Loss: 0.10627
Epoch [23/30] Training [102/488] Loss: 0.14820
Epoch [23/30] Training [103/488] Loss: 0.17570
Epoch [23/30] Training [104/488] Loss: 0.15533
Epoch [23/30] Training [105/488] Loss: 0.15470
Epoch [23/30] Training [106/488] Loss: 0.11245
Epoch [23/30] Training [107/488] Loss: 0.09944
Epoch [23/30] Training [108/488] Loss: 0.38771
Epoch [23/30] Training [109/488] Loss: 0.12859
Epoch [23/30] Training [110/488] Loss: 0.08270
Epoch [23/30] Training [111/488] Loss: 0.17580
Epoch [23/30] Training [112/488] Loss: 0.09963
Epoch [23/30] Training [113/488] Loss: 0.07999
Epoch [23/30] Training [114/488] Loss: 0.17456
Epoch [23/30] Training [115/488] Loss: 0.19483
Epoch [23/30] Training [116/488] Loss: 0.17818
Epoch [23/30] Training [117/488] Loss: 0.38610
Epoch [23/30] Training [118/488] Loss: 0.12391
Epoch [23/30] Training [119/488] Loss: 0.09663
Epoch [23/30] Training [120/488] Loss: 0.11509
Epoch [23/30] Training [121/488] Loss: 0.14962
Epoch [23/30] Training [122/488] Loss: 0.24273
Epoch [23/30] Training [123/488] Loss: 0.19591
Epoch [23/30] Training [124/488] Loss: 0.71003
Epoch [23/30] Training [125/488] Loss: 0.17512
Epoch [23/30] Training [126/488] Loss: 0.30283
Epoch [23/30] Training [127/488] Loss: 0.15032
Epoch [23/30] Training [128/488] Loss: 0.23332
Epoch [23/30] Training [129/488] Loss: 0.19819
Epoch [23/30] Training [130/488] Loss: 0.10483
Epoch [23/30] Training [131/488] Loss: 0.15438
Epoch [23/30] Training [132/488] Loss: 0.31234
Epoch [23/30] Training [133/488] Loss: 0.12228
Epoch [23/30] Training [134/488] Loss: 0.11315
Epoch [23/30] Training [135/488] Loss: 0.14013
Epoch [23/30] Training [136/488] Loss: 0.31694
Epoch [23/30] Training [137/488] Loss: 0.14964
Epoch [23/30] Training [138/488] Loss: 0.10393
Epoch [23/30] Training [139/488] Loss: 0.16908
Epoch [23/30] Training [140/488] Loss: 0.13934
Epoch [23/30] Training [141/488] Loss: 0.10215
Epoch [23/30] Training [142/488] Loss: 0.48535
Epoch [23/30] Training [143/488] Loss: 0.26310
Epoch [23/30] Training [144/488] Loss: 0.66089
Epoch [23/30] Training [145/488] Loss: 0.11839
Epoch [23/30] Training [146/488] Loss: 0.15746
Epoch [23/30] Training [147/488] Loss: 0.11554
Epoch [23/30] Training [148/488] Loss: 0.17087
Epoch [23/30] Training [149/488] Loss: 0.28368
Epoch [23/30] Training [150/488] Loss: 0.23007
Epoch [23/30] Training [151/488] Loss: 0.10616
Epoch [23/30] Training [152/488] Loss: 0.32291
Epoch [23/30] Training [153/488] Loss: 0.12842
Epoch [23/30] Training [154/488] Loss: 0.14162
Epoch [23/30] Training [155/488] Loss: 0.09255
Epoch [23/30] Training [156/488] Loss: 0.29240
Epoch [23/30] Training [157/488] Loss: 0.12351
Epoch [23/30] Training [158/488] Loss: 0.09729
Epoch [23/30] Training [159/488] Loss: 0.11174
Epoch [23/30] Training [160/488] Loss: 0.21071
Epoch [23/30] Training [161/488] Loss: 0.12363
Epoch [23/30] Training [162/488] Loss: 0.11789
Epoch [23/30] Training [163/488] Loss: 0.17802
Epoch [23/30] Training [164/488] Loss: 0.12124
Epoch [23/30] Training [165/488] Loss: 0.20248
Epoch [23/30] Training [166/488] Loss: 0.37201
Epoch [23/30] Training [167/488] Loss: 0.20310
Epoch [23/30] Training [168/488] Loss: 0.16144
Epoch [23/30] Training [169/488] Loss: 0.08225
Epoch [23/30] Training [170/488] Loss: 0.30673
Epoch [23/30] Training [171/488] Loss: 0.36733
Epoch [23/30] Training [172/488] Loss: 0.40417
Epoch [23/30] Training [173/488] Loss: 0.20439
Epoch [23/30] Training [174/488] Loss: 0.09760
Epoch [23/30] Training [175/488] Loss: 0.13084
Epoch [23/30] Training [176/488] Loss: 0.11804
Epoch [23/30] Training [177/488] Loss: 0.15715
Epoch [23/30] Training [178/488] Loss: 0.12267
Epoch [23/30] Training [179/488] Loss: 0.10839
Epoch [23/30] Training [180/488] Loss: 0.10794
Epoch [23/30] Training [181/488] Loss: 0.26566
Epoch [23/30] Training [182/488] Loss: 0.12020
Epoch [23/30] Training [183/488] Loss: 0.14763
Epoch [23/30] Training [184/488] Loss: 0.29741
Epoch [23/30] Training [185/488] Loss: 0.13437
Epoch [23/30] Training [186/488] Loss: 0.11612
Epoch [23/30] Training [187/488] Loss: 0.16078
Epoch [23/30] Training [188/488] Loss: 0.13143
Epoch [23/30] Training [189/488] Loss: 0.09658
Epoch [23/30] Training [190/488] Loss: 0.45228
Epoch [23/30] Training [191/488] Loss: 0.16287
Epoch [23/30] Training [192/488] Loss: 0.23172
Epoch [23/30] Training [193/488] Loss: 0.14279
Epoch [23/30] Training [194/488] Loss: 0.45333
Epoch [23/30] Training [195/488] Loss: 0.09973
Epoch [23/30] Training [196/488] Loss: 0.24015
Epoch [23/30] Training [197/488] Loss: 0.24241
Epoch [23/30] Training [198/488] Loss: 0.18167
Epoch [23/30] Training [199/488] Loss: 0.10750
Epoch [23/30] Training [200/488] Loss: 0.16203
Epoch [23/30] Training [201/488] Loss: 0.12759
Epoch [23/30] Training [202/488] Loss: 0.14781
Epoch [23/30] Training [203/488] Loss: 0.14052
Epoch [23/30] Training [204/488] Loss: 0.15193
Epoch [23/30] Training [205/488] Loss: 0.27673
Epoch [23/30] Training [206/488] Loss: 0.12509
Epoch [23/30] Training [207/488] Loss: 0.12106
Epoch [23/30] Training [208/488] Loss: 0.55434
Epoch [23/30] Training [209/488] Loss: 0.11540
Epoch [23/30] Training [210/488] Loss: 0.13363
Epoch [23/30] Training [211/488] Loss: 0.25352
Epoch [23/30] Training [212/488] Loss: 0.18497
Epoch [23/30] Training [213/488] Loss: 0.09804
Epoch [23/30] Training [214/488] Loss: 0.10373
Epoch [23/30] Training [215/488] Loss: 0.15937
Epoch [23/30] Training [216/488] Loss: 0.09974
Epoch [23/30] Training [217/488] Loss: 0.16791
Epoch [23/30] Training [218/488] Loss: 0.10975
Epoch [23/30] Training [219/488] Loss: 0.15012
Epoch [23/30] Training [220/488] Loss: 0.10323
Epoch [23/30] Training [221/488] Loss: 0.12000
Epoch [23/30] Training [222/488] Loss: 0.09647
Epoch [23/30] Training [223/488] Loss: 0.15709
Epoch [23/30] Training [224/488] Loss: 0.46740
Epoch [23/30] Training [225/488] Loss: 0.23323
Epoch [23/30] Training [226/488] Loss: 0.43956
Epoch [23/30] Training [227/488] Loss: 0.10981
Epoch [23/30] Training [228/488] Loss: 0.15143
Epoch [23/30] Training [229/488] Loss: 0.16938
Epoch [23/30] Training [230/488] Loss: 0.13639
Epoch [23/30] Training [231/488] Loss: 0.16254
Epoch [23/30] Training [232/488] Loss: 0.16159
Epoch [23/30] Training [233/488] Loss: 0.11345
Epoch [23/30] Training [234/488] Loss: 0.10497
Epoch [23/30] Training [235/488] Loss: 0.71370
Epoch [23/30] Training [236/488] Loss: 0.24236
Epoch [23/30] Training [237/488] Loss: 0.19170
Epoch [23/30] Training [238/488] Loss: 0.10904
Epoch [23/30] Training [239/488] Loss: 0.11275
Epoch [23/30] Training [240/488] Loss: 0.09197
Epoch [23/30] Training [241/488] Loss: 0.35447
Epoch [23/30] Training [242/488] Loss: 0.34787
Epoch [23/30] Training [243/488] Loss: 0.13305
Epoch [23/30] Training [244/488] Loss: 0.16837
Epoch [23/30] Training [245/488] Loss: 0.13940
Epoch [23/30] Training [246/488] Loss: 0.10216
Epoch [23/30] Training [247/488] Loss: 0.08785
Epoch [23/30] Training [248/488] Loss: 0.13683
Epoch [23/30] Training [249/488] Loss: 0.11829
Epoch [23/30] Training [250/488] Loss: 0.14385
Epoch [23/30] Training [251/488] Loss: 0.10703
Epoch [23/30] Training [252/488] Loss: 0.10226
Epoch [23/30] Training [253/488] Loss: 0.25945
Epoch [23/30] Training [254/488] Loss: 0.16714
Epoch [23/30] Training [255/488] Loss: 0.12812
Epoch [23/30] Training [256/488] Loss: 0.13834
Epoch [23/30] Training [257/488] Loss: 0.10466
Epoch [23/30] Training [258/488] Loss: 0.18049
Epoch [23/30] Training [259/488] Loss: 0.25745
Epoch [23/30] Training [260/488] Loss: 0.10460
Epoch [23/30] Training [261/488] Loss: 0.12673
Epoch [23/30] Training [262/488] Loss: 0.40196
Epoch [23/30] Training [263/488] Loss: 0.15918
Epoch [23/30] Training [264/488] Loss: 0.15115
Epoch [23/30] Training [265/488] Loss: 0.37321
Epoch [23/30] Training [266/488] Loss: 0.16437
Epoch [23/30] Training [267/488] Loss: 0.09665
Epoch [23/30] Training [268/488] Loss: 0.55298
Epoch [23/30] Training [269/488] Loss: 0.18362
Epoch [23/30] Training [270/488] Loss: 0.32843
Epoch [23/30] Training [271/488] Loss: 0.11257
Epoch [23/30] Training [272/488] Loss: 0.14477
Epoch [23/30] Training [273/488] Loss: 0.19633
Epoch [23/30] Training [274/488] Loss: 0.30464
Epoch [23/30] Training [275/488] Loss: 0.10976
Epoch [23/30] Training [276/488] Loss: 0.14765
Epoch [23/30] Training [277/488] Loss: 0.11160
Epoch [23/30] Training [278/488] Loss: 0.11990
Epoch [23/30] Training [279/488] Loss: 0.08929
Epoch [23/30] Training [280/488] Loss: 0.24924
Epoch [23/30] Training [281/488] Loss: 0.35789
Epoch [23/30] Training [282/488] Loss: 0.15857
Epoch [23/30] Training [283/488] Loss: 0.71586
Epoch [23/30] Training [284/488] Loss: 0.25072
Epoch [23/30] Training [285/488] Loss: 0.44075
Epoch [23/30] Training [286/488] Loss: 0.16369
Epoch [23/30] Training [287/488] Loss: 0.16038
Epoch [23/30] Training [288/488] Loss: 0.20642
Epoch [23/30] Training [289/488] Loss: 0.18131
Epoch [23/30] Training [290/488] Loss: 0.63822
Epoch [23/30] Training [291/488] Loss: 0.15503
Epoch [23/30] Training [292/488] Loss: 0.14035
Epoch [23/30] Training [293/488] Loss: 0.13671
Epoch [23/30] Training [294/488] Loss: 0.10761
Epoch [23/30] Training [295/488] Loss: 0.09755
Epoch [23/30] Training [296/488] Loss: 0.10362
Epoch [23/30] Training [297/488] Loss: 0.10615
Epoch [23/30] Training [298/488] Loss: 0.42599
Epoch [23/30] Training [299/488] Loss: 0.11163
Epoch [23/30] Training [300/488] Loss: 0.14549
Epoch [23/30] Training [301/488] Loss: 0.11456
Epoch [23/30] Training [302/488] Loss: 0.27326
Epoch [23/30] Training [303/488] Loss: 0.11488
Epoch [23/30] Training [304/488] Loss: 0.68307
Epoch [23/30] Training [305/488] Loss: 0.16135
Epoch [23/30] Training [306/488] Loss: 0.09607
Epoch [23/30] Training [307/488] Loss: 0.18253
Epoch [23/30] Training [308/488] Loss: 0.28867
Epoch [23/30] Training [309/488] Loss: 0.16336
Epoch [23/30] Training [310/488] Loss: 0.08790
Epoch [23/30] Training [311/488] Loss: 0.13028
Epoch [23/30] Training [312/488] Loss: 0.12673
Epoch [23/30] Training [313/488] Loss: 0.35791
Epoch [23/30] Training [314/488] Loss: 0.41702
Epoch [23/30] Training [315/488] Loss: 0.18795
Epoch [23/30] Training [316/488] Loss: 0.14981
Epoch [23/30] Training [317/488] Loss: 0.13960
Epoch [23/30] Training [318/488] Loss: 0.15881
Epoch [23/30] Training [319/488] Loss: 0.20823
Epoch [23/30] Training [320/488] Loss: 0.22456
Epoch [23/30] Training [321/488] Loss: 0.10561
Epoch [23/30] Training [322/488] Loss: 0.10628
Epoch [23/30] Training [323/488] Loss: 0.30460
Epoch [23/30] Training [324/488] Loss: 0.18066
Epoch [23/30] Training [325/488] Loss: 0.11484
Epoch [23/30] Training [326/488] Loss: 0.14629
Epoch [23/30] Training [327/488] Loss: 0.12140
Epoch [23/30] Training [328/488] Loss: 0.08780
Epoch [23/30] Training [329/488] Loss: 0.14703
Epoch [23/30] Training [330/488] Loss: 0.13980
Epoch [23/30] Training [331/488] Loss: 0.11550
Epoch [23/30] Training [332/488] Loss: 0.34910
Epoch [23/30] Training [333/488] Loss: 0.12796
Epoch [23/30] Training [334/488] Loss: 0.13624
Epoch [23/30] Training [335/488] Loss: 0.18936
Epoch [23/30] Training [336/488] Loss: 0.13709
Epoch [23/30] Training [337/488] Loss: 0.15148
Epoch [23/30] Training [338/488] Loss: 0.12939
Epoch [23/30] Training [339/488] Loss: 0.14119
Epoch [23/30] Training [340/488] Loss: 0.11631
Epoch [23/30] Training [341/488] Loss: 0.16617
Epoch [23/30] Training [342/488] Loss: 0.18145
Epoch [23/30] Training [343/488] Loss: 0.10627
Epoch [23/30] Training [344/488] Loss: 0.15202
Epoch [23/30] Training [345/488] Loss: 0.11299
Epoch [23/30] Training [346/488] Loss: 0.33369
Epoch [23/30] Training [347/488] Loss: 0.25608
Epoch [23/30] Training [348/488] Loss: 0.18559
Epoch [23/30] Training [349/488] Loss: 0.12598
Epoch [23/30] Training [350/488] Loss: 0.18617
Epoch [23/30] Training [351/488] Loss: 0.10700
Epoch [23/30] Training [352/488] Loss: 0.28722
Epoch [23/30] Training [353/488] Loss: 0.18193
Epoch [23/30] Training [354/488] Loss: 0.14648
Epoch [23/30] Training [355/488] Loss: 0.32743
Epoch [23/30] Training [356/488] Loss: 0.10601
Epoch [23/30] Training [357/488] Loss: 0.19473
Epoch [23/30] Training [358/488] Loss: 0.29669
Epoch [23/30] Training [359/488] Loss: 0.18554
Epoch [23/30] Training [360/488] Loss: 0.13626
Epoch [23/30] Training [361/488] Loss: 0.17918
Epoch [23/30] Training [362/488] Loss: 0.13772
Epoch [23/30] Training [363/488] Loss: 0.21929
Epoch [23/30] Training [364/488] Loss: 0.24816
Epoch [23/30] Training [365/488] Loss: 0.74577
Epoch [23/30] Training [366/488] Loss: 0.13162
Epoch [23/30] Training [367/488] Loss: 0.12377
Epoch [23/30] Training [368/488] Loss: 0.08332
Epoch [23/30] Training [369/488] Loss: 0.08125
Epoch [23/30] Training [370/488] Loss: 0.13382
Epoch [23/30] Training [371/488] Loss: 0.18418
Epoch [23/30] Training [372/488] Loss: 0.18067
Epoch [23/30] Training [373/488] Loss: 0.10263
Epoch [23/30] Training [374/488] Loss: 0.10131
Epoch [23/30] Training [375/488] Loss: 0.35365
Epoch [23/30] Training [376/488] Loss: 0.22971
Epoch [23/30] Training [377/488] Loss: 0.24534
Epoch [23/30] Training [378/488] Loss: 0.13663
Epoch [23/30] Training [379/488] Loss: 0.11193
Epoch [23/30] Training [380/488] Loss: 0.17460
Epoch [23/30] Training [381/488] Loss: 0.10818
Epoch [23/30] Training [382/488] Loss: 0.17555
Epoch [23/30] Training [383/488] Loss: 0.16117
Epoch [23/30] Training [384/488] Loss: 0.11531
Epoch [23/30] Training [385/488] Loss: 0.27563
Epoch [23/30] Training [386/488] Loss: 0.09032
Epoch [23/30] Training [387/488] Loss: 0.12794
Epoch [23/30] Training [388/488] Loss: 0.14312
Epoch [23/30] Training [389/488] Loss: 0.09121
Epoch [23/30] Training [390/488] Loss: 0.17883
Epoch [23/30] Training [391/488] Loss: 0.18934
Epoch [23/30] Training [392/488] Loss: 0.28918
Epoch [23/30] Training [393/488] Loss: 0.17935
Epoch [23/30] Training [394/488] Loss: 0.16274
Epoch [23/30] Training [395/488] Loss: 0.11792
Epoch [23/30] Training [396/488] Loss: 0.14079
Epoch [23/30] Training [397/488] Loss: 0.19166
Epoch [23/30] Training [398/488] Loss: 0.24912
Epoch [23/30] Training [399/488] Loss: 0.18234
Epoch [23/30] Training [400/488] Loss: 0.11633
Epoch [23/30] Training [401/488] Loss: 0.11258
Epoch [23/30] Training [402/488] Loss: 0.19411
Epoch [23/30] Training [403/488] Loss: 0.13389
Epoch [23/30] Training [404/488] Loss: 0.09369
Epoch [23/30] Training [405/488] Loss: 0.23841
Epoch [23/30] Training [406/488] Loss: 0.13776
Epoch [23/30] Training [407/488] Loss: 0.12586
Epoch [23/30] Training [408/488] Loss: 0.36749
Epoch [23/30] Training [409/488] Loss: 0.20002
Epoch [23/30] Training [410/488] Loss: 0.61946
Epoch [23/30] Training [411/488] Loss: 0.12959
Epoch [23/30] Training [412/488] Loss: 0.25309
Epoch [23/30] Training [413/488] Loss: 0.12574
Epoch [23/30] Training [414/488] Loss: 0.12134
Epoch [23/30] Training [415/488] Loss: 0.14088
Epoch [23/30] Training [416/488] Loss: 0.36954
Epoch [23/30] Training [417/488] Loss: 0.21123
Epoch [23/30] Training [418/488] Loss: 0.15626
Epoch [23/30] Training [419/488] Loss: 0.16966
Epoch [23/30] Training [420/488] Loss: 0.10730
Epoch [23/30] Training [421/488] Loss: 0.19441
Epoch [23/30] Training [422/488] Loss: 0.08471
Epoch [23/30] Training [423/488] Loss: 0.09028
Epoch [23/30] Training [424/488] Loss: 0.22077
Epoch [23/30] Training [425/488] Loss: 0.22372
Epoch [23/30] Training [426/488] Loss: 0.14196
Epoch [23/30] Training [427/488] Loss: 0.07772
Epoch [23/30] Training [428/488] Loss: 0.16001
Epoch [23/30] Training [429/488] Loss: 0.11138
Epoch [23/30] Training [430/488] Loss: 0.12127
Epoch [23/30] Training [431/488] Loss: 0.32155
Epoch [23/30] Training [432/488] Loss: 0.10441
Epoch [23/30] Training [433/488] Loss: 0.21299
Epoch [23/30] Training [434/488] Loss: 0.15581
Epoch [23/30] Training [435/488] Loss: 0.31822
Epoch [23/30] Training [436/488] Loss: 0.19206
Epoch [23/30] Training [437/488] Loss: 0.14734
Epoch [23/30] Training [438/488] Loss: 0.14476
Epoch [23/30] Training [439/488] Loss: 0.09966
Epoch [23/30] Training [440/488] Loss: 0.21205
Epoch [23/30] Training [441/488] Loss: 0.22018
Epoch [23/30] Training [442/488] Loss: 0.14574
Epoch [23/30] Training [443/488] Loss: 0.12778
Epoch [23/30] Training [444/488] Loss: 0.18343
Epoch [23/30] Training [445/488] Loss: 0.13886
Epoch [23/30] Training [446/488] Loss: 0.26013
Epoch [23/30] Training [447/488] Loss: 0.22219
Epoch [23/30] Training [448/488] Loss: 0.13730
Epoch [23/30] Training [449/488] Loss: 0.09785
Epoch [23/30] Training [450/488] Loss: 0.15173
Epoch [23/30] Training [451/488] Loss: 0.47083
Epoch [23/30] Training [452/488] Loss: 0.09253
Epoch [23/30] Training [453/488] Loss: 0.24413
Epoch [23/30] Training [454/488] Loss: 0.10644
Epoch [23/30] Training [455/488] Loss: 0.24570
Epoch [23/30] Training [456/488] Loss: 0.16102
Epoch [23/30] Training [457/488] Loss: 0.11889
Epoch [23/30] Training [458/488] Loss: 0.16854
Epoch [23/30] Training [459/488] Loss: 0.12381
Epoch [23/30] Training [460/488] Loss: 0.16873
Epoch [23/30] Training [461/488] Loss: 0.10318
Epoch [23/30] Training [462/488] Loss: 0.17593
Epoch [23/30] Training [463/488] Loss: 0.11854
Epoch [23/30] Training [464/488] Loss: 0.10584
Epoch [23/30] Training [465/488] Loss: 0.58297
Epoch [23/30] Training [466/488] Loss: 0.10441
Epoch [23/30] Training [467/488] Loss: 0.24603
Epoch [23/30] Training [468/488] Loss: 0.23144
Epoch [23/30] Training [469/488] Loss: 0.17280
Epoch [23/30] Training [470/488] Loss: 0.13093
Epoch [23/30] Training [471/488] Loss: 0.32657
Epoch [23/30] Training [472/488] Loss: 0.12252
Epoch [23/30] Training [473/488] Loss: 0.23439
Epoch [23/30] Training [474/488] Loss: 0.35306
Epoch [23/30] Training [475/488] Loss: 0.10871
Epoch [23/30] Training [476/488] Loss: 0.14879
Epoch [23/30] Training [477/488] Loss: 0.16174
Epoch [23/30] Training [478/488] Loss: 0.25334
Epoch [23/30] Training [479/488] Loss: 0.34695
Epoch [23/30] Training [480/488] Loss: 0.16048
Epoch [23/30] Training [481/488] Loss: 0.28023
Epoch [23/30] Training [482/488] Loss: 0.09173
Epoch [23/30] Training [483/488] Loss: 0.12058
Epoch [23/30] Training [484/488] Loss: 0.22395
Epoch [23/30] Training [485/488] Loss: 0.15878
Epoch [23/30] Training [486/488] Loss: 0.20125
Epoch [23/30] Training [487/488] Loss: 0.12257
Epoch [23/30] Training [488/488] Loss: 0.08791
Epoch [23/30] Training metric {'Train/mean dice_metric': 0.8965855836868286, 'Train/TC dice_metric': 0.910836935043335, 'Train/WT dice_metric': 0.9368041157722473, 'Train/ET dice_metric': 0.8421155214309692}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [23/30] Validation [1/123] Loss: 0.16231  focal_loss 0.00202  dice_loss 0.16029
Epoch [23/30] Validation [2/123] Loss: 0.33293  focal_loss 0.00186  dice_loss 0.33106
Epoch [23/30] Validation [3/123] Loss: 0.13795  focal_loss 0.00165  dice_loss 0.13630
Epoch [23/30] Validation [4/123] Loss: 0.21031  focal_loss 0.00154  dice_loss 0.20876
Epoch [23/30] Validation [5/123] Loss: 0.31528  focal_loss 0.01100  dice_loss 0.30427
Epoch [23/30] Validation [6/123] Loss: 0.32556  focal_loss 0.00346  dice_loss 0.32210
Epoch [23/30] Validation [7/123] Loss: 0.34103  focal_loss 0.00233  dice_loss 0.33870
Epoch [23/30] Validation [8/123] Loss: 0.30963  focal_loss 0.00148  dice_loss 0.30815
Epoch [23/30] Validation [9/123] Loss: 0.21884  focal_loss 0.00149  dice_loss 0.21735
Epoch [23/30] Validation [10/123] Loss: 0.48690  focal_loss 0.00503  dice_loss 0.48187
Epoch [23/30] Validation [11/123] Loss: 0.57137  focal_loss 0.00563  dice_loss 0.56574
Epoch [23/30] Validation [12/123] Loss: 0.17019  focal_loss 0.00210  dice_loss 0.16809
Epoch [23/30] Validation [13/123] Loss: 0.15958  focal_loss 0.00317  dice_loss 0.15641
Epoch [23/30] Validation [14/123] Loss: 0.17188  focal_loss 0.00097  dice_loss 0.17090
Epoch [23/30] Validation [15/123] Loss: 0.30972  focal_loss 0.00178  dice_loss 0.30794
Epoch [23/30] Validation [16/123] Loss: 0.54458  focal_loss 0.00618  dice_loss 0.53840
Epoch [23/30] Validation [17/123] Loss: 0.44158  focal_loss 0.00216  dice_loss 0.43942
Epoch [23/30] Validation [18/123] Loss: 0.37802  focal_loss 0.00961  dice_loss 0.36841
Epoch [23/30] Validation [19/123] Loss: 0.28709  focal_loss 0.02083  dice_loss 0.26626
Epoch [23/30] Validation [20/123] Loss: 0.40681  focal_loss 0.00096  dice_loss 0.40585
Epoch [23/30] Validation [21/123] Loss: 0.29542  focal_loss 0.00136  dice_loss 0.29406
Epoch [23/30] Validation [22/123] Loss: 0.68130  focal_loss 0.02144  dice_loss 0.65986
Epoch [23/30] Validation [23/123] Loss: 0.16130  focal_loss 0.00191  dice_loss 0.15939
Epoch [23/30] Validation [24/123] Loss: 0.25444  focal_loss 0.00445  dice_loss 0.25000
Epoch [23/30] Validation [25/123] Loss: 0.40574  focal_loss 0.01294  dice_loss 0.39280
Epoch [23/30] Validation [26/123] Loss: 0.15525  focal_loss 0.00147  dice_loss 0.15378
Epoch [23/30] Validation [27/123] Loss: 0.22527  focal_loss 0.00633  dice_loss 0.21894
Epoch [23/30] Validation [28/123] Loss: 0.56496  focal_loss 0.01153  dice_loss 0.55344
Epoch [23/30] Validation [29/123] Loss: 0.39703  focal_loss 0.01495  dice_loss 0.38208
Epoch [23/30] Validation [30/123] Loss: 0.20211  focal_loss 0.00351  dice_loss 0.19860
Epoch [23/30] Validation [31/123] Loss: 0.14458  focal_loss 0.00160  dice_loss 0.14298
Epoch [23/30] Validation [32/123] Loss: 0.26230  focal_loss 0.00490  dice_loss 0.25739
Epoch [23/30] Validation [33/123] Loss: 0.32070  focal_loss 0.00245  dice_loss 0.31825
Epoch [23/30] Validation [34/123] Loss: 0.32202  focal_loss 0.00560  dice_loss 0.31642
Epoch [23/30] Validation [35/123] Loss: 0.18747  focal_loss 0.00156  dice_loss 0.18590
Epoch [23/30] Validation [36/123] Loss: 0.20895  focal_loss 0.00111  dice_loss 0.20783
Epoch [23/30] Validation [37/123] Loss: 0.36655  focal_loss 0.01557  dice_loss 0.35098
Epoch [23/30] Validation [38/123] Loss: 0.16044  focal_loss 0.00146  dice_loss 0.15898
Epoch [23/30] Validation [39/123] Loss: 0.16225  focal_loss 0.00163  dice_loss 0.16062
Epoch [23/30] Validation [40/123] Loss: 0.25920  focal_loss 0.00101  dice_loss 0.25819
Epoch [23/30] Validation [41/123] Loss: 0.15589  focal_loss 0.00186  dice_loss 0.15404
Epoch [23/30] Validation [42/123] Loss: 0.15069  focal_loss 0.00165  dice_loss 0.14904
Epoch [23/30] Validation [43/123] Loss: 0.26838  focal_loss 0.02851  dice_loss 0.23986
Epoch [23/30] Validation [44/123] Loss: 0.64699  focal_loss 0.02421  dice_loss 0.62277
Epoch [23/30] Validation [45/123] Loss: 0.24940  focal_loss 0.00188  dice_loss 0.24752
Epoch [23/30] Validation [46/123] Loss: 0.28937  focal_loss 0.00291  dice_loss 0.28646
Epoch [23/30] Validation [47/123] Loss: 0.24485  focal_loss 0.00168  dice_loss 0.24317
Epoch [23/30] Validation [48/123] Loss: 0.40561  focal_loss 0.00644  dice_loss 0.39917
Epoch [23/30] Validation [49/123] Loss: 0.21442  focal_loss 0.02307  dice_loss 0.19135
Epoch [23/30] Validation [50/123] Loss: 0.16971  focal_loss 0.00235  dice_loss 0.16736
Epoch [23/30] Validation [51/123] Loss: 0.36933  focal_loss 0.01220  dice_loss 0.35713
Epoch [23/30] Validation [52/123] Loss: 0.17458  focal_loss 0.00084  dice_loss 0.17374
Epoch [23/30] Validation [53/123] Loss: 0.22822  focal_loss 0.00099  dice_loss 0.22723
Epoch [23/30] Validation [54/123] Loss: 0.30421  focal_loss 0.00249  dice_loss 0.30172
Epoch [23/30] Validation [55/123] Loss: 0.24729  focal_loss 0.00156  dice_loss 0.24573
Epoch [23/30] Validation [56/123] Loss: 0.20300  focal_loss 0.00543  dice_loss 0.19757
Epoch [23/30] Validation [57/123] Loss: 0.26549  focal_loss 0.01317  dice_loss 0.25232
Epoch [23/30] Validation [58/123] Loss: 0.20576  focal_loss 0.00187  dice_loss 0.20388
Epoch [23/30] Validation [59/123] Loss: 0.70510  focal_loss 0.02507  dice_loss 0.68003
Epoch [23/30] Validation [60/123] Loss: 0.21519  focal_loss 0.00562  dice_loss 0.20956
Epoch [23/30] Validation [61/123] Loss: 0.65071  focal_loss 0.01765  dice_loss 0.63306
Epoch [23/30] Validation [62/123] Loss: 0.52367  focal_loss 0.03313  dice_loss 0.49053
Epoch [23/30] Validation [63/123] Loss: 0.32643  focal_loss 0.00197  dice_loss 0.32446
Epoch [23/30] Validation [64/123] Loss: 0.39707  focal_loss 0.02226  dice_loss 0.37481
Epoch [23/30] Validation [65/123] Loss: 0.18219  focal_loss 0.00097  dice_loss 0.18122
Epoch [23/30] Validation [66/123] Loss: 0.19009  focal_loss 0.00174  dice_loss 0.18836
Epoch [23/30] Validation [67/123] Loss: 0.36606  focal_loss 0.00914  dice_loss 0.35691
Epoch [23/30] Validation [68/123] Loss: 0.31474  focal_loss 0.00121  dice_loss 0.31353
Epoch [23/30] Validation [69/123] Loss: 0.37655  focal_loss 0.00739  dice_loss 0.36916
Epoch [23/30] Validation [70/123] Loss: 0.31726  focal_loss 0.00342  dice_loss 0.31384
Epoch [23/30] Validation [71/123] Loss: 0.16915  focal_loss 0.00104  dice_loss 0.16811
Epoch [23/30] Validation [72/123] Loss: 0.16366  focal_loss 0.00185  dice_loss 0.16181
Epoch [23/30] Validation [73/123] Loss: 0.28225  focal_loss 0.00809  dice_loss 0.27417
Epoch [23/30] Validation [74/123] Loss: 0.30840  focal_loss 0.01136  dice_loss 0.29704
Epoch [23/30] Validation [75/123] Loss: 0.19138  focal_loss 0.00106  dice_loss 0.19032
Epoch [23/30] Validation [76/123] Loss: 0.45424  focal_loss 0.00766  dice_loss 0.44659
Epoch [23/30] Validation [77/123] Loss: 0.33990  focal_loss 0.00133  dice_loss 0.33856
Epoch [23/30] Validation [78/123] Loss: 0.22250  focal_loss 0.00165  dice_loss 0.22086
Epoch [23/30] Validation [79/123] Loss: 0.25015  focal_loss 0.00145  dice_loss 0.24870
Epoch [23/30] Validation [80/123] Loss: 0.17270  focal_loss 0.00227  dice_loss 0.17043
Epoch [23/30] Validation [81/123] Loss: 0.21954  focal_loss 0.00251  dice_loss 0.21703
Epoch [23/30] Validation [82/123] Loss: 0.15930  focal_loss 0.00094  dice_loss 0.15835
Epoch [23/30] Validation [83/123] Loss: 0.42550  focal_loss 0.01664  dice_loss 0.40886
Epoch [23/30] Validation [84/123] Loss: 0.20449  focal_loss 0.00140  dice_loss 0.20309
Epoch [23/30] Validation [85/123] Loss: 0.30959  focal_loss 0.00463  dice_loss 0.30496
Epoch [23/30] Validation [86/123] Loss: 0.19262  focal_loss 0.00502  dice_loss 0.18760
Epoch [23/30] Validation [87/123] Loss: 0.19393  focal_loss 0.00661  dice_loss 0.18733
Epoch [23/30] Validation [88/123] Loss: 0.20371  focal_loss 0.00591  dice_loss 0.19781
Epoch [23/30] Validation [89/123] Loss: 0.17150  focal_loss 0.00252  dice_loss 0.16898
Epoch [23/30] Validation [90/123] Loss: 0.25101  focal_loss 0.00357  dice_loss 0.24744
Epoch [23/30] Validation [91/123] Loss: 0.20223  focal_loss 0.00242  dice_loss 0.19981
Epoch [23/30] Validation [92/123] Loss: 0.15043  focal_loss 0.00122  dice_loss 0.14921
Epoch [23/30] Validation [93/123] Loss: 0.16483  focal_loss 0.00212  dice_loss 0.16272
Epoch [23/30] Validation [94/123] Loss: 0.30466  focal_loss 0.00216  dice_loss 0.30250
Epoch [23/30] Validation [95/123] Loss: 0.21082  focal_loss 0.00291  dice_loss 0.20790
Epoch [23/30] Validation [96/123] Loss: 0.26056  focal_loss 0.00173  dice_loss 0.25883
Epoch [23/30] Validation [97/123] Loss: 0.59113  focal_loss 0.00958  dice_loss 0.58156
Epoch [23/30] Validation [98/123] Loss: 0.27109  focal_loss 0.00133  dice_loss 0.26976
Epoch [23/30] Validation [99/123] Loss: 0.25607  focal_loss 0.00079  dice_loss 0.25528
Epoch [23/30] Validation [100/123] Loss: 0.28689  focal_loss 0.00120  dice_loss 0.28569
Epoch [23/30] Validation [101/123] Loss: 0.24674  focal_loss 0.00137  dice_loss 0.24537
Epoch [23/30] Validation [102/123] Loss: 0.29771  focal_loss 0.00098  dice_loss 0.29673
Epoch [23/30] Validation [103/123] Loss: 0.47785  focal_loss 0.00188  dice_loss 0.47598
Epoch [23/30] Validation [104/123] Loss: 0.39309  focal_loss 0.00965  dice_loss 0.38344
Epoch [23/30] Validation [105/123] Loss: 0.17192  focal_loss 0.00341  dice_loss 0.16851
Epoch [23/30] Validation [106/123] Loss: 0.17137  focal_loss 0.00099  dice_loss 0.17038
Epoch [23/30] Validation [107/123] Loss: 0.49892  focal_loss 0.00359  dice_loss 0.49533
Epoch [23/30] Validation [108/123] Loss: 0.17578  focal_loss 0.00076  dice_loss 0.17502
Epoch [23/30] Validation [109/123] Loss: 0.18464  focal_loss 0.00555  dice_loss 0.17909
Epoch [23/30] Validation [110/123] Loss: 0.32628  focal_loss 0.00416  dice_loss 0.32212
Epoch [23/30] Validation [111/123] Loss: 0.34903  focal_loss 0.00461  dice_loss 0.34442
Epoch [23/30] Validation [112/123] Loss: 0.27942  focal_loss 0.00168  dice_loss 0.27774
Epoch [23/30] Validation [113/123] Loss: 0.22724  focal_loss 0.00261  dice_loss 0.22463
Epoch [23/30] Validation [114/123] Loss: 0.29292  focal_loss 0.00543  dice_loss 0.28749
Epoch [23/30] Validation [115/123] Loss: 0.24812  focal_loss 0.00606  dice_loss 0.24206
Epoch [23/30] Validation [116/123] Loss: 0.20112  focal_loss 0.00054  dice_loss 0.20058
Epoch [23/30] Validation [117/123] Loss: 0.21903  focal_loss 0.00123  dice_loss 0.21780
Epoch [23/30] Validation [118/123] Loss: 0.13855  focal_loss 0.00191  dice_loss 0.13664
Epoch [23/30] Validation [119/123] Loss: 0.16399  focal_loss 0.00169  dice_loss 0.16230
Epoch [23/30] Validation [120/123] Loss: 0.19838  focal_loss 0.00209  dice_loss 0.19629
Epoch [23/30] Validation [121/123] Loss: 0.65014  focal_loss 0.02590  dice_loss 0.62424
Epoch [23/30] Validation [122/123] Loss: 0.59068  focal_loss 0.00273  dice_loss 0.58795
Epoch [23/30] Validation [123/123] Loss: 0.18636  focal_loss 0.00151  dice_loss 0.18485
Epoch [23/30] Validation metric {'Val/mean dice_metric': 0.8925412893295288, 'Val/TC dice_metric': 0.904944658279419, 'Val/WT dice_metric': 0.9328690767288208, 'Val/ET dice_metric': 0.8398098945617676}
Epoch [23/30] lr = [0.00023208660251050156, 0.00023208660251050156] best acc: tensor([0.8917], device='cuda:0'), mean acc: tensor([0.8925], device='cuda:0'), mean class: tensor([0.9049, 0.9329, 0.8398], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [24/30] Training [1/488] Loss: 0.28984
Epoch [24/30] Training [2/488] Loss: 0.28763
Epoch [24/30] Training [3/488] Loss: 0.19554
Epoch [24/30] Training [4/488] Loss: 0.14252
Epoch [24/30] Training [5/488] Loss: 0.15740
Epoch [24/30] Training [6/488] Loss: 0.10269
Epoch [24/30] Training [7/488] Loss: 0.10838
Epoch [24/30] Training [8/488] Loss: 0.09916
Epoch [24/30] Training [9/488] Loss: 0.12231
Epoch [24/30] Training [10/488] Loss: 0.09377
Epoch [24/30] Training [11/488] Loss: 0.12100
Epoch [24/30] Training [12/488] Loss: 0.13893
Epoch [24/30] Training [13/488] Loss: 0.17913
Epoch [24/30] Training [14/488] Loss: 0.09081
Epoch [24/30] Training [15/488] Loss: 0.20624
Epoch [24/30] Training [16/488] Loss: 0.11812
Epoch [24/30] Training [17/488] Loss: 0.10617
Epoch [24/30] Training [18/488] Loss: 0.12987
Epoch [24/30] Training [19/488] Loss: 0.13286
Epoch [24/30] Training [20/488] Loss: 0.22660
Epoch [24/30] Training [21/488] Loss: 0.11145
Epoch [24/30] Training [22/488] Loss: 0.13583
Epoch [24/30] Training [23/488] Loss: 0.14005
Epoch [24/30] Training [24/488] Loss: 0.14526
Epoch [24/30] Training [25/488] Loss: 0.12305
Epoch [24/30] Training [26/488] Loss: 0.17939
Epoch [24/30] Training [27/488] Loss: 0.12887
Epoch [24/30] Training [28/488] Loss: 0.13336
Epoch [24/30] Training [29/488] Loss: 0.35013
Epoch [24/30] Training [30/488] Loss: 0.22271
Epoch [24/30] Training [31/488] Loss: 0.14703
Epoch [24/30] Training [32/488] Loss: 0.24159
Epoch [24/30] Training [33/488] Loss: 0.58179
Epoch [24/30] Training [34/488] Loss: 0.09892
Epoch [24/30] Training [35/488] Loss: 0.14290
Epoch [24/30] Training [36/488] Loss: 0.13489
Epoch [24/30] Training [37/488] Loss: 0.09581
Epoch [24/30] Training [38/488] Loss: 0.13001
Epoch [24/30] Training [39/488] Loss: 0.22082
Epoch [24/30] Training [40/488] Loss: 0.30778
Epoch [24/30] Training [41/488] Loss: 0.20529
Epoch [24/30] Training [42/488] Loss: 0.22904
Epoch [24/30] Training [43/488] Loss: 0.17575
Epoch [24/30] Training [44/488] Loss: 0.15530
Epoch [24/30] Training [45/488] Loss: 0.07491
Epoch [24/30] Training [46/488] Loss: 0.13134
Epoch [24/30] Training [47/488] Loss: 0.09473
Epoch [24/30] Training [48/488] Loss: 0.21042
Epoch [24/30] Training [49/488] Loss: 0.16553
Epoch [24/30] Training [50/488] Loss: 0.27966
Epoch [24/30] Training [51/488] Loss: 0.14314
Epoch [24/30] Training [52/488] Loss: 0.17160
Epoch [24/30] Training [53/488] Loss: 0.11287
Epoch [24/30] Training [54/488] Loss: 0.12450
Epoch [24/30] Training [55/488] Loss: 0.40576
Epoch [24/30] Training [56/488] Loss: 0.17150
Epoch [24/30] Training [57/488] Loss: 0.11630
Epoch [24/30] Training [58/488] Loss: 0.45551
Epoch [24/30] Training [59/488] Loss: 0.14857
Epoch [24/30] Training [60/488] Loss: 0.16605
Epoch [24/30] Training [61/488] Loss: 0.10201
Epoch [24/30] Training [62/488] Loss: 0.31812
Epoch [24/30] Training [63/488] Loss: 0.10880
Epoch [24/30] Training [64/488] Loss: 0.16609
Epoch [24/30] Training [65/488] Loss: 0.10402
Epoch [24/30] Training [66/488] Loss: 0.24057
Epoch [24/30] Training [67/488] Loss: 0.11525
Epoch [24/30] Training [68/488] Loss: 0.31645
Epoch [24/30] Training [69/488] Loss: 0.17733
Epoch [24/30] Training [70/488] Loss: 0.16585
Epoch [24/30] Training [71/488] Loss: 0.14899
Epoch [24/30] Training [72/488] Loss: 0.18901
Epoch [24/30] Training [73/488] Loss: 0.14013
Epoch [24/30] Training [74/488] Loss: 0.13418
Epoch [24/30] Training [75/488] Loss: 0.13438
Epoch [24/30] Training [76/488] Loss: 0.24079
Epoch [24/30] Training [77/488] Loss: 0.09612
Epoch [24/30] Training [78/488] Loss: 0.08797
Epoch [24/30] Training [79/488] Loss: 0.35561
Epoch [24/30] Training [80/488] Loss: 0.08799
Epoch [24/30] Training [81/488] Loss: 0.15815
Epoch [24/30] Training [82/488] Loss: 0.11920
Epoch [24/30] Training [83/488] Loss: 0.11097
Epoch [24/30] Training [84/488] Loss: 0.38017
Epoch [24/30] Training [85/488] Loss: 0.10277
Epoch [24/30] Training [86/488] Loss: 0.18051
Epoch [24/30] Training [87/488] Loss: 0.42943
Epoch [24/30] Training [88/488] Loss: 0.30649
Epoch [24/30] Training [89/488] Loss: 0.18348
Epoch [24/30] Training [90/488] Loss: 0.26842
Epoch [24/30] Training [91/488] Loss: 0.10868
Epoch [24/30] Training [92/488] Loss: 0.24514
Epoch [24/30] Training [93/488] Loss: 0.17197
Epoch [24/30] Training [94/488] Loss: 0.09038
Epoch [24/30] Training [95/488] Loss: 0.09660
Epoch [24/30] Training [96/488] Loss: 0.11304
Epoch [24/30] Training [97/488] Loss: 0.12456
Epoch [24/30] Training [98/488] Loss: 0.38289
Epoch [24/30] Training [99/488] Loss: 0.11373
Epoch [24/30] Training [100/488] Loss: 0.13164
Epoch [24/30] Training [101/488] Loss: 0.11139
Epoch [24/30] Training [102/488] Loss: 0.43988
Epoch [24/30] Training [103/488] Loss: 0.21764
Epoch [24/30] Training [104/488] Loss: 0.13307
Epoch [24/30] Training [105/488] Loss: 0.15192
Epoch [24/30] Training [106/488] Loss: 0.10464
Epoch [24/30] Training [107/488] Loss: 0.07978
Epoch [24/30] Training [108/488] Loss: 0.14883
Epoch [24/30] Training [109/488] Loss: 0.10226
Epoch [24/30] Training [110/488] Loss: 0.13865
Epoch [24/30] Training [111/488] Loss: 0.11315
Epoch [24/30] Training [112/488] Loss: 0.17555
Epoch [24/30] Training [113/488] Loss: 0.10121
Epoch [24/30] Training [114/488] Loss: 0.50069
Epoch [24/30] Training [115/488] Loss: 0.10859
Epoch [24/30] Training [116/488] Loss: 0.13970
Epoch [24/30] Training [117/488] Loss: 0.11242
Epoch [24/30] Training [118/488] Loss: 0.35998
Epoch [24/30] Training [119/488] Loss: 0.10695
Epoch [24/30] Training [120/488] Loss: 0.41903
Epoch [24/30] Training [121/488] Loss: 0.14618
Epoch [24/30] Training [122/488] Loss: 0.46602
Epoch [24/30] Training [123/488] Loss: 0.19139
Epoch [24/30] Training [124/488] Loss: 0.14935
Epoch [24/30] Training [125/488] Loss: 0.18019
Epoch [24/30] Training [126/488] Loss: 0.15097
Epoch [24/30] Training [127/488] Loss: 0.15925
Epoch [24/30] Training [128/488] Loss: 0.17796
Epoch [24/30] Training [129/488] Loss: 0.37558
Epoch [24/30] Training [130/488] Loss: 0.08637
Epoch [24/30] Training [131/488] Loss: 0.30943
Epoch [24/30] Training [132/488] Loss: 0.71806
Epoch [24/30] Training [133/488] Loss: 0.18775
Epoch [24/30] Training [134/488] Loss: 0.29935
Epoch [24/30] Training [135/488] Loss: 0.09742
Epoch [24/30] Training [136/488] Loss: 0.21648
Epoch [24/30] Training [137/488] Loss: 0.11635
Epoch [24/30] Training [138/488] Loss: 0.09760
Epoch [24/30] Training [139/488] Loss: 0.16225
Epoch [24/30] Training [140/488] Loss: 0.10185
Epoch [24/30] Training [141/488] Loss: 0.15401
Epoch [24/30] Training [142/488] Loss: 0.13580
Epoch [24/30] Training [143/488] Loss: 0.26744
Epoch [24/30] Training [144/488] Loss: 0.14290
Epoch [24/30] Training [145/488] Loss: 0.16146
Epoch [24/30] Training [146/488] Loss: 0.12839
Epoch [24/30] Training [147/488] Loss: 0.14354
Epoch [24/30] Training [148/488] Loss: 0.16517
Epoch [24/30] Training [149/488] Loss: 0.17638
Epoch [24/30] Training [150/488] Loss: 0.09871
Epoch [24/30] Training [151/488] Loss: 0.10002
Epoch [24/30] Training [152/488] Loss: 0.08653
Epoch [24/30] Training [153/488] Loss: 0.36943
Epoch [24/30] Training [154/488] Loss: 0.13716
Epoch [24/30] Training [155/488] Loss: 0.23389
Epoch [24/30] Training [156/488] Loss: 0.10410
Epoch [24/30] Training [157/488] Loss: 0.23091
Epoch [24/30] Training [158/488] Loss: 0.11448
Epoch [24/30] Training [159/488] Loss: 0.26600
Epoch [24/30] Training [160/488] Loss: 0.69564
Epoch [24/30] Training [161/488] Loss: 0.18044
Epoch [24/30] Training [162/488] Loss: 0.12719
Epoch [24/30] Training [163/488] Loss: 0.18024
Epoch [24/30] Training [164/488] Loss: 0.13533
Epoch [24/30] Training [165/488] Loss: 0.24615
Epoch [24/30] Training [166/488] Loss: 0.11198
Epoch [24/30] Training [167/488] Loss: 0.73152
Epoch [24/30] Training [168/488] Loss: 0.15813
Epoch [24/30] Training [169/488] Loss: 0.23086
Epoch [24/30] Training [170/488] Loss: 0.12227
Epoch [24/30] Training [171/488] Loss: 0.16266
Epoch [24/30] Training [172/488] Loss: 0.20782
Epoch [24/30] Training [173/488] Loss: 0.12002
Epoch [24/30] Training [174/488] Loss: 0.07921
Epoch [24/30] Training [175/488] Loss: 0.11263
Epoch [24/30] Training [176/488] Loss: 0.26320
Epoch [24/30] Training [177/488] Loss: 0.17668
Epoch [24/30] Training [178/488] Loss: 0.10975
Epoch [24/30] Training [179/488] Loss: 0.11185
Epoch [24/30] Training [180/488] Loss: 0.29278
Epoch [24/30] Training [181/488] Loss: 0.11424
Epoch [24/30] Training [182/488] Loss: 0.11219
Epoch [24/30] Training [183/488] Loss: 0.15293
Epoch [24/30] Training [184/488] Loss: 0.12522
Epoch [24/30] Training [185/488] Loss: 0.14762
Epoch [24/30] Training [186/488] Loss: 0.09691
Epoch [24/30] Training [187/488] Loss: 0.11761
Epoch [24/30] Training [188/488] Loss: 0.21682
Epoch [24/30] Training [189/488] Loss: 0.26661
Epoch [24/30] Training [190/488] Loss: 0.10240
Epoch [24/30] Training [191/488] Loss: 0.12142
Epoch [24/30] Training [192/488] Loss: 0.15062
Epoch [24/30] Training [193/488] Loss: 0.21077
Epoch [24/30] Training [194/488] Loss: 0.14560
Epoch [24/30] Training [195/488] Loss: 0.19702
Epoch [24/30] Training [196/488] Loss: 0.09019
Epoch [24/30] Training [197/488] Loss: 0.13228
Epoch [24/30] Training [198/488] Loss: 0.12947
Epoch [24/30] Training [199/488] Loss: 0.15190
Epoch [24/30] Training [200/488] Loss: 0.19267
Epoch [24/30] Training [201/488] Loss: 0.10963
Epoch [24/30] Training [202/488] Loss: 0.16648
Epoch [24/30] Training [203/488] Loss: 0.10997
Epoch [24/30] Training [204/488] Loss: 0.28948
Epoch [24/30] Training [205/488] Loss: 0.10955
Epoch [24/30] Training [206/488] Loss: 0.11083
Epoch [24/30] Training [207/488] Loss: 0.15914
Epoch [24/30] Training [208/488] Loss: 0.40501
Epoch [24/30] Training [209/488] Loss: 0.16403
Epoch [24/30] Training [210/488] Loss: 0.12266
Epoch [24/30] Training [211/488] Loss: 0.13897
Epoch [24/30] Training [212/488] Loss: 0.16064
Epoch [24/30] Training [213/488] Loss: 0.14796
Epoch [24/30] Training [214/488] Loss: 0.10356
Epoch [24/30] Training [215/488] Loss: 0.20129
Epoch [24/30] Training [216/488] Loss: 0.13111
Epoch [24/30] Training [217/488] Loss: 0.16513
Epoch [24/30] Training [218/488] Loss: 0.10590
Epoch [24/30] Training [219/488] Loss: 0.14347
Epoch [24/30] Training [220/488] Loss: 0.15676
Epoch [24/30] Training [221/488] Loss: 0.10813
Epoch [24/30] Training [222/488] Loss: 0.10627
Epoch [24/30] Training [223/488] Loss: 0.16330
Epoch [24/30] Training [224/488] Loss: 0.10017
Epoch [24/30] Training [225/488] Loss: 0.14543
Epoch [24/30] Training [226/488] Loss: 0.18036
Epoch [24/30] Training [227/488] Loss: 0.11492
Epoch [24/30] Training [228/488] Loss: 0.08913
Epoch [24/30] Training [229/488] Loss: 0.12453
Epoch [24/30] Training [230/488] Loss: 0.09856
Epoch [24/30] Training [231/488] Loss: 0.15713
Epoch [24/30] Training [232/488] Loss: 0.23284
Epoch [24/30] Training [233/488] Loss: 0.16495
Epoch [24/30] Training [234/488] Loss: 0.22027
Epoch [24/30] Training [235/488] Loss: 0.24424
Epoch [24/30] Training [236/488] Loss: 0.11014
Epoch [24/30] Training [237/488] Loss: 0.10467
Epoch [24/30] Training [238/488] Loss: 0.12530
Epoch [24/30] Training [239/488] Loss: 0.08473
Epoch [24/30] Training [240/488] Loss: 0.28719
Epoch [24/30] Training [241/488] Loss: 0.15502
Epoch [24/30] Training [242/488] Loss: 0.16180
Epoch [24/30] Training [243/488] Loss: 0.13339
Epoch [24/30] Training [244/488] Loss: 0.31972
Epoch [24/30] Training [245/488] Loss: 0.35751
Epoch [24/30] Training [246/488] Loss: 0.25334
Epoch [24/30] Training [247/488] Loss: 0.10483
Epoch [24/30] Training [248/488] Loss: 0.09544
Epoch [24/30] Training [249/488] Loss: 0.10971
Epoch [24/30] Training [250/488] Loss: 0.11767
Epoch [24/30] Training [251/488] Loss: 0.12056
Epoch [24/30] Training [252/488] Loss: 0.76784
Epoch [24/30] Training [253/488] Loss: 0.35208
Epoch [24/30] Training [254/488] Loss: 0.18698
Epoch [24/30] Training [255/488] Loss: 0.15435
Epoch [24/30] Training [256/488] Loss: 0.17604
Epoch [24/30] Training [257/488] Loss: 0.26418
Epoch [24/30] Training [258/488] Loss: 0.12596
Epoch [24/30] Training [259/488] Loss: 0.11883
Epoch [24/30] Training [260/488] Loss: 0.22812
Epoch [24/30] Training [261/488] Loss: 0.14634
Epoch [24/30] Training [262/488] Loss: 0.13056
Epoch [24/30] Training [263/488] Loss: 0.54973
Epoch [24/30] Training [264/488] Loss: 0.18500
Epoch [24/30] Training [265/488] Loss: 0.16688
Epoch [24/30] Training [266/488] Loss: 0.13738
Epoch [24/30] Training [267/488] Loss: 0.31015
Epoch [24/30] Training [268/488] Loss: 0.11904
Epoch [24/30] Training [269/488] Loss: 0.17822
Epoch [24/30] Training [270/488] Loss: 0.14156
Epoch [24/30] Training [271/488] Loss: 0.10460
Epoch [24/30] Training [272/488] Loss: 0.10598
Epoch [24/30] Training [273/488] Loss: 0.10468
Epoch [24/30] Training [274/488] Loss: 0.41961
Epoch [24/30] Training [275/488] Loss: 0.11058
Epoch [24/30] Training [276/488] Loss: 0.16024
Epoch [24/30] Training [277/488] Loss: 0.12521
Epoch [24/30] Training [278/488] Loss: 0.10384
Epoch [24/30] Training [279/488] Loss: 0.27948
Epoch [24/30] Training [280/488] Loss: 0.26077
Epoch [24/30] Training [281/488] Loss: 0.12024
Epoch [24/30] Training [282/488] Loss: 0.68300
Epoch [24/30] Training [283/488] Loss: 0.08922
Epoch [24/30] Training [284/488] Loss: 0.14253
Epoch [24/30] Training [285/488] Loss: 0.15114
Epoch [24/30] Training [286/488] Loss: 0.09030
Epoch [24/30] Training [287/488] Loss: 0.08546
Epoch [24/30] Training [288/488] Loss: 0.10061
Epoch [24/30] Training [289/488] Loss: 0.16148
Epoch [24/30] Training [290/488] Loss: 0.13609
Epoch [24/30] Training [291/488] Loss: 0.16413
Epoch [24/30] Training [292/488] Loss: 0.33276
Epoch [24/30] Training [293/488] Loss: 0.14603
Epoch [24/30] Training [294/488] Loss: 0.11898
Epoch [24/30] Training [295/488] Loss: 0.17942
Epoch [24/30] Training [296/488] Loss: 0.13706
Epoch [24/30] Training [297/488] Loss: 0.09835
Epoch [24/30] Training [298/488] Loss: 0.09608
Epoch [24/30] Training [299/488] Loss: 0.10724
Epoch [24/30] Training [300/488] Loss: 0.10602
Epoch [24/30] Training [301/488] Loss: 0.12203
Epoch [24/30] Training [302/488] Loss: 0.10884
Epoch [24/30] Training [303/488] Loss: 0.19618
Epoch [24/30] Training [304/488] Loss: 0.13632
Epoch [24/30] Training [305/488] Loss: 0.38181
Epoch [24/30] Training [306/488] Loss: 0.09681
Epoch [24/30] Training [307/488] Loss: 0.70009
Epoch [24/30] Training [308/488] Loss: 0.14601
Epoch [24/30] Training [309/488] Loss: 0.26209
Epoch [24/30] Training [310/488] Loss: 0.14895
Epoch [24/30] Training [311/488] Loss: 0.10737
Epoch [24/30] Training [312/488] Loss: 0.10075
Epoch [24/30] Training [313/488] Loss: 0.10545
Epoch [24/30] Training [314/488] Loss: 0.15369
Epoch [24/30] Training [315/488] Loss: 0.07926
Epoch [24/30] Training [316/488] Loss: 0.14742
Epoch [24/30] Training [317/488] Loss: 0.19881
Epoch [24/30] Training [318/488] Loss: 0.14152
Epoch [24/30] Training [319/488] Loss: 0.13422
Epoch [24/30] Training [320/488] Loss: 0.09267
Epoch [24/30] Training [321/488] Loss: 0.13278
Epoch [24/30] Training [322/488] Loss: 0.09149
Epoch [24/30] Training [323/488] Loss: 0.28704
Epoch [24/30] Training [324/488] Loss: 0.22144
Epoch [24/30] Training [325/488] Loss: 0.18733
Epoch [24/30] Training [326/488] Loss: 0.14384
Epoch [24/30] Training [327/488] Loss: 0.17869
Epoch [24/30] Training [328/488] Loss: 0.17780
Epoch [24/30] Training [329/488] Loss: 0.16629
Epoch [24/30] Training [330/488] Loss: 0.31395
Epoch [24/30] Training [331/488] Loss: 0.10549
Epoch [24/30] Training [332/488] Loss: 0.10029
Epoch [24/30] Training [333/488] Loss: 0.18224
Epoch [24/30] Training [334/488] Loss: 0.22531
Epoch [24/30] Training [335/488] Loss: 0.18579
Epoch [24/30] Training [336/488] Loss: 0.10901
Epoch [24/30] Training [337/488] Loss: 0.47500
Epoch [24/30] Training [338/488] Loss: 0.14391
Epoch [24/30] Training [339/488] Loss: 0.13290
Epoch [24/30] Training [340/488] Loss: 0.11877
Epoch [24/30] Training [341/488] Loss: 0.08196
Epoch [24/30] Training [342/488] Loss: 0.17071
Epoch [24/30] Training [343/488] Loss: 0.09950
Epoch [24/30] Training [344/488] Loss: 0.09673
Epoch [24/30] Training [345/488] Loss: 0.11889
Epoch [24/30] Training [346/488] Loss: 0.16744
Epoch [24/30] Training [347/488] Loss: 0.18388
Epoch [24/30] Training [348/488] Loss: 0.13997
Epoch [24/30] Training [349/488] Loss: 0.14945
Epoch [24/30] Training [350/488] Loss: 0.09985
Epoch [24/30] Training [351/488] Loss: 0.11368
Epoch [24/30] Training [352/488] Loss: 0.46810
Epoch [24/30] Training [353/488] Loss: 0.08268
Epoch [24/30] Training [354/488] Loss: 0.12460
Epoch [24/30] Training [355/488] Loss: 0.23654
Epoch [24/30] Training [356/488] Loss: 0.12151
Epoch [24/30] Training [357/488] Loss: 0.28134
Epoch [24/30] Training [358/488] Loss: 0.11636
Epoch [24/30] Training [359/488] Loss: 0.14877
Epoch [24/30] Training [360/488] Loss: 0.34342
Epoch [24/30] Training [361/488] Loss: 0.12352
Epoch [24/30] Training [362/488] Loss: 0.32605
Epoch [24/30] Training [363/488] Loss: 0.11891
Epoch [24/30] Training [364/488] Loss: 0.30879
Epoch [24/30] Training [365/488] Loss: 0.14831
Epoch [24/30] Training [366/488] Loss: 0.12865
Epoch [24/30] Training [367/488] Loss: 0.15921
Epoch [24/30] Training [368/488] Loss: 0.15749
Epoch [24/30] Training [369/488] Loss: 0.10677
Epoch [24/30] Training [370/488] Loss: 0.09299
Epoch [24/30] Training [371/488] Loss: 0.12536
Epoch [24/30] Training [372/488] Loss: 0.32128
Epoch [24/30] Training [373/488] Loss: 0.11328
Epoch [24/30] Training [374/488] Loss: 0.19861
Epoch [24/30] Training [375/488] Loss: 0.50830
Epoch [24/30] Training [376/488] Loss: 0.13247
Epoch [24/30] Training [377/488] Loss: 0.17579
Epoch [24/30] Training [378/488] Loss: 0.23510
Epoch [24/30] Training [379/488] Loss: 0.25547
Epoch [24/30] Training [380/488] Loss: 0.12579
Epoch [24/30] Training [381/488] Loss: 0.22865
Epoch [24/30] Training [382/488] Loss: 0.12495
Epoch [24/30] Training [383/488] Loss: 0.38417
Epoch [24/30] Training [384/488] Loss: 0.12637
Epoch [24/30] Training [385/488] Loss: 0.13775
Epoch [24/30] Training [386/488] Loss: 0.09484
Epoch [24/30] Training [387/488] Loss: 0.16770
Epoch [24/30] Training [388/488] Loss: 0.08249
Epoch [24/30] Training [389/488] Loss: 0.14573
Epoch [24/30] Training [390/488] Loss: 0.32689
Epoch [24/30] Training [391/488] Loss: 0.13912
Epoch [24/30] Training [392/488] Loss: 0.13563
Epoch [24/30] Training [393/488] Loss: 0.10553
Epoch [24/30] Training [394/488] Loss: 0.38839
Epoch [24/30] Training [395/488] Loss: 0.17773
Epoch [24/30] Training [396/488] Loss: 0.08572
Epoch [24/30] Training [397/488] Loss: 0.40148
Epoch [24/30] Training [398/488] Loss: 0.13153
Epoch [24/30] Training [399/488] Loss: 0.25012
Epoch [24/30] Training [400/488] Loss: 0.11879
Epoch [24/30] Training [401/488] Loss: 0.17509
Epoch [24/30] Training [402/488] Loss: 0.67679
Epoch [24/30] Training [403/488] Loss: 0.10722
Epoch [24/30] Training [404/488] Loss: 0.12304
Epoch [24/30] Training [405/488] Loss: 0.18076
Epoch [24/30] Training [406/488] Loss: 0.15919
Epoch [24/30] Training [407/488] Loss: 0.22800
Epoch [24/30] Training [408/488] Loss: 0.33814
Epoch [24/30] Training [409/488] Loss: 0.10359
Epoch [24/30] Training [410/488] Loss: 0.13783
Epoch [24/30] Training [411/488] Loss: 0.12363
Epoch [24/30] Training [412/488] Loss: 0.11610
Epoch [24/30] Training [413/488] Loss: 0.16172
Epoch [24/30] Training [414/488] Loss: 0.10015
Epoch [24/30] Training [415/488] Loss: 0.09269
Epoch [24/30] Training [416/488] Loss: 0.10375
Epoch [24/30] Training [417/488] Loss: 0.63358
Epoch [24/30] Training [418/488] Loss: 0.22813
Epoch [24/30] Training [419/488] Loss: 0.12078
Epoch [24/30] Training [420/488] Loss: 0.10434
Epoch [24/30] Training [421/488] Loss: 0.13484
Epoch [24/30] Training [422/488] Loss: 0.36508
Epoch [24/30] Training [423/488] Loss: 0.14642
Epoch [24/30] Training [424/488] Loss: 0.11418
Epoch [24/30] Training [425/488] Loss: 0.27744
Epoch [24/30] Training [426/488] Loss: 0.13715
Epoch [24/30] Training [427/488] Loss: 0.08853
Epoch [24/30] Training [428/488] Loss: 0.28158
Epoch [24/30] Training [429/488] Loss: 0.14097
Epoch [24/30] Training [430/488] Loss: 0.12068
Epoch [24/30] Training [431/488] Loss: 0.14599
Epoch [24/30] Training [432/488] Loss: 0.10477
Epoch [24/30] Training [433/488] Loss: 0.09645
Epoch [24/30] Training [434/488] Loss: 0.07467
Epoch [24/30] Training [435/488] Loss: 0.42777
Epoch [24/30] Training [436/488] Loss: 0.07624
Epoch [24/30] Training [437/488] Loss: 0.27731
Epoch [24/30] Training [438/488] Loss: 0.17507
Epoch [24/30] Training [439/488] Loss: 0.13556
Epoch [24/30] Training [440/488] Loss: 0.27491
Epoch [24/30] Training [441/488] Loss: 0.25768
Epoch [24/30] Training [442/488] Loss: 0.15721
Epoch [24/30] Training [443/488] Loss: 0.12965
Epoch [24/30] Training [444/488] Loss: 0.32416
Epoch [24/30] Training [445/488] Loss: 0.13232
Epoch [24/30] Training [446/488] Loss: 0.11780
Epoch [24/30] Training [447/488] Loss: 0.09864
Epoch [24/30] Training [448/488] Loss: 0.09446
Epoch [24/30] Training [449/488] Loss: 0.22409
Epoch [24/30] Training [450/488] Loss: 0.10494
Epoch [24/30] Training [451/488] Loss: 0.11087
Epoch [24/30] Training [452/488] Loss: 0.09429
Epoch [24/30] Training [453/488] Loss: 0.11203
Epoch [24/30] Training [454/488] Loss: 0.35781
Epoch [24/30] Training [455/488] Loss: 0.11738
Epoch [24/30] Training [456/488] Loss: 0.17679
Epoch [24/30] Training [457/488] Loss: 0.09887
Epoch [24/30] Training [458/488] Loss: 0.11445
Epoch [24/30] Training [459/488] Loss: 0.09543
Epoch [24/30] Training [460/488] Loss: 0.08479
Epoch [24/30] Training [461/488] Loss: 0.09884
Epoch [24/30] Training [462/488] Loss: 0.12897
Epoch [24/30] Training [463/488] Loss: 0.18079
Epoch [24/30] Training [464/488] Loss: 0.11437
Epoch [24/30] Training [465/488] Loss: 0.12181
Epoch [24/30] Training [466/488] Loss: 0.10730
Epoch [24/30] Training [467/488] Loss: 0.09763
Epoch [24/30] Training [468/488] Loss: 0.24068
Epoch [24/30] Training [469/488] Loss: 0.09832
Epoch [24/30] Training [470/488] Loss: 0.32643
Epoch [24/30] Training [471/488] Loss: 0.19602
Epoch [24/30] Training [472/488] Loss: 0.09588
Epoch [24/30] Training [473/488] Loss: 0.09196
Epoch [24/30] Training [474/488] Loss: 0.16577
Epoch [24/30] Training [475/488] Loss: 0.12512
Epoch [24/30] Training [476/488] Loss: 0.10803
Epoch [24/30] Training [477/488] Loss: 0.17080
Epoch [24/30] Training [478/488] Loss: 0.29385
Epoch [24/30] Training [479/488] Loss: 0.09942
Epoch [24/30] Training [480/488] Loss: 0.10791
Epoch [24/30] Training [481/488] Loss: 0.09100
Epoch [24/30] Training [482/488] Loss: 0.09477
Epoch [24/30] Training [483/488] Loss: 0.16200
Epoch [24/30] Training [484/488] Loss: 0.13606
Epoch [24/30] Training [485/488] Loss: 0.17622
Epoch [24/30] Training [486/488] Loss: 0.13501
Epoch [24/30] Training [487/488] Loss: 0.16454
Epoch [24/30] Training [488/488] Loss: 0.12776
Epoch [24/30] Training metric {'Train/mean dice_metric': 0.8988950252532959, 'Train/TC dice_metric': 0.9133498072624207, 'Train/WT dice_metric': 0.9371621012687683, 'Train/ET dice_metric': 0.846173107624054}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [24/30] Validation [1/123] Loss: 0.15401  focal_loss 0.00206  dice_loss 0.15195
Epoch [24/30] Validation [2/123] Loss: 0.31709  focal_loss 0.00119  dice_loss 0.31589
Epoch [24/30] Validation [3/123] Loss: 0.13234  focal_loss 0.00172  dice_loss 0.13063
Epoch [24/30] Validation [4/123] Loss: 0.20073  focal_loss 0.00134  dice_loss 0.19939
Epoch [24/30] Validation [5/123] Loss: 0.31061  focal_loss 0.01106  dice_loss 0.29955
Epoch [24/30] Validation [6/123] Loss: 0.29248  focal_loss 0.00228  dice_loss 0.29021
Epoch [24/30] Validation [7/123] Loss: 0.28841  focal_loss 0.00065  dice_loss 0.28776
Epoch [24/30] Validation [8/123] Loss: 0.29897  focal_loss 0.00134  dice_loss 0.29763
Epoch [24/30] Validation [9/123] Loss: 0.21834  focal_loss 0.00192  dice_loss 0.21642
Epoch [24/30] Validation [10/123] Loss: 0.43757  focal_loss 0.00354  dice_loss 0.43403
Epoch [24/30] Validation [11/123] Loss: 0.52719  focal_loss 0.00339  dice_loss 0.52380
Epoch [24/30] Validation [12/123] Loss: 0.15361  focal_loss 0.00147  dice_loss 0.15214
Epoch [24/30] Validation [13/123] Loss: 0.15759  focal_loss 0.00322  dice_loss 0.15437
Epoch [24/30] Validation [14/123] Loss: 0.16108  focal_loss 0.00091  dice_loss 0.16016
Epoch [24/30] Validation [15/123] Loss: 0.29424  focal_loss 0.00133  dice_loss 0.29291
Epoch [24/30] Validation [16/123] Loss: 0.45454  focal_loss 0.00235  dice_loss 0.45218
Epoch [24/30] Validation [17/123] Loss: 0.44347  focal_loss 0.00218  dice_loss 0.44129
Epoch [24/30] Validation [18/123] Loss: 0.30285  focal_loss 0.00354  dice_loss 0.29931
Epoch [24/30] Validation [19/123] Loss: 0.24404  focal_loss 0.00828  dice_loss 0.23576
Epoch [24/30] Validation [20/123] Loss: 0.38638  focal_loss 0.00082  dice_loss 0.38556
Epoch [24/30] Validation [21/123] Loss: 0.26969  focal_loss 0.00086  dice_loss 0.26884
Epoch [24/30] Validation [22/123] Loss: 0.59303  focal_loss 0.00865  dice_loss 0.58438
Epoch [24/30] Validation [23/123] Loss: 0.14571  focal_loss 0.00196  dice_loss 0.14375
Epoch [24/30] Validation [24/123] Loss: 0.23272  focal_loss 0.00289  dice_loss 0.22983
Epoch [24/30] Validation [25/123] Loss: 0.32609  focal_loss 0.00656  dice_loss 0.31953
Epoch [24/30] Validation [26/123] Loss: 0.15249  focal_loss 0.00187  dice_loss 0.15062
Epoch [24/30] Validation [27/123] Loss: 0.17719  focal_loss 0.00191  dice_loss 0.17528
Epoch [24/30] Validation [28/123] Loss: 0.51171  focal_loss 0.00509  dice_loss 0.50662
Epoch [24/30] Validation [29/123] Loss: 0.29183  focal_loss 0.00281  dice_loss 0.28902
Epoch [24/30] Validation [30/123] Loss: 0.19183  focal_loss 0.00351  dice_loss 0.18833
Epoch [24/30] Validation [31/123] Loss: 0.13750  focal_loss 0.00169  dice_loss 0.13581
Epoch [24/30] Validation [32/123] Loss: 0.24484  focal_loss 0.00354  dice_loss 0.24129
Epoch [24/30] Validation [33/123] Loss: 0.30024  focal_loss 0.00174  dice_loss 0.29850
Epoch [24/30] Validation [34/123] Loss: 0.22403  focal_loss 0.00104  dice_loss 0.22298
Epoch [24/30] Validation [35/123] Loss: 0.17201  focal_loss 0.00182  dice_loss 0.17020
Epoch [24/30] Validation [36/123] Loss: 0.20211  focal_loss 0.00125  dice_loss 0.20086
Epoch [24/30] Validation [37/123] Loss: 0.30815  focal_loss 0.00414  dice_loss 0.30401
Epoch [24/30] Validation [38/123] Loss: 0.15533  focal_loss 0.00170  dice_loss 0.15363
Epoch [24/30] Validation [39/123] Loss: 0.14755  focal_loss 0.00110  dice_loss 0.14645
Epoch [24/30] Validation [40/123] Loss: 0.24837  focal_loss 0.00091  dice_loss 0.24746
Epoch [24/30] Validation [41/123] Loss: 0.14875  focal_loss 0.00161  dice_loss 0.14714
Epoch [24/30] Validation [42/123] Loss: 0.14036  focal_loss 0.00166  dice_loss 0.13870
Epoch [24/30] Validation [43/123] Loss: 0.24531  focal_loss 0.02326  dice_loss 0.22205
Epoch [24/30] Validation [44/123] Loss: 0.53328  focal_loss 0.00685  dice_loss 0.52644
Epoch [24/30] Validation [45/123] Loss: 0.24511  focal_loss 0.00205  dice_loss 0.24306
Epoch [24/30] Validation [46/123] Loss: 0.29340  focal_loss 0.00330  dice_loss 0.29010
Epoch [24/30] Validation [47/123] Loss: 0.23088  focal_loss 0.00151  dice_loss 0.22937
Epoch [24/30] Validation [48/123] Loss: 0.38928  focal_loss 0.00598  dice_loss 0.38330
Epoch [24/30] Validation [49/123] Loss: 0.16818  focal_loss 0.00410  dice_loss 0.16408
Epoch [24/30] Validation [50/123] Loss: 0.15852  focal_loss 0.00220  dice_loss 0.15632
Epoch [24/30] Validation [51/123] Loss: 0.33970  focal_loss 0.01025  dice_loss 0.32945
Epoch [24/30] Validation [52/123] Loss: 0.16760  focal_loss 0.00095  dice_loss 0.16665
Epoch [24/30] Validation [53/123] Loss: 0.21439  focal_loss 0.00088  dice_loss 0.21351
Epoch [24/30] Validation [54/123] Loss: 0.27457  focal_loss 0.00146  dice_loss 0.27311
Epoch [24/30] Validation [55/123] Loss: 0.22551  focal_loss 0.00127  dice_loss 0.22424
Epoch [24/30] Validation [56/123] Loss: 0.17965  focal_loss 0.00385  dice_loss 0.17580
Epoch [24/30] Validation [57/123] Loss: 0.24679  focal_loss 0.00819  dice_loss 0.23860
Epoch [24/30] Validation [58/123] Loss: 0.19690  focal_loss 0.00198  dice_loss 0.19492
Epoch [24/30] Validation [59/123] Loss: 0.58551  focal_loss 0.00939  dice_loss 0.57612
Epoch [24/30] Validation [60/123] Loss: 0.19243  focal_loss 0.00249  dice_loss 0.18994
Epoch [24/30] Validation [61/123] Loss: 0.55863  focal_loss 0.00221  dice_loss 0.55642
Epoch [24/30] Validation [62/123] Loss: 0.48240  focal_loss 0.01630  dice_loss 0.46609
Epoch [24/30] Validation [63/123] Loss: 0.31125  focal_loss 0.00152  dice_loss 0.30972
Epoch [24/30] Validation [64/123] Loss: 0.35756  focal_loss 0.01076  dice_loss 0.34681
Epoch [24/30] Validation [65/123] Loss: 0.17373  focal_loss 0.00101  dice_loss 0.17272
Epoch [24/30] Validation [66/123] Loss: 0.17328  focal_loss 0.00106  dice_loss 0.17222
Epoch [24/30] Validation [67/123] Loss: 0.32409  focal_loss 0.00543  dice_loss 0.31866
Epoch [24/30] Validation [68/123] Loss: 0.29918  focal_loss 0.00102  dice_loss 0.29816
Epoch [24/30] Validation [69/123] Loss: 0.37311  focal_loss 0.00750  dice_loss 0.36561
Epoch [24/30] Validation [70/123] Loss: 0.29276  focal_loss 0.00277  dice_loss 0.29000
Epoch [24/30] Validation [71/123] Loss: 0.15842  focal_loss 0.00101  dice_loss 0.15741
Epoch [24/30] Validation [72/123] Loss: 0.15111  focal_loss 0.00167  dice_loss 0.14944
Epoch [24/30] Validation [73/123] Loss: 0.24600  focal_loss 0.00284  dice_loss 0.24315
Epoch [24/30] Validation [74/123] Loss: 0.24196  focal_loss 0.00169  dice_loss 0.24027
Epoch [24/30] Validation [75/123] Loss: 0.19391  focal_loss 0.00172  dice_loss 0.19219
Epoch [24/30] Validation [76/123] Loss: 0.46651  focal_loss 0.00444  dice_loss 0.46207
Epoch [24/30] Validation [77/123] Loss: 0.30940  focal_loss 0.00083  dice_loss 0.30857
Epoch [24/30] Validation [78/123] Loss: 0.21437  focal_loss 0.00157  dice_loss 0.21281
Epoch [24/30] Validation [79/123] Loss: 0.24331  focal_loss 0.00154  dice_loss 0.24177
Epoch [24/30] Validation [80/123] Loss: 0.16847  focal_loss 0.00252  dice_loss 0.16595
Epoch [24/30] Validation [81/123] Loss: 0.20274  focal_loss 0.00213  dice_loss 0.20061
Epoch [24/30] Validation [82/123] Loss: 0.15175  focal_loss 0.00101  dice_loss 0.15073
Epoch [24/30] Validation [83/123] Loss: 0.35156  focal_loss 0.01143  dice_loss 0.34013
Epoch [24/30] Validation [84/123] Loss: 0.19569  focal_loss 0.00140  dice_loss 0.19429
Epoch [24/30] Validation [85/123] Loss: 0.23100  focal_loss 0.00221  dice_loss 0.22879
Epoch [24/30] Validation [86/123] Loss: 0.17070  focal_loss 0.00129  dice_loss 0.16941
Epoch [24/30] Validation [87/123] Loss: 0.17937  focal_loss 0.00247  dice_loss 0.17690
Epoch [24/30] Validation [88/123] Loss: 0.18201  focal_loss 0.00163  dice_loss 0.18038
Epoch [24/30] Validation [89/123] Loss: 0.15729  focal_loss 0.00206  dice_loss 0.15523
Epoch [24/30] Validation [90/123] Loss: 0.23428  focal_loss 0.00196  dice_loss 0.23232
Epoch [24/30] Validation [91/123] Loss: 0.17901  focal_loss 0.00138  dice_loss 0.17763
Epoch [24/30] Validation [92/123] Loss: 0.14418  focal_loss 0.00143  dice_loss 0.14275
Epoch [24/30] Validation [93/123] Loss: 0.15438  focal_loss 0.00205  dice_loss 0.15232
Epoch [24/30] Validation [94/123] Loss: 0.29085  focal_loss 0.00175  dice_loss 0.28910
Epoch [24/30] Validation [95/123] Loss: 0.20366  focal_loss 0.00255  dice_loss 0.20111
Epoch [24/30] Validation [96/123] Loss: 0.25262  focal_loss 0.00171  dice_loss 0.25092
Epoch [24/30] Validation [97/123] Loss: 0.57723  focal_loss 0.00698  dice_loss 0.57025
Epoch [24/30] Validation [98/123] Loss: 0.25364  focal_loss 0.00096  dice_loss 0.25268
Epoch [24/30] Validation [99/123] Loss: 0.24517  focal_loss 0.00080  dice_loss 0.24437
Epoch [24/30] Validation [100/123] Loss: 0.28077  focal_loss 0.00137  dice_loss 0.27940
Epoch [24/30] Validation [101/123] Loss: 0.23777  focal_loss 0.00119  dice_loss 0.23659
Epoch [24/30] Validation [102/123] Loss: 0.27625  focal_loss 0.00081  dice_loss 0.27544
Epoch [24/30] Validation [103/123] Loss: 0.44521  focal_loss 0.00110  dice_loss 0.44411
Epoch [24/30] Validation [104/123] Loss: 0.35902  focal_loss 0.00398  dice_loss 0.35504
Epoch [24/30] Validation [105/123] Loss: 0.16323  focal_loss 0.00301  dice_loss 0.16023
Epoch [24/30] Validation [106/123] Loss: 0.16474  focal_loss 0.00108  dice_loss 0.16367
Epoch [24/30] Validation [107/123] Loss: 0.46645  focal_loss 0.00209  dice_loss 0.46437
Epoch [24/30] Validation [108/123] Loss: 0.16651  focal_loss 0.00079  dice_loss 0.16572
Epoch [24/30] Validation [109/123] Loss: 0.17418  focal_loss 0.00518  dice_loss 0.16900
Epoch [24/30] Validation [110/123] Loss: 0.30427  focal_loss 0.00353  dice_loss 0.30074
Epoch [24/30] Validation [111/123] Loss: 0.32065  focal_loss 0.00363  dice_loss 0.31702
Epoch [24/30] Validation [112/123] Loss: 0.24240  focal_loss 0.00083  dice_loss 0.24157
Epoch [24/30] Validation [113/123] Loss: 0.20238  focal_loss 0.00151  dice_loss 0.20087
Epoch [24/30] Validation [114/123] Loss: 0.28346  focal_loss 0.00498  dice_loss 0.27848
Epoch [24/30] Validation [115/123] Loss: 0.24624  focal_loss 0.00628  dice_loss 0.23996
Epoch [24/30] Validation [116/123] Loss: 0.19002  focal_loss 0.00057  dice_loss 0.18946
Epoch [24/30] Validation [117/123] Loss: 0.21056  focal_loss 0.00125  dice_loss 0.20930
Epoch [24/30] Validation [118/123] Loss: 0.13405  focal_loss 0.00206  dice_loss 0.13200
Epoch [24/30] Validation [119/123] Loss: 0.15230  focal_loss 0.00147  dice_loss 0.15084
Epoch [24/30] Validation [120/123] Loss: 0.18893  focal_loss 0.00213  dice_loss 0.18680
Epoch [24/30] Validation [121/123] Loss: 0.61451  focal_loss 0.02092  dice_loss 0.59358
Epoch [24/30] Validation [122/123] Loss: 0.47597  focal_loss 0.00053  dice_loss 0.47545
Epoch [24/30] Validation [123/123] Loss: 0.18540  focal_loss 0.00179  dice_loss 0.18361
Epoch [24/30] Validation metric {'Val/mean dice_metric': 0.8966814279556274, 'Val/TC dice_metric': 0.9092789888381958, 'Val/WT dice_metric': 0.9360158443450928, 'Val/ET dice_metric': 0.8447493314743042}
Epoch [24/30] lr = [0.00018128800512565513, 0.00018128800512565513] best acc: tensor([0.8925], device='cuda:0'), mean acc: tensor([0.8967], device='cuda:0'), mean class: tensor([0.9093, 0.9360, 0.8447], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [25/30] Training [1/488] Loss: 0.13205
Epoch [25/30] Training [2/488] Loss: 0.16286
Epoch [25/30] Training [3/488] Loss: 0.11187
Epoch [25/30] Training [4/488] Loss: 0.13852
Epoch [25/30] Training [5/488] Loss: 0.38851
Epoch [25/30] Training [6/488] Loss: 0.12429
Epoch [25/30] Training [7/488] Loss: 0.09702
Epoch [25/30] Training [8/488] Loss: 0.41444
Epoch [25/30] Training [9/488] Loss: 0.48797
Epoch [25/30] Training [10/488] Loss: 0.10677
Epoch [25/30] Training [11/488] Loss: 0.11542
Epoch [25/30] Training [12/488] Loss: 0.10795
Epoch [25/30] Training [13/488] Loss: 0.12469
Epoch [25/30] Training [14/488] Loss: 0.43641
Epoch [25/30] Training [15/488] Loss: 0.12022
Epoch [25/30] Training [16/488] Loss: 0.12264
Epoch [25/30] Training [17/488] Loss: 0.26600
Epoch [25/30] Training [18/488] Loss: 0.17087
Epoch [25/30] Training [19/488] Loss: 0.10296
Epoch [25/30] Training [20/488] Loss: 0.09543
Epoch [25/30] Training [21/488] Loss: 0.13491
Epoch [25/30] Training [22/488] Loss: 0.09977
Epoch [25/30] Training [23/488] Loss: 0.17614
Epoch [25/30] Training [24/488] Loss: 0.10653
Epoch [25/30] Training [25/488] Loss: 0.10103
Epoch [25/30] Training [26/488] Loss: 0.20298
Epoch [25/30] Training [27/488] Loss: 0.37379
Epoch [25/30] Training [28/488] Loss: 0.37566
Epoch [25/30] Training [29/488] Loss: 0.08865
Epoch [25/30] Training [30/488] Loss: 0.18116
Epoch [25/30] Training [31/488] Loss: 0.14461
Epoch [25/30] Training [32/488] Loss: 0.42912
Epoch [25/30] Training [33/488] Loss: 0.12320
Epoch [25/30] Training [34/488] Loss: 0.09346
Epoch [25/30] Training [35/488] Loss: 0.11816
Epoch [25/30] Training [36/488] Loss: 0.23641
Epoch [25/30] Training [37/488] Loss: 0.12906
Epoch [25/30] Training [38/488] Loss: 0.12025
Epoch [25/30] Training [39/488] Loss: 0.15976
Epoch [25/30] Training [40/488] Loss: 0.10129
Epoch [25/30] Training [41/488] Loss: 0.09622
Epoch [25/30] Training [42/488] Loss: 0.09740
Epoch [25/30] Training [43/488] Loss: 0.15464
Epoch [25/30] Training [44/488] Loss: 0.18444
Epoch [25/30] Training [45/488] Loss: 0.10017
Epoch [25/30] Training [46/488] Loss: 0.29896
Epoch [25/30] Training [47/488] Loss: 0.15967
Epoch [25/30] Training [48/488] Loss: 0.14388
Epoch [25/30] Training [49/488] Loss: 0.11334
Epoch [25/30] Training [50/488] Loss: 0.17016
Epoch [25/30] Training [51/488] Loss: 0.13249
Epoch [25/30] Training [52/488] Loss: 0.22520
Epoch [25/30] Training [53/488] Loss: 0.17917
Epoch [25/30] Training [54/488] Loss: 0.07681
Epoch [25/30] Training [55/488] Loss: 0.09967
Epoch [25/30] Training [56/488] Loss: 0.10879
Epoch [25/30] Training [57/488] Loss: 0.11591
Epoch [25/30] Training [58/488] Loss: 0.36559
Epoch [25/30] Training [59/488] Loss: 0.21424
Epoch [25/30] Training [60/488] Loss: 0.19738
Epoch [25/30] Training [61/488] Loss: 0.46841
Epoch [25/30] Training [62/488] Loss: 0.10967
Epoch [25/30] Training [63/488] Loss: 0.09125
Epoch [25/30] Training [64/488] Loss: 0.22506
Epoch [25/30] Training [65/488] Loss: 0.18503
Epoch [25/30] Training [66/488] Loss: 0.27200
Epoch [25/30] Training [67/488] Loss: 0.15062
Epoch [25/30] Training [68/488] Loss: 0.11769
Epoch [25/30] Training [69/488] Loss: 0.13032
Epoch [25/30] Training [70/488] Loss: 0.70890
Epoch [25/30] Training [71/488] Loss: 0.10651
Epoch [25/30] Training [72/488] Loss: 0.16765
Epoch [25/30] Training [73/488] Loss: 0.14435
Epoch [25/30] Training [74/488] Loss: 0.14580
Epoch [25/30] Training [75/488] Loss: 0.10178
Epoch [25/30] Training [76/488] Loss: 0.09799
Epoch [25/30] Training [77/488] Loss: 0.12909
Epoch [25/30] Training [78/488] Loss: 0.13877
Epoch [25/30] Training [79/488] Loss: 0.13205
Epoch [25/30] Training [80/488] Loss: 0.12091
Epoch [25/30] Training [81/488] Loss: 0.12873
Epoch [25/30] Training [82/488] Loss: 0.10251
Epoch [25/30] Training [83/488] Loss: 0.11804
Epoch [25/30] Training [84/488] Loss: 0.12388
Epoch [25/30] Training [85/488] Loss: 0.21260
Epoch [25/30] Training [86/488] Loss: 0.22086
Epoch [25/30] Training [87/488] Loss: 0.10556
Epoch [25/30] Training [88/488] Loss: 0.16357
Epoch [25/30] Training [89/488] Loss: 0.16477
Epoch [25/30] Training [90/488] Loss: 0.13018
Epoch [25/30] Training [91/488] Loss: 0.09780
Epoch [25/30] Training [92/488] Loss: 0.10476
Epoch [25/30] Training [93/488] Loss: 0.10275
Epoch [25/30] Training [94/488] Loss: 0.12187
Epoch [25/30] Training [95/488] Loss: 0.09260
Epoch [25/30] Training [96/488] Loss: 0.09955
Epoch [25/30] Training [97/488] Loss: 0.15336
Epoch [25/30] Training [98/488] Loss: 0.07098
Epoch [25/30] Training [99/488] Loss: 0.08668
Epoch [25/30] Training [100/488] Loss: 0.13705
Epoch [25/30] Training [101/488] Loss: 0.10858
Epoch [25/30] Training [102/488] Loss: 0.59286
Epoch [25/30] Training [103/488] Loss: 0.22918
Epoch [25/30] Training [104/488] Loss: 0.09887
Epoch [25/30] Training [105/488] Loss: 0.11050
Epoch [25/30] Training [106/488] Loss: 0.30280
Epoch [25/30] Training [107/488] Loss: 0.09153
Epoch [25/30] Training [108/488] Loss: 0.15663
Epoch [25/30] Training [109/488] Loss: 0.28026
Epoch [25/30] Training [110/488] Loss: 0.26105
Epoch [25/30] Training [111/488] Loss: 0.11566
Epoch [25/30] Training [112/488] Loss: 0.14337
Epoch [25/30] Training [113/488] Loss: 0.07143
Epoch [25/30] Training [114/488] Loss: 0.10504
Epoch [25/30] Training [115/488] Loss: 0.09768
Epoch [25/30] Training [116/488] Loss: 0.17412
Epoch [25/30] Training [117/488] Loss: 0.13457
Epoch [25/30] Training [118/488] Loss: 0.25308
Epoch [25/30] Training [119/488] Loss: 0.08782
Epoch [25/30] Training [120/488] Loss: 0.11482
Epoch [25/30] Training [121/488] Loss: 0.11254
Epoch [25/30] Training [122/488] Loss: 0.12308
Epoch [25/30] Training [123/488] Loss: 0.11519
Epoch [25/30] Training [124/488] Loss: 0.22286
Epoch [25/30] Training [125/488] Loss: 0.10479
Epoch [25/30] Training [126/488] Loss: 0.25362
Epoch [25/30] Training [127/488] Loss: 0.17695
Epoch [25/30] Training [128/488] Loss: 0.32289
Epoch [25/30] Training [129/488] Loss: 0.14438
Epoch [25/30] Training [130/488] Loss: 0.10484
Epoch [25/30] Training [131/488] Loss: 0.08241
Epoch [25/30] Training [132/488] Loss: 0.26235
Epoch [25/30] Training [133/488] Loss: 0.08793
Epoch [25/30] Training [134/488] Loss: 0.22210
Epoch [25/30] Training [135/488] Loss: 0.24298
Epoch [25/30] Training [136/488] Loss: 0.13158
Epoch [25/30] Training [137/488] Loss: 0.29153
Epoch [25/30] Training [138/488] Loss: 0.22716
Epoch [25/30] Training [139/488] Loss: 0.09771
Epoch [25/30] Training [140/488] Loss: 0.37019
Epoch [25/30] Training [141/488] Loss: 0.09217
Epoch [25/30] Training [142/488] Loss: 0.15994
Epoch [25/30] Training [143/488] Loss: 0.35883
Epoch [25/30] Training [144/488] Loss: 0.13613
Epoch [25/30] Training [145/488] Loss: 0.14269
Epoch [25/30] Training [146/488] Loss: 0.15435
Epoch [25/30] Training [147/488] Loss: 0.13597
Epoch [25/30] Training [148/488] Loss: 0.13541
Epoch [25/30] Training [149/488] Loss: 0.10676
Epoch [25/30] Training [150/488] Loss: 0.17309
Epoch [25/30] Training [151/488] Loss: 0.11750
Epoch [25/30] Training [152/488] Loss: 0.13073
Epoch [25/30] Training [153/488] Loss: 0.31329
Epoch [25/30] Training [154/488] Loss: 0.10804
Epoch [25/30] Training [155/488] Loss: 0.16265
Epoch [25/30] Training [156/488] Loss: 0.15700
Epoch [25/30] Training [157/488] Loss: 0.12330
Epoch [25/30] Training [158/488] Loss: 0.11597
Epoch [25/30] Training [159/488] Loss: 0.20938
Epoch [25/30] Training [160/488] Loss: 0.10366
Epoch [25/30] Training [161/488] Loss: 0.33812
Epoch [25/30] Training [162/488] Loss: 0.13399
Epoch [25/30] Training [163/488] Loss: 0.09846
Epoch [25/30] Training [164/488] Loss: 0.19100
Epoch [25/30] Training [165/488] Loss: 0.19620
Epoch [25/30] Training [166/488] Loss: 0.17166
Epoch [25/30] Training [167/488] Loss: 0.22708
Epoch [25/30] Training [168/488] Loss: 0.16676
Epoch [25/30] Training [169/488] Loss: 0.09852
Epoch [25/30] Training [170/488] Loss: 0.10978
Epoch [25/30] Training [171/488] Loss: 0.11920
Epoch [25/30] Training [172/488] Loss: 0.18744
Epoch [25/30] Training [173/488] Loss: 0.14674
Epoch [25/30] Training [174/488] Loss: 0.10803
Epoch [25/30] Training [175/488] Loss: 0.12381
Epoch [25/30] Training [176/488] Loss: 0.11183
Epoch [25/30] Training [177/488] Loss: 0.09801
Epoch [25/30] Training [178/488] Loss: 0.38198
Epoch [25/30] Training [179/488] Loss: 0.12568
Epoch [25/30] Training [180/488] Loss: 0.36023
Epoch [25/30] Training [181/488] Loss: 0.27348
Epoch [25/30] Training [182/488] Loss: 0.08968
Epoch [25/30] Training [183/488] Loss: 0.14982
Epoch [25/30] Training [184/488] Loss: 0.14018
Epoch [25/30] Training [185/488] Loss: 0.11232
Epoch [25/30] Training [186/488] Loss: 0.10296
Epoch [25/30] Training [187/488] Loss: 0.21336
Epoch [25/30] Training [188/488] Loss: 0.15400
Epoch [25/30] Training [189/488] Loss: 0.09494
Epoch [25/30] Training [190/488] Loss: 0.47745
Epoch [25/30] Training [191/488] Loss: 0.12189
Epoch [25/30] Training [192/488] Loss: 0.11287
Epoch [25/30] Training [193/488] Loss: 0.14261
Epoch [25/30] Training [194/488] Loss: 0.12941
Epoch [25/30] Training [195/488] Loss: 0.10288
Epoch [25/30] Training [196/488] Loss: 0.20384
Epoch [25/30] Training [197/488] Loss: 0.54186
Epoch [25/30] Training [198/488] Loss: 0.16703
Epoch [25/30] Training [199/488] Loss: 0.10252
Epoch [25/30] Training [200/488] Loss: 0.28241
Epoch [25/30] Training [201/488] Loss: 0.16884
Epoch [25/30] Training [202/488] Loss: 0.29732
Epoch [25/30] Training [203/488] Loss: 0.17336
Epoch [25/30] Training [204/488] Loss: 0.12886
Epoch [25/30] Training [205/488] Loss: 0.07679
Epoch [25/30] Training [206/488] Loss: 0.12511
Epoch [25/30] Training [207/488] Loss: 0.18269
Epoch [25/30] Training [208/488] Loss: 0.25562
Epoch [25/30] Training [209/488] Loss: 0.09230
Epoch [25/30] Training [210/488] Loss: 0.10780
Epoch [25/30] Training [211/488] Loss: 0.11256
Epoch [25/30] Training [212/488] Loss: 0.11816
Epoch [25/30] Training [213/488] Loss: 0.26880
Epoch [25/30] Training [214/488] Loss: 0.13471
Epoch [25/30] Training [215/488] Loss: 0.10490
Epoch [25/30] Training [216/488] Loss: 0.70084
Epoch [25/30] Training [217/488] Loss: 0.30134
Epoch [25/30] Training [218/488] Loss: 0.25404
Epoch [25/30] Training [219/488] Loss: 0.15491
Epoch [25/30] Training [220/488] Loss: 0.14361
Epoch [25/30] Training [221/488] Loss: 0.10220
Epoch [25/30] Training [222/488] Loss: 0.13172
Epoch [25/30] Training [223/488] Loss: 0.11722
Epoch [25/30] Training [224/488] Loss: 0.09179
Epoch [25/30] Training [225/488] Loss: 0.13333
Epoch [25/30] Training [226/488] Loss: 0.15314
Epoch [25/30] Training [227/488] Loss: 0.15098
Epoch [25/30] Training [228/488] Loss: 0.10791
Epoch [25/30] Training [229/488] Loss: 0.10123
Epoch [25/30] Training [230/488] Loss: 0.11911
Epoch [25/30] Training [231/488] Loss: 0.33631
Epoch [25/30] Training [232/488] Loss: 0.16125
Epoch [25/30] Training [233/488] Loss: 0.10821
Epoch [25/30] Training [234/488] Loss: 0.16440
Epoch [25/30] Training [235/488] Loss: 0.17388
Epoch [25/30] Training [236/488] Loss: 0.72159
Epoch [25/30] Training [237/488] Loss: 0.10822
Epoch [25/30] Training [238/488] Loss: 0.09377
Epoch [25/30] Training [239/488] Loss: 0.08966
Epoch [25/30] Training [240/488] Loss: 0.08614
Epoch [25/30] Training [241/488] Loss: 0.12407
Epoch [25/30] Training [242/488] Loss: 0.16594
Epoch [25/30] Training [243/488] Loss: 0.09518
Epoch [25/30] Training [244/488] Loss: 0.49410
Epoch [25/30] Training [245/488] Loss: 0.21550
Epoch [25/30] Training [246/488] Loss: 0.12071
Epoch [25/30] Training [247/488] Loss: 0.21844
Epoch [25/30] Training [248/488] Loss: 0.09252
Epoch [25/30] Training [249/488] Loss: 0.09825
Epoch [25/30] Training [250/488] Loss: 0.23813
Epoch [25/30] Training [251/488] Loss: 0.12715
Epoch [25/30] Training [252/488] Loss: 0.21039
Epoch [25/30] Training [253/488] Loss: 0.09199
Epoch [25/30] Training [254/488] Loss: 0.11149
Epoch [25/30] Training [255/488] Loss: 0.23712
Epoch [25/30] Training [256/488] Loss: 0.06813
Epoch [25/30] Training [257/488] Loss: 0.22732
Epoch [25/30] Training [258/488] Loss: 0.13515
Epoch [25/30] Training [259/488] Loss: 0.08656
Epoch [25/30] Training [260/488] Loss: 0.12177
Epoch [25/30] Training [261/488] Loss: 0.13282
Epoch [25/30] Training [262/488] Loss: 0.14290
Epoch [25/30] Training [263/488] Loss: 0.24281
Epoch [25/30] Training [264/488] Loss: 0.11727
Epoch [25/30] Training [265/488] Loss: 0.10099
Epoch [25/30] Training [266/488] Loss: 0.13841
Epoch [25/30] Training [267/488] Loss: 0.14976
Epoch [25/30] Training [268/488] Loss: 0.11746
Epoch [25/30] Training [269/488] Loss: 0.11149
Epoch [25/30] Training [270/488] Loss: 0.11512
Epoch [25/30] Training [271/488] Loss: 0.14539
Epoch [25/30] Training [272/488] Loss: 0.28882
Epoch [25/30] Training [273/488] Loss: 0.09772
Epoch [25/30] Training [274/488] Loss: 0.15531
Epoch [25/30] Training [275/488] Loss: 0.11644
Epoch [25/30] Training [276/488] Loss: 0.10616
Epoch [25/30] Training [277/488] Loss: 0.16226
Epoch [25/30] Training [278/488] Loss: 0.53310
Epoch [25/30] Training [279/488] Loss: 0.20890
Epoch [25/30] Training [280/488] Loss: 0.33297
Epoch [25/30] Training [281/488] Loss: 0.14934
Epoch [25/30] Training [282/488] Loss: 0.12826
Epoch [25/30] Training [283/488] Loss: 0.25420
Epoch [25/30] Training [284/488] Loss: 0.08258
Epoch [25/30] Training [285/488] Loss: 0.10537
Epoch [25/30] Training [286/488] Loss: 0.12044
Epoch [25/30] Training [287/488] Loss: 0.13439
Epoch [25/30] Training [288/488] Loss: 0.08665
Epoch [25/30] Training [289/488] Loss: 0.31556
Epoch [25/30] Training [290/488] Loss: 0.11174
Epoch [25/30] Training [291/488] Loss: 0.10381
Epoch [25/30] Training [292/488] Loss: 0.17372
Epoch [25/30] Training [293/488] Loss: 0.13137
Epoch [25/30] Training [294/488] Loss: 0.11152
Epoch [25/30] Training [295/488] Loss: 0.14304
Epoch [25/30] Training [296/488] Loss: 0.09500
Epoch [25/30] Training [297/488] Loss: 0.22960
Epoch [25/30] Training [298/488] Loss: 0.11828
Epoch [25/30] Training [299/488] Loss: 0.10137
Epoch [25/30] Training [300/488] Loss: 0.17113
Epoch [25/30] Training [301/488] Loss: 0.08199
Epoch [25/30] Training [302/488] Loss: 0.12430
Epoch [25/30] Training [303/488] Loss: 0.30134
Epoch [25/30] Training [304/488] Loss: 0.72112
Epoch [25/30] Training [305/488] Loss: 0.32187
Epoch [25/30] Training [306/488] Loss: 0.12070
Epoch [25/30] Training [307/488] Loss: 0.11336
Epoch [25/30] Training [308/488] Loss: 0.14718
Epoch [25/30] Training [309/488] Loss: 0.09383
Epoch [25/30] Training [310/488] Loss: 0.13988
Epoch [25/30] Training [311/488] Loss: 0.23165
Epoch [25/30] Training [312/488] Loss: 0.36261
Epoch [25/30] Training [313/488] Loss: 0.12391
Epoch [25/30] Training [314/488] Loss: 0.11671
Epoch [25/30] Training [315/488] Loss: 0.15152
Epoch [25/30] Training [316/488] Loss: 0.43927
Epoch [25/30] Training [317/488] Loss: 0.10073
Epoch [25/30] Training [318/488] Loss: 0.18156
Epoch [25/30] Training [319/488] Loss: 0.14108
Epoch [25/30] Training [320/488] Loss: 0.30130
Epoch [25/30] Training [321/488] Loss: 0.15217
Epoch [25/30] Training [322/488] Loss: 0.10434
Epoch [25/30] Training [323/488] Loss: 0.20117
Epoch [25/30] Training [324/488] Loss: 0.09071
Epoch [25/30] Training [325/488] Loss: 0.47095
Epoch [25/30] Training [326/488] Loss: 0.17638
Epoch [25/30] Training [327/488] Loss: 0.58781
Epoch [25/30] Training [328/488] Loss: 0.17411
Epoch [25/30] Training [329/488] Loss: 0.15541
Epoch [25/30] Training [330/488] Loss: 0.15191
Epoch [25/30] Training [331/488] Loss: 0.09672
Epoch [25/30] Training [332/488] Loss: 0.12355
Epoch [25/30] Training [333/488] Loss: 0.18540
Epoch [25/30] Training [334/488] Loss: 0.15313
Epoch [25/30] Training [335/488] Loss: 0.27269
Epoch [25/30] Training [336/488] Loss: 0.14638
Epoch [25/30] Training [337/488] Loss: 0.14775
Epoch [25/30] Training [338/488] Loss: 0.26021
Epoch [25/30] Training [339/488] Loss: 0.10727
Epoch [25/30] Training [340/488] Loss: 0.20456
Epoch [25/30] Training [341/488] Loss: 0.09843
Epoch [25/30] Training [342/488] Loss: 0.12133
Epoch [25/30] Training [343/488] Loss: 0.16570
Epoch [25/30] Training [344/488] Loss: 0.19277
Epoch [25/30] Training [345/488] Loss: 0.13645
Epoch [25/30] Training [346/488] Loss: 0.23325
Epoch [25/30] Training [347/488] Loss: 0.18042
Epoch [25/30] Training [348/488] Loss: 0.37626
Epoch [25/30] Training [349/488] Loss: 0.17021
Epoch [25/30] Training [350/488] Loss: 0.10587
Epoch [25/30] Training [351/488] Loss: 0.08547
Epoch [25/30] Training [352/488] Loss: 0.18878
Epoch [25/30] Training [353/488] Loss: 0.17201
Epoch [25/30] Training [354/488] Loss: 0.15767
Epoch [25/30] Training [355/488] Loss: 0.17685
Epoch [25/30] Training [356/488] Loss: 0.30893
Epoch [25/30] Training [357/488] Loss: 0.34111
Epoch [25/30] Training [358/488] Loss: 0.24570
Epoch [25/30] Training [359/488] Loss: 0.34085
Epoch [25/30] Training [360/488] Loss: 0.11630
Epoch [25/30] Training [361/488] Loss: 0.07890
Epoch [25/30] Training [362/488] Loss: 0.10430
Epoch [25/30] Training [363/488] Loss: 0.10844
Epoch [25/30] Training [364/488] Loss: 0.17238
Epoch [25/30] Training [365/488] Loss: 0.10958
Epoch [25/30] Training [366/488] Loss: 0.11241
Epoch [25/30] Training [367/488] Loss: 0.25220
Epoch [25/30] Training [368/488] Loss: 0.26545
Epoch [25/30] Training [369/488] Loss: 0.10620
Epoch [25/30] Training [370/488] Loss: 0.09796
Epoch [25/30] Training [371/488] Loss: 0.12719
Epoch [25/30] Training [372/488] Loss: 0.15842
Epoch [25/30] Training [373/488] Loss: 0.23712
Epoch [25/30] Training [374/488] Loss: 0.09414
Epoch [25/30] Training [375/488] Loss: 0.14109
Epoch [25/30] Training [376/488] Loss: 0.08656
Epoch [25/30] Training [377/488] Loss: 0.35864
Epoch [25/30] Training [378/488] Loss: 0.16109
Epoch [25/30] Training [379/488] Loss: 0.18894
Epoch [25/30] Training [380/488] Loss: 0.14290
Epoch [25/30] Training [381/488] Loss: 0.22383
Epoch [25/30] Training [382/488] Loss: 0.11505
Epoch [25/30] Training [383/488] Loss: 0.14122
Epoch [25/30] Training [384/488] Loss: 0.09452
Epoch [25/30] Training [385/488] Loss: 0.15055
Epoch [25/30] Training [386/488] Loss: 0.12286
Epoch [25/30] Training [387/488] Loss: 0.08314
Epoch [25/30] Training [388/488] Loss: 0.23164
Epoch [25/30] Training [389/488] Loss: 0.34301
Epoch [25/30] Training [390/488] Loss: 0.09638
Epoch [25/30] Training [391/488] Loss: 0.09886
Epoch [25/30] Training [392/488] Loss: 0.14099
Epoch [25/30] Training [393/488] Loss: 0.11353
Epoch [25/30] Training [394/488] Loss: 0.13857
Epoch [25/30] Training [395/488] Loss: 0.22043
Epoch [25/30] Training [396/488] Loss: 0.10129
Epoch [25/30] Training [397/488] Loss: 0.16383
Epoch [25/30] Training [398/488] Loss: 0.12505
Epoch [25/30] Training [399/488] Loss: 0.15547
Epoch [25/30] Training [400/488] Loss: 0.12837
Epoch [25/30] Training [401/488] Loss: 0.17550
Epoch [25/30] Training [402/488] Loss: 0.13906
Epoch [25/30] Training [403/488] Loss: 0.12865
Epoch [25/30] Training [404/488] Loss: 0.08862
Epoch [25/30] Training [405/488] Loss: 0.12583
Epoch [25/30] Training [406/488] Loss: 0.65240
Epoch [25/30] Training [407/488] Loss: 0.12310
Epoch [25/30] Training [408/488] Loss: 0.10059
Epoch [25/30] Training [409/488] Loss: 0.12985
Epoch [25/30] Training [410/488] Loss: 0.17618
Epoch [25/30] Training [411/488] Loss: 0.12717
Epoch [25/30] Training [412/488] Loss: 0.63003
Epoch [25/30] Training [413/488] Loss: 0.21976
Epoch [25/30] Training [414/488] Loss: 0.16580
Epoch [25/30] Training [415/488] Loss: 0.07932
Epoch [25/30] Training [416/488] Loss: 0.16743
Epoch [25/30] Training [417/488] Loss: 0.11743
Epoch [25/30] Training [418/488] Loss: 0.22739
Epoch [25/30] Training [419/488] Loss: 0.09395
Epoch [25/30] Training [420/488] Loss: 0.11650
Epoch [25/30] Training [421/488] Loss: 0.21683
Epoch [25/30] Training [422/488] Loss: 0.29415
Epoch [25/30] Training [423/488] Loss: 0.08949
Epoch [25/30] Training [424/488] Loss: 0.09551
Epoch [25/30] Training [425/488] Loss: 0.11409
Epoch [25/30] Training [426/488] Loss: 0.27981
Epoch [25/30] Training [427/488] Loss: 0.11787
Epoch [25/30] Training [428/488] Loss: 0.14982
Epoch [25/30] Training [429/488] Loss: 0.12968
Epoch [25/30] Training [430/488] Loss: 0.08014
Epoch [25/30] Training [431/488] Loss: 0.13853
Epoch [25/30] Training [432/488] Loss: 0.10219
Epoch [25/30] Training [433/488] Loss: 0.15931
Epoch [25/30] Training [434/488] Loss: 0.14243
Epoch [25/30] Training [435/488] Loss: 0.15564
Epoch [25/30] Training [436/488] Loss: 0.11602
Epoch [25/30] Training [437/488] Loss: 0.13994
Epoch [25/30] Training [438/488] Loss: 0.10735
Epoch [25/30] Training [439/488] Loss: 0.09756
Epoch [25/30] Training [440/488] Loss: 0.10987
Epoch [25/30] Training [441/488] Loss: 0.13098
Epoch [25/30] Training [442/488] Loss: 0.08989
Epoch [25/30] Training [443/488] Loss: 0.12042
Epoch [25/30] Training [444/488] Loss: 0.09811
Epoch [25/30] Training [445/488] Loss: 0.09312
Epoch [25/30] Training [446/488] Loss: 0.10426
Epoch [25/30] Training [447/488] Loss: 0.08666
Epoch [25/30] Training [448/488] Loss: 0.12048
Epoch [25/30] Training [449/488] Loss: 0.19655
Epoch [25/30] Training [450/488] Loss: 0.10744
Epoch [25/30] Training [451/488] Loss: 0.15569
Epoch [25/30] Training [452/488] Loss: 0.07914
Epoch [25/30] Training [453/488] Loss: 0.16472
Epoch [25/30] Training [454/488] Loss: 0.13541
Epoch [25/30] Training [455/488] Loss: 0.13851
Epoch [25/30] Training [456/488] Loss: 0.14525
Epoch [25/30] Training [457/488] Loss: 0.08142
Epoch [25/30] Training [458/488] Loss: 0.11954
Epoch [25/30] Training [459/488] Loss: 0.45165
Epoch [25/30] Training [460/488] Loss: 0.09072
Epoch [25/30] Training [461/488] Loss: 0.41633
Epoch [25/30] Training [462/488] Loss: 0.33670
Epoch [25/30] Training [463/488] Loss: 0.07557
Epoch [25/30] Training [464/488] Loss: 0.10043
Epoch [25/30] Training [465/488] Loss: 0.14431
Epoch [25/30] Training [466/488] Loss: 0.11543
Epoch [25/30] Training [467/488] Loss: 0.13182
Epoch [25/30] Training [468/488] Loss: 0.09499
Epoch [25/30] Training [469/488] Loss: 0.17728
Epoch [25/30] Training [470/488] Loss: 0.14113
Epoch [25/30] Training [471/488] Loss: 0.17920
Epoch [25/30] Training [472/488] Loss: 0.13430
Epoch [25/30] Training [473/488] Loss: 0.16807
Epoch [25/30] Training [474/488] Loss: 0.10159
Epoch [25/30] Training [475/488] Loss: 0.16064
Epoch [25/30] Training [476/488] Loss: 0.23182
Epoch [25/30] Training [477/488] Loss: 0.24129
Epoch [25/30] Training [478/488] Loss: 0.14900
Epoch [25/30] Training [479/488] Loss: 0.24059
Epoch [25/30] Training [480/488] Loss: 0.14315
Epoch [25/30] Training [481/488] Loss: 0.15894
Epoch [25/30] Training [482/488] Loss: 0.15001
Epoch [25/30] Training [483/488] Loss: 0.33482
Epoch [25/30] Training [484/488] Loss: 0.09181
Epoch [25/30] Training [485/488] Loss: 0.10124
Epoch [25/30] Training [486/488] Loss: 0.14111
Epoch [25/30] Training [487/488] Loss: 0.13711
Epoch [25/30] Training [488/488] Loss: 0.46040
Epoch [25/30] Training metric {'Train/mean dice_metric': 0.9021363258361816, 'Train/TC dice_metric': 0.9185702800750732, 'Train/WT dice_metric': 0.9391844868659973, 'Train/ET dice_metric': 0.8486541509628296}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [25/30] Validation [1/123] Loss: 0.15811  focal_loss 0.00233  dice_loss 0.15578
Epoch [25/30] Validation [2/123] Loss: 0.30955  focal_loss 0.00123  dice_loss 0.30833
Epoch [25/30] Validation [3/123] Loss: 0.13290  focal_loss 0.00181  dice_loss 0.13110
Epoch [25/30] Validation [4/123] Loss: 0.19495  focal_loss 0.00134  dice_loss 0.19361
Epoch [25/30] Validation [5/123] Loss: 0.30080  focal_loss 0.01069  dice_loss 0.29011
Epoch [25/30] Validation [6/123] Loss: 0.27569  focal_loss 0.00184  dice_loss 0.27385
Epoch [25/30] Validation [7/123] Loss: 0.28824  focal_loss 0.00075  dice_loss 0.28749
Epoch [25/30] Validation [8/123] Loss: 0.30774  focal_loss 0.00153  dice_loss 0.30621
Epoch [25/30] Validation [9/123] Loss: 0.20796  focal_loss 0.00141  dice_loss 0.20654
Epoch [25/30] Validation [10/123] Loss: 0.43050  focal_loss 0.00323  dice_loss 0.42727
Epoch [25/30] Validation [11/123] Loss: 0.52611  focal_loss 0.00359  dice_loss 0.52252
Epoch [25/30] Validation [12/123] Loss: 0.17511  focal_loss 0.00199  dice_loss 0.17312
Epoch [25/30] Validation [13/123] Loss: 0.16636  focal_loss 0.00383  dice_loss 0.16253
Epoch [25/30] Validation [14/123] Loss: 0.15585  focal_loss 0.00088  dice_loss 0.15497
Epoch [25/30] Validation [15/123] Loss: 0.29336  focal_loss 0.00149  dice_loss 0.29188
Epoch [25/30] Validation [16/123] Loss: 0.49515  focal_loss 0.00337  dice_loss 0.49178
Epoch [25/30] Validation [17/123] Loss: 0.42262  focal_loss 0.00199  dice_loss 0.42063
Epoch [25/30] Validation [18/123] Loss: 0.35793  focal_loss 0.00895  dice_loss 0.34898
Epoch [25/30] Validation [19/123] Loss: 0.26043  focal_loss 0.01032  dice_loss 0.25011
Epoch [25/30] Validation [20/123] Loss: 0.37231  focal_loss 0.00078  dice_loss 0.37153
Epoch [25/30] Validation [21/123] Loss: 0.26579  focal_loss 0.00080  dice_loss 0.26499
Epoch [25/30] Validation [22/123] Loss: 0.69472  focal_loss 0.01007  dice_loss 0.68464
Epoch [25/30] Validation [23/123] Loss: 0.16897  focal_loss 0.00239  dice_loss 0.16659
Epoch [25/30] Validation [24/123] Loss: 0.23166  focal_loss 0.00298  dice_loss 0.22868
Epoch [25/30] Validation [25/123] Loss: 0.30040  focal_loss 0.00485  dice_loss 0.29555
Epoch [25/30] Validation [26/123] Loss: 0.14780  focal_loss 0.00178  dice_loss 0.14602
Epoch [25/30] Validation [27/123] Loss: 0.19910  focal_loss 0.00267  dice_loss 0.19643
Epoch [25/30] Validation [28/123] Loss: 0.46301  focal_loss 0.00549  dice_loss 0.45752
Epoch [25/30] Validation [29/123] Loss: 0.29567  focal_loss 0.00366  dice_loss 0.29201
Epoch [25/30] Validation [30/123] Loss: 0.19919  focal_loss 0.00396  dice_loss 0.19523
Epoch [25/30] Validation [31/123] Loss: 0.13982  focal_loss 0.00173  dice_loss 0.13809
Epoch [25/30] Validation [32/123] Loss: 0.23940  focal_loss 0.00376  dice_loss 0.23564
Epoch [25/30] Validation [33/123] Loss: 0.30046  focal_loss 0.00170  dice_loss 0.29876
Epoch [25/30] Validation [34/123] Loss: 0.28603  focal_loss 0.00345  dice_loss 0.28258
Epoch [25/30] Validation [35/123] Loss: 0.18172  focal_loss 0.00188  dice_loss 0.17984
Epoch [25/30] Validation [36/123] Loss: 0.19960  focal_loss 0.00118  dice_loss 0.19842
Epoch [25/30] Validation [37/123] Loss: 0.29282  focal_loss 0.00358  dice_loss 0.28924
Epoch [25/30] Validation [38/123] Loss: 0.14793  focal_loss 0.00151  dice_loss 0.14642
Epoch [25/30] Validation [39/123] Loss: 0.14980  focal_loss 0.00141  dice_loss 0.14839
Epoch [25/30] Validation [40/123] Loss: 0.24563  focal_loss 0.00088  dice_loss 0.24475
Epoch [25/30] Validation [41/123] Loss: 0.15168  focal_loss 0.00171  dice_loss 0.14997
Epoch [25/30] Validation [42/123] Loss: 0.15838  focal_loss 0.00210  dice_loss 0.15628
Epoch [25/30] Validation [43/123] Loss: 0.23499  focal_loss 0.01776  dice_loss 0.21723
Epoch [25/30] Validation [44/123] Loss: 0.53665  focal_loss 0.00902  dice_loss 0.52763
Epoch [25/30] Validation [45/123] Loss: 0.24048  focal_loss 0.00203  dice_loss 0.23845
Epoch [25/30] Validation [46/123] Loss: 0.27932  focal_loss 0.00296  dice_loss 0.27636
Epoch [25/30] Validation [47/123] Loss: 0.22962  focal_loss 0.00133  dice_loss 0.22829
Epoch [25/30] Validation [48/123] Loss: 0.34985  focal_loss 0.00411  dice_loss 0.34574
Epoch [25/30] Validation [49/123] Loss: 0.18010  focal_loss 0.00995  dice_loss 0.17015
Epoch [25/30] Validation [50/123] Loss: 0.16736  focal_loss 0.00269  dice_loss 0.16467
Epoch [25/30] Validation [51/123] Loss: 0.34026  focal_loss 0.00959  dice_loss 0.33066
Epoch [25/30] Validation [52/123] Loss: 0.16457  focal_loss 0.00088  dice_loss 0.16369
Epoch [25/30] Validation [53/123] Loss: 0.21288  focal_loss 0.00087  dice_loss 0.21200
Epoch [25/30] Validation [54/123] Loss: 0.27668  focal_loss 0.00167  dice_loss 0.27501
Epoch [25/30] Validation [55/123] Loss: 0.22639  focal_loss 0.00126  dice_loss 0.22514
Epoch [25/30] Validation [56/123] Loss: 0.18974  focal_loss 0.00439  dice_loss 0.18535
Epoch [25/30] Validation [57/123] Loss: 0.24732  focal_loss 0.00795  dice_loss 0.23937
Epoch [25/30] Validation [58/123] Loss: 0.20293  focal_loss 0.00215  dice_loss 0.20077
Epoch [25/30] Validation [59/123] Loss: 0.56395  focal_loss 0.00818  dice_loss 0.55577
Epoch [25/30] Validation [60/123] Loss: 0.20063  focal_loss 0.00376  dice_loss 0.19687
Epoch [25/30] Validation [61/123] Loss: 0.60131  focal_loss 0.00835  dice_loss 0.59295
Epoch [25/30] Validation [62/123] Loss: 0.45473  focal_loss 0.01661  dice_loss 0.43812
Epoch [25/30] Validation [63/123] Loss: 0.29970  focal_loss 0.00159  dice_loss 0.29811
Epoch [25/30] Validation [64/123] Loss: 0.34462  focal_loss 0.00683  dice_loss 0.33779
Epoch [25/30] Validation [65/123] Loss: 0.17698  focal_loss 0.00119  dice_loss 0.17579
Epoch [25/30] Validation [66/123] Loss: 0.17779  focal_loss 0.00141  dice_loss 0.17638
Epoch [25/30] Validation [67/123] Loss: 0.37687  focal_loss 0.01263  dice_loss 0.36424
Epoch [25/30] Validation [68/123] Loss: 0.29041  focal_loss 0.00089  dice_loss 0.28952
Epoch [25/30] Validation [69/123] Loss: 0.36798  focal_loss 0.00652  dice_loss 0.36145
Epoch [25/30] Validation [70/123] Loss: 0.29920  focal_loss 0.00315  dice_loss 0.29605
Epoch [25/30] Validation [71/123] Loss: 0.15976  focal_loss 0.00110  dice_loss 0.15865
Epoch [25/30] Validation [72/123] Loss: 0.16648  focal_loss 0.00231  dice_loss 0.16417
Epoch [25/30] Validation [73/123] Loss: 0.25103  focal_loss 0.00349  dice_loss 0.24755
Epoch [25/30] Validation [74/123] Loss: 0.23623  focal_loss 0.00236  dice_loss 0.23387
Epoch [25/30] Validation [75/123] Loss: 0.18062  focal_loss 0.00130  dice_loss 0.17932
Epoch [25/30] Validation [76/123] Loss: 0.42681  focal_loss 0.00425  dice_loss 0.42256
Epoch [25/30] Validation [77/123] Loss: 0.31190  focal_loss 0.00086  dice_loss 0.31104
Epoch [25/30] Validation [78/123] Loss: 0.20758  focal_loss 0.00142  dice_loss 0.20616
Epoch [25/30] Validation [79/123] Loss: 0.22373  focal_loss 0.00097  dice_loss 0.22275
Epoch [25/30] Validation [80/123] Loss: 0.16659  focal_loss 0.00259  dice_loss 0.16401
Epoch [25/30] Validation [81/123] Loss: 0.19974  focal_loss 0.00212  dice_loss 0.19763
Epoch [25/30] Validation [82/123] Loss: 0.15498  focal_loss 0.00119  dice_loss 0.15379
Epoch [25/30] Validation [83/123] Loss: 0.34822  focal_loss 0.01225  dice_loss 0.33597
Epoch [25/30] Validation [84/123] Loss: 0.19493  focal_loss 0.00145  dice_loss 0.19348
Epoch [25/30] Validation [85/123] Loss: 0.26156  focal_loss 0.00352  dice_loss 0.25804
Epoch [25/30] Validation [86/123] Loss: 0.17093  focal_loss 0.00133  dice_loss 0.16960
Epoch [25/30] Validation [87/123] Loss: 0.18061  focal_loss 0.00293  dice_loss 0.17767
Epoch [25/30] Validation [88/123] Loss: 0.17861  focal_loss 0.00153  dice_loss 0.17708
Epoch [25/30] Validation [89/123] Loss: 0.16647  focal_loss 0.00275  dice_loss 0.16372
Epoch [25/30] Validation [90/123] Loss: 0.22428  focal_loss 0.00180  dice_loss 0.22248
Epoch [25/30] Validation [91/123] Loss: 0.19169  focal_loss 0.00209  dice_loss 0.18959
Epoch [25/30] Validation [92/123] Loss: 0.14277  focal_loss 0.00142  dice_loss 0.14135
Epoch [25/30] Validation [93/123] Loss: 0.17099  focal_loss 0.00249  dice_loss 0.16850
Epoch [25/30] Validation [94/123] Loss: 0.28828  focal_loss 0.00180  dice_loss 0.28648
Epoch [25/30] Validation [95/123] Loss: 0.19936  focal_loss 0.00251  dice_loss 0.19685
Epoch [25/30] Validation [96/123] Loss: 0.23420  focal_loss 0.00126  dice_loss 0.23295
Epoch [25/30] Validation [97/123] Loss: 0.56435  focal_loss 0.00626  dice_loss 0.55810
Epoch [25/30] Validation [98/123] Loss: 0.24324  focal_loss 0.00089  dice_loss 0.24235
Epoch [25/30] Validation [99/123] Loss: 0.23472  focal_loss 0.00060  dice_loss 0.23413
Epoch [25/30] Validation [100/123] Loss: 0.26085  focal_loss 0.00091  dice_loss 0.25994
Epoch [25/30] Validation [101/123] Loss: 0.22922  focal_loss 0.00106  dice_loss 0.22816
Epoch [25/30] Validation [102/123] Loss: 0.25903  focal_loss 0.00056  dice_loss 0.25847
Epoch [25/30] Validation [103/123] Loss: 0.48067  focal_loss 0.00153  dice_loss 0.47914
Epoch [25/30] Validation [104/123] Loss: 0.36216  focal_loss 0.00510  dice_loss 0.35706
Epoch [25/30] Validation [105/123] Loss: 0.16093  focal_loss 0.00320  dice_loss 0.15774
Epoch [25/30] Validation [106/123] Loss: 0.16139  focal_loss 0.00094  dice_loss 0.16045
Epoch [25/30] Validation [107/123] Loss: 0.43844  focal_loss 0.00181  dice_loss 0.43663
Epoch [25/30] Validation [108/123] Loss: 0.16921  focal_loss 0.00092  dice_loss 0.16829
Epoch [25/30] Validation [109/123] Loss: 0.17981  focal_loss 0.00541  dice_loss 0.17440
Epoch [25/30] Validation [110/123] Loss: 0.33552  focal_loss 0.00530  dice_loss 0.33021
Epoch [25/30] Validation [111/123] Loss: 0.31662  focal_loss 0.00358  dice_loss 0.31304
Epoch [25/30] Validation [112/123] Loss: 0.24475  focal_loss 0.00086  dice_loss 0.24388
Epoch [25/30] Validation [113/123] Loss: 0.20965  focal_loss 0.00187  dice_loss 0.20778
Epoch [25/30] Validation [114/123] Loss: 0.27369  focal_loss 0.00463  dice_loss 0.26905
Epoch [25/30] Validation [115/123] Loss: 0.23739  focal_loss 0.00645  dice_loss 0.23093
Epoch [25/30] Validation [116/123] Loss: 0.18887  focal_loss 0.00059  dice_loss 0.18828
Epoch [25/30] Validation [117/123] Loss: 0.20875  focal_loss 0.00116  dice_loss 0.20759
Epoch [25/30] Validation [118/123] Loss: 0.13431  focal_loss 0.00205  dice_loss 0.13227
Epoch [25/30] Validation [119/123] Loss: 0.16617  focal_loss 0.00171  dice_loss 0.16446
Epoch [25/30] Validation [120/123] Loss: 0.18902  focal_loss 0.00215  dice_loss 0.18686
Epoch [25/30] Validation [121/123] Loss: 0.61987  focal_loss 0.02073  dice_loss 0.59914
Epoch [25/30] Validation [122/123] Loss: 0.48339  focal_loss 0.00047  dice_loss 0.48292
Epoch [25/30] Validation [123/123] Loss: 0.18664  focal_loss 0.00189  dice_loss 0.18475
Epoch [25/30] Validation metric {'Val/mean dice_metric': 0.8993533849716187, 'Val/TC dice_metric': 0.913135826587677, 'Val/WT dice_metric': 0.9374185800552368, 'Val/ET dice_metric': 0.8475056886672974}
Epoch [25/30] lr = [0.00013551568628929433, 0.00013551568628929433] best acc: tensor([0.8967], device='cuda:0'), mean acc: tensor([0.8994], device='cuda:0'), mean class: tensor([0.9131, 0.9374, 0.8475], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [26/30] Training [1/488] Loss: 0.11131
Epoch [26/30] Training [2/488] Loss: 0.09928
Epoch [26/30] Training [3/488] Loss: 0.16846
Epoch [26/30] Training [4/488] Loss: 0.11240
Epoch [26/30] Training [5/488] Loss: 0.08016
Epoch [26/30] Training [6/488] Loss: 0.09978
Epoch [26/30] Training [7/488] Loss: 0.09725
Epoch [26/30] Training [8/488] Loss: 0.13301
Epoch [26/30] Training [9/488] Loss: 0.69759
Epoch [26/30] Training [10/488] Loss: 0.35811
Epoch [26/30] Training [11/488] Loss: 0.16902
Epoch [26/30] Training [12/488] Loss: 0.11865
Epoch [26/30] Training [13/488] Loss: 0.08449
Epoch [26/30] Training [14/488] Loss: 0.44850
Epoch [26/30] Training [15/488] Loss: 0.12825
Epoch [26/30] Training [16/488] Loss: 0.10776
Epoch [26/30] Training [17/488] Loss: 0.33218
Epoch [26/30] Training [18/488] Loss: 0.11585
Epoch [26/30] Training [19/488] Loss: 0.42986
Epoch [26/30] Training [20/488] Loss: 0.11777
Epoch [26/30] Training [21/488] Loss: 0.09587
Epoch [26/30] Training [22/488] Loss: 0.13594
Epoch [26/30] Training [23/488] Loss: 0.26314
Epoch [26/30] Training [24/488] Loss: 0.17963
Epoch [26/30] Training [25/488] Loss: 0.20186
Epoch [26/30] Training [26/488] Loss: 0.10276
Epoch [26/30] Training [27/488] Loss: 0.09259
Epoch [26/30] Training [28/488] Loss: 0.10273
Epoch [26/30] Training [29/488] Loss: 0.10891
Epoch [26/30] Training [30/488] Loss: 0.21955
Epoch [26/30] Training [31/488] Loss: 0.10647
Epoch [26/30] Training [32/488] Loss: 0.09659
Epoch [26/30] Training [33/488] Loss: 0.17155
Epoch [26/30] Training [34/488] Loss: 0.10738
Epoch [26/30] Training [35/488] Loss: 0.22641
Epoch [26/30] Training [36/488] Loss: 0.09564
Epoch [26/30] Training [37/488] Loss: 0.21723
Epoch [26/30] Training [38/488] Loss: 0.16756
Epoch [26/30] Training [39/488] Loss: 0.71024
Epoch [26/30] Training [40/488] Loss: 0.10243
Epoch [26/30] Training [41/488] Loss: 0.09601
Epoch [26/30] Training [42/488] Loss: 0.09599
Epoch [26/30] Training [43/488] Loss: 0.37639
Epoch [26/30] Training [44/488] Loss: 0.16429
Epoch [26/30] Training [45/488] Loss: 0.17447
Epoch [26/30] Training [46/488] Loss: 0.08151
Epoch [26/30] Training [47/488] Loss: 0.13054
Epoch [26/30] Training [48/488] Loss: 0.14233
Epoch [26/30] Training [49/488] Loss: 0.10362
Epoch [26/30] Training [50/488] Loss: 0.17425
Epoch [26/30] Training [51/488] Loss: 0.17312
Epoch [26/30] Training [52/488] Loss: 0.08657
Epoch [26/30] Training [53/488] Loss: 0.10748
Epoch [26/30] Training [54/488] Loss: 0.16285
Epoch [26/30] Training [55/488] Loss: 0.11539
Epoch [26/30] Training [56/488] Loss: 0.41166
Epoch [26/30] Training [57/488] Loss: 0.24769
Epoch [26/30] Training [58/488] Loss: 0.58291
Epoch [26/30] Training [59/488] Loss: 0.16403
Epoch [26/30] Training [60/488] Loss: 0.12605
Epoch [26/30] Training [61/488] Loss: 0.15467
Epoch [26/30] Training [62/488] Loss: 0.51284
Epoch [26/30] Training [63/488] Loss: 0.09273
Epoch [26/30] Training [64/488] Loss: 0.11503
Epoch [26/30] Training [65/488] Loss: 0.13013
Epoch [26/30] Training [66/488] Loss: 0.15118
Epoch [26/30] Training [67/488] Loss: 0.23881
Epoch [26/30] Training [68/488] Loss: 0.12808
Epoch [26/30] Training [69/488] Loss: 0.14813
Epoch [26/30] Training [70/488] Loss: 0.16057
Epoch [26/30] Training [71/488] Loss: 0.12004
Epoch [26/30] Training [72/488] Loss: 0.24324
Epoch [26/30] Training [73/488] Loss: 0.09030
Epoch [26/30] Training [74/488] Loss: 0.16603
Epoch [26/30] Training [75/488] Loss: 0.12417
Epoch [26/30] Training [76/488] Loss: 0.10535
Epoch [26/30] Training [77/488] Loss: 0.23024
Epoch [26/30] Training [78/488] Loss: 0.09766
Epoch [26/30] Training [79/488] Loss: 0.14622
Epoch [26/30] Training [80/488] Loss: 0.11512
Epoch [26/30] Training [81/488] Loss: 0.12421
Epoch [26/30] Training [82/488] Loss: 0.12470
Epoch [26/30] Training [83/488] Loss: 0.11334
Epoch [26/30] Training [84/488] Loss: 0.08894
Epoch [26/30] Training [85/488] Loss: 0.14606
Epoch [26/30] Training [86/488] Loss: 0.11088
Epoch [26/30] Training [87/488] Loss: 0.08597
Epoch [26/30] Training [88/488] Loss: 0.14367
Epoch [26/30] Training [89/488] Loss: 0.14345
Epoch [26/30] Training [90/488] Loss: 0.11843
Epoch [26/30] Training [91/488] Loss: 0.11258
Epoch [26/30] Training [92/488] Loss: 0.13839
Epoch [26/30] Training [93/488] Loss: 0.08329
Epoch [26/30] Training [94/488] Loss: 0.12642
Epoch [26/30] Training [95/488] Loss: 0.14724
Epoch [26/30] Training [96/488] Loss: 0.09528
Epoch [26/30] Training [97/488] Loss: 0.63880
Epoch [26/30] Training [98/488] Loss: 0.08588
Epoch [26/30] Training [99/488] Loss: 0.11425
Epoch [26/30] Training [100/488] Loss: 0.44858
Epoch [26/30] Training [101/488] Loss: 0.20342
Epoch [26/30] Training [102/488] Loss: 0.10129
Epoch [26/30] Training [103/488] Loss: 0.11814
Epoch [26/30] Training [104/488] Loss: 0.14663
Epoch [26/30] Training [105/488] Loss: 0.21402
Epoch [26/30] Training [106/488] Loss: 0.08570
Epoch [26/30] Training [107/488] Loss: 0.15866
Epoch [26/30] Training [108/488] Loss: 0.09588
Epoch [26/30] Training [109/488] Loss: 0.14934
Epoch [26/30] Training [110/488] Loss: 0.43725
Epoch [26/30] Training [111/488] Loss: 0.07066
Epoch [26/30] Training [112/488] Loss: 0.13735
Epoch [26/30] Training [113/488] Loss: 0.12823
Epoch [26/30] Training [114/488] Loss: 0.10378
Epoch [26/30] Training [115/488] Loss: 0.25749
Epoch [26/30] Training [116/488] Loss: 0.15934
Epoch [26/30] Training [117/488] Loss: 0.24741
Epoch [26/30] Training [118/488] Loss: 0.13519
Epoch [26/30] Training [119/488] Loss: 0.12897
Epoch [26/30] Training [120/488] Loss: 0.09128
Epoch [26/30] Training [121/488] Loss: 0.11442
Epoch [26/30] Training [122/488] Loss: 0.10058
Epoch [26/30] Training [123/488] Loss: 0.18633
Epoch [26/30] Training [124/488] Loss: 0.08869
Epoch [26/30] Training [125/488] Loss: 0.14677
Epoch [26/30] Training [126/488] Loss: 0.09664
Epoch [26/30] Training [127/488] Loss: 0.16144
Epoch [26/30] Training [128/488] Loss: 0.12329
Epoch [26/30] Training [129/488] Loss: 0.24407
Epoch [26/30] Training [130/488] Loss: 0.16200
Epoch [26/30] Training [131/488] Loss: 0.09286
Epoch [26/30] Training [132/488] Loss: 0.14651
Epoch [26/30] Training [133/488] Loss: 0.40002
Epoch [26/30] Training [134/488] Loss: 0.14146
Epoch [26/30] Training [135/488] Loss: 0.15923
Epoch [26/30] Training [136/488] Loss: 0.16124
Epoch [26/30] Training [137/488] Loss: 0.21664
Epoch [26/30] Training [138/488] Loss: 0.21202
Epoch [26/30] Training [139/488] Loss: 0.09471
Epoch [26/30] Training [140/488] Loss: 0.14555
Epoch [26/30] Training [141/488] Loss: 0.10847
Epoch [26/30] Training [142/488] Loss: 0.14641
Epoch [26/30] Training [143/488] Loss: 0.14996
Epoch [26/30] Training [144/488] Loss: 0.11403
Epoch [26/30] Training [145/488] Loss: 0.09971
Epoch [26/30] Training [146/488] Loss: 0.20314
Epoch [26/30] Training [147/488] Loss: 0.53640
Epoch [26/30] Training [148/488] Loss: 0.23704
Epoch [26/30] Training [149/488] Loss: 0.08644
Epoch [26/30] Training [150/488] Loss: 0.10999
Epoch [26/30] Training [151/488] Loss: 0.13234
Epoch [26/30] Training [152/488] Loss: 0.22018
Epoch [26/30] Training [153/488] Loss: 0.36900
Epoch [26/30] Training [154/488] Loss: 0.13125
Epoch [26/30] Training [155/488] Loss: 0.13943
Epoch [26/30] Training [156/488] Loss: 0.11580
Epoch [26/30] Training [157/488] Loss: 0.13814
Epoch [26/30] Training [158/488] Loss: 0.19490
Epoch [26/30] Training [159/488] Loss: 0.11547
Epoch [26/30] Training [160/488] Loss: 0.06993
Epoch [26/30] Training [161/488] Loss: 0.11510
Epoch [26/30] Training [162/488] Loss: 0.22091
Epoch [26/30] Training [163/488] Loss: 0.17865
Epoch [26/30] Training [164/488] Loss: 0.09912
Epoch [26/30] Training [165/488] Loss: 0.14395
Epoch [26/30] Training [166/488] Loss: 0.09559
Epoch [26/30] Training [167/488] Loss: 0.11572
Epoch [26/30] Training [168/488] Loss: 0.14940
Epoch [26/30] Training [169/488] Loss: 0.10868
Epoch [26/30] Training [170/488] Loss: 0.23721
Epoch [26/30] Training [171/488] Loss: 0.22416
Epoch [26/30] Training [172/488] Loss: 0.09777
Epoch [26/30] Training [173/488] Loss: 0.09010
Epoch [26/30] Training [174/488] Loss: 0.11738
Epoch [26/30] Training [175/488] Loss: 0.10623
Epoch [26/30] Training [176/488] Loss: 0.11411
Epoch [26/30] Training [177/488] Loss: 0.12909
Epoch [26/30] Training [178/488] Loss: 0.09091
Epoch [26/30] Training [179/488] Loss: 0.63289
Epoch [26/30] Training [180/488] Loss: 0.14526
Epoch [26/30] Training [181/488] Loss: 0.11118
Epoch [26/30] Training [182/488] Loss: 0.10931
Epoch [26/30] Training [183/488] Loss: 0.09272
Epoch [26/30] Training [184/488] Loss: 0.07677
Epoch [26/30] Training [185/488] Loss: 0.13993
Epoch [26/30] Training [186/488] Loss: 0.12442
Epoch [26/30] Training [187/488] Loss: 0.10043
Epoch [26/30] Training [188/488] Loss: 0.53567
Epoch [26/30] Training [189/488] Loss: 0.17274
Epoch [26/30] Training [190/488] Loss: 0.13283
Epoch [26/30] Training [191/488] Loss: 0.08847
Epoch [26/30] Training [192/488] Loss: 0.08198
Epoch [26/30] Training [193/488] Loss: 0.10856
Epoch [26/30] Training [194/488] Loss: 0.13495
Epoch [26/30] Training [195/488] Loss: 0.09556
Epoch [26/30] Training [196/488] Loss: 0.24460
Epoch [26/30] Training [197/488] Loss: 0.07857
Epoch [26/30] Training [198/488] Loss: 0.12294
Epoch [26/30] Training [199/488] Loss: 0.12305
Epoch [26/30] Training [200/488] Loss: 0.40197
Epoch [26/30] Training [201/488] Loss: 0.15197
Epoch [26/30] Training [202/488] Loss: 0.15576
Epoch [26/30] Training [203/488] Loss: 0.20376
Epoch [26/30] Training [204/488] Loss: 0.15478
Epoch [26/30] Training [205/488] Loss: 0.16029
Epoch [26/30] Training [206/488] Loss: 0.45478
Epoch [26/30] Training [207/488] Loss: 0.29348
Epoch [26/30] Training [208/488] Loss: 0.13004
Epoch [26/30] Training [209/488] Loss: 0.10033
Epoch [26/30] Training [210/488] Loss: 0.11538
Epoch [26/30] Training [211/488] Loss: 0.21854
Epoch [26/30] Training [212/488] Loss: 0.14062
Epoch [26/30] Training [213/488] Loss: 0.27213
Epoch [26/30] Training [214/488] Loss: 0.12827
Epoch [26/30] Training [215/488] Loss: 0.10081
Epoch [26/30] Training [216/488] Loss: 0.70308
Epoch [26/30] Training [217/488] Loss: 0.10646
Epoch [26/30] Training [218/488] Loss: 0.15924
Epoch [26/30] Training [219/488] Loss: 0.15240
Epoch [26/30] Training [220/488] Loss: 0.28863
Epoch [26/30] Training [221/488] Loss: 0.11198
Epoch [26/30] Training [222/488] Loss: 0.32939
Epoch [26/30] Training [223/488] Loss: 0.15413
Epoch [26/30] Training [224/488] Loss: 0.34246
Epoch [26/30] Training [225/488] Loss: 0.11100
Epoch [26/30] Training [226/488] Loss: 0.10283
Epoch [26/30] Training [227/488] Loss: 0.25697
Epoch [26/30] Training [228/488] Loss: 0.09091
Epoch [26/30] Training [229/488] Loss: 0.25639
Epoch [26/30] Training [230/488] Loss: 0.09030
Epoch [26/30] Training [231/488] Loss: 0.08243
Epoch [26/30] Training [232/488] Loss: 0.23404
Epoch [26/30] Training [233/488] Loss: 0.07756
Epoch [26/30] Training [234/488] Loss: 0.19292
Epoch [26/30] Training [235/488] Loss: 0.14550
Epoch [26/30] Training [236/488] Loss: 0.12688
Epoch [26/30] Training [237/488] Loss: 0.09201
Epoch [26/30] Training [238/488] Loss: 0.12795
Epoch [26/30] Training [239/488] Loss: 0.10421
Epoch [26/30] Training [240/488] Loss: 0.21149
Epoch [26/30] Training [241/488] Loss: 0.11096
Epoch [26/30] Training [242/488] Loss: 0.09746
Epoch [26/30] Training [243/488] Loss: 0.11342
Epoch [26/30] Training [244/488] Loss: 0.16853
Epoch [26/30] Training [245/488] Loss: 0.09725
Epoch [26/30] Training [246/488] Loss: 0.13846
Epoch [26/30] Training [247/488] Loss: 0.12519
Epoch [26/30] Training [248/488] Loss: 0.39438
Epoch [26/30] Training [249/488] Loss: 0.13290
Epoch [26/30] Training [250/488] Loss: 0.32050
Epoch [26/30] Training [251/488] Loss: 0.09606
Epoch [26/30] Training [252/488] Loss: 0.42018
Epoch [26/30] Training [253/488] Loss: 0.13452
Epoch [26/30] Training [254/488] Loss: 0.22682
Epoch [26/30] Training [255/488] Loss: 0.13741
Epoch [26/30] Training [256/488] Loss: 0.11610
Epoch [26/30] Training [257/488] Loss: 0.09837
Epoch [26/30] Training [258/488] Loss: 0.13947
Epoch [26/30] Training [259/488] Loss: 0.19785
Epoch [26/30] Training [260/488] Loss: 0.10664
Epoch [26/30] Training [261/488] Loss: 0.18381
Epoch [26/30] Training [262/488] Loss: 0.09010
Epoch [26/30] Training [263/488] Loss: 0.34546
Epoch [26/30] Training [264/488] Loss: 0.12618
Epoch [26/30] Training [265/488] Loss: 0.10339
Epoch [26/30] Training [266/488] Loss: 0.17278
Epoch [26/30] Training [267/488] Loss: 0.12375
Epoch [26/30] Training [268/488] Loss: 0.34209
Epoch [26/30] Training [269/488] Loss: 0.11345
Epoch [26/30] Training [270/488] Loss: 0.11670
Epoch [26/30] Training [271/488] Loss: 0.10004
Epoch [26/30] Training [272/488] Loss: 0.10342
Epoch [26/30] Training [273/488] Loss: 0.14580
Epoch [26/30] Training [274/488] Loss: 0.15040
Epoch [26/30] Training [275/488] Loss: 0.07208
Epoch [26/30] Training [276/488] Loss: 0.09965
Epoch [26/30] Training [277/488] Loss: 0.11255
Epoch [26/30] Training [278/488] Loss: 0.09981
Epoch [26/30] Training [279/488] Loss: 0.12468
Epoch [26/30] Training [280/488] Loss: 0.10006
Epoch [26/30] Training [281/488] Loss: 0.14139
Epoch [26/30] Training [282/488] Loss: 0.26237
Epoch [26/30] Training [283/488] Loss: 0.16075
Epoch [26/30] Training [284/488] Loss: 0.12305
Epoch [26/30] Training [285/488] Loss: 0.12970
Epoch [26/30] Training [286/488] Loss: 0.09692
Epoch [26/30] Training [287/488] Loss: 0.17863
Epoch [26/30] Training [288/488] Loss: 0.14337
Epoch [26/30] Training [289/488] Loss: 0.11691
Epoch [26/30] Training [290/488] Loss: 0.09149
Epoch [26/30] Training [291/488] Loss: 0.11283
Epoch [26/30] Training [292/488] Loss: 0.28709
Epoch [26/30] Training [293/488] Loss: 0.34914
Epoch [26/30] Training [294/488] Loss: 0.10958
Epoch [26/30] Training [295/488] Loss: 0.14480
Epoch [26/30] Training [296/488] Loss: 0.15397
Epoch [26/30] Training [297/488] Loss: 0.13154
Epoch [26/30] Training [298/488] Loss: 0.11188
Epoch [26/30] Training [299/488] Loss: 0.34185
Epoch [26/30] Training [300/488] Loss: 0.11095
Epoch [26/30] Training [301/488] Loss: 0.08994
Epoch [26/30] Training [302/488] Loss: 0.23398
Epoch [26/30] Training [303/488] Loss: 0.16408
Epoch [26/30] Training [304/488] Loss: 0.13806
Epoch [26/30] Training [305/488] Loss: 0.15069
Epoch [26/30] Training [306/488] Loss: 0.24560
Epoch [26/30] Training [307/488] Loss: 0.12008
Epoch [26/30] Training [308/488] Loss: 0.13028
Epoch [26/30] Training [309/488] Loss: 0.08011
Epoch [26/30] Training [310/488] Loss: 0.10768
Epoch [26/30] Training [311/488] Loss: 0.10932
Epoch [26/30] Training [312/488] Loss: 0.21239
Epoch [26/30] Training [313/488] Loss: 0.29002
Epoch [26/30] Training [314/488] Loss: 0.09813
Epoch [26/30] Training [315/488] Loss: 0.33096
Epoch [26/30] Training [316/488] Loss: 0.08199
Epoch [26/30] Training [317/488] Loss: 0.07338
Epoch [26/30] Training [318/488] Loss: 0.12107
Epoch [26/30] Training [319/488] Loss: 0.29842
Epoch [26/30] Training [320/488] Loss: 0.10854
Epoch [26/30] Training [321/488] Loss: 0.31341
Epoch [26/30] Training [322/488] Loss: 0.16292
Epoch [26/30] Training [323/488] Loss: 0.13921
Epoch [26/30] Training [324/488] Loss: 0.14881
Epoch [26/30] Training [325/488] Loss: 0.22499
Epoch [26/30] Training [326/488] Loss: 0.27182
Epoch [26/30] Training [327/488] Loss: 0.08570
Epoch [26/30] Training [328/488] Loss: 0.13713
Epoch [26/30] Training [329/488] Loss: 0.25369
Epoch [26/30] Training [330/488] Loss: 0.09063
Epoch [26/30] Training [331/488] Loss: 0.11884
Epoch [26/30] Training [332/488] Loss: 0.11428
Epoch [26/30] Training [333/488] Loss: 0.33299
Epoch [26/30] Training [334/488] Loss: 0.16415
Epoch [26/30] Training [335/488] Loss: 0.13346
Epoch [26/30] Training [336/488] Loss: 0.26945
Epoch [26/30] Training [337/488] Loss: 0.12094
Epoch [26/30] Training [338/488] Loss: 0.13048
Epoch [26/30] Training [339/488] Loss: 0.10650
Epoch [26/30] Training [340/488] Loss: 0.17460
Epoch [26/30] Training [341/488] Loss: 0.09783
Epoch [26/30] Training [342/488] Loss: 0.10367
Epoch [26/30] Training [343/488] Loss: 0.10159
Epoch [26/30] Training [344/488] Loss: 0.29287
Epoch [26/30] Training [345/488] Loss: 0.12921
Epoch [26/30] Training [346/488] Loss: 0.19512
Epoch [26/30] Training [347/488] Loss: 0.19715
Epoch [26/30] Training [348/488] Loss: 0.25591
Epoch [26/30] Training [349/488] Loss: 0.08346
Epoch [26/30] Training [350/488] Loss: 0.16277
Epoch [26/30] Training [351/488] Loss: 0.09476
Epoch [26/30] Training [352/488] Loss: 0.14438
Epoch [26/30] Training [353/488] Loss: 0.20772
Epoch [26/30] Training [354/488] Loss: 0.22467
Epoch [26/30] Training [355/488] Loss: 0.09881
Epoch [26/30] Training [356/488] Loss: 0.28941
Epoch [26/30] Training [357/488] Loss: 0.20235
Epoch [26/30] Training [358/488] Loss: 0.06960
Epoch [26/30] Training [359/488] Loss: 0.08652
Epoch [26/30] Training [360/488] Loss: 0.13319
Epoch [26/30] Training [361/488] Loss: 0.24361
Epoch [26/30] Training [362/488] Loss: 0.17921
Epoch [26/30] Training [363/488] Loss: 0.27797
Epoch [26/30] Training [364/488] Loss: 0.10479
Epoch [26/30] Training [365/488] Loss: 0.57368
Epoch [26/30] Training [366/488] Loss: 0.37287
Epoch [26/30] Training [367/488] Loss: 0.16642
Epoch [26/30] Training [368/488] Loss: 0.12827
Epoch [26/30] Training [369/488] Loss: 0.09229
Epoch [26/30] Training [370/488] Loss: 0.17415
Epoch [26/30] Training [371/488] Loss: 0.28234
Epoch [26/30] Training [372/488] Loss: 0.11135
Epoch [26/30] Training [373/488] Loss: 0.19927
Epoch [26/30] Training [374/488] Loss: 0.18761
Epoch [26/30] Training [375/488] Loss: 0.11980
Epoch [26/30] Training [376/488] Loss: 0.10424
Epoch [26/30] Training [377/488] Loss: 0.11166
Epoch [26/30] Training [378/488] Loss: 0.21093
Epoch [26/30] Training [379/488] Loss: 0.10737
Epoch [26/30] Training [380/488] Loss: 0.17542
Epoch [26/30] Training [381/488] Loss: 0.09436
Epoch [26/30] Training [382/488] Loss: 0.14008
Epoch [26/30] Training [383/488] Loss: 0.09632
Epoch [26/30] Training [384/488] Loss: 0.14848
Epoch [26/30] Training [385/488] Loss: 0.10541
Epoch [26/30] Training [386/488] Loss: 0.13377
Epoch [26/30] Training [387/488] Loss: 0.14041
Epoch [26/30] Training [388/488] Loss: 0.21150
Epoch [26/30] Training [389/488] Loss: 0.13457
Epoch [26/30] Training [390/488] Loss: 0.16732
Epoch [26/30] Training [391/488] Loss: 0.09677
Epoch [26/30] Training [392/488] Loss: 0.17539
Epoch [26/30] Training [393/488] Loss: 0.12640
Epoch [26/30] Training [394/488] Loss: 0.11940
Epoch [26/30] Training [395/488] Loss: 0.14352
Epoch [26/30] Training [396/488] Loss: 0.10494
Epoch [26/30] Training [397/488] Loss: 0.11841
Epoch [26/30] Training [398/488] Loss: 0.50387
Epoch [26/30] Training [399/488] Loss: 0.17275
Epoch [26/30] Training [400/488] Loss: 0.26149
Epoch [26/30] Training [401/488] Loss: 0.32840
Epoch [26/30] Training [402/488] Loss: 0.09390
Epoch [26/30] Training [403/488] Loss: 0.54769
Epoch [26/30] Training [404/488] Loss: 0.13531
Epoch [26/30] Training [405/488] Loss: 0.25921
Epoch [26/30] Training [406/488] Loss: 0.15125
Epoch [26/30] Training [407/488] Loss: 0.21107
Epoch [26/30] Training [408/488] Loss: 0.11203
Epoch [26/30] Training [409/488] Loss: 0.13907
Epoch [26/30] Training [410/488] Loss: 0.46942
Epoch [26/30] Training [411/488] Loss: 0.09880
Epoch [26/30] Training [412/488] Loss: 0.08603
Epoch [26/30] Training [413/488] Loss: 0.13936
Epoch [26/30] Training [414/488] Loss: 0.14669
Epoch [26/30] Training [415/488] Loss: 0.16459
Epoch [26/30] Training [416/488] Loss: 0.16600
Epoch [26/30] Training [417/488] Loss: 0.09900
Epoch [26/30] Training [418/488] Loss: 0.15049
Epoch [26/30] Training [419/488] Loss: 0.16335
Epoch [26/30] Training [420/488] Loss: 0.23301
Epoch [26/30] Training [421/488] Loss: 0.09828
Epoch [26/30] Training [422/488] Loss: 0.11395
Epoch [26/30] Training [423/488] Loss: 0.10308
Epoch [26/30] Training [424/488] Loss: 0.12604
Epoch [26/30] Training [425/488] Loss: 0.16636
Epoch [26/30] Training [426/488] Loss: 0.12280
Epoch [26/30] Training [427/488] Loss: 0.11603
Epoch [26/30] Training [428/488] Loss: 0.09276
Epoch [26/30] Training [429/488] Loss: 0.12164
Epoch [26/30] Training [430/488] Loss: 0.10805
Epoch [26/30] Training [431/488] Loss: 0.11477
Epoch [26/30] Training [432/488] Loss: 0.13267
Epoch [26/30] Training [433/488] Loss: 0.10769
Epoch [26/30] Training [434/488] Loss: 0.36263
Epoch [26/30] Training [435/488] Loss: 0.17155
Epoch [26/30] Training [436/488] Loss: 0.14282
Epoch [26/30] Training [437/488] Loss: 0.08746
Epoch [26/30] Training [438/488] Loss: 0.16313
Epoch [26/30] Training [439/488] Loss: 0.23603
Epoch [26/30] Training [440/488] Loss: 0.12920
Epoch [26/30] Training [441/488] Loss: 0.10277
Epoch [26/30] Training [442/488] Loss: 0.09470
Epoch [26/30] Training [443/488] Loss: 0.13112
Epoch [26/30] Training [444/488] Loss: 0.09982
Epoch [26/30] Training [445/488] Loss: 0.30630
Epoch [26/30] Training [446/488] Loss: 0.09174
Epoch [26/30] Training [447/488] Loss: 0.10126
Epoch [26/30] Training [448/488] Loss: 0.12660
Epoch [26/30] Training [449/488] Loss: 0.23187
Epoch [26/30] Training [450/488] Loss: 0.11238
Epoch [26/30] Training [451/488] Loss: 0.20969
Epoch [26/30] Training [452/488] Loss: 0.08826
Epoch [26/30] Training [453/488] Loss: 0.16153
Epoch [26/30] Training [454/488] Loss: 0.17320
Epoch [26/30] Training [455/488] Loss: 0.14058
Epoch [26/30] Training [456/488] Loss: 0.20039
Epoch [26/30] Training [457/488] Loss: 0.10157
Epoch [26/30] Training [458/488] Loss: 0.10085
Epoch [26/30] Training [459/488] Loss: 0.10067
Epoch [26/30] Training [460/488] Loss: 0.41997
Epoch [26/30] Training [461/488] Loss: 0.34301
Epoch [26/30] Training [462/488] Loss: 0.15611
Epoch [26/30] Training [463/488] Loss: 0.21862
Epoch [26/30] Training [464/488] Loss: 0.11892
Epoch [26/30] Training [465/488] Loss: 0.33354
Epoch [26/30] Training [466/488] Loss: 0.09409
Epoch [26/30] Training [467/488] Loss: 0.08723
Epoch [26/30] Training [468/488] Loss: 0.35009
Epoch [26/30] Training [469/488] Loss: 0.22429
Epoch [26/30] Training [470/488] Loss: 0.17841
Epoch [26/30] Training [471/488] Loss: 0.08542
Epoch [26/30] Training [472/488] Loss: 0.09047
Epoch [26/30] Training [473/488] Loss: 0.07861
Epoch [26/30] Training [474/488] Loss: 0.14074
Epoch [26/30] Training [475/488] Loss: 0.12170
Epoch [26/30] Training [476/488] Loss: 0.17360
Epoch [26/30] Training [477/488] Loss: 0.08600
Epoch [26/30] Training [478/488] Loss: 0.10864
Epoch [26/30] Training [479/488] Loss: 0.10275
Epoch [26/30] Training [480/488] Loss: 0.11319
Epoch [26/30] Training [481/488] Loss: 0.14450
Epoch [26/30] Training [482/488] Loss: 0.11767
Epoch [26/30] Training [483/488] Loss: 0.08170
Epoch [26/30] Training [484/488] Loss: 0.13777
Epoch [26/30] Training [485/488] Loss: 0.15937
Epoch [26/30] Training [486/488] Loss: 0.11158
Epoch [26/30] Training [487/488] Loss: 0.13041
Epoch [26/30] Training [488/488] Loss: 0.16786
Epoch [26/30] Training metric {'Train/mean dice_metric': 0.904875636100769, 'Train/TC dice_metric': 0.921305239200592, 'Train/WT dice_metric': 0.9408366084098816, 'Train/ET dice_metric': 0.8524848818778992}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [26/30] Validation [1/123] Loss: 0.14477  focal_loss 0.00182  dice_loss 0.14295
Epoch [26/30] Validation [2/123] Loss: 0.31185  focal_loss 0.00155  dice_loss 0.31030
Epoch [26/30] Validation [3/123] Loss: 0.12418  focal_loss 0.00159  dice_loss 0.12258
Epoch [26/30] Validation [4/123] Loss: 0.19020  focal_loss 0.00142  dice_loss 0.18878
Epoch [26/30] Validation [5/123] Loss: 0.31493  focal_loss 0.01141  dice_loss 0.30352
Epoch [26/30] Validation [6/123] Loss: 0.30778  focal_loss 0.00340  dice_loss 0.30437
Epoch [26/30] Validation [7/123] Loss: 0.31947  focal_loss 0.00199  dice_loss 0.31748
Epoch [26/30] Validation [8/123] Loss: 0.29191  focal_loss 0.00138  dice_loss 0.29053
Epoch [26/30] Validation [9/123] Loss: 0.20636  focal_loss 0.00171  dice_loss 0.20465
Epoch [26/30] Validation [10/123] Loss: 0.44303  focal_loss 0.00414  dice_loss 0.43889
Epoch [26/30] Validation [11/123] Loss: 0.53962  focal_loss 0.00446  dice_loss 0.53516
Epoch [26/30] Validation [12/123] Loss: 0.14865  focal_loss 0.00178  dice_loss 0.14688
Epoch [26/30] Validation [13/123] Loss: 0.15352  focal_loss 0.00314  dice_loss 0.15038
Epoch [26/30] Validation [14/123] Loss: 0.15237  focal_loss 0.00100  dice_loss 0.15137
Epoch [26/30] Validation [15/123] Loss: 0.28956  focal_loss 0.00158  dice_loss 0.28798
Epoch [26/30] Validation [16/123] Loss: 0.46698  focal_loss 0.00266  dice_loss 0.46432
Epoch [26/30] Validation [17/123] Loss: 0.42929  focal_loss 0.00239  dice_loss 0.42690
Epoch [26/30] Validation [18/123] Loss: 0.29624  focal_loss 0.00332  dice_loss 0.29292
Epoch [26/30] Validation [19/123] Loss: 0.27600  focal_loss 0.01887  dice_loss 0.25713
Epoch [26/30] Validation [20/123] Loss: 0.38950  focal_loss 0.00121  dice_loss 0.38829
Epoch [26/30] Validation [21/123] Loss: 0.27415  focal_loss 0.00122  dice_loss 0.27292
Epoch [26/30] Validation [22/123] Loss: 0.63399  focal_loss 0.01665  dice_loss 0.61734
Epoch [26/30] Validation [23/123] Loss: 0.13580  focal_loss 0.00179  dice_loss 0.13401
Epoch [26/30] Validation [24/123] Loss: 0.24019  focal_loss 0.00443  dice_loss 0.23576
Epoch [26/30] Validation [25/123] Loss: 0.39208  focal_loss 0.01246  dice_loss 0.37962
Epoch [26/30] Validation [26/123] Loss: 0.13677  focal_loss 0.00131  dice_loss 0.13546
Epoch [26/30] Validation [27/123] Loss: 0.19891  focal_loss 0.00677  dice_loss 0.19214
Epoch [26/30] Validation [28/123] Loss: 0.57469  focal_loss 0.01184  dice_loss 0.56286
Epoch [26/30] Validation [29/123] Loss: 0.37475  focal_loss 0.01388  dice_loss 0.36087
Epoch [26/30] Validation [30/123] Loss: 0.18119  focal_loss 0.00320  dice_loss 0.17799
Epoch [26/30] Validation [31/123] Loss: 0.12860  focal_loss 0.00146  dice_loss 0.12714
Epoch [26/30] Validation [32/123] Loss: 0.24940  focal_loss 0.00503  dice_loss 0.24437
Epoch [26/30] Validation [33/123] Loss: 0.28576  focal_loss 0.00172  dice_loss 0.28403
Epoch [26/30] Validation [34/123] Loss: 0.30315  focal_loss 0.00477  dice_loss 0.29838
Epoch [26/30] Validation [35/123] Loss: 0.15841  focal_loss 0.00127  dice_loss 0.15714
Epoch [26/30] Validation [36/123] Loss: 0.18862  focal_loss 0.00099  dice_loss 0.18763
Epoch [26/30] Validation [37/123] Loss: 0.31613  focal_loss 0.00726  dice_loss 0.30887
Epoch [26/30] Validation [38/123] Loss: 0.14061  focal_loss 0.00130  dice_loss 0.13931
Epoch [26/30] Validation [39/123] Loss: 0.14272  focal_loss 0.00121  dice_loss 0.14151
Epoch [26/30] Validation [40/123] Loss: 0.23703  focal_loss 0.00091  dice_loss 0.23612
Epoch [26/30] Validation [41/123] Loss: 0.13742  focal_loss 0.00139  dice_loss 0.13603
Epoch [26/30] Validation [42/123] Loss: 0.12868  focal_loss 0.00131  dice_loss 0.12737
Epoch [26/30] Validation [43/123] Loss: 0.30858  focal_loss 0.03885  dice_loss 0.26973
Epoch [26/30] Validation [44/123] Loss: 0.68580  focal_loss 0.02824  dice_loss 0.65757
Epoch [26/30] Validation [45/123] Loss: 0.23138  focal_loss 0.00193  dice_loss 0.22945
Epoch [26/30] Validation [46/123] Loss: 0.26765  focal_loss 0.00261  dice_loss 0.26504
Epoch [26/30] Validation [47/123] Loss: 0.21949  focal_loss 0.00153  dice_loss 0.21796
Epoch [26/30] Validation [48/123] Loss: 0.39296  focal_loss 0.00675  dice_loss 0.38621
Epoch [26/30] Validation [49/123] Loss: 0.19025  focal_loss 0.01847  dice_loss 0.17178
Epoch [26/30] Validation [50/123] Loss: 0.15254  focal_loss 0.00216  dice_loss 0.15039
Epoch [26/30] Validation [51/123] Loss: 0.34471  focal_loss 0.01216  dice_loss 0.33255
Epoch [26/30] Validation [52/123] Loss: 0.15579  focal_loss 0.00075  dice_loss 0.15504
Epoch [26/30] Validation [53/123] Loss: 0.20097  focal_loss 0.00078  dice_loss 0.20019
Epoch [26/30] Validation [54/123] Loss: 0.26968  focal_loss 0.00175  dice_loss 0.26794
Epoch [26/30] Validation [55/123] Loss: 0.21740  focal_loss 0.00124  dice_loss 0.21615
Epoch [26/30] Validation [56/123] Loss: 0.18958  focal_loss 0.00626  dice_loss 0.18332
Epoch [26/30] Validation [57/123] Loss: 0.23799  focal_loss 0.01166  dice_loss 0.22633
Epoch [26/30] Validation [58/123] Loss: 0.18387  focal_loss 0.00169  dice_loss 0.18218
Epoch [26/30] Validation [59/123] Loss: 0.64162  focal_loss 0.01760  dice_loss 0.62402
Epoch [26/30] Validation [60/123] Loss: 0.19124  focal_loss 0.00350  dice_loss 0.18774
Epoch [26/30] Validation [61/123] Loss: 0.60793  focal_loss 0.01182  dice_loss 0.59611
Epoch [26/30] Validation [62/123] Loss: 0.50906  focal_loss 0.03028  dice_loss 0.47878
Epoch [26/30] Validation [63/123] Loss: 0.31914  focal_loss 0.00263  dice_loss 0.31652
Epoch [26/30] Validation [64/123] Loss: 0.38494  focal_loss 0.01927  dice_loss 0.36567
Epoch [26/30] Validation [65/123] Loss: 0.16471  focal_loss 0.00104  dice_loss 0.16367
Epoch [26/30] Validation [66/123] Loss: 0.17142  focal_loss 0.00156  dice_loss 0.16986
Epoch [26/30] Validation [67/123] Loss: 0.32707  focal_loss 0.00669  dice_loss 0.32038
Epoch [26/30] Validation [68/123] Loss: 0.29196  focal_loss 0.00111  dice_loss 0.29085
Epoch [26/30] Validation [69/123] Loss: 0.37551  focal_loss 0.00860  dice_loss 0.36691
Epoch [26/30] Validation [70/123] Loss: 0.28876  focal_loss 0.00297  dice_loss 0.28579
Epoch [26/30] Validation [71/123] Loss: 0.14768  focal_loss 0.00092  dice_loss 0.14676
Epoch [26/30] Validation [72/123] Loss: 0.13949  focal_loss 0.00153  dice_loss 0.13795
Epoch [26/30] Validation [73/123] Loss: 0.24983  focal_loss 0.00575  dice_loss 0.24408
Epoch [26/30] Validation [74/123] Loss: 0.26225  focal_loss 0.00399  dice_loss 0.25825
Epoch [26/30] Validation [75/123] Loss: 0.17216  focal_loss 0.00119  dice_loss 0.17097
Epoch [26/30] Validation [76/123] Loss: 0.45992  focal_loss 0.00737  dice_loss 0.45255
Epoch [26/30] Validation [77/123] Loss: 0.30491  focal_loss 0.00105  dice_loss 0.30387
Epoch [26/30] Validation [78/123] Loss: 0.20462  focal_loss 0.00149  dice_loss 0.20313
Epoch [26/30] Validation [79/123] Loss: 0.22776  focal_loss 0.00133  dice_loss 0.22642
Epoch [26/30] Validation [80/123] Loss: 0.15522  focal_loss 0.00205  dice_loss 0.15317
Epoch [26/30] Validation [81/123] Loss: 0.19726  focal_loss 0.00226  dice_loss 0.19500
Epoch [26/30] Validation [82/123] Loss: 0.14500  focal_loss 0.00102  dice_loss 0.14398
Epoch [26/30] Validation [83/123] Loss: 0.33062  focal_loss 0.01079  dice_loss 0.31984
Epoch [26/30] Validation [84/123] Loss: 0.18251  focal_loss 0.00114  dice_loss 0.18136
Epoch [26/30] Validation [85/123] Loss: 0.26913  focal_loss 0.00406  dice_loss 0.26507
Epoch [26/30] Validation [86/123] Loss: 0.16693  focal_loss 0.00208  dice_loss 0.16485
Epoch [26/30] Validation [87/123] Loss: 0.17337  focal_loss 0.00245  dice_loss 0.17092
Epoch [26/30] Validation [88/123] Loss: 0.18087  focal_loss 0.00346  dice_loss 0.17741
Epoch [26/30] Validation [89/123] Loss: 0.15370  focal_loss 0.00216  dice_loss 0.15154
Epoch [26/30] Validation [90/123] Loss: 0.22819  focal_loss 0.00265  dice_loss 0.22553
Epoch [26/30] Validation [91/123] Loss: 0.17395  focal_loss 0.00176  dice_loss 0.17219
Epoch [26/30] Validation [92/123] Loss: 0.13537  focal_loss 0.00126  dice_loss 0.13412
Epoch [26/30] Validation [93/123] Loss: 0.14284  focal_loss 0.00180  dice_loss 0.14103
Epoch [26/30] Validation [94/123] Loss: 0.27942  focal_loss 0.00170  dice_loss 0.27772
Epoch [26/30] Validation [95/123] Loss: 0.19860  focal_loss 0.00289  dice_loss 0.19572
Epoch [26/30] Validation [96/123] Loss: 0.26193  focal_loss 0.00252  dice_loss 0.25941
Epoch [26/30] Validation [97/123] Loss: 0.58050  focal_loss 0.00944  dice_loss 0.57106
Epoch [26/30] Validation [98/123] Loss: 0.24639  focal_loss 0.00114  dice_loss 0.24525
Epoch [26/30] Validation [99/123] Loss: 0.23020  focal_loss 0.00074  dice_loss 0.22946
Epoch [26/30] Validation [100/123] Loss: 0.26695  focal_loss 0.00127  dice_loss 0.26568
Epoch [26/30] Validation [101/123] Loss: 0.22835  focal_loss 0.00123  dice_loss 0.22713
Epoch [26/30] Validation [102/123] Loss: 0.27726  focal_loss 0.00098  dice_loss 0.27628
Epoch [26/30] Validation [103/123] Loss: 0.44165  focal_loss 0.00125  dice_loss 0.44040
Epoch [26/30] Validation [104/123] Loss: 0.37080  focal_loss 0.00752  dice_loss 0.36328
Epoch [26/30] Validation [105/123] Loss: 0.15623  focal_loss 0.00307  dice_loss 0.15316
Epoch [26/30] Validation [106/123] Loss: 0.15219  focal_loss 0.00095  dice_loss 0.15123
Epoch [26/30] Validation [107/123] Loss: 0.47856  focal_loss 0.00309  dice_loss 0.47547
Epoch [26/30] Validation [108/123] Loss: 0.15850  focal_loss 0.00075  dice_loss 0.15775
Epoch [26/30] Validation [109/123] Loss: 0.17014  focal_loss 0.00501  dice_loss 0.16513
Epoch [26/30] Validation [110/123] Loss: 0.29869  focal_loss 0.00326  dice_loss 0.29543
Epoch [26/30] Validation [111/123] Loss: 0.31252  focal_loss 0.00391  dice_loss 0.30862
Epoch [26/30] Validation [112/123] Loss: 0.25667  focal_loss 0.00179  dice_loss 0.25487
Epoch [26/30] Validation [113/123] Loss: 0.19743  focal_loss 0.00175  dice_loss 0.19568
Epoch [26/30] Validation [114/123] Loss: 0.26212  focal_loss 0.00441  dice_loss 0.25771
Epoch [26/30] Validation [115/123] Loss: 0.23986  focal_loss 0.00659  dice_loss 0.23328
Epoch [26/30] Validation [116/123] Loss: 0.18118  focal_loss 0.00056  dice_loss 0.18062
Epoch [26/30] Validation [117/123] Loss: 0.19967  focal_loss 0.00110  dice_loss 0.19857
Epoch [26/30] Validation [118/123] Loss: 0.12668  focal_loss 0.00195  dice_loss 0.12473
Epoch [26/30] Validation [119/123] Loss: 0.14454  focal_loss 0.00147  dice_loss 0.14307
Epoch [26/30] Validation [120/123] Loss: 0.17697  focal_loss 0.00180  dice_loss 0.17517
Epoch [26/30] Validation [121/123] Loss: 0.65586  focal_loss 0.02860  dice_loss 0.62726
Epoch [26/30] Validation [122/123] Loss: 0.52976  focal_loss 0.00136  dice_loss 0.52840
Epoch [26/30] Validation [123/123] Loss: 0.17403  focal_loss 0.00166  dice_loss 0.17237
Epoch [26/30] Validation metric {'Val/mean dice_metric': 0.900801420211792, 'Val/TC dice_metric': 0.9155159592628479, 'Val/WT dice_metric': 0.9370792508125305, 'Val/ET dice_metric': 0.8498090505599976}
Epoch [26/30] lr = [9.549150281252633e-05, 9.549150281252633e-05] best acc: tensor([0.8994], device='cuda:0'), mean acc: tensor([0.9008], device='cuda:0'), mean class: tensor([0.9155, 0.9371, 0.8498], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [27/30] Training [1/488] Loss: 0.09120
Epoch [27/30] Training [2/488] Loss: 0.09310
Epoch [27/30] Training [3/488] Loss: 0.11728
Epoch [27/30] Training [4/488] Loss: 0.10686
Epoch [27/30] Training [5/488] Loss: 0.10279
Epoch [27/30] Training [6/488] Loss: 0.07131
Epoch [27/30] Training [7/488] Loss: 0.08096
Epoch [27/30] Training [8/488] Loss: 0.22005
Epoch [27/30] Training [9/488] Loss: 0.10779
Epoch [27/30] Training [10/488] Loss: 0.22663
Epoch [27/30] Training [11/488] Loss: 0.21504
Epoch [27/30] Training [12/488] Loss: 0.14575
Epoch [27/30] Training [13/488] Loss: 0.30227
Epoch [27/30] Training [14/488] Loss: 0.12883
Epoch [27/30] Training [15/488] Loss: 0.36143
Epoch [27/30] Training [16/488] Loss: 0.12437
Epoch [27/30] Training [17/488] Loss: 0.12079
Epoch [27/30] Training [18/488] Loss: 0.25962
Epoch [27/30] Training [19/488] Loss: 0.35126
Epoch [27/30] Training [20/488] Loss: 0.12232
Epoch [27/30] Training [21/488] Loss: 0.08046
Epoch [27/30] Training [22/488] Loss: 0.11841
Epoch [27/30] Training [23/488] Loss: 0.12183
Epoch [27/30] Training [24/488] Loss: 0.15742
Epoch [27/30] Training [25/488] Loss: 0.12402
Epoch [27/30] Training [26/488] Loss: 0.15341
Epoch [27/30] Training [27/488] Loss: 0.16408
Epoch [27/30] Training [28/488] Loss: 0.20785
Epoch [27/30] Training [29/488] Loss: 0.12146
Epoch [27/30] Training [30/488] Loss: 0.08700
Epoch [27/30] Training [31/488] Loss: 0.12491
Epoch [27/30] Training [32/488] Loss: 0.13626
Epoch [27/30] Training [33/488] Loss: 0.29412
Epoch [27/30] Training [34/488] Loss: 0.09011
Epoch [27/30] Training [35/488] Loss: 0.12785
Epoch [27/30] Training [36/488] Loss: 0.10031
Epoch [27/30] Training [37/488] Loss: 0.13675
Epoch [27/30] Training [38/488] Loss: 0.11832
Epoch [27/30] Training [39/488] Loss: 0.13174
Epoch [27/30] Training [40/488] Loss: 0.10040
Epoch [27/30] Training [41/488] Loss: 0.14591
Epoch [27/30] Training [42/488] Loss: 0.09927
Epoch [27/30] Training [43/488] Loss: 0.09417
Epoch [27/30] Training [44/488] Loss: 0.15380
Epoch [27/30] Training [45/488] Loss: 0.10117
Epoch [27/30] Training [46/488] Loss: 0.14072
Epoch [27/30] Training [47/488] Loss: 0.21429
Epoch [27/30] Training [48/488] Loss: 0.10755
Epoch [27/30] Training [49/488] Loss: 0.18543
Epoch [27/30] Training [50/488] Loss: 0.10678
Epoch [27/30] Training [51/488] Loss: 0.07284
Epoch [27/30] Training [52/488] Loss: 0.06756
Epoch [27/30] Training [53/488] Loss: 0.09975
Epoch [27/30] Training [54/488] Loss: 0.40864
Epoch [27/30] Training [55/488] Loss: 0.22162
Epoch [27/30] Training [56/488] Loss: 0.09260
Epoch [27/30] Training [57/488] Loss: 0.08954
Epoch [27/30] Training [58/488] Loss: 0.25442
Epoch [27/30] Training [59/488] Loss: 0.15900
Epoch [27/30] Training [60/488] Loss: 0.30319
Epoch [27/30] Training [61/488] Loss: 0.40476
Epoch [27/30] Training [62/488] Loss: 0.10073
Epoch [27/30] Training [63/488] Loss: 0.11417
Epoch [27/30] Training [64/488] Loss: 0.19133
Epoch [27/30] Training [65/488] Loss: 0.16522
Epoch [27/30] Training [66/488] Loss: 0.10313
Epoch [27/30] Training [67/488] Loss: 0.09436
Epoch [27/30] Training [68/488] Loss: 0.14555
Epoch [27/30] Training [69/488] Loss: 0.26894
Epoch [27/30] Training [70/488] Loss: 0.18674
Epoch [27/30] Training [71/488] Loss: 0.06654
Epoch [27/30] Training [72/488] Loss: 0.08576
Epoch [27/30] Training [73/488] Loss: 0.17414
Epoch [27/30] Training [74/488] Loss: 0.09136
Epoch [27/30] Training [75/488] Loss: 0.13203
Epoch [27/30] Training [76/488] Loss: 0.17162
Epoch [27/30] Training [77/488] Loss: 0.11621
Epoch [27/30] Training [78/488] Loss: 0.12583
Epoch [27/30] Training [79/488] Loss: 0.10208
Epoch [27/30] Training [80/488] Loss: 0.08713
Epoch [27/30] Training [81/488] Loss: 0.12366
Epoch [27/30] Training [82/488] Loss: 0.15598
Epoch [27/30] Training [83/488] Loss: 0.47507
Epoch [27/30] Training [84/488] Loss: 0.12055
Epoch [27/30] Training [85/488] Loss: 0.11315
Epoch [27/30] Training [86/488] Loss: 0.29069
Epoch [27/30] Training [87/488] Loss: 0.33505
Epoch [27/30] Training [88/488] Loss: 0.12237
Epoch [27/30] Training [89/488] Loss: 0.09089
Epoch [27/30] Training [90/488] Loss: 0.72205
Epoch [27/30] Training [91/488] Loss: 0.21546
Epoch [27/30] Training [92/488] Loss: 0.12711
Epoch [27/30] Training [93/488] Loss: 0.28754
Epoch [27/30] Training [94/488] Loss: 0.10244
Epoch [27/30] Training [95/488] Loss: 0.19425
Epoch [27/30] Training [96/488] Loss: 0.09746
Epoch [27/30] Training [97/488] Loss: 0.14984
Epoch [27/30] Training [98/488] Loss: 0.16625
Epoch [27/30] Training [99/488] Loss: 0.07742
Epoch [27/30] Training [100/488] Loss: 0.22566
Epoch [27/30] Training [101/488] Loss: 0.16660
Epoch [27/30] Training [102/488] Loss: 0.47137
Epoch [27/30] Training [103/488] Loss: 0.13825
Epoch [27/30] Training [104/488] Loss: 0.12819
Epoch [27/30] Training [105/488] Loss: 0.12176
Epoch [27/30] Training [106/488] Loss: 0.44922
Epoch [27/30] Training [107/488] Loss: 0.10454
Epoch [27/30] Training [108/488] Loss: 0.12211
Epoch [27/30] Training [109/488] Loss: 0.30387
Epoch [27/30] Training [110/488] Loss: 0.46655
Epoch [27/30] Training [111/488] Loss: 0.14574
Epoch [27/30] Training [112/488] Loss: 0.08838
Epoch [27/30] Training [113/488] Loss: 0.20162
Epoch [27/30] Training [114/488] Loss: 0.28265
Epoch [27/30] Training [115/488] Loss: 0.08532
Epoch [27/30] Training [116/488] Loss: 0.09788
Epoch [27/30] Training [117/488] Loss: 0.08868
Epoch [27/30] Training [118/488] Loss: 0.17839
Epoch [27/30] Training [119/488] Loss: 0.15639
Epoch [27/30] Training [120/488] Loss: 0.28827
Epoch [27/30] Training [121/488] Loss: 0.15226
Epoch [27/30] Training [122/488] Loss: 0.16622
Epoch [27/30] Training [123/488] Loss: 0.13312
Epoch [27/30] Training [124/488] Loss: 0.19996
Epoch [27/30] Training [125/488] Loss: 0.08370
Epoch [27/30] Training [126/488] Loss: 0.17400
Epoch [27/30] Training [127/488] Loss: 0.24852
Epoch [27/30] Training [128/488] Loss: 0.33326
Epoch [27/30] Training [129/488] Loss: 0.12582
Epoch [27/30] Training [130/488] Loss: 0.13160
Epoch [27/30] Training [131/488] Loss: 0.22642
Epoch [27/30] Training [132/488] Loss: 0.09160
Epoch [27/30] Training [133/488] Loss: 0.26180
Epoch [27/30] Training [134/488] Loss: 0.10047
Epoch [27/30] Training [135/488] Loss: 0.10445
Epoch [27/30] Training [136/488] Loss: 0.09075
Epoch [27/30] Training [137/488] Loss: 0.12647
Epoch [27/30] Training [138/488] Loss: 0.17212
Epoch [27/30] Training [139/488] Loss: 0.09168
Epoch [27/30] Training [140/488] Loss: 0.11536
Epoch [27/30] Training [141/488] Loss: 0.13360
Epoch [27/30] Training [142/488] Loss: 0.13152
Epoch [27/30] Training [143/488] Loss: 0.13586
Epoch [27/30] Training [144/488] Loss: 0.10720
Epoch [27/30] Training [145/488] Loss: 0.19509
Epoch [27/30] Training [146/488] Loss: 0.24245
Epoch [27/30] Training [147/488] Loss: 0.35677
Epoch [27/30] Training [148/488] Loss: 0.15672
Epoch [27/30] Training [149/488] Loss: 0.30140
Epoch [27/30] Training [150/488] Loss: 0.14757
Epoch [27/30] Training [151/488] Loss: 0.11256
Epoch [27/30] Training [152/488] Loss: 0.08221
Epoch [27/30] Training [153/488] Loss: 0.09198
Epoch [27/30] Training [154/488] Loss: 0.12366
Epoch [27/30] Training [155/488] Loss: 0.14828
Epoch [27/30] Training [156/488] Loss: 0.11273
Epoch [27/30] Training [157/488] Loss: 0.10826
Epoch [27/30] Training [158/488] Loss: 0.16532
Epoch [27/30] Training [159/488] Loss: 0.09675
Epoch [27/30] Training [160/488] Loss: 0.15282
Epoch [27/30] Training [161/488] Loss: 0.08525
Epoch [27/30] Training [162/488] Loss: 0.09193
Epoch [27/30] Training [163/488] Loss: 0.10124
Epoch [27/30] Training [164/488] Loss: 0.13917
Epoch [27/30] Training [165/488] Loss: 0.12086
Epoch [27/30] Training [166/488] Loss: 0.11639
Epoch [27/30] Training [167/488] Loss: 0.11569
Epoch [27/30] Training [168/488] Loss: 0.11948
Epoch [27/30] Training [169/488] Loss: 0.09346
Epoch [27/30] Training [170/488] Loss: 0.25433
Epoch [27/30] Training [171/488] Loss: 0.13598
Epoch [27/30] Training [172/488] Loss: 0.08206
Epoch [27/30] Training [173/488] Loss: 0.09008
Epoch [27/30] Training [174/488] Loss: 0.38049
Epoch [27/30] Training [175/488] Loss: 0.14425
Epoch [27/30] Training [176/488] Loss: 0.08810
Epoch [27/30] Training [177/488] Loss: 0.09110
Epoch [27/30] Training [178/488] Loss: 0.09810
Epoch [27/30] Training [179/488] Loss: 0.14126
Epoch [27/30] Training [180/488] Loss: 0.13930
Epoch [27/30] Training [181/488] Loss: 0.09279
Epoch [27/30] Training [182/488] Loss: 0.11255
Epoch [27/30] Training [183/488] Loss: 0.14364
Epoch [27/30] Training [184/488] Loss: 0.18737
Epoch [27/30] Training [185/488] Loss: 0.20548
Epoch [27/30] Training [186/488] Loss: 0.12032
Epoch [27/30] Training [187/488] Loss: 0.22871
Epoch [27/30] Training [188/488] Loss: 0.19389
Epoch [27/30] Training [189/488] Loss: 0.12872
Epoch [27/30] Training [190/488] Loss: 0.14792
Epoch [27/30] Training [191/488] Loss: 0.10087
Epoch [27/30] Training [192/488] Loss: 0.15122
Epoch [27/30] Training [193/488] Loss: 0.08460
Epoch [27/30] Training [194/488] Loss: 0.13620
Epoch [27/30] Training [195/488] Loss: 0.11622
Epoch [27/30] Training [196/488] Loss: 0.11588
Epoch [27/30] Training [197/488] Loss: 0.19031
Epoch [27/30] Training [198/488] Loss: 0.16586
Epoch [27/30] Training [199/488] Loss: 0.13285
Epoch [27/30] Training [200/488] Loss: 0.16806
Epoch [27/30] Training [201/488] Loss: 0.21565
Epoch [27/30] Training [202/488] Loss: 0.56558
Epoch [27/30] Training [203/488] Loss: 0.23214
Epoch [27/30] Training [204/488] Loss: 0.16634
Epoch [27/30] Training [205/488] Loss: 0.11583
Epoch [27/30] Training [206/488] Loss: 0.16493
Epoch [27/30] Training [207/488] Loss: 0.11444
Epoch [27/30] Training [208/488] Loss: 0.20052
Epoch [27/30] Training [209/488] Loss: 0.10456
Epoch [27/30] Training [210/488] Loss: 0.23180
Epoch [27/30] Training [211/488] Loss: 0.18812
Epoch [27/30] Training [212/488] Loss: 0.10644
Epoch [27/30] Training [213/488] Loss: 0.12352
Epoch [27/30] Training [214/488] Loss: 0.11448
Epoch [27/30] Training [215/488] Loss: 0.11669
Epoch [27/30] Training [216/488] Loss: 0.42372
Epoch [27/30] Training [217/488] Loss: 0.22710
Epoch [27/30] Training [218/488] Loss: 0.08816
Epoch [27/30] Training [219/488] Loss: 0.09569
Epoch [27/30] Training [220/488] Loss: 0.12173
Epoch [27/30] Training [221/488] Loss: 0.14752
Epoch [27/30] Training [222/488] Loss: 0.15420
Epoch [27/30] Training [223/488] Loss: 0.75230
Epoch [27/30] Training [224/488] Loss: 0.33074
Epoch [27/30] Training [225/488] Loss: 0.09062
Epoch [27/30] Training [226/488] Loss: 0.10541
Epoch [27/30] Training [227/488] Loss: 0.17428
Epoch [27/30] Training [228/488] Loss: 0.15357
Epoch [27/30] Training [229/488] Loss: 0.09855
Epoch [27/30] Training [230/488] Loss: 0.11411
Epoch [27/30] Training [231/488] Loss: 0.07636
Epoch [27/30] Training [232/488] Loss: 0.13533
Epoch [27/30] Training [233/488] Loss: 0.09101
Epoch [27/30] Training [234/488] Loss: 0.14144
Epoch [27/30] Training [235/488] Loss: 0.13320
Epoch [27/30] Training [236/488] Loss: 0.13658
Epoch [27/30] Training [237/488] Loss: 0.12678
Epoch [27/30] Training [238/488] Loss: 0.09609
Epoch [27/30] Training [239/488] Loss: 0.18754
Epoch [27/30] Training [240/488] Loss: 0.10208
Epoch [27/30] Training [241/488] Loss: 0.38884
Epoch [27/30] Training [242/488] Loss: 0.10263
Epoch [27/30] Training [243/488] Loss: 0.10310
Epoch [27/30] Training [244/488] Loss: 0.13077
Epoch [27/30] Training [245/488] Loss: 0.11213
Epoch [27/30] Training [246/488] Loss: 0.15101
Epoch [27/30] Training [247/488] Loss: 0.10003
Epoch [27/30] Training [248/488] Loss: 0.12912
Epoch [27/30] Training [249/488] Loss: 0.10723
Epoch [27/30] Training [250/488] Loss: 0.19636
Epoch [27/30] Training [251/488] Loss: 0.13642
Epoch [27/30] Training [252/488] Loss: 0.15849
Epoch [27/30] Training [253/488] Loss: 0.19864
Epoch [27/30] Training [254/488] Loss: 0.34401
Epoch [27/30] Training [255/488] Loss: 0.37919
Epoch [27/30] Training [256/488] Loss: 0.13667
Epoch [27/30] Training [257/488] Loss: 0.13132
Epoch [27/30] Training [258/488] Loss: 0.54356
Epoch [27/30] Training [259/488] Loss: 0.08635
Epoch [27/30] Training [260/488] Loss: 0.10463
Epoch [27/30] Training [261/488] Loss: 0.14106
Epoch [27/30] Training [262/488] Loss: 0.25970
Epoch [27/30] Training [263/488] Loss: 0.71686
Epoch [27/30] Training [264/488] Loss: 0.15082
Epoch [27/30] Training [265/488] Loss: 0.13602
Epoch [27/30] Training [266/488] Loss: 0.11387
Epoch [27/30] Training [267/488] Loss: 0.19746
Epoch [27/30] Training [268/488] Loss: 0.15281
Epoch [27/30] Training [269/488] Loss: 0.11043
Epoch [27/30] Training [270/488] Loss: 0.07228
Epoch [27/30] Training [271/488] Loss: 0.07691
Epoch [27/30] Training [272/488] Loss: 0.11684
Epoch [27/30] Training [273/488] Loss: 0.10797
Epoch [27/30] Training [274/488] Loss: 0.25778
Epoch [27/30] Training [275/488] Loss: 0.10237
Epoch [27/30] Training [276/488] Loss: 0.12083
Epoch [27/30] Training [277/488] Loss: 0.08257
Epoch [27/30] Training [278/488] Loss: 0.20684
Epoch [27/30] Training [279/488] Loss: 0.11386
Epoch [27/30] Training [280/488] Loss: 0.09059
Epoch [27/30] Training [281/488] Loss: 0.11071
Epoch [27/30] Training [282/488] Loss: 0.15145
Epoch [27/30] Training [283/488] Loss: 0.21327
Epoch [27/30] Training [284/488] Loss: 0.16103
Epoch [27/30] Training [285/488] Loss: 0.22664
Epoch [27/30] Training [286/488] Loss: 0.14329
Epoch [27/30] Training [287/488] Loss: 0.40904
Epoch [27/30] Training [288/488] Loss: 0.08868
Epoch [27/30] Training [289/488] Loss: 0.10403
Epoch [27/30] Training [290/488] Loss: 0.12332
Epoch [27/30] Training [291/488] Loss: 0.09143
Epoch [27/30] Training [292/488] Loss: 0.24847
Epoch [27/30] Training [293/488] Loss: 0.19295
Epoch [27/30] Training [294/488] Loss: 0.21560
Epoch [27/30] Training [295/488] Loss: 0.28496
Epoch [27/30] Training [296/488] Loss: 0.10004
Epoch [27/30] Training [297/488] Loss: 0.15962
Epoch [27/30] Training [298/488] Loss: 0.17265
Epoch [27/30] Training [299/488] Loss: 0.08231
Epoch [27/30] Training [300/488] Loss: 0.08879
Epoch [27/30] Training [301/488] Loss: 0.08602
Epoch [27/30] Training [302/488] Loss: 0.23296
Epoch [27/30] Training [303/488] Loss: 0.12701
Epoch [27/30] Training [304/488] Loss: 0.10320
Epoch [27/30] Training [305/488] Loss: 0.32078
Epoch [27/30] Training [306/488] Loss: 0.15330
Epoch [27/30] Training [307/488] Loss: 0.12294
Epoch [27/30] Training [308/488] Loss: 0.13573
Epoch [27/30] Training [309/488] Loss: 0.14082
Epoch [27/30] Training [310/488] Loss: 0.10820
Epoch [27/30] Training [311/488] Loss: 0.16561
Epoch [27/30] Training [312/488] Loss: 0.13934
Epoch [27/30] Training [313/488] Loss: 0.09601
Epoch [27/30] Training [314/488] Loss: 0.15669
Epoch [27/30] Training [315/488] Loss: 0.17976
Epoch [27/30] Training [316/488] Loss: 0.10360
Epoch [27/30] Training [317/488] Loss: 0.08351
Epoch [27/30] Training [318/488] Loss: 0.08193
Epoch [27/30] Training [319/488] Loss: 0.09078
Epoch [27/30] Training [320/488] Loss: 0.21281
Epoch [27/30] Training [321/488] Loss: 0.14698
Epoch [27/30] Training [322/488] Loss: 0.08939
Epoch [27/30] Training [323/488] Loss: 0.16605
Epoch [27/30] Training [324/488] Loss: 0.15089
Epoch [27/30] Training [325/488] Loss: 0.10001
Epoch [27/30] Training [326/488] Loss: 0.10611
Epoch [27/30] Training [327/488] Loss: 0.08769
Epoch [27/30] Training [328/488] Loss: 0.11369
Epoch [27/30] Training [329/488] Loss: 0.09360
Epoch [27/30] Training [330/488] Loss: 0.10958
Epoch [27/30] Training [331/488] Loss: 0.10860
Epoch [27/30] Training [332/488] Loss: 0.10742
Epoch [27/30] Training [333/488] Loss: 0.15011
Epoch [27/30] Training [334/488] Loss: 0.08714
Epoch [27/30] Training [335/488] Loss: 0.43643
Epoch [27/30] Training [336/488] Loss: 0.15212
Epoch [27/30] Training [337/488] Loss: 0.09755
Epoch [27/30] Training [338/488] Loss: 0.09208
Epoch [27/30] Training [339/488] Loss: 0.08538
Epoch [27/30] Training [340/488] Loss: 0.11725
Epoch [27/30] Training [341/488] Loss: 0.15784
Epoch [27/30] Training [342/488] Loss: 0.10672
Epoch [27/30] Training [343/488] Loss: 0.23014
Epoch [27/30] Training [344/488] Loss: 0.13136
Epoch [27/30] Training [345/488] Loss: 0.08274
Epoch [27/30] Training [346/488] Loss: 0.09002
Epoch [27/30] Training [347/488] Loss: 0.09759
Epoch [27/30] Training [348/488] Loss: 0.17524
Epoch [27/30] Training [349/488] Loss: 0.28850
Epoch [27/30] Training [350/488] Loss: 0.10470
Epoch [27/30] Training [351/488] Loss: 0.12589
Epoch [27/30] Training [352/488] Loss: 0.16771
Epoch [27/30] Training [353/488] Loss: 0.09732
Epoch [27/30] Training [354/488] Loss: 0.35586
Epoch [27/30] Training [355/488] Loss: 0.31259
Epoch [27/30] Training [356/488] Loss: 0.12913
Epoch [27/30] Training [357/488] Loss: 0.14212
Epoch [27/30] Training [358/488] Loss: 0.13018
Epoch [27/30] Training [359/488] Loss: 0.16648
Epoch [27/30] Training [360/488] Loss: 0.29357
Epoch [27/30] Training [361/488] Loss: 0.12600
Epoch [27/30] Training [362/488] Loss: 0.07644
Epoch [27/30] Training [363/488] Loss: 0.11029
Epoch [27/30] Training [364/488] Loss: 0.15555
Epoch [27/30] Training [365/488] Loss: 0.13194
Epoch [27/30] Training [366/488] Loss: 0.28484
Epoch [27/30] Training [367/488] Loss: 0.27134
Epoch [27/30] Training [368/488] Loss: 0.11791
Epoch [27/30] Training [369/488] Loss: 0.32617
Epoch [27/30] Training [370/488] Loss: 0.17772
Epoch [27/30] Training [371/488] Loss: 0.09464
Epoch [27/30] Training [372/488] Loss: 0.09463
Epoch [27/30] Training [373/488] Loss: 0.10952
Epoch [27/30] Training [374/488] Loss: 0.09978
Epoch [27/30] Training [375/488] Loss: 0.10196
Epoch [27/30] Training [376/488] Loss: 0.09402
Epoch [27/30] Training [377/488] Loss: 0.61631
Epoch [27/30] Training [378/488] Loss: 0.07682
Epoch [27/30] Training [379/488] Loss: 0.18644
Epoch [27/30] Training [380/488] Loss: 0.21941
Epoch [27/30] Training [381/488] Loss: 0.11206
Epoch [27/30] Training [382/488] Loss: 0.70553
Epoch [27/30] Training [383/488] Loss: 0.21587
Epoch [27/30] Training [384/488] Loss: 0.21061
Epoch [27/30] Training [385/488] Loss: 0.12731
Epoch [27/30] Training [386/488] Loss: 0.08628
Epoch [27/30] Training [387/488] Loss: 0.10469
Epoch [27/30] Training [388/488] Loss: 0.09746
Epoch [27/30] Training [389/488] Loss: 0.18432
Epoch [27/30] Training [390/488] Loss: 0.12338
Epoch [27/30] Training [391/488] Loss: 0.14727
Epoch [27/30] Training [392/488] Loss: 0.12070
Epoch [27/30] Training [393/488] Loss: 0.10802
Epoch [27/30] Training [394/488] Loss: 0.11183
Epoch [27/30] Training [395/488] Loss: 0.22026
Epoch [27/30] Training [396/488] Loss: 0.08069
Epoch [27/30] Training [397/488] Loss: 0.06955
Epoch [27/30] Training [398/488] Loss: 0.32016
Epoch [27/30] Training [399/488] Loss: 0.09993
Epoch [27/30] Training [400/488] Loss: 0.13489
Epoch [27/30] Training [401/488] Loss: 0.10598
Epoch [27/30] Training [402/488] Loss: 0.10331
Epoch [27/30] Training [403/488] Loss: 0.10657
Epoch [27/30] Training [404/488] Loss: 0.09445
Epoch [27/30] Training [405/488] Loss: 0.26690
Epoch [27/30] Training [406/488] Loss: 0.09502
Epoch [27/30] Training [407/488] Loss: 0.10789
Epoch [27/30] Training [408/488] Loss: 0.09099
Epoch [27/30] Training [409/488] Loss: 0.11526
Epoch [27/30] Training [410/488] Loss: 0.10700
Epoch [27/30] Training [411/488] Loss: 0.13435
Epoch [27/30] Training [412/488] Loss: 0.09957
Epoch [27/30] Training [413/488] Loss: 0.11145
Epoch [27/30] Training [414/488] Loss: 0.21602
Epoch [27/30] Training [415/488] Loss: 0.10892
Epoch [27/30] Training [416/488] Loss: 0.12213
Epoch [27/30] Training [417/488] Loss: 0.23887
Epoch [27/30] Training [418/488] Loss: 0.15738
Epoch [27/30] Training [419/488] Loss: 0.15494
Epoch [27/30] Training [420/488] Loss: 0.12065
Epoch [27/30] Training [421/488] Loss: 0.12241
Epoch [27/30] Training [422/488] Loss: 0.08546
Epoch [27/30] Training [423/488] Loss: 0.33365
Epoch [27/30] Training [424/488] Loss: 0.21868
Epoch [27/30] Training [425/488] Loss: 0.11234
Epoch [27/30] Training [426/488] Loss: 0.31948
Epoch [27/30] Training [427/488] Loss: 0.13782
Epoch [27/30] Training [428/488] Loss: 0.20571
Epoch [27/30] Training [429/488] Loss: 0.08464
Epoch [27/30] Training [430/488] Loss: 0.14022
Epoch [27/30] Training [431/488] Loss: 0.15060
Epoch [27/30] Training [432/488] Loss: 0.09088
Epoch [27/30] Training [433/488] Loss: 0.15596
Epoch [27/30] Training [434/488] Loss: 0.10169
Epoch [27/30] Training [435/488] Loss: 0.34808
Epoch [27/30] Training [436/488] Loss: 0.12090
Epoch [27/30] Training [437/488] Loss: 0.09519
Epoch [27/30] Training [438/488] Loss: 0.12893
Epoch [27/30] Training [439/488] Loss: 0.10417
Epoch [27/30] Training [440/488] Loss: 0.54394
Epoch [27/30] Training [441/488] Loss: 0.12876
Epoch [27/30] Training [442/488] Loss: 0.20262
Epoch [27/30] Training [443/488] Loss: 0.45069
Epoch [27/30] Training [444/488] Loss: 0.11154
Epoch [27/30] Training [445/488] Loss: 0.10660
Epoch [27/30] Training [446/488] Loss: 0.10591
Epoch [27/30] Training [447/488] Loss: 0.13004
Epoch [27/30] Training [448/488] Loss: 0.11245
Epoch [27/30] Training [449/488] Loss: 0.15249
Epoch [27/30] Training [450/488] Loss: 0.09601
Epoch [27/30] Training [451/488] Loss: 0.11944
Epoch [27/30] Training [452/488] Loss: 0.10419
Epoch [27/30] Training [453/488] Loss: 0.13203
Epoch [27/30] Training [454/488] Loss: 0.17269
Epoch [27/30] Training [455/488] Loss: 0.09189
Epoch [27/30] Training [456/488] Loss: 0.66457
Epoch [27/30] Training [457/488] Loss: 0.11955
Epoch [27/30] Training [458/488] Loss: 0.19524
Epoch [27/30] Training [459/488] Loss: 0.16307
Epoch [27/30] Training [460/488] Loss: 0.13527
Epoch [27/30] Training [461/488] Loss: 0.11375
Epoch [27/30] Training [462/488] Loss: 0.49930
Epoch [27/30] Training [463/488] Loss: 0.12530
Epoch [27/30] Training [464/488] Loss: 0.09860
Epoch [27/30] Training [465/488] Loss: 0.22937
Epoch [27/30] Training [466/488] Loss: 0.09750
Epoch [27/30] Training [467/488] Loss: 0.31275
Epoch [27/30] Training [468/488] Loss: 0.13003
Epoch [27/30] Training [469/488] Loss: 0.13559
Epoch [27/30] Training [470/488] Loss: 0.13689
Epoch [27/30] Training [471/488] Loss: 0.17732
Epoch [27/30] Training [472/488] Loss: 0.15261
Epoch [27/30] Training [473/488] Loss: 0.12417
Epoch [27/30] Training [474/488] Loss: 0.17820
Epoch [27/30] Training [475/488] Loss: 0.12657
Epoch [27/30] Training [476/488] Loss: 0.35126
Epoch [27/30] Training [477/488] Loss: 0.09983
Epoch [27/30] Training [478/488] Loss: 0.32888
Epoch [27/30] Training [479/488] Loss: 0.11567
Epoch [27/30] Training [480/488] Loss: 0.14081
Epoch [27/30] Training [481/488] Loss: 0.14174
Epoch [27/30] Training [482/488] Loss: 0.24055
Epoch [27/30] Training [483/488] Loss: 0.12420
Epoch [27/30] Training [484/488] Loss: 0.10469
Epoch [27/30] Training [485/488] Loss: 0.41470
Epoch [27/30] Training [486/488] Loss: 0.10607
Epoch [27/30] Training [487/488] Loss: 0.10042
Epoch [27/30] Training [488/488] Loss: 0.16317
Epoch [27/30] Training metric {'Train/mean dice_metric': 0.9064568281173706, 'Train/TC dice_metric': 0.922982931137085, 'Train/WT dice_metric': 0.9421479105949402, 'Train/ET dice_metric': 0.8542394042015076}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [27/30] Validation [1/123] Loss: 0.14699  focal_loss 0.00205  dice_loss 0.14494
Epoch [27/30] Validation [2/123] Loss: 0.30337  focal_loss 0.00111  dice_loss 0.30225
Epoch [27/30] Validation [3/123] Loss: 0.12811  focal_loss 0.00184  dice_loss 0.12627
Epoch [27/30] Validation [4/123] Loss: 0.18649  focal_loss 0.00123  dice_loss 0.18526
Epoch [27/30] Validation [5/123] Loss: 0.28847  focal_loss 0.01015  dice_loss 0.27832
Epoch [27/30] Validation [6/123] Loss: 0.25659  focal_loss 0.00179  dice_loss 0.25480
Epoch [27/30] Validation [7/123] Loss: 0.28618  focal_loss 0.00078  dice_loss 0.28540
Epoch [27/30] Validation [8/123] Loss: 0.31745  focal_loss 0.00194  dice_loss 0.31551
Epoch [27/30] Validation [9/123] Loss: 0.20210  focal_loss 0.00146  dice_loss 0.20064
Epoch [27/30] Validation [10/123] Loss: 0.40605  focal_loss 0.00289  dice_loss 0.40317
Epoch [27/30] Validation [11/123] Loss: 0.43022  focal_loss 0.00201  dice_loss 0.42822
Epoch [27/30] Validation [12/123] Loss: 0.15455  focal_loss 0.00177  dice_loss 0.15279
Epoch [27/30] Validation [13/123] Loss: 0.17107  focal_loss 0.00429  dice_loss 0.16678
Epoch [27/30] Validation [14/123] Loss: 0.14865  focal_loss 0.00082  dice_loss 0.14783
Epoch [27/30] Validation [15/123] Loss: 0.28734  focal_loss 0.00145  dice_loss 0.28589
Epoch [27/30] Validation [16/123] Loss: 0.39307  focal_loss 0.00167  dice_loss 0.39141
Epoch [27/30] Validation [17/123] Loss: 0.41506  focal_loss 0.00201  dice_loss 0.41306
Epoch [27/30] Validation [18/123] Loss: 0.27343  focal_loss 0.00240  dice_loss 0.27103
Epoch [27/30] Validation [19/123] Loss: 0.25242  focal_loss 0.01271  dice_loss 0.23972
Epoch [27/30] Validation [20/123] Loss: 0.37091  focal_loss 0.00078  dice_loss 0.37012
Epoch [27/30] Validation [21/123] Loss: 0.26183  focal_loss 0.00084  dice_loss 0.26099
Epoch [27/30] Validation [22/123] Loss: 0.64395  focal_loss 0.00934  dice_loss 0.63461
Epoch [27/30] Validation [23/123] Loss: 0.14198  focal_loss 0.00222  dice_loss 0.13977
Epoch [27/30] Validation [24/123] Loss: 0.22341  focal_loss 0.00313  dice_loss 0.22028
Epoch [27/30] Validation [25/123] Loss: 0.34708  focal_loss 0.00929  dice_loss 0.33779
Epoch [27/30] Validation [26/123] Loss: 0.15351  focal_loss 0.00229  dice_loss 0.15122
Epoch [27/30] Validation [27/123] Loss: 0.17549  focal_loss 0.00256  dice_loss 0.17293
Epoch [27/30] Validation [28/123] Loss: 0.47238  focal_loss 0.00670  dice_loss 0.46568
Epoch [27/30] Validation [29/123] Loss: 0.30396  focal_loss 0.00480  dice_loss 0.29916
Epoch [27/30] Validation [30/123] Loss: 0.18724  focal_loss 0.00361  dice_loss 0.18363
Epoch [27/30] Validation [31/123] Loss: 0.13574  focal_loss 0.00201  dice_loss 0.13373
Epoch [27/30] Validation [32/123] Loss: 0.22897  focal_loss 0.00374  dice_loss 0.22524
Epoch [27/30] Validation [33/123] Loss: 0.27571  focal_loss 0.00135  dice_loss 0.27436
Epoch [27/30] Validation [34/123] Loss: 0.22213  focal_loss 0.00134  dice_loss 0.22078
Epoch [27/30] Validation [35/123] Loss: 0.16904  focal_loss 0.00185  dice_loss 0.16718
Epoch [27/30] Validation [36/123] Loss: 0.20124  focal_loss 0.00164  dice_loss 0.19959
Epoch [27/30] Validation [37/123] Loss: 0.28790  focal_loss 0.00399  dice_loss 0.28392
Epoch [27/30] Validation [38/123] Loss: 0.14861  focal_loss 0.00176  dice_loss 0.14685
Epoch [27/30] Validation [39/123] Loss: 0.14566  focal_loss 0.00137  dice_loss 0.14429
Epoch [27/30] Validation [40/123] Loss: 0.23831  focal_loss 0.00089  dice_loss 0.23741
Epoch [27/30] Validation [41/123] Loss: 0.14553  focal_loss 0.00175  dice_loss 0.14378
Epoch [27/30] Validation [42/123] Loss: 0.15035  focal_loss 0.00255  dice_loss 0.14780
Epoch [27/30] Validation [43/123] Loss: 0.26169  focal_loss 0.03067  dice_loss 0.23102
Epoch [27/30] Validation [44/123] Loss: 0.56969  focal_loss 0.01453  dice_loss 0.55516
Epoch [27/30] Validation [45/123] Loss: 0.23704  focal_loss 0.00232  dice_loss 0.23472
Epoch [27/30] Validation [46/123] Loss: 0.26795  focal_loss 0.00320  dice_loss 0.26475
Epoch [27/30] Validation [47/123] Loss: 0.21199  focal_loss 0.00113  dice_loss 0.21086
Epoch [27/30] Validation [48/123] Loss: 0.34471  focal_loss 0.00426  dice_loss 0.34045
Epoch [27/30] Validation [49/123] Loss: 0.18091  focal_loss 0.01202  dice_loss 0.16890
Epoch [27/30] Validation [50/123] Loss: 0.15919  focal_loss 0.00278  dice_loss 0.15641
Epoch [27/30] Validation [51/123] Loss: 0.33245  focal_loss 0.01079  dice_loss 0.32166
Epoch [27/30] Validation [52/123] Loss: 0.15996  focal_loss 0.00100  dice_loss 0.15896
Epoch [27/30] Validation [53/123] Loss: 0.20458  focal_loss 0.00100  dice_loss 0.20358
Epoch [27/30] Validation [54/123] Loss: 0.24654  focal_loss 0.00092  dice_loss 0.24562
Epoch [27/30] Validation [55/123] Loss: 0.21889  focal_loss 0.00125  dice_loss 0.21764
Epoch [27/30] Validation [56/123] Loss: 0.16870  focal_loss 0.00423  dice_loss 0.16447
Epoch [27/30] Validation [57/123] Loss: 0.24135  focal_loss 0.01048  dice_loss 0.23087
Epoch [27/30] Validation [58/123] Loss: 0.20103  focal_loss 0.00233  dice_loss 0.19869
Epoch [27/30] Validation [59/123] Loss: 0.54333  focal_loss 0.00729  dice_loss 0.53605
Epoch [27/30] Validation [60/123] Loss: 0.18473  focal_loss 0.00293  dice_loss 0.18180
Epoch [27/30] Validation [61/123] Loss: 0.56163  focal_loss 0.00328  dice_loss 0.55835
Epoch [27/30] Validation [62/123] Loss: 0.45761  focal_loss 0.01812  dice_loss 0.43949
Epoch [27/30] Validation [63/123] Loss: 0.29115  focal_loss 0.00153  dice_loss 0.28961
Epoch [27/30] Validation [64/123] Loss: 0.36437  focal_loss 0.01232  dice_loss 0.35205
Epoch [27/30] Validation [65/123] Loss: 0.17473  focal_loss 0.00146  dice_loss 0.17328
Epoch [27/30] Validation [66/123] Loss: 0.16808  focal_loss 0.00129  dice_loss 0.16679
Epoch [27/30] Validation [67/123] Loss: 0.32291  focal_loss 0.00635  dice_loss 0.31656
Epoch [27/30] Validation [68/123] Loss: 0.28331  focal_loss 0.00087  dice_loss 0.28244
Epoch [27/30] Validation [69/123] Loss: 0.37122  focal_loss 0.00780  dice_loss 0.36342
Epoch [27/30] Validation [70/123] Loss: 0.25716  focal_loss 0.00193  dice_loss 0.25523
Epoch [27/30] Validation [71/123] Loss: 0.15275  focal_loss 0.00113  dice_loss 0.15162
Epoch [27/30] Validation [72/123] Loss: 0.14865  focal_loss 0.00207  dice_loss 0.14657
Epoch [27/30] Validation [73/123] Loss: 0.23620  focal_loss 0.00318  dice_loss 0.23302
Epoch [27/30] Validation [74/123] Loss: 0.21892  focal_loss 0.00147  dice_loss 0.21745
Epoch [27/30] Validation [75/123] Loss: 0.17837  focal_loss 0.00163  dice_loss 0.17674
Epoch [27/30] Validation [76/123] Loss: 0.47903  focal_loss 0.00546  dice_loss 0.47357
Epoch [27/30] Validation [77/123] Loss: 0.29448  focal_loss 0.00071  dice_loss 0.29377
Epoch [27/30] Validation [78/123] Loss: 0.20502  focal_loss 0.00143  dice_loss 0.20358
Epoch [27/30] Validation [79/123] Loss: 0.21599  focal_loss 0.00095  dice_loss 0.21503
Epoch [27/30] Validation [80/123] Loss: 0.16409  focal_loss 0.00278  dice_loss 0.16131
Epoch [27/30] Validation [81/123] Loss: 0.16897  focal_loss 0.00121  dice_loss 0.16777
Epoch [27/30] Validation [82/123] Loss: 0.15308  focal_loss 0.00146  dice_loss 0.15162
Epoch [27/30] Validation [83/123] Loss: 0.33542  focal_loss 0.01046  dice_loss 0.32496
Epoch [27/30] Validation [84/123] Loss: 0.18889  focal_loss 0.00150  dice_loss 0.18739
Epoch [27/30] Validation [85/123] Loss: 0.25581  focal_loss 0.00351  dice_loss 0.25231
Epoch [27/30] Validation [86/123] Loss: 0.16310  focal_loss 0.00136  dice_loss 0.16174
Epoch [27/30] Validation [87/123] Loss: 0.17811  focal_loss 0.00300  dice_loss 0.17511
Epoch [27/30] Validation [88/123] Loss: 0.17318  focal_loss 0.00186  dice_loss 0.17132
Epoch [27/30] Validation [89/123] Loss: 0.15456  focal_loss 0.00241  dice_loss 0.15215
Epoch [27/30] Validation [90/123] Loss: 0.20580  focal_loss 0.00169  dice_loss 0.20411
Epoch [27/30] Validation [91/123] Loss: 0.16995  focal_loss 0.00165  dice_loss 0.16830
Epoch [27/30] Validation [92/123] Loss: 0.14042  focal_loss 0.00175  dice_loss 0.13867
Epoch [27/30] Validation [93/123] Loss: 0.14604  focal_loss 0.00187  dice_loss 0.14416
Epoch [27/30] Validation [94/123] Loss: 0.27042  focal_loss 0.00134  dice_loss 0.26908
Epoch [27/30] Validation [95/123] Loss: 0.19773  focal_loss 0.00270  dice_loss 0.19502
Epoch [27/30] Validation [96/123] Loss: 0.25322  focal_loss 0.00222  dice_loss 0.25101
Epoch [27/30] Validation [97/123] Loss: 0.51282  focal_loss 0.00500  dice_loss 0.50782
Epoch [27/30] Validation [98/123] Loss: 0.23198  focal_loss 0.00072  dice_loss 0.23126
Epoch [27/30] Validation [99/123] Loss: 0.22928  focal_loss 0.00065  dice_loss 0.22863
Epoch [27/30] Validation [100/123] Loss: 0.25363  focal_loss 0.00088  dice_loss 0.25276
Epoch [27/30] Validation [101/123] Loss: 0.22061  focal_loss 0.00092  dice_loss 0.21970
Epoch [27/30] Validation [102/123] Loss: 0.25837  focal_loss 0.00068  dice_loss 0.25769
Epoch [27/30] Validation [103/123] Loss: 0.39204  focal_loss 0.00073  dice_loss 0.39131
Epoch [27/30] Validation [104/123] Loss: 0.35724  focal_loss 0.00519  dice_loss 0.35204
Epoch [27/30] Validation [105/123] Loss: 0.16088  focal_loss 0.00344  dice_loss 0.15745
Epoch [27/30] Validation [106/123] Loss: 0.15580  focal_loss 0.00106  dice_loss 0.15474
Epoch [27/30] Validation [107/123] Loss: 0.43626  focal_loss 0.00174  dice_loss 0.43452
Epoch [27/30] Validation [108/123] Loss: 0.17348  focal_loss 0.00137  dice_loss 0.17211
Epoch [27/30] Validation [109/123] Loss: 0.18582  focal_loss 0.00653  dice_loss 0.17929
Epoch [27/30] Validation [110/123] Loss: 0.27785  focal_loss 0.00263  dice_loss 0.27522
Epoch [27/30] Validation [111/123] Loss: 0.30254  focal_loss 0.00322  dice_loss 0.29932
Epoch [27/30] Validation [112/123] Loss: 0.25217  focal_loss 0.00127  dice_loss 0.25090
Epoch [27/30] Validation [113/123] Loss: 0.18890  focal_loss 0.00136  dice_loss 0.18754
Epoch [27/30] Validation [114/123] Loss: 0.26842  focal_loss 0.00450  dice_loss 0.26391
Epoch [27/30] Validation [115/123] Loss: 0.24882  focal_loss 0.00712  dice_loss 0.24170
Epoch [27/30] Validation [116/123] Loss: 0.18772  focal_loss 0.00084  dice_loss 0.18688
Epoch [27/30] Validation [117/123] Loss: 0.20137  focal_loss 0.00123  dice_loss 0.20014
Epoch [27/30] Validation [118/123] Loss: 0.13512  focal_loss 0.00250  dice_loss 0.13263
Epoch [27/30] Validation [119/123] Loss: 0.15981  focal_loss 0.00231  dice_loss 0.15750
Epoch [27/30] Validation [120/123] Loss: 0.18724  focal_loss 0.00244  dice_loss 0.18479
Epoch [27/30] Validation [121/123] Loss: 0.61546  focal_loss 0.01987  dice_loss 0.59559
Epoch [27/30] Validation [122/123] Loss: 0.49982  focal_loss 0.00067  dice_loss 0.49915
Epoch [27/30] Validation [123/123] Loss: 0.19474  focal_loss 0.00238  dice_loss 0.19236
Epoch [27/30] Validation metric {'Val/mean dice_metric': 0.9039679765701294, 'Val/TC dice_metric': 0.9193377494812012, 'Val/WT dice_metric': 0.939622163772583, 'Val/ET dice_metric': 0.8529438972473145}
Epoch [27/30] lr = [6.184665997806821e-05, 6.184665997806821e-05] best acc: tensor([0.9008], device='cuda:0'), mean acc: tensor([0.9040], device='cuda:0'), mean class: tensor([0.9193, 0.9396, 0.8529], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [28/30] Training [1/488] Loss: 0.13434
Epoch [28/30] Training [2/488] Loss: 0.09207
Epoch [28/30] Training [3/488] Loss: 0.19915
Epoch [28/30] Training [4/488] Loss: 0.10107
Epoch [28/30] Training [5/488] Loss: 0.11264
Epoch [28/30] Training [6/488] Loss: 0.23876
Epoch [28/30] Training [7/488] Loss: 0.11386
Epoch [28/30] Training [8/488] Loss: 0.09504
Epoch [28/30] Training [9/488] Loss: 0.09663
Epoch [28/30] Training [10/488] Loss: 0.34821
Epoch [28/30] Training [11/488] Loss: 0.13984
Epoch [28/30] Training [12/488] Loss: 0.13918
Epoch [28/30] Training [13/488] Loss: 0.10051
Epoch [28/30] Training [14/488] Loss: 0.10277
Epoch [28/30] Training [15/488] Loss: 0.12812
Epoch [28/30] Training [16/488] Loss: 0.11848
Epoch [28/30] Training [17/488] Loss: 0.12881
Epoch [28/30] Training [18/488] Loss: 0.09140
Epoch [28/30] Training [19/488] Loss: 0.10649
Epoch [28/30] Training [20/488] Loss: 0.14213
Epoch [28/30] Training [21/488] Loss: 0.11138
Epoch [28/30] Training [22/488] Loss: 0.19870
Epoch [28/30] Training [23/488] Loss: 0.13554
Epoch [28/30] Training [24/488] Loss: 0.08212
Epoch [28/30] Training [25/488] Loss: 0.22733
Epoch [28/30] Training [26/488] Loss: 0.11540
Epoch [28/30] Training [27/488] Loss: 0.13929
Epoch [28/30] Training [28/488] Loss: 0.28566
Epoch [28/30] Training [29/488] Loss: 0.11124
Epoch [28/30] Training [30/488] Loss: 0.12945
Epoch [28/30] Training [31/488] Loss: 0.08644
Epoch [28/30] Training [32/488] Loss: 0.35458
Epoch [28/30] Training [33/488] Loss: 0.15846
Epoch [28/30] Training [34/488] Loss: 0.08912
Epoch [28/30] Training [35/488] Loss: 0.09922
Epoch [28/30] Training [36/488] Loss: 0.12756
Epoch [28/30] Training [37/488] Loss: 0.12703
Epoch [28/30] Training [38/488] Loss: 0.13942
Epoch [28/30] Training [39/488] Loss: 0.08543
Epoch [28/30] Training [40/488] Loss: 0.40075
Epoch [28/30] Training [41/488] Loss: 0.61955
Epoch [28/30] Training [42/488] Loss: 0.22576
Epoch [28/30] Training [43/488] Loss: 0.10004
Epoch [28/30] Training [44/488] Loss: 0.17295
Epoch [28/30] Training [45/488] Loss: 0.40526
Epoch [28/30] Training [46/488] Loss: 0.23077
Epoch [28/30] Training [47/488] Loss: 0.22862
Epoch [28/30] Training [48/488] Loss: 0.20126
Epoch [28/30] Training [49/488] Loss: 0.18837
Epoch [28/30] Training [50/488] Loss: 0.11025
Epoch [28/30] Training [51/488] Loss: 0.12756
Epoch [28/30] Training [52/488] Loss: 0.10129
Epoch [28/30] Training [53/488] Loss: 0.10220
Epoch [28/30] Training [54/488] Loss: 0.12405
Epoch [28/30] Training [55/488] Loss: 0.10440
Epoch [28/30] Training [56/488] Loss: 0.23587
Epoch [28/30] Training [57/488] Loss: 0.25851
Epoch [28/30] Training [58/488] Loss: 0.07925
Epoch [28/30] Training [59/488] Loss: 0.16090
Epoch [28/30] Training [60/488] Loss: 0.09434
Epoch [28/30] Training [61/488] Loss: 0.16478
Epoch [28/30] Training [62/488] Loss: 0.45914
Epoch [28/30] Training [63/488] Loss: 0.13263
Epoch [28/30] Training [64/488] Loss: 0.09663
Epoch [28/30] Training [65/488] Loss: 0.08703
Epoch [28/30] Training [66/488] Loss: 0.16686
Epoch [28/30] Training [67/488] Loss: 0.08881
Epoch [28/30] Training [68/488] Loss: 0.17047
Epoch [28/30] Training [69/488] Loss: 0.21081
Epoch [28/30] Training [70/488] Loss: 0.14192
Epoch [28/30] Training [71/488] Loss: 0.12637
Epoch [28/30] Training [72/488] Loss: 0.07978
Epoch [28/30] Training [73/488] Loss: 0.17909
Epoch [28/30] Training [74/488] Loss: 0.11514
Epoch [28/30] Training [75/488] Loss: 0.33046
Epoch [28/30] Training [76/488] Loss: 0.09347
Epoch [28/30] Training [77/488] Loss: 0.18536
Epoch [28/30] Training [78/488] Loss: 0.13265
Epoch [28/30] Training [79/488] Loss: 0.10054
Epoch [28/30] Training [80/488] Loss: 0.19704
Epoch [28/30] Training [81/488] Loss: 0.10716
Epoch [28/30] Training [82/488] Loss: 0.22383
Epoch [28/30] Training [83/488] Loss: 0.11080
Epoch [28/30] Training [84/488] Loss: 0.41858
Epoch [28/30] Training [85/488] Loss: 0.07879
Epoch [28/30] Training [86/488] Loss: 0.15373
Epoch [28/30] Training [87/488] Loss: 0.28410
Epoch [28/30] Training [88/488] Loss: 0.14420
Epoch [28/30] Training [89/488] Loss: 0.14691
Epoch [28/30] Training [90/488] Loss: 0.11523
Epoch [28/30] Training [91/488] Loss: 0.08586
Epoch [28/30] Training [92/488] Loss: 0.09434
Epoch [28/30] Training [93/488] Loss: 0.12360
Epoch [28/30] Training [94/488] Loss: 0.09256
Epoch [28/30] Training [95/488] Loss: 0.12783
Epoch [28/30] Training [96/488] Loss: 0.16767
Epoch [28/30] Training [97/488] Loss: 0.08785
Epoch [28/30] Training [98/488] Loss: 0.09267
Epoch [28/30] Training [99/488] Loss: 0.25796
Epoch [28/30] Training [100/488] Loss: 0.19636
Epoch [28/30] Training [101/488] Loss: 0.14239
Epoch [28/30] Training [102/488] Loss: 0.13665
Epoch [28/30] Training [103/488] Loss: 0.11429
Epoch [28/30] Training [104/488] Loss: 0.10093
Epoch [28/30] Training [105/488] Loss: 0.39321
Epoch [28/30] Training [106/488] Loss: 0.14702
Epoch [28/30] Training [107/488] Loss: 0.22905
Epoch [28/30] Training [108/488] Loss: 0.08619
Epoch [28/30] Training [109/488] Loss: 0.22580
Epoch [28/30] Training [110/488] Loss: 0.10182
Epoch [28/30] Training [111/488] Loss: 0.38539
Epoch [28/30] Training [112/488] Loss: 0.10817
Epoch [28/30] Training [113/488] Loss: 0.13523
Epoch [28/30] Training [114/488] Loss: 0.10308
Epoch [28/30] Training [115/488] Loss: 0.25716
Epoch [28/30] Training [116/488] Loss: 0.16839
Epoch [28/30] Training [117/488] Loss: 0.10369
Epoch [28/30] Training [118/488] Loss: 0.14639
Epoch [28/30] Training [119/488] Loss: 0.11487
Epoch [28/30] Training [120/488] Loss: 0.10189
Epoch [28/30] Training [121/488] Loss: 0.09709
Epoch [28/30] Training [122/488] Loss: 0.11892
Epoch [28/30] Training [123/488] Loss: 0.15522
Epoch [28/30] Training [124/488] Loss: 0.09767
Epoch [28/30] Training [125/488] Loss: 0.48006
Epoch [28/30] Training [126/488] Loss: 0.12184
Epoch [28/30] Training [127/488] Loss: 0.16105
Epoch [28/30] Training [128/488] Loss: 0.11173
Epoch [28/30] Training [129/488] Loss: 0.11231
Epoch [28/30] Training [130/488] Loss: 0.36786
Epoch [28/30] Training [131/488] Loss: 0.08580
Epoch [28/30] Training [132/488] Loss: 0.11405
Epoch [28/30] Training [133/488] Loss: 0.08880
Epoch [28/30] Training [134/488] Loss: 0.11039
Epoch [28/30] Training [135/488] Loss: 0.09782
Epoch [28/30] Training [136/488] Loss: 0.09184
Epoch [28/30] Training [137/488] Loss: 0.19411
Epoch [28/30] Training [138/488] Loss: 0.11277
Epoch [28/30] Training [139/488] Loss: 0.29466
Epoch [28/30] Training [140/488] Loss: 0.09304
Epoch [28/30] Training [141/488] Loss: 0.14412
Epoch [28/30] Training [142/488] Loss: 0.08800
Epoch [28/30] Training [143/488] Loss: 0.14862
Epoch [28/30] Training [144/488] Loss: 0.10483
Epoch [28/30] Training [145/488] Loss: 0.08339
Epoch [28/30] Training [146/488] Loss: 0.13166
Epoch [28/30] Training [147/488] Loss: 0.12320
Epoch [28/30] Training [148/488] Loss: 0.07540
Epoch [28/30] Training [149/488] Loss: 0.53603
Epoch [28/30] Training [150/488] Loss: 0.32647
Epoch [28/30] Training [151/488] Loss: 0.10332
Epoch [28/30] Training [152/488] Loss: 0.54418
Epoch [28/30] Training [153/488] Loss: 0.07348
Epoch [28/30] Training [154/488] Loss: 0.44274
Epoch [28/30] Training [155/488] Loss: 0.12611
Epoch [28/30] Training [156/488] Loss: 0.21604
Epoch [28/30] Training [157/488] Loss: 0.24306
Epoch [28/30] Training [158/488] Loss: 0.18937
Epoch [28/30] Training [159/488] Loss: 0.58851
Epoch [28/30] Training [160/488] Loss: 0.08118
Epoch [28/30] Training [161/488] Loss: 0.34029
Epoch [28/30] Training [162/488] Loss: 0.15183
Epoch [28/30] Training [163/488] Loss: 0.09537
Epoch [28/30] Training [164/488] Loss: 0.06789
Epoch [28/30] Training [165/488] Loss: 0.15048
Epoch [28/30] Training [166/488] Loss: 0.10189
Epoch [28/30] Training [167/488] Loss: 0.23610
Epoch [28/30] Training [168/488] Loss: 0.12478
Epoch [28/30] Training [169/488] Loss: 0.58397
Epoch [28/30] Training [170/488] Loss: 0.09978
Epoch [28/30] Training [171/488] Loss: 0.12076
Epoch [28/30] Training [172/488] Loss: 0.41961
Epoch [28/30] Training [173/488] Loss: 0.17482
Epoch [28/30] Training [174/488] Loss: 0.09280
Epoch [28/30] Training [175/488] Loss: 0.28922
Epoch [28/30] Training [176/488] Loss: 0.13554
Epoch [28/30] Training [177/488] Loss: 0.15932
Epoch [28/30] Training [178/488] Loss: 0.10973
Epoch [28/30] Training [179/488] Loss: 0.09627
Epoch [28/30] Training [180/488] Loss: 0.39311
Epoch [28/30] Training [181/488] Loss: 0.19943
Epoch [28/30] Training [182/488] Loss: 0.09489
Epoch [28/30] Training [183/488] Loss: 0.23803
Epoch [28/30] Training [184/488] Loss: 0.11090
Epoch [28/30] Training [185/488] Loss: 0.17297
Epoch [28/30] Training [186/488] Loss: 0.12744
Epoch [28/30] Training [187/488] Loss: 0.15503
Epoch [28/30] Training [188/488] Loss: 0.13780
Epoch [28/30] Training [189/488] Loss: 0.10814
Epoch [28/30] Training [190/488] Loss: 0.10811
Epoch [28/30] Training [191/488] Loss: 0.15550
Epoch [28/30] Training [192/488] Loss: 0.10626
Epoch [28/30] Training [193/488] Loss: 0.10480
Epoch [28/30] Training [194/488] Loss: 0.31507
Epoch [28/30] Training [195/488] Loss: 0.12166
Epoch [28/30] Training [196/488] Loss: 0.10098
Epoch [28/30] Training [197/488] Loss: 0.10385
Epoch [28/30] Training [198/488] Loss: 0.14746
Epoch [28/30] Training [199/488] Loss: 0.06718
Epoch [28/30] Training [200/488] Loss: 0.34571
Epoch [28/30] Training [201/488] Loss: 0.70899
Epoch [28/30] Training [202/488] Loss: 0.17476
Epoch [28/30] Training [203/488] Loss: 0.15125
Epoch [28/30] Training [204/488] Loss: 0.07174
Epoch [28/30] Training [205/488] Loss: 0.17254
Epoch [28/30] Training [206/488] Loss: 0.09492
Epoch [28/30] Training [207/488] Loss: 0.08615
Epoch [28/30] Training [208/488] Loss: 0.15446
Epoch [28/30] Training [209/488] Loss: 0.13528
Epoch [28/30] Training [210/488] Loss: 0.22735
Epoch [28/30] Training [211/488] Loss: 0.24703
Epoch [28/30] Training [212/488] Loss: 0.22846
Epoch [28/30] Training [213/488] Loss: 0.08161
Epoch [28/30] Training [214/488] Loss: 0.12045
Epoch [28/30] Training [215/488] Loss: 0.09431
Epoch [28/30] Training [216/488] Loss: 0.13388
Epoch [28/30] Training [217/488] Loss: 0.11712
Epoch [28/30] Training [218/488] Loss: 0.10188
Epoch [28/30] Training [219/488] Loss: 0.09832
Epoch [28/30] Training [220/488] Loss: 0.14907
Epoch [28/30] Training [221/488] Loss: 0.10241
Epoch [28/30] Training [222/488] Loss: 0.12198
Epoch [28/30] Training [223/488] Loss: 0.11229
Epoch [28/30] Training [224/488] Loss: 0.10476
Epoch [28/30] Training [225/488] Loss: 0.08470
Epoch [28/30] Training [226/488] Loss: 0.16118
Epoch [28/30] Training [227/488] Loss: 0.10555
Epoch [28/30] Training [228/488] Loss: 0.24509
Epoch [28/30] Training [229/488] Loss: 0.07148
Epoch [28/30] Training [230/488] Loss: 0.11201
Epoch [28/30] Training [231/488] Loss: 0.26585
Epoch [28/30] Training [232/488] Loss: 0.15853
Epoch [28/30] Training [233/488] Loss: 0.14443
Epoch [28/30] Training [234/488] Loss: 0.10839
Epoch [28/30] Training [235/488] Loss: 0.12316
Epoch [28/30] Training [236/488] Loss: 0.23740
Epoch [28/30] Training [237/488] Loss: 0.20237
Epoch [28/30] Training [238/488] Loss: 0.32987
Epoch [28/30] Training [239/488] Loss: 0.13424
Epoch [28/30] Training [240/488] Loss: 0.17036
Epoch [28/30] Training [241/488] Loss: 0.32402
Epoch [28/30] Training [242/488] Loss: 0.08714
Epoch [28/30] Training [243/488] Loss: 0.16991
Epoch [28/30] Training [244/488] Loss: 0.09488
Epoch [28/30] Training [245/488] Loss: 0.15660
Epoch [28/30] Training [246/488] Loss: 0.19629
Epoch [28/30] Training [247/488] Loss: 0.09835
Epoch [28/30] Training [248/488] Loss: 0.09506
Epoch [28/30] Training [249/488] Loss: 0.16442
Epoch [28/30] Training [250/488] Loss: 0.15175
Epoch [28/30] Training [251/488] Loss: 0.12779
Epoch [28/30] Training [252/488] Loss: 0.11914
Epoch [28/30] Training [253/488] Loss: 0.22572
Epoch [28/30] Training [254/488] Loss: 0.11936
Epoch [28/30] Training [255/488] Loss: 0.70219
Epoch [28/30] Training [256/488] Loss: 0.08839
Epoch [28/30] Training [257/488] Loss: 0.13510
Epoch [28/30] Training [258/488] Loss: 0.13877
Epoch [28/30] Training [259/488] Loss: 0.12351
Epoch [28/30] Training [260/488] Loss: 0.11322
Epoch [28/30] Training [261/488] Loss: 0.13745
Epoch [28/30] Training [262/488] Loss: 0.12674
Epoch [28/30] Training [263/488] Loss: 0.31424
Epoch [28/30] Training [264/488] Loss: 0.09689
Epoch [28/30] Training [265/488] Loss: 0.21128
Epoch [28/30] Training [266/488] Loss: 0.27352
Epoch [28/30] Training [267/488] Loss: 0.08493
Epoch [28/30] Training [268/488] Loss: 0.17718
Epoch [28/30] Training [269/488] Loss: 0.08529
Epoch [28/30] Training [270/488] Loss: 0.10031
Epoch [28/30] Training [271/488] Loss: 0.28180
Epoch [28/30] Training [272/488] Loss: 0.07894
Epoch [28/30] Training [273/488] Loss: 0.25140
Epoch [28/30] Training [274/488] Loss: 0.40109
Epoch [28/30] Training [275/488] Loss: 0.21449
Epoch [28/30] Training [276/488] Loss: 0.12635
Epoch [28/30] Training [277/488] Loss: 0.11395
Epoch [28/30] Training [278/488] Loss: 0.09840
Epoch [28/30] Training [279/488] Loss: 0.09735
Epoch [28/30] Training [280/488] Loss: 0.09938
Epoch [28/30] Training [281/488] Loss: 0.23218
Epoch [28/30] Training [282/488] Loss: 0.08880
Epoch [28/30] Training [283/488] Loss: 0.11357
Epoch [28/30] Training [284/488] Loss: 0.32080
Epoch [28/30] Training [285/488] Loss: 0.10457
Epoch [28/30] Training [286/488] Loss: 0.19059
Epoch [28/30] Training [287/488] Loss: 0.14905
Epoch [28/30] Training [288/488] Loss: 0.34735
Epoch [28/30] Training [289/488] Loss: 0.09357
Epoch [28/30] Training [290/488] Loss: 0.10107
Epoch [28/30] Training [291/488] Loss: 0.13656
Epoch [28/30] Training [292/488] Loss: 0.10278
Epoch [28/30] Training [293/488] Loss: 0.45484
Epoch [28/30] Training [294/488] Loss: 0.10398
Epoch [28/30] Training [295/488] Loss: 0.08625
Epoch [28/30] Training [296/488] Loss: 0.40832
Epoch [28/30] Training [297/488] Loss: 0.13964
Epoch [28/30] Training [298/488] Loss: 0.16037
Epoch [28/30] Training [299/488] Loss: 0.10914
Epoch [28/30] Training [300/488] Loss: 0.13304
Epoch [28/30] Training [301/488] Loss: 0.12489
Epoch [28/30] Training [302/488] Loss: 0.22604
Epoch [28/30] Training [303/488] Loss: 0.14589
Epoch [28/30] Training [304/488] Loss: 0.10637
Epoch [28/30] Training [305/488] Loss: 0.08170
Epoch [28/30] Training [306/488] Loss: 0.22549
Epoch [28/30] Training [307/488] Loss: 0.16308
Epoch [28/30] Training [308/488] Loss: 0.23994
Epoch [28/30] Training [309/488] Loss: 0.18020
Epoch [28/30] Training [310/488] Loss: 0.19727
Epoch [28/30] Training [311/488] Loss: 0.15276
Epoch [28/30] Training [312/488] Loss: 0.16754
Epoch [28/30] Training [313/488] Loss: 0.11113
Epoch [28/30] Training [314/488] Loss: 0.34927
Epoch [28/30] Training [315/488] Loss: 0.45004
Epoch [28/30] Training [316/488] Loss: 0.34074
Epoch [28/30] Training [317/488] Loss: 0.09093
Epoch [28/30] Training [318/488] Loss: 0.14945
Epoch [28/30] Training [319/488] Loss: 0.30110
Epoch [28/30] Training [320/488] Loss: 0.09045
Epoch [28/30] Training [321/488] Loss: 0.10354
Epoch [28/30] Training [322/488] Loss: 0.09186
Epoch [28/30] Training [323/488] Loss: 0.10641
Epoch [28/30] Training [324/488] Loss: 0.16320
Epoch [28/30] Training [325/488] Loss: 0.11530
Epoch [28/30] Training [326/488] Loss: 0.07434
Epoch [28/30] Training [327/488] Loss: 0.10397
Epoch [28/30] Training [328/488] Loss: 0.13525
Epoch [28/30] Training [329/488] Loss: 0.12466
Epoch [28/30] Training [330/488] Loss: 0.12830
Epoch [28/30] Training [331/488] Loss: 0.10856
Epoch [28/30] Training [332/488] Loss: 0.09178
Epoch [28/30] Training [333/488] Loss: 0.09572
Epoch [28/30] Training [334/488] Loss: 0.18567
Epoch [28/30] Training [335/488] Loss: 0.11169
Epoch [28/30] Training [336/488] Loss: 0.11807
Epoch [28/30] Training [337/488] Loss: 0.06952
Epoch [28/30] Training [338/488] Loss: 0.25209
Epoch [28/30] Training [339/488] Loss: 0.14463
Epoch [28/30] Training [340/488] Loss: 0.13256
Epoch [28/30] Training [341/488] Loss: 0.26341
Epoch [28/30] Training [342/488] Loss: 0.22350
Epoch [28/30] Training [343/488] Loss: 0.09862
Epoch [28/30] Training [344/488] Loss: 0.15508
Epoch [28/30] Training [345/488] Loss: 0.09902
Epoch [28/30] Training [346/488] Loss: 0.12469
Epoch [28/30] Training [347/488] Loss: 0.12631
Epoch [28/30] Training [348/488] Loss: 0.12171
Epoch [28/30] Training [349/488] Loss: 0.13364
Epoch [28/30] Training [350/488] Loss: 0.13353
Epoch [28/30] Training [351/488] Loss: 0.11978
Epoch [28/30] Training [352/488] Loss: 0.14100
Epoch [28/30] Training [353/488] Loss: 0.08073
Epoch [28/30] Training [354/488] Loss: 0.12025
Epoch [28/30] Training [355/488] Loss: 0.12347
Epoch [28/30] Training [356/488] Loss: 0.11722
Epoch [28/30] Training [357/488] Loss: 0.11954
Epoch [28/30] Training [358/488] Loss: 0.13698
Epoch [28/30] Training [359/488] Loss: 0.13160
Epoch [28/30] Training [360/488] Loss: 0.21940
Epoch [28/30] Training [361/488] Loss: 0.20679
Epoch [28/30] Training [362/488] Loss: 0.18051
Epoch [28/30] Training [363/488] Loss: 0.16099
Epoch [28/30] Training [364/488] Loss: 0.15829
Epoch [28/30] Training [365/488] Loss: 0.11250
Epoch [28/30] Training [366/488] Loss: 0.19450
Epoch [28/30] Training [367/488] Loss: 0.13461
Epoch [28/30] Training [368/488] Loss: 0.19529
Epoch [28/30] Training [369/488] Loss: 0.13972
Epoch [28/30] Training [370/488] Loss: 0.13508
Epoch [28/30] Training [371/488] Loss: 0.12859
Epoch [28/30] Training [372/488] Loss: 0.14940
Epoch [28/30] Training [373/488] Loss: 0.10026
Epoch [28/30] Training [374/488] Loss: 0.13364
Epoch [28/30] Training [375/488] Loss: 0.09617
Epoch [28/30] Training [376/488] Loss: 0.14061
Epoch [28/30] Training [377/488] Loss: 0.10584
Epoch [28/30] Training [378/488] Loss: 0.20452
Epoch [28/30] Training [379/488] Loss: 0.09244
Epoch [28/30] Training [380/488] Loss: 0.17017
Epoch [28/30] Training [381/488] Loss: 0.57804
Epoch [28/30] Training [382/488] Loss: 0.11516
Epoch [28/30] Training [383/488] Loss: 0.12781
Epoch [28/30] Training [384/488] Loss: 0.08807
Epoch [28/30] Training [385/488] Loss: 0.09009
Epoch [28/30] Training [386/488] Loss: 0.10570
Epoch [28/30] Training [387/488] Loss: 0.09211
Epoch [28/30] Training [388/488] Loss: 0.09213
Epoch [28/30] Training [389/488] Loss: 0.14603
Epoch [28/30] Training [390/488] Loss: 0.09079
Epoch [28/30] Training [391/488] Loss: 0.44478
Epoch [28/30] Training [392/488] Loss: 0.10175
Epoch [28/30] Training [393/488] Loss: 0.11286
Epoch [28/30] Training [394/488] Loss: 0.16875
Epoch [28/30] Training [395/488] Loss: 0.33782
Epoch [28/30] Training [396/488] Loss: 0.08712
Epoch [28/30] Training [397/488] Loss: 0.14477
Epoch [28/30] Training [398/488] Loss: 0.28820
Epoch [28/30] Training [399/488] Loss: 0.28364
Epoch [28/30] Training [400/488] Loss: 0.17743
Epoch [28/30] Training [401/488] Loss: 0.13268
Epoch [28/30] Training [402/488] Loss: 0.16253
Epoch [28/30] Training [403/488] Loss: 0.08532
Epoch [28/30] Training [404/488] Loss: 0.12266
Epoch [28/30] Training [405/488] Loss: 0.13439
Epoch [28/30] Training [406/488] Loss: 0.11598
Epoch [28/30] Training [407/488] Loss: 0.10407
Epoch [28/30] Training [408/488] Loss: 0.10949
Epoch [28/30] Training [409/488] Loss: 0.13292
Epoch [28/30] Training [410/488] Loss: 0.11978
Epoch [28/30] Training [411/488] Loss: 0.23001
Epoch [28/30] Training [412/488] Loss: 0.11413
Epoch [28/30] Training [413/488] Loss: 0.13673
Epoch [28/30] Training [414/488] Loss: 0.09158
Epoch [28/30] Training [415/488] Loss: 0.10560
Epoch [28/30] Training [416/488] Loss: 0.11355
Epoch [28/30] Training [417/488] Loss: 0.16241
Epoch [28/30] Training [418/488] Loss: 0.10077
Epoch [28/30] Training [419/488] Loss: 0.21978
Epoch [28/30] Training [420/488] Loss: 0.12205
Epoch [28/30] Training [421/488] Loss: 0.08957
Epoch [28/30] Training [422/488] Loss: 0.25206
Epoch [28/30] Training [423/488] Loss: 0.15358
Epoch [28/30] Training [424/488] Loss: 0.12095
Epoch [28/30] Training [425/488] Loss: 0.29109
Epoch [28/30] Training [426/488] Loss: 0.11988
Epoch [28/30] Training [427/488] Loss: 0.06779
Epoch [28/30] Training [428/488] Loss: 0.14879
Epoch [28/30] Training [429/488] Loss: 0.17173
Epoch [28/30] Training [430/488] Loss: 0.09782
Epoch [28/30] Training [431/488] Loss: 0.13975
Epoch [28/30] Training [432/488] Loss: 0.12179
Epoch [28/30] Training [433/488] Loss: 0.21805
Epoch [28/30] Training [434/488] Loss: 0.08619
Epoch [28/30] Training [435/488] Loss: 0.13610
Epoch [28/30] Training [436/488] Loss: 0.20525
Epoch [28/30] Training [437/488] Loss: 0.08251
Epoch [28/30] Training [438/488] Loss: 0.11689
Epoch [28/30] Training [439/488] Loss: 0.08417
Epoch [28/30] Training [440/488] Loss: 0.08824
Epoch [28/30] Training [441/488] Loss: 0.19912
Epoch [28/30] Training [442/488] Loss: 0.15701
Epoch [28/30] Training [443/488] Loss: 0.22380
Epoch [28/30] Training [444/488] Loss: 0.14217
Epoch [28/30] Training [445/488] Loss: 0.15563
Epoch [28/30] Training [446/488] Loss: 0.09619
Epoch [28/30] Training [447/488] Loss: 0.07550
Epoch [28/30] Training [448/488] Loss: 0.08607
Epoch [28/30] Training [449/488] Loss: 0.21450
Epoch [28/30] Training [450/488] Loss: 0.10095
Epoch [28/30] Training [451/488] Loss: 0.12942
Epoch [28/30] Training [452/488] Loss: 0.29204
Epoch [28/30] Training [453/488] Loss: 0.11845
Epoch [28/30] Training [454/488] Loss: 0.10875
Epoch [28/30] Training [455/488] Loss: 0.13429
Epoch [28/30] Training [456/488] Loss: 0.21936
Epoch [28/30] Training [457/488] Loss: 0.07514
Epoch [28/30] Training [458/488] Loss: 0.71227
Epoch [28/30] Training [459/488] Loss: 0.14159
Epoch [28/30] Training [460/488] Loss: 0.09176
Epoch [28/30] Training [461/488] Loss: 0.12964
Epoch [28/30] Training [462/488] Loss: 0.14088
Epoch [28/30] Training [463/488] Loss: 0.09624
Epoch [28/30] Training [464/488] Loss: 0.07918
Epoch [28/30] Training [465/488] Loss: 0.17428
Epoch [28/30] Training [466/488] Loss: 0.12069
Epoch [28/30] Training [467/488] Loss: 0.08927
Epoch [28/30] Training [468/488] Loss: 0.13835
Epoch [28/30] Training [469/488] Loss: 0.08645
Epoch [28/30] Training [470/488] Loss: 0.10842
Epoch [28/30] Training [471/488] Loss: 0.10404
Epoch [28/30] Training [472/488] Loss: 0.09924
Epoch [28/30] Training [473/488] Loss: 0.08439
Epoch [28/30] Training [474/488] Loss: 0.07999
Epoch [28/30] Training [475/488] Loss: 0.09924
Epoch [28/30] Training [476/488] Loss: 0.15247
Epoch [28/30] Training [477/488] Loss: 0.09005
Epoch [28/30] Training [478/488] Loss: 0.11288
Epoch [28/30] Training [479/488] Loss: 0.15774
Epoch [28/30] Training [480/488] Loss: 0.11580
Epoch [28/30] Training [481/488] Loss: 0.09235
Epoch [28/30] Training [482/488] Loss: 0.18833
Epoch [28/30] Training [483/488] Loss: 0.09619
Epoch [28/30] Training [484/488] Loss: 0.11360
Epoch [28/30] Training [485/488] Loss: 0.08639
Epoch [28/30] Training [486/488] Loss: 0.08209
Epoch [28/30] Training [487/488] Loss: 0.16083
Epoch [28/30] Training [488/488] Loss: 0.34077
Epoch [28/30] Training metric {'Train/mean dice_metric': 0.9082827568054199, 'Train/TC dice_metric': 0.9260217547416687, 'Train/WT dice_metric': 0.9430027604103088, 'Train/ET dice_metric': 0.8558238744735718}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [28/30] Validation [1/123] Loss: 0.14447  focal_loss 0.00191  dice_loss 0.14256
Epoch [28/30] Validation [2/123] Loss: 0.30671  focal_loss 0.00151  dice_loss 0.30521
Epoch [28/30] Validation [3/123] Loss: 0.12155  focal_loss 0.00159  dice_loss 0.11996
Epoch [28/30] Validation [4/123] Loss: 0.18502  focal_loss 0.00131  dice_loss 0.18372
Epoch [28/30] Validation [5/123] Loss: 0.28542  focal_loss 0.00970  dice_loss 0.27572
Epoch [28/30] Validation [6/123] Loss: 0.27079  focal_loss 0.00228  dice_loss 0.26851
Epoch [28/30] Validation [7/123] Loss: 0.27538  focal_loss 0.00065  dice_loss 0.27473
Epoch [28/30] Validation [8/123] Loss: 0.30067  focal_loss 0.00156  dice_loss 0.29911
Epoch [28/30] Validation [9/123] Loss: 0.20147  focal_loss 0.00151  dice_loss 0.19997
Epoch [28/30] Validation [10/123] Loss: 0.40885  focal_loss 0.00309  dice_loss 0.40575
Epoch [28/30] Validation [11/123] Loss: 0.52058  focal_loss 0.00374  dice_loss 0.51684
Epoch [28/30] Validation [12/123] Loss: 0.14489  focal_loss 0.00158  dice_loss 0.14331
Epoch [28/30] Validation [13/123] Loss: 0.15547  focal_loss 0.00374  dice_loss 0.15173
Epoch [28/30] Validation [14/123] Loss: 0.14516  focal_loss 0.00082  dice_loss 0.14434
Epoch [28/30] Validation [15/123] Loss: 0.28102  focal_loss 0.00141  dice_loss 0.27961
Epoch [28/30] Validation [16/123] Loss: 0.46833  focal_loss 0.00281  dice_loss 0.46553
Epoch [28/30] Validation [17/123] Loss: 0.41819  focal_loss 0.00224  dice_loss 0.41595
Epoch [28/30] Validation [18/123] Loss: 0.29243  focal_loss 0.00348  dice_loss 0.28895
Epoch [28/30] Validation [19/123] Loss: 0.25203  focal_loss 0.01464  dice_loss 0.23739
Epoch [28/30] Validation [20/123] Loss: 0.37696  focal_loss 0.00097  dice_loss 0.37599
Epoch [28/30] Validation [21/123] Loss: 0.25546  focal_loss 0.00077  dice_loss 0.25469
Epoch [28/30] Validation [22/123] Loss: 0.62033  focal_loss 0.01251  dice_loss 0.60782
Epoch [28/30] Validation [23/123] Loss: 0.13463  focal_loss 0.00193  dice_loss 0.13270
Epoch [28/30] Validation [24/123] Loss: 0.22246  focal_loss 0.00338  dice_loss 0.21908
Epoch [28/30] Validation [25/123] Loss: 0.33500  focal_loss 0.00840  dice_loss 0.32660
Epoch [28/30] Validation [26/123] Loss: 0.14162  focal_loss 0.00172  dice_loss 0.13990
Epoch [28/30] Validation [27/123] Loss: 0.17671  focal_loss 0.00308  dice_loss 0.17363
Epoch [28/30] Validation [28/123] Loss: 0.49581  focal_loss 0.00783  dice_loss 0.48798
Epoch [28/30] Validation [29/123] Loss: 0.30162  focal_loss 0.00464  dice_loss 0.29698
Epoch [28/30] Validation [30/123] Loss: 0.17771  focal_loss 0.00309  dice_loss 0.17463
Epoch [28/30] Validation [31/123] Loss: 0.12731  focal_loss 0.00160  dice_loss 0.12571
Epoch [28/30] Validation [32/123] Loss: 0.23239  focal_loss 0.00420  dice_loss 0.22819
Epoch [28/30] Validation [33/123] Loss: 0.28246  focal_loss 0.00176  dice_loss 0.28070
Epoch [28/30] Validation [34/123] Loss: 0.22679  focal_loss 0.00142  dice_loss 0.22537
Epoch [28/30] Validation [35/123] Loss: 0.15917  focal_loss 0.00156  dice_loss 0.15760
Epoch [28/30] Validation [36/123] Loss: 0.18672  focal_loss 0.00111  dice_loss 0.18560
Epoch [28/30] Validation [37/123] Loss: 0.28920  focal_loss 0.00445  dice_loss 0.28474
Epoch [28/30] Validation [38/123] Loss: 0.13902  focal_loss 0.00144  dice_loss 0.13759
Epoch [28/30] Validation [39/123] Loss: 0.14154  focal_loss 0.00128  dice_loss 0.14025
Epoch [28/30] Validation [40/123] Loss: 0.23248  focal_loss 0.00090  dice_loss 0.23158
Epoch [28/30] Validation [41/123] Loss: 0.13687  focal_loss 0.00143  dice_loss 0.13544
Epoch [28/30] Validation [42/123] Loss: 0.12824  focal_loss 0.00154  dice_loss 0.12670
Epoch [28/30] Validation [43/123] Loss: 0.25244  focal_loss 0.03067  dice_loss 0.22177
Epoch [28/30] Validation [44/123] Loss: 0.58208  focal_loss 0.01620  dice_loss 0.56589
Epoch [28/30] Validation [45/123] Loss: 0.22448  focal_loss 0.00179  dice_loss 0.22269
Epoch [28/30] Validation [46/123] Loss: 0.26021  focal_loss 0.00264  dice_loss 0.25757
Epoch [28/30] Validation [47/123] Loss: 0.21215  focal_loss 0.00139  dice_loss 0.21076
Epoch [28/30] Validation [48/123] Loss: 0.36875  focal_loss 0.00580  dice_loss 0.36295
Epoch [28/30] Validation [49/123] Loss: 0.17972  focal_loss 0.01554  dice_loss 0.16417
Epoch [28/30] Validation [50/123] Loss: 0.15016  focal_loss 0.00221  dice_loss 0.14795
Epoch [28/30] Validation [51/123] Loss: 0.33244  focal_loss 0.01101  dice_loss 0.32143
Epoch [28/30] Validation [52/123] Loss: 0.15423  focal_loss 0.00080  dice_loss 0.15343
Epoch [28/30] Validation [53/123] Loss: 0.19745  focal_loss 0.00082  dice_loss 0.19663
Epoch [28/30] Validation [54/123] Loss: 0.26165  focal_loss 0.00155  dice_loss 0.26010
Epoch [28/30] Validation [55/123] Loss: 0.21400  focal_loss 0.00121  dice_loss 0.21279
Epoch [28/30] Validation [56/123] Loss: 0.16217  focal_loss 0.00410  dice_loss 0.15807
Epoch [28/30] Validation [57/123] Loss: 0.23627  focal_loss 0.01163  dice_loss 0.22464
Epoch [28/30] Validation [58/123] Loss: 0.18873  focal_loss 0.00186  dice_loss 0.18687
Epoch [28/30] Validation [59/123] Loss: 0.56481  focal_loss 0.00975  dice_loss 0.55506
Epoch [28/30] Validation [60/123] Loss: 0.18087  focal_loss 0.00305  dice_loss 0.17783
Epoch [28/30] Validation [61/123] Loss: 0.55181  focal_loss 0.00298  dice_loss 0.54883
Epoch [28/30] Validation [62/123] Loss: 0.47193  focal_loss 0.02253  dice_loss 0.44940
Epoch [28/30] Validation [63/123] Loss: 0.30015  focal_loss 0.00198  dice_loss 0.29817
Epoch [28/30] Validation [64/123] Loss: 0.35862  focal_loss 0.01415  dice_loss 0.34447
Epoch [28/30] Validation [65/123] Loss: 0.16363  focal_loss 0.00105  dice_loss 0.16258
Epoch [28/30] Validation [66/123] Loss: 0.16571  focal_loss 0.00143  dice_loss 0.16427
Epoch [28/30] Validation [67/123] Loss: 0.31532  focal_loss 0.00572  dice_loss 0.30961
Epoch [28/30] Validation [68/123] Loss: 0.28573  focal_loss 0.00108  dice_loss 0.28465
Epoch [28/30] Validation [69/123] Loss: 0.36752  focal_loss 0.00740  dice_loss 0.36012
Epoch [28/30] Validation [70/123] Loss: 0.27709  focal_loss 0.00248  dice_loss 0.27461
Epoch [28/30] Validation [71/123] Loss: 0.14445  focal_loss 0.00095  dice_loss 0.14349
Epoch [28/30] Validation [72/123] Loss: 0.14031  focal_loss 0.00165  dice_loss 0.13866
Epoch [28/30] Validation [73/123] Loss: 0.23596  focal_loss 0.00393  dice_loss 0.23203
Epoch [28/30] Validation [74/123] Loss: 0.22762  focal_loss 0.00215  dice_loss 0.22547
Epoch [28/30] Validation [75/123] Loss: 0.16672  focal_loss 0.00112  dice_loss 0.16560
Epoch [28/30] Validation [76/123] Loss: 0.45447  focal_loss 0.00646  dice_loss 0.44802
Epoch [28/30] Validation [77/123] Loss: 0.29848  focal_loss 0.00096  dice_loss 0.29753
Epoch [28/30] Validation [78/123] Loss: 0.19915  focal_loss 0.00141  dice_loss 0.19774
Epoch [28/30] Validation [79/123] Loss: 0.21906  focal_loss 0.00126  dice_loss 0.21779
Epoch [28/30] Validation [80/123] Loss: 0.15829  focal_loss 0.00246  dice_loss 0.15584
Epoch [28/30] Validation [81/123] Loss: 0.18345  focal_loss 0.00180  dice_loss 0.18165
Epoch [28/30] Validation [82/123] Loss: 0.14315  focal_loss 0.00107  dice_loss 0.14208
Epoch [28/30] Validation [83/123] Loss: 0.31940  focal_loss 0.01000  dice_loss 0.30940
Epoch [28/30] Validation [84/123] Loss: 0.18120  focal_loss 0.00128  dice_loss 0.17992
Epoch [28/30] Validation [85/123] Loss: 0.24531  focal_loss 0.00284  dice_loss 0.24247
Epoch [28/30] Validation [86/123] Loss: 0.15847  focal_loss 0.00116  dice_loss 0.15731
Epoch [28/30] Validation [87/123] Loss: 0.17226  focal_loss 0.00273  dice_loss 0.16953
Epoch [28/30] Validation [88/123] Loss: 0.17224  focal_loss 0.00200  dice_loss 0.17023
Epoch [28/30] Validation [89/123] Loss: 0.15260  focal_loss 0.00229  dice_loss 0.15031
Epoch [28/30] Validation [90/123] Loss: 0.20922  focal_loss 0.00183  dice_loss 0.20739
Epoch [28/30] Validation [91/123] Loss: 0.16385  focal_loss 0.00147  dice_loss 0.16238
Epoch [28/30] Validation [92/123] Loss: 0.13094  focal_loss 0.00118  dice_loss 0.12975
Epoch [28/30] Validation [93/123] Loss: 0.14134  focal_loss 0.00191  dice_loss 0.13943
Epoch [28/30] Validation [94/123] Loss: 0.27675  focal_loss 0.00177  dice_loss 0.27497
Epoch [28/30] Validation [95/123] Loss: 0.19342  focal_loss 0.00271  dice_loss 0.19071
Epoch [28/30] Validation [96/123] Loss: 0.24718  focal_loss 0.00200  dice_loss 0.24518
Epoch [28/30] Validation [97/123] Loss: 0.56634  focal_loss 0.00807  dice_loss 0.55828
Epoch [28/30] Validation [98/123] Loss: 0.23741  focal_loss 0.00096  dice_loss 0.23645
Epoch [28/30] Validation [99/123] Loss: 0.22381  focal_loss 0.00068  dice_loss 0.22313
Epoch [28/30] Validation [100/123] Loss: 0.26076  focal_loss 0.00121  dice_loss 0.25955
Epoch [28/30] Validation [101/123] Loss: 0.22192  focal_loss 0.00112  dice_loss 0.22080
Epoch [28/30] Validation [102/123] Loss: 0.25923  focal_loss 0.00075  dice_loss 0.25848
Epoch [28/30] Validation [103/123] Loss: 0.41141  focal_loss 0.00095  dice_loss 0.41045
Epoch [28/30] Validation [104/123] Loss: 0.35845  focal_loss 0.00633  dice_loss 0.35212
Epoch [28/30] Validation [105/123] Loss: 0.15747  focal_loss 0.00328  dice_loss 0.15419
Epoch [28/30] Validation [106/123] Loss: 0.14839  focal_loss 0.00092  dice_loss 0.14747
Epoch [28/30] Validation [107/123] Loss: 0.45956  focal_loss 0.00264  dice_loss 0.45692
Epoch [28/30] Validation [108/123] Loss: 0.15775  focal_loss 0.00084  dice_loss 0.15691
Epoch [28/30] Validation [109/123] Loss: 0.17037  focal_loss 0.00525  dice_loss 0.16512
Epoch [28/30] Validation [110/123] Loss: 0.28336  focal_loss 0.00305  dice_loss 0.28030
Epoch [28/30] Validation [111/123] Loss: 0.30668  focal_loss 0.00376  dice_loss 0.30292
Epoch [28/30] Validation [112/123] Loss: 0.23193  focal_loss 0.00081  dice_loss 0.23112
Epoch [28/30] Validation [113/123] Loss: 0.19441  focal_loss 0.00180  dice_loss 0.19261
Epoch [28/30] Validation [114/123] Loss: 0.28417  focal_loss 0.00591  dice_loss 0.27826
Epoch [28/30] Validation [115/123] Loss: 0.23294  focal_loss 0.00617  dice_loss 0.22677
Epoch [28/30] Validation [116/123] Loss: 0.17572  focal_loss 0.00051  dice_loss 0.17521
Epoch [28/30] Validation [117/123] Loss: 0.19673  focal_loss 0.00112  dice_loss 0.19560
Epoch [28/30] Validation [118/123] Loss: 0.12528  focal_loss 0.00198  dice_loss 0.12330
Epoch [28/30] Validation [119/123] Loss: 0.14401  focal_loss 0.00152  dice_loss 0.14248
Epoch [28/30] Validation [120/123] Loss: 0.17505  focal_loss 0.00183  dice_loss 0.17322
Epoch [28/30] Validation [121/123] Loss: 0.61716  focal_loss 0.02186  dice_loss 0.59530
Epoch [28/30] Validation [122/123] Loss: 0.48187  focal_loss 0.00068  dice_loss 0.48120
Epoch [28/30] Validation [123/123] Loss: 0.17434  focal_loss 0.00169  dice_loss 0.17265
Epoch [28/30] Validation metric {'Val/mean dice_metric': 0.9053703546524048, 'Val/TC dice_metric': 0.9214415550231934, 'Val/WT dice_metric': 0.9404745697975159, 'Val/ET dice_metric': 0.8541948795318604}
Epoch [28/30] lr = [3.5111757055874326e-05, 3.5111757055874326e-05] best acc: tensor([0.9040], device='cuda:0'), mean acc: tensor([0.9054], device='cuda:0'), mean class: tensor([0.9214, 0.9405, 0.8542], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [29/30] Training [1/488] Loss: 0.17740
Epoch [29/30] Training [2/488] Loss: 0.11933
Epoch [29/30] Training [3/488] Loss: 0.21760
Epoch [29/30] Training [4/488] Loss: 0.11881
Epoch [29/30] Training [5/488] Loss: 0.38466
Epoch [29/30] Training [6/488] Loss: 0.15562
Epoch [29/30] Training [7/488] Loss: 0.10162
Epoch [29/30] Training [8/488] Loss: 0.11050
Epoch [29/30] Training [9/488] Loss: 0.12763
Epoch [29/30] Training [10/488] Loss: 0.23124
Epoch [29/30] Training [11/488] Loss: 0.10784
Epoch [29/30] Training [12/488] Loss: 0.08571
Epoch [29/30] Training [13/488] Loss: 0.14536
Epoch [29/30] Training [14/488] Loss: 0.40804
Epoch [29/30] Training [15/488] Loss: 0.17027
Epoch [29/30] Training [16/488] Loss: 0.44448
Epoch [29/30] Training [17/488] Loss: 0.54483
Epoch [29/30] Training [18/488] Loss: 0.18577
Epoch [29/30] Training [19/488] Loss: 0.10868
Epoch [29/30] Training [20/488] Loss: 0.22109
Epoch [29/30] Training [21/488] Loss: 0.08884
Epoch [29/30] Training [22/488] Loss: 0.15287
Epoch [29/30] Training [23/488] Loss: 0.10246
Epoch [29/30] Training [24/488] Loss: 0.08605
Epoch [29/30] Training [25/488] Loss: 0.10419
Epoch [29/30] Training [26/488] Loss: 0.11100
Epoch [29/30] Training [27/488] Loss: 0.12454
Epoch [29/30] Training [28/488] Loss: 0.21827
Epoch [29/30] Training [29/488] Loss: 0.22656
Epoch [29/30] Training [30/488] Loss: 0.12394
Epoch [29/30] Training [31/488] Loss: 0.11685
Epoch [29/30] Training [32/488] Loss: 0.22107
Epoch [29/30] Training [33/488] Loss: 0.11294
Epoch [29/30] Training [34/488] Loss: 0.19415
Epoch [29/30] Training [35/488] Loss: 0.11538
Epoch [29/30] Training [36/488] Loss: 0.16545
Epoch [29/30] Training [37/488] Loss: 0.15070
Epoch [29/30] Training [38/488] Loss: 0.09366
Epoch [29/30] Training [39/488] Loss: 0.09840
Epoch [29/30] Training [40/488] Loss: 0.19859
Epoch [29/30] Training [41/488] Loss: 0.09638
Epoch [29/30] Training [42/488] Loss: 0.11146
Epoch [29/30] Training [43/488] Loss: 0.15779
Epoch [29/30] Training [44/488] Loss: 0.12209
Epoch [29/30] Training [45/488] Loss: 0.14732
Epoch [29/30] Training [46/488] Loss: 0.24244
Epoch [29/30] Training [47/488] Loss: 0.13254
Epoch [29/30] Training [48/488] Loss: 0.09531
Epoch [29/30] Training [49/488] Loss: 0.11245
Epoch [29/30] Training [50/488] Loss: 0.21158
Epoch [29/30] Training [51/488] Loss: 0.08172
Epoch [29/30] Training [52/488] Loss: 0.11107
Epoch [29/30] Training [53/488] Loss: 0.08592
Epoch [29/30] Training [54/488] Loss: 0.15179
Epoch [29/30] Training [55/488] Loss: 0.10439
Epoch [29/30] Training [56/488] Loss: 0.07605
Epoch [29/30] Training [57/488] Loss: 0.28540
Epoch [29/30] Training [58/488] Loss: 0.59573
Epoch [29/30] Training [59/488] Loss: 0.09738
Epoch [29/30] Training [60/488] Loss: 0.18790
Epoch [29/30] Training [61/488] Loss: 0.16535
Epoch [29/30] Training [62/488] Loss: 0.12487
Epoch [29/30] Training [63/488] Loss: 0.14683
Epoch [29/30] Training [64/488] Loss: 0.14643
Epoch [29/30] Training [65/488] Loss: 0.07520
Epoch [29/30] Training [66/488] Loss: 0.21673
Epoch [29/30] Training [67/488] Loss: 0.14018
Epoch [29/30] Training [68/488] Loss: 0.06764
Epoch [29/30] Training [69/488] Loss: 0.25141
Epoch [29/30] Training [70/488] Loss: 0.18763
Epoch [29/30] Training [71/488] Loss: 0.08261
Epoch [29/30] Training [72/488] Loss: 0.09605
Epoch [29/30] Training [73/488] Loss: 0.12033
Epoch [29/30] Training [74/488] Loss: 0.07902
Epoch [29/30] Training [75/488] Loss: 0.14309
Epoch [29/30] Training [76/488] Loss: 0.10508
Epoch [29/30] Training [77/488] Loss: 0.21537
Epoch [29/30] Training [78/488] Loss: 0.10137
Epoch [29/30] Training [79/488] Loss: 0.09357
Epoch [29/30] Training [80/488] Loss: 0.12501
Epoch [29/30] Training [81/488] Loss: 0.13754
Epoch [29/30] Training [82/488] Loss: 0.29044
Epoch [29/30] Training [83/488] Loss: 0.09181
Epoch [29/30] Training [84/488] Loss: 0.09080
Epoch [29/30] Training [85/488] Loss: 0.08431
Epoch [29/30] Training [86/488] Loss: 0.15896
Epoch [29/30] Training [87/488] Loss: 0.09368
Epoch [29/30] Training [88/488] Loss: 0.12236
Epoch [29/30] Training [89/488] Loss: 0.13798
Epoch [29/30] Training [90/488] Loss: 0.11079
Epoch [29/30] Training [91/488] Loss: 0.11940
Epoch [29/30] Training [92/488] Loss: 0.09470
Epoch [29/30] Training [93/488] Loss: 0.09648
Epoch [29/30] Training [94/488] Loss: 0.31899
Epoch [29/30] Training [95/488] Loss: 0.07092
Epoch [29/30] Training [96/488] Loss: 0.13042
Epoch [29/30] Training [97/488] Loss: 0.09861
Epoch [29/30] Training [98/488] Loss: 0.13183
Epoch [29/30] Training [99/488] Loss: 0.21029
Epoch [29/30] Training [100/488] Loss: 0.15852
Epoch [29/30] Training [101/488] Loss: 0.36671
Epoch [29/30] Training [102/488] Loss: 0.10094
Epoch [29/30] Training [103/488] Loss: 0.10948
Epoch [29/30] Training [104/488] Loss: 0.29275
Epoch [29/30] Training [105/488] Loss: 0.13575
Epoch [29/30] Training [106/488] Loss: 0.07329
Epoch [29/30] Training [107/488] Loss: 0.08665
Epoch [29/30] Training [108/488] Loss: 0.17373
Epoch [29/30] Training [109/488] Loss: 0.09402
Epoch [29/30] Training [110/488] Loss: 0.16344
Epoch [29/30] Training [111/488] Loss: 0.70262
Epoch [29/30] Training [112/488] Loss: 0.12812
Epoch [29/30] Training [113/488] Loss: 0.26068
Epoch [29/30] Training [114/488] Loss: 0.19429
Epoch [29/30] Training [115/488] Loss: 0.09130
Epoch [29/30] Training [116/488] Loss: 0.08712
Epoch [29/30] Training [117/488] Loss: 0.13470
Epoch [29/30] Training [118/488] Loss: 0.16509
Epoch [29/30] Training [119/488] Loss: 0.18731
Epoch [29/30] Training [120/488] Loss: 0.28622
Epoch [29/30] Training [121/488] Loss: 0.09040
Epoch [29/30] Training [122/488] Loss: 0.10826
Epoch [29/30] Training [123/488] Loss: 0.09069
Epoch [29/30] Training [124/488] Loss: 0.24184
Epoch [29/30] Training [125/488] Loss: 0.12257
Epoch [29/30] Training [126/488] Loss: 0.32579
Epoch [29/30] Training [127/488] Loss: 0.10060
Epoch [29/30] Training [128/488] Loss: 0.12903
Epoch [29/30] Training [129/488] Loss: 0.13345
Epoch [29/30] Training [130/488] Loss: 0.11068
Epoch [29/30] Training [131/488] Loss: 0.13464
Epoch [29/30] Training [132/488] Loss: 0.12208
Epoch [29/30] Training [133/488] Loss: 0.13112
Epoch [29/30] Training [134/488] Loss: 0.11246
Epoch [29/30] Training [135/488] Loss: 0.13703
Epoch [29/30] Training [136/488] Loss: 0.13890
Epoch [29/30] Training [137/488] Loss: 0.09882
Epoch [29/30] Training [138/488] Loss: 0.26485
Epoch [29/30] Training [139/488] Loss: 0.17490
Epoch [29/30] Training [140/488] Loss: 0.13651
Epoch [29/30] Training [141/488] Loss: 0.17464
Epoch [29/30] Training [142/488] Loss: 0.12421
Epoch [29/30] Training [143/488] Loss: 0.08986
Epoch [29/30] Training [144/488] Loss: 0.08488
Epoch [29/30] Training [145/488] Loss: 0.09310
Epoch [29/30] Training [146/488] Loss: 0.32615
Epoch [29/30] Training [147/488] Loss: 0.29359
Epoch [29/30] Training [148/488] Loss: 0.15231
Epoch [29/30] Training [149/488] Loss: 0.34333
Epoch [29/30] Training [150/488] Loss: 0.09506
Epoch [29/30] Training [151/488] Loss: 0.08195
Epoch [29/30] Training [152/488] Loss: 0.08913
Epoch [29/30] Training [153/488] Loss: 0.11120
Epoch [29/30] Training [154/488] Loss: 0.21424
Epoch [29/30] Training [155/488] Loss: 0.21657
Epoch [29/30] Training [156/488] Loss: 0.10273
Epoch [29/30] Training [157/488] Loss: 0.11444
Epoch [29/30] Training [158/488] Loss: 0.09127
Epoch [29/30] Training [159/488] Loss: 0.18407
Epoch [29/30] Training [160/488] Loss: 0.08975
Epoch [29/30] Training [161/488] Loss: 0.14257
Epoch [29/30] Training [162/488] Loss: 0.28549
Epoch [29/30] Training [163/488] Loss: 0.13240
Epoch [29/30] Training [164/488] Loss: 0.20005
Epoch [29/30] Training [165/488] Loss: 0.22182
Epoch [29/30] Training [166/488] Loss: 0.12629
Epoch [29/30] Training [167/488] Loss: 0.06631
Epoch [29/30] Training [168/488] Loss: 0.16359
Epoch [29/30] Training [169/488] Loss: 0.14425
Epoch [29/30] Training [170/488] Loss: 0.11898
Epoch [29/30] Training [171/488] Loss: 0.21074
Epoch [29/30] Training [172/488] Loss: 0.15528
Epoch [29/30] Training [173/488] Loss: 0.11641
Epoch [29/30] Training [174/488] Loss: 0.08016
Epoch [29/30] Training [175/488] Loss: 0.14599
Epoch [29/30] Training [176/488] Loss: 0.13532
Epoch [29/30] Training [177/488] Loss: 0.09908
Epoch [29/30] Training [178/488] Loss: 0.09752
Epoch [29/30] Training [179/488] Loss: 0.13306
Epoch [29/30] Training [180/488] Loss: 0.12133
Epoch [29/30] Training [181/488] Loss: 0.13375
Epoch [29/30] Training [182/488] Loss: 0.10722
Epoch [29/30] Training [183/488] Loss: 0.09136
Epoch [29/30] Training [184/488] Loss: 0.12817
Epoch [29/30] Training [185/488] Loss: 0.09051
Epoch [29/30] Training [186/488] Loss: 0.15657
Epoch [29/30] Training [187/488] Loss: 0.11215
Epoch [29/30] Training [188/488] Loss: 0.71292
Epoch [29/30] Training [189/488] Loss: 0.45270
Epoch [29/30] Training [190/488] Loss: 0.09187
Epoch [29/30] Training [191/488] Loss: 0.14753
Epoch [29/30] Training [192/488] Loss: 0.10496
Epoch [29/30] Training [193/488] Loss: 0.14014
Epoch [29/30] Training [194/488] Loss: 0.17382
Epoch [29/30] Training [195/488] Loss: 0.08594
Epoch [29/30] Training [196/488] Loss: 0.28326
Epoch [29/30] Training [197/488] Loss: 0.08759
Epoch [29/30] Training [198/488] Loss: 0.11325
Epoch [29/30] Training [199/488] Loss: 0.09755
Epoch [29/30] Training [200/488] Loss: 0.08280
Epoch [29/30] Training [201/488] Loss: 0.10927
Epoch [29/30] Training [202/488] Loss: 0.13469
Epoch [29/30] Training [203/488] Loss: 0.12353
Epoch [29/30] Training [204/488] Loss: 0.18153
Epoch [29/30] Training [205/488] Loss: 0.07002
Epoch [29/30] Training [206/488] Loss: 0.34715
Epoch [29/30] Training [207/488] Loss: 0.19629
Epoch [29/30] Training [208/488] Loss: 0.14853
Epoch [29/30] Training [209/488] Loss: 0.13346
Epoch [29/30] Training [210/488] Loss: 0.16126
Epoch [29/30] Training [211/488] Loss: 0.13762
Epoch [29/30] Training [212/488] Loss: 0.11081
Epoch [29/30] Training [213/488] Loss: 0.10943
Epoch [29/30] Training [214/488] Loss: 0.13480
Epoch [29/30] Training [215/488] Loss: 0.10074
Epoch [29/30] Training [216/488] Loss: 0.14876
Epoch [29/30] Training [217/488] Loss: 0.14992
Epoch [29/30] Training [218/488] Loss: 0.20963
Epoch [29/30] Training [219/488] Loss: 0.09830
Epoch [29/30] Training [220/488] Loss: 0.19811
Epoch [29/30] Training [221/488] Loss: 0.25899
Epoch [29/30] Training [222/488] Loss: 0.40662
Epoch [29/30] Training [223/488] Loss: 0.11885
Epoch [29/30] Training [224/488] Loss: 0.47811
Epoch [29/30] Training [225/488] Loss: 0.52280
Epoch [29/30] Training [226/488] Loss: 0.15248
Epoch [29/30] Training [227/488] Loss: 0.08349
Epoch [29/30] Training [228/488] Loss: 0.17818
Epoch [29/30] Training [229/488] Loss: 0.14077
Epoch [29/30] Training [230/488] Loss: 0.09132
Epoch [29/30] Training [231/488] Loss: 0.07363
Epoch [29/30] Training [232/488] Loss: 0.19783
Epoch [29/30] Training [233/488] Loss: 0.40641
Epoch [29/30] Training [234/488] Loss: 0.21962
Epoch [29/30] Training [235/488] Loss: 0.58271
Epoch [29/30] Training [236/488] Loss: 0.16554
Epoch [29/30] Training [237/488] Loss: 0.09927
Epoch [29/30] Training [238/488] Loss: 0.10597
Epoch [29/30] Training [239/488] Loss: 0.10321
Epoch [29/30] Training [240/488] Loss: 0.32409
Epoch [29/30] Training [241/488] Loss: 0.10961
Epoch [29/30] Training [242/488] Loss: 0.08594
Epoch [29/30] Training [243/488] Loss: 0.46569
Epoch [29/30] Training [244/488] Loss: 0.21609
Epoch [29/30] Training [245/488] Loss: 0.10038
Epoch [29/30] Training [246/488] Loss: 0.12716
Epoch [29/30] Training [247/488] Loss: 0.10313
Epoch [29/30] Training [248/488] Loss: 0.08775
Epoch [29/30] Training [249/488] Loss: 0.29809
Epoch [29/30] Training [250/488] Loss: 0.15742
Epoch [29/30] Training [251/488] Loss: 0.14052
Epoch [29/30] Training [252/488] Loss: 0.17917
Epoch [29/30] Training [253/488] Loss: 0.15801
Epoch [29/30] Training [254/488] Loss: 0.10340
Epoch [29/30] Training [255/488] Loss: 0.09671
Epoch [29/30] Training [256/488] Loss: 0.11014
Epoch [29/30] Training [257/488] Loss: 0.32672
Epoch [29/30] Training [258/488] Loss: 0.13588
Epoch [29/30] Training [259/488] Loss: 0.20634
Epoch [29/30] Training [260/488] Loss: 0.08409
Epoch [29/30] Training [261/488] Loss: 0.10336
Epoch [29/30] Training [262/488] Loss: 0.12504
Epoch [29/30] Training [263/488] Loss: 0.21010
Epoch [29/30] Training [264/488] Loss: 0.11090
Epoch [29/30] Training [265/488] Loss: 0.10647
Epoch [29/30] Training [266/488] Loss: 0.09294
Epoch [29/30] Training [267/488] Loss: 0.09398
Epoch [29/30] Training [268/488] Loss: 0.19796
Epoch [29/30] Training [269/488] Loss: 0.13771
Epoch [29/30] Training [270/488] Loss: 0.06785
Epoch [29/30] Training [271/488] Loss: 0.12959
Epoch [29/30] Training [272/488] Loss: 0.10257
Epoch [29/30] Training [273/488] Loss: 0.08547
Epoch [29/30] Training [274/488] Loss: 0.09308
Epoch [29/30] Training [275/488] Loss: 0.28291
Epoch [29/30] Training [276/488] Loss: 0.11255
Epoch [29/30] Training [277/488] Loss: 0.08666
Epoch [29/30] Training [278/488] Loss: 0.07192
Epoch [29/30] Training [279/488] Loss: 0.40545
Epoch [29/30] Training [280/488] Loss: 0.09298
Epoch [29/30] Training [281/488] Loss: 0.11565
Epoch [29/30] Training [282/488] Loss: 0.11115
Epoch [29/30] Training [283/488] Loss: 0.10434
Epoch [29/30] Training [284/488] Loss: 0.28404
Epoch [29/30] Training [285/488] Loss: 0.13443
Epoch [29/30] Training [286/488] Loss: 0.19025
Epoch [29/30] Training [287/488] Loss: 0.08476
Epoch [29/30] Training [288/488] Loss: 0.11410
Epoch [29/30] Training [289/488] Loss: 0.13967
Epoch [29/30] Training [290/488] Loss: 0.13732
Epoch [29/30] Training [291/488] Loss: 0.08937
Epoch [29/30] Training [292/488] Loss: 0.32315
Epoch [29/30] Training [293/488] Loss: 0.10229
Epoch [29/30] Training [294/488] Loss: 0.11604
Epoch [29/30] Training [295/488] Loss: 0.10906
Epoch [29/30] Training [296/488] Loss: 0.15662
Epoch [29/30] Training [297/488] Loss: 0.12989
Epoch [29/30] Training [298/488] Loss: 0.11718
Epoch [29/30] Training [299/488] Loss: 0.12608
Epoch [29/30] Training [300/488] Loss: 0.29722
Epoch [29/30] Training [301/488] Loss: 0.25430
Epoch [29/30] Training [302/488] Loss: 0.08952
Epoch [29/30] Training [303/488] Loss: 0.15798
Epoch [29/30] Training [304/488] Loss: 0.12824
Epoch [29/30] Training [305/488] Loss: 0.19961
Epoch [29/30] Training [306/488] Loss: 0.16612
Epoch [29/30] Training [307/488] Loss: 0.10278
Epoch [29/30] Training [308/488] Loss: 0.11829
Epoch [29/30] Training [309/488] Loss: 0.11265
Epoch [29/30] Training [310/488] Loss: 0.13565
Epoch [29/30] Training [311/488] Loss: 0.07899
Epoch [29/30] Training [312/488] Loss: 0.09161
Epoch [29/30] Training [313/488] Loss: 0.11806
Epoch [29/30] Training [314/488] Loss: 0.10923
Epoch [29/30] Training [315/488] Loss: 0.11303
Epoch [29/30] Training [316/488] Loss: 0.09149
Epoch [29/30] Training [317/488] Loss: 0.11904
Epoch [29/30] Training [318/488] Loss: 0.12219
Epoch [29/30] Training [319/488] Loss: 0.08061
Epoch [29/30] Training [320/488] Loss: 0.12692
Epoch [29/30] Training [321/488] Loss: 0.10033
Epoch [29/30] Training [322/488] Loss: 0.09857
Epoch [29/30] Training [323/488] Loss: 0.09269
Epoch [29/30] Training [324/488] Loss: 0.32752
Epoch [29/30] Training [325/488] Loss: 0.14419
Epoch [29/30] Training [326/488] Loss: 0.11036
Epoch [29/30] Training [327/488] Loss: 0.18457
Epoch [29/30] Training [328/488] Loss: 0.15453
Epoch [29/30] Training [329/488] Loss: 0.30876
Epoch [29/30] Training [330/488] Loss: 0.12586
Epoch [29/30] Training [331/488] Loss: 0.10441
Epoch [29/30] Training [332/488] Loss: 0.09794
Epoch [29/30] Training [333/488] Loss: 0.38369
Epoch [29/30] Training [334/488] Loss: 0.12630
Epoch [29/30] Training [335/488] Loss: 0.33358
Epoch [29/30] Training [336/488] Loss: 0.08544
Epoch [29/30] Training [337/488] Loss: 0.10850
Epoch [29/30] Training [338/488] Loss: 0.44221
Epoch [29/30] Training [339/488] Loss: 0.15055
Epoch [29/30] Training [340/488] Loss: 0.08757
Epoch [29/30] Training [341/488] Loss: 0.10350
Epoch [29/30] Training [342/488] Loss: 0.10037
Epoch [29/30] Training [343/488] Loss: 0.22733
Epoch [29/30] Training [344/488] Loss: 0.09965
Epoch [29/30] Training [345/488] Loss: 0.13993
Epoch [29/30] Training [346/488] Loss: 0.24978
Epoch [29/30] Training [347/488] Loss: 0.21562
Epoch [29/30] Training [348/488] Loss: 0.22389
Epoch [29/30] Training [349/488] Loss: 0.10555
Epoch [29/30] Training [350/488] Loss: 0.10567
Epoch [29/30] Training [351/488] Loss: 0.10568
Epoch [29/30] Training [352/488] Loss: 0.11748
Epoch [29/30] Training [353/488] Loss: 0.20433
Epoch [29/30] Training [354/488] Loss: 0.08019
Epoch [29/30] Training [355/488] Loss: 0.12405
Epoch [29/30] Training [356/488] Loss: 0.24002
Epoch [29/30] Training [357/488] Loss: 0.13101
Epoch [29/30] Training [358/488] Loss: 0.10192
Epoch [29/30] Training [359/488] Loss: 0.09853
Epoch [29/30] Training [360/488] Loss: 0.13408
Epoch [29/30] Training [361/488] Loss: 0.33967
Epoch [29/30] Training [362/488] Loss: 0.09022
Epoch [29/30] Training [363/488] Loss: 0.12219
Epoch [29/30] Training [364/488] Loss: 0.09899
Epoch [29/30] Training [365/488] Loss: 0.70783
Epoch [29/30] Training [366/488] Loss: 0.16318
Epoch [29/30] Training [367/488] Loss: 0.23514
Epoch [29/30] Training [368/488] Loss: 0.51879
Epoch [29/30] Training [369/488] Loss: 0.21883
Epoch [29/30] Training [370/488] Loss: 0.31161
Epoch [29/30] Training [371/488] Loss: 0.13272
Epoch [29/30] Training [372/488] Loss: 0.10379
Epoch [29/30] Training [373/488] Loss: 0.09688
Epoch [29/30] Training [374/488] Loss: 0.13683
Epoch [29/30] Training [375/488] Loss: 0.15276
Epoch [29/30] Training [376/488] Loss: 0.21913
Epoch [29/30] Training [377/488] Loss: 0.15220
Epoch [29/30] Training [378/488] Loss: 0.12231
Epoch [29/30] Training [379/488] Loss: 0.55227
Epoch [29/30] Training [380/488] Loss: 0.15651
Epoch [29/30] Training [381/488] Loss: 0.15152
Epoch [29/30] Training [382/488] Loss: 0.08146
Epoch [29/30] Training [383/488] Loss: 0.13882
Epoch [29/30] Training [384/488] Loss: 0.12895
Epoch [29/30] Training [385/488] Loss: 0.08385
Epoch [29/30] Training [386/488] Loss: 0.12899
Epoch [29/30] Training [387/488] Loss: 0.11503
Epoch [29/30] Training [388/488] Loss: 0.12489
Epoch [29/30] Training [389/488] Loss: 0.08056
Epoch [29/30] Training [390/488] Loss: 0.22253
Epoch [29/30] Training [391/488] Loss: 0.22522
Epoch [29/30] Training [392/488] Loss: 0.17593
Epoch [29/30] Training [393/488] Loss: 0.09894
Epoch [29/30] Training [394/488] Loss: 0.24250
Epoch [29/30] Training [395/488] Loss: 0.10265
Epoch [29/30] Training [396/488] Loss: 0.10564
Epoch [29/30] Training [397/488] Loss: 0.09661
Epoch [29/30] Training [398/488] Loss: 0.09498
Epoch [29/30] Training [399/488] Loss: 0.14585
Epoch [29/30] Training [400/488] Loss: 0.10999
Epoch [29/30] Training [401/488] Loss: 0.14786
Epoch [29/30] Training [402/488] Loss: 0.15094
Epoch [29/30] Training [403/488] Loss: 0.07997
Epoch [29/30] Training [404/488] Loss: 0.12346
Epoch [29/30] Training [405/488] Loss: 0.07523
Epoch [29/30] Training [406/488] Loss: 0.34563
Epoch [29/30] Training [407/488] Loss: 0.08192
Epoch [29/30] Training [408/488] Loss: 0.13278
Epoch [29/30] Training [409/488] Loss: 0.26915
Epoch [29/30] Training [410/488] Loss: 0.10225
Epoch [29/30] Training [411/488] Loss: 0.14791
Epoch [29/30] Training [412/488] Loss: 0.08819
Epoch [29/30] Training [413/488] Loss: 0.11324
Epoch [29/30] Training [414/488] Loss: 0.09633
Epoch [29/30] Training [415/488] Loss: 0.11049
Epoch [29/30] Training [416/488] Loss: 0.11455
Epoch [29/30] Training [417/488] Loss: 0.08005
Epoch [29/30] Training [418/488] Loss: 0.13153
Epoch [29/30] Training [419/488] Loss: 0.08915
Epoch [29/30] Training [420/488] Loss: 0.13471
Epoch [29/30] Training [421/488] Loss: 0.12268
Epoch [29/30] Training [422/488] Loss: 0.08995
Epoch [29/30] Training [423/488] Loss: 0.09193
Epoch [29/30] Training [424/488] Loss: 0.08148
Epoch [29/30] Training [425/488] Loss: 0.08953
Epoch [29/30] Training [426/488] Loss: 0.14460
Epoch [29/30] Training [427/488] Loss: 0.08992
Epoch [29/30] Training [428/488] Loss: 0.15820
Epoch [29/30] Training [429/488] Loss: 0.16665
Epoch [29/30] Training [430/488] Loss: 0.23857
Epoch [29/30] Training [431/488] Loss: 0.16752
Epoch [29/30] Training [432/488] Loss: 0.22471
Epoch [29/30] Training [433/488] Loss: 0.10566
Epoch [29/30] Training [434/488] Loss: 0.11858
Epoch [29/30] Training [435/488] Loss: 0.15101
Epoch [29/30] Training [436/488] Loss: 0.10209
Epoch [29/30] Training [437/488] Loss: 0.08924
Epoch [29/30] Training [438/488] Loss: 0.09895
Epoch [29/30] Training [439/488] Loss: 0.08833
Epoch [29/30] Training [440/488] Loss: 0.15081
Epoch [29/30] Training [441/488] Loss: 0.40213
Epoch [29/30] Training [442/488] Loss: 0.13635
Epoch [29/30] Training [443/488] Loss: 0.12534
Epoch [29/30] Training [444/488] Loss: 0.12023
Epoch [29/30] Training [445/488] Loss: 0.08183
Epoch [29/30] Training [446/488] Loss: 0.08490
Epoch [29/30] Training [447/488] Loss: 0.10042
Epoch [29/30] Training [448/488] Loss: 0.14298
Epoch [29/30] Training [449/488] Loss: 0.12530
Epoch [29/30] Training [450/488] Loss: 0.08482
Epoch [29/30] Training [451/488] Loss: 0.09171
Epoch [29/30] Training [452/488] Loss: 0.44758
Epoch [29/30] Training [453/488] Loss: 0.10502
Epoch [29/30] Training [454/488] Loss: 0.10519
Epoch [29/30] Training [455/488] Loss: 0.17917
Epoch [29/30] Training [456/488] Loss: 0.09483
Epoch [29/30] Training [457/488] Loss: 0.14203
Epoch [29/30] Training [458/488] Loss: 0.16477
Epoch [29/30] Training [459/488] Loss: 0.12551
Epoch [29/30] Training [460/488] Loss: 0.34656
Epoch [29/30] Training [461/488] Loss: 0.22585
Epoch [29/30] Training [462/488] Loss: 0.32510
Epoch [29/30] Training [463/488] Loss: 0.22171
Epoch [29/30] Training [464/488] Loss: 0.14308
Epoch [29/30] Training [465/488] Loss: 0.16558
Epoch [29/30] Training [466/488] Loss: 0.17174
Epoch [29/30] Training [467/488] Loss: 0.25356
Epoch [29/30] Training [468/488] Loss: 0.10958
Epoch [29/30] Training [469/488] Loss: 0.17981
Epoch [29/30] Training [470/488] Loss: 0.13035
Epoch [29/30] Training [471/488] Loss: 0.14213
Epoch [29/30] Training [472/488] Loss: 0.28161
Epoch [29/30] Training [473/488] Loss: 0.11852
Epoch [29/30] Training [474/488] Loss: 0.46175
Epoch [29/30] Training [475/488] Loss: 0.11238
Epoch [29/30] Training [476/488] Loss: 0.31938
Epoch [29/30] Training [477/488] Loss: 0.09589
Epoch [29/30] Training [478/488] Loss: 0.18197
Epoch [29/30] Training [479/488] Loss: 0.09610
Epoch [29/30] Training [480/488] Loss: 0.11441
Epoch [29/30] Training [481/488] Loss: 0.11159
Epoch [29/30] Training [482/488] Loss: 0.10919
Epoch [29/30] Training [483/488] Loss: 0.07818
Epoch [29/30] Training [484/488] Loss: 0.14970
Epoch [29/30] Training [485/488] Loss: 0.15897
Epoch [29/30] Training [486/488] Loss: 0.11749
Epoch [29/30] Training [487/488] Loss: 0.19644
Epoch [29/30] Training [488/488] Loss: 0.08645
Epoch [29/30] Training metric {'Train/mean dice_metric': 0.9092428684234619, 'Train/TC dice_metric': 0.9269794225692749, 'Train/WT dice_metric': 0.943922221660614, 'Train/ET dice_metric': 0.8568270206451416}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [29/30] Validation [1/123] Loss: 0.14370  focal_loss 0.00194  dice_loss 0.14176
Epoch [29/30] Validation [2/123] Loss: 0.30263  focal_loss 0.00134  dice_loss 0.30128
Epoch [29/30] Validation [3/123] Loss: 0.12178  focal_loss 0.00162  dice_loss 0.12016
Epoch [29/30] Validation [4/123] Loss: 0.18379  focal_loss 0.00124  dice_loss 0.18254
Epoch [29/30] Validation [5/123] Loss: 0.28026  focal_loss 0.00985  dice_loss 0.27041
Epoch [29/30] Validation [6/123] Loss: 0.25746  focal_loss 0.00190  dice_loss 0.25556
Epoch [29/30] Validation [7/123] Loss: 0.27750  focal_loss 0.00068  dice_loss 0.27683
Epoch [29/30] Validation [8/123] Loss: 0.30236  focal_loss 0.00161  dice_loss 0.30075
Epoch [29/30] Validation [9/123] Loss: 0.20016  focal_loss 0.00151  dice_loss 0.19865
Epoch [29/30] Validation [10/123] Loss: 0.39578  focal_loss 0.00267  dice_loss 0.39311
Epoch [29/30] Validation [11/123] Loss: 0.48570  focal_loss 0.00284  dice_loss 0.48286
Epoch [29/30] Validation [12/123] Loss: 0.14548  focal_loss 0.00165  dice_loss 0.14383
Epoch [29/30] Validation [13/123] Loss: 0.15519  focal_loss 0.00375  dice_loss 0.15144
Epoch [29/30] Validation [14/123] Loss: 0.14495  focal_loss 0.00082  dice_loss 0.14413
Epoch [29/30] Validation [15/123] Loss: 0.27985  focal_loss 0.00135  dice_loss 0.27849
Epoch [29/30] Validation [16/123] Loss: 0.44789  focal_loss 0.00238  dice_loss 0.44550
Epoch [29/30] Validation [17/123] Loss: 0.41404  focal_loss 0.00215  dice_loss 0.41189
Epoch [29/30] Validation [18/123] Loss: 0.28175  focal_loss 0.00302  dice_loss 0.27873
Epoch [29/30] Validation [19/123] Loss: 0.25338  focal_loss 0.01407  dice_loss 0.23932
Epoch [29/30] Validation [20/123] Loss: 0.37760  focal_loss 0.00096  dice_loss 0.37664
Epoch [29/30] Validation [21/123] Loss: 0.25662  focal_loss 0.00078  dice_loss 0.25585
Epoch [29/30] Validation [22/123] Loss: 0.60005  focal_loss 0.01117  dice_loss 0.58888
Epoch [29/30] Validation [23/123] Loss: 0.13601  focal_loss 0.00208  dice_loss 0.13393
Epoch [29/30] Validation [24/123] Loss: 0.22022  focal_loss 0.00327  dice_loss 0.21695
Epoch [29/30] Validation [25/123] Loss: 0.34112  focal_loss 0.00930  dice_loss 0.33182
Epoch [29/30] Validation [26/123] Loss: 0.14349  focal_loss 0.00186  dice_loss 0.14163
Epoch [29/30] Validation [27/123] Loss: 0.17111  focal_loss 0.00244  dice_loss 0.16867
Epoch [29/30] Validation [28/123] Loss: 0.47619  focal_loss 0.00723  dice_loss 0.46896
Epoch [29/30] Validation [29/123] Loss: 0.29339  focal_loss 0.00467  dice_loss 0.28872
Epoch [29/30] Validation [30/123] Loss: 0.17802  focal_loss 0.00315  dice_loss 0.17487
Epoch [29/30] Validation [31/123] Loss: 0.12759  focal_loss 0.00166  dice_loss 0.12593
Epoch [29/30] Validation [32/123] Loss: 0.22802  focal_loss 0.00391  dice_loss 0.22411
Epoch [29/30] Validation [33/123] Loss: 0.27574  focal_loss 0.00148  dice_loss 0.27426
Epoch [29/30] Validation [34/123] Loss: 0.20352  focal_loss 0.00078  dice_loss 0.20274
Epoch [29/30] Validation [35/123] Loss: 0.15893  focal_loss 0.00159  dice_loss 0.15734
Epoch [29/30] Validation [36/123] Loss: 0.18731  focal_loss 0.00114  dice_loss 0.18617
Epoch [29/30] Validation [37/123] Loss: 0.29127  focal_loss 0.00473  dice_loss 0.28653
Epoch [29/30] Validation [38/123] Loss: 0.13871  focal_loss 0.00141  dice_loss 0.13729
Epoch [29/30] Validation [39/123] Loss: 0.14118  focal_loss 0.00128  dice_loss 0.13990
Epoch [29/30] Validation [40/123] Loss: 0.23227  focal_loss 0.00089  dice_loss 0.23139
Epoch [29/30] Validation [41/123] Loss: 0.13648  focal_loss 0.00143  dice_loss 0.13505
Epoch [29/30] Validation [42/123] Loss: 0.12783  focal_loss 0.00155  dice_loss 0.12629
Epoch [29/30] Validation [43/123] Loss: 0.25509  focal_loss 0.03221  dice_loss 0.22289
Epoch [29/30] Validation [44/123] Loss: 0.55678  focal_loss 0.01352  dice_loss 0.54326
Epoch [29/30] Validation [45/123] Loss: 0.22643  focal_loss 0.00193  dice_loss 0.22451
Epoch [29/30] Validation [46/123] Loss: 0.26135  focal_loss 0.00283  dice_loss 0.25852
Epoch [29/30] Validation [47/123] Loss: 0.20922  focal_loss 0.00128  dice_loss 0.20794
Epoch [29/30] Validation [48/123] Loss: 0.35624  focal_loss 0.00511  dice_loss 0.35113
Epoch [29/30] Validation [49/123] Loss: 0.17434  focal_loss 0.01231  dice_loss 0.16204
Epoch [29/30] Validation [50/123] Loss: 0.15090  focal_loss 0.00231  dice_loss 0.14859
Epoch [29/30] Validation [51/123] Loss: 0.32804  focal_loss 0.01076  dice_loss 0.31727
Epoch [29/30] Validation [52/123] Loss: 0.15370  focal_loss 0.00082  dice_loss 0.15288
Epoch [29/30] Validation [53/123] Loss: 0.19495  focal_loss 0.00078  dice_loss 0.19417
Epoch [29/30] Validation [54/123] Loss: 0.25448  focal_loss 0.00129  dice_loss 0.25319
Epoch [29/30] Validation [55/123] Loss: 0.21342  focal_loss 0.00122  dice_loss 0.21220
Epoch [29/30] Validation [56/123] Loss: 0.15760  focal_loss 0.00358  dice_loss 0.15402
Epoch [29/30] Validation [57/123] Loss: 0.23466  focal_loss 0.01092  dice_loss 0.22374
Epoch [29/30] Validation [58/123] Loss: 0.19086  focal_loss 0.00192  dice_loss 0.18894
Epoch [29/30] Validation [59/123] Loss: 0.55014  focal_loss 0.00875  dice_loss 0.54140
Epoch [29/30] Validation [60/123] Loss: 0.18066  focal_loss 0.00293  dice_loss 0.17773
Epoch [29/30] Validation [61/123] Loss: 0.54501  focal_loss 0.00292  dice_loss 0.54209
Epoch [29/30] Validation [62/123] Loss: 0.46596  focal_loss 0.02122  dice_loss 0.44474
Epoch [29/30] Validation [63/123] Loss: 0.29376  focal_loss 0.00175  dice_loss 0.29201
Epoch [29/30] Validation [64/123] Loss: 0.35679  focal_loss 0.01332  dice_loss 0.34347
Epoch [29/30] Validation [65/123] Loss: 0.16456  focal_loss 0.00110  dice_loss 0.16346
Epoch [29/30] Validation [66/123] Loss: 0.16552  focal_loss 0.00139  dice_loss 0.16413
Epoch [29/30] Validation [67/123] Loss: 0.31723  focal_loss 0.00604  dice_loss 0.31119
Epoch [29/30] Validation [68/123] Loss: 0.28419  focal_loss 0.00103  dice_loss 0.28317
Epoch [29/30] Validation [69/123] Loss: 0.36828  focal_loss 0.00758  dice_loss 0.36070
Epoch [29/30] Validation [70/123] Loss: 0.26752  focal_loss 0.00218  dice_loss 0.26535
Epoch [29/30] Validation [71/123] Loss: 0.14371  focal_loss 0.00093  dice_loss 0.14278
Epoch [29/30] Validation [72/123] Loss: 0.14077  focal_loss 0.00166  dice_loss 0.13911
Epoch [29/30] Validation [73/123] Loss: 0.23266  focal_loss 0.00347  dice_loss 0.22919
Epoch [29/30] Validation [74/123] Loss: 0.22107  focal_loss 0.00181  dice_loss 0.21926
Epoch [29/30] Validation [75/123] Loss: 0.17149  focal_loss 0.00136  dice_loss 0.17012
Epoch [29/30] Validation [76/123] Loss: 0.45906  focal_loss 0.00599  dice_loss 0.45306
Epoch [29/30] Validation [77/123] Loss: 0.29390  focal_loss 0.00084  dice_loss 0.29306
Epoch [29/30] Validation [78/123] Loss: 0.19818  focal_loss 0.00137  dice_loss 0.19681
Epoch [29/30] Validation [79/123] Loss: 0.21579  focal_loss 0.00117  dice_loss 0.21462
Epoch [29/30] Validation [80/123] Loss: 0.15952  focal_loss 0.00259  dice_loss 0.15694
Epoch [29/30] Validation [81/123] Loss: 0.17402  focal_loss 0.00147  dice_loss 0.17255
Epoch [29/30] Validation [82/123] Loss: 0.14498  focal_loss 0.00117  dice_loss 0.14381
Epoch [29/30] Validation [83/123] Loss: 0.31589  focal_loss 0.00973  dice_loss 0.30616
Epoch [29/30] Validation [84/123] Loss: 0.18162  focal_loss 0.00130  dice_loss 0.18032
Epoch [29/30] Validation [85/123] Loss: 0.25294  focal_loss 0.00340  dice_loss 0.24955
Epoch [29/30] Validation [86/123] Loss: 0.15838  focal_loss 0.00122  dice_loss 0.15716
Epoch [29/30] Validation [87/123] Loss: 0.17218  focal_loss 0.00279  dice_loss 0.16939
Epoch [29/30] Validation [88/123] Loss: 0.17132  focal_loss 0.00200  dice_loss 0.16932
Epoch [29/30] Validation [89/123] Loss: 0.15170  focal_loss 0.00233  dice_loss 0.14937
Epoch [29/30] Validation [90/123] Loss: 0.20558  focal_loss 0.00180  dice_loss 0.20379
Epoch [29/30] Validation [91/123] Loss: 0.16235  focal_loss 0.00143  dice_loss 0.16093
Epoch [29/30] Validation [92/123] Loss: 0.13310  focal_loss 0.00138  dice_loss 0.13172
Epoch [29/30] Validation [93/123] Loss: 0.14062  focal_loss 0.00189  dice_loss 0.13873
Epoch [29/30] Validation [94/123] Loss: 0.27360  focal_loss 0.00161  dice_loss 0.27199
Epoch [29/30] Validation [95/123] Loss: 0.19294  focal_loss 0.00269  dice_loss 0.19025
Epoch [29/30] Validation [96/123] Loss: 0.24526  focal_loss 0.00204  dice_loss 0.24322
Epoch [29/30] Validation [97/123] Loss: 0.53630  focal_loss 0.00632  dice_loss 0.52999
Epoch [29/30] Validation [98/123] Loss: 0.23336  focal_loss 0.00085  dice_loss 0.23251
Epoch [29/30] Validation [99/123] Loss: 0.22214  focal_loss 0.00064  dice_loss 0.22150
Epoch [29/30] Validation [100/123] Loss: 0.25848  focal_loss 0.00114  dice_loss 0.25733
Epoch [29/30] Validation [101/123] Loss: 0.21956  focal_loss 0.00103  dice_loss 0.21853
Epoch [29/30] Validation [102/123] Loss: 0.25725  focal_loss 0.00072  dice_loss 0.25654
Epoch [29/30] Validation [103/123] Loss: 0.40327  focal_loss 0.00089  dice_loss 0.40238
Epoch [29/30] Validation [104/123] Loss: 0.35476  focal_loss 0.00587  dice_loss 0.34890
Epoch [29/30] Validation [105/123] Loss: 0.15604  focal_loss 0.00332  dice_loss 0.15273
Epoch [29/30] Validation [106/123] Loss: 0.14851  focal_loss 0.00095  dice_loss 0.14757
Epoch [29/30] Validation [107/123] Loss: 0.45558  focal_loss 0.00256  dice_loss 0.45302
Epoch [29/30] Validation [108/123] Loss: 0.15970  focal_loss 0.00092  dice_loss 0.15878
Epoch [29/30] Validation [109/123] Loss: 0.17127  focal_loss 0.00552  dice_loss 0.16575
Epoch [29/30] Validation [110/123] Loss: 0.27948  focal_loss 0.00292  dice_loss 0.27656
Epoch [29/30] Validation [111/123] Loss: 0.30304  focal_loss 0.00354  dice_loss 0.29949
Epoch [29/30] Validation [112/123] Loss: 0.23253  focal_loss 0.00083  dice_loss 0.23169
Epoch [29/30] Validation [113/123] Loss: 0.19224  focal_loss 0.00173  dice_loss 0.19052
Epoch [29/30] Validation [114/123] Loss: 0.27481  focal_loss 0.00529  dice_loss 0.26952
Epoch [29/30] Validation [115/123] Loss: 0.23628  focal_loss 0.00643  dice_loss 0.22985
Epoch [29/30] Validation [116/123] Loss: 0.17673  focal_loss 0.00055  dice_loss 0.17618
Epoch [29/30] Validation [117/123] Loss: 0.19574  focal_loss 0.00113  dice_loss 0.19461
Epoch [29/30] Validation [118/123] Loss: 0.12673  focal_loss 0.00208  dice_loss 0.12465
Epoch [29/30] Validation [119/123] Loss: 0.14506  focal_loss 0.00161  dice_loss 0.14345
Epoch [29/30] Validation [120/123] Loss: 0.17430  focal_loss 0.00183  dice_loss 0.17248
Epoch [29/30] Validation [121/123] Loss: 0.60949  focal_loss 0.02027  dice_loss 0.58922
Epoch [29/30] Validation [122/123] Loss: 0.48886  focal_loss 0.00069  dice_loss 0.48817
Epoch [29/30] Validation [123/123] Loss: 0.17617  focal_loss 0.00179  dice_loss 0.17438
Epoch [29/30] Validation metric {'Val/mean dice_metric': 0.9066348075866699, 'Val/TC dice_metric': 0.9230185151100159, 'Val/WT dice_metric': 0.9413953423500061, 'Val/ET dice_metric': 0.8554906249046326}
Epoch [29/30] lr = [1.5708419435684518e-05, 1.5708419435684518e-05] best acc: tensor([0.9054], device='cuda:0'), mean acc: tensor([0.9066], device='cuda:0'), mean class: tensor([0.9230, 0.9414, 0.8555], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [30/30] Training [1/488] Loss: 0.33905
Epoch [30/30] Training [2/488] Loss: 0.20853
Epoch [30/30] Training [3/488] Loss: 0.15221
Epoch [30/30] Training [4/488] Loss: 0.16036
Epoch [30/30] Training [5/488] Loss: 0.08141
Epoch [30/30] Training [6/488] Loss: 0.09584
Epoch [30/30] Training [7/488] Loss: 0.08706
Epoch [30/30] Training [8/488] Loss: 0.07946
Epoch [30/30] Training [9/488] Loss: 0.11560
Epoch [30/30] Training [10/488] Loss: 0.11087
Epoch [30/30] Training [11/488] Loss: 0.09271
Epoch [30/30] Training [12/488] Loss: 0.14513
Epoch [30/30] Training [13/488] Loss: 0.09502
Epoch [30/30] Training [14/488] Loss: 0.09405
Epoch [30/30] Training [15/488] Loss: 0.16452
Epoch [30/30] Training [16/488] Loss: 0.20524
Epoch [30/30] Training [17/488] Loss: 0.21752
Epoch [30/30] Training [18/488] Loss: 0.08840
Epoch [30/30] Training [19/488] Loss: 0.24848
Epoch [30/30] Training [20/488] Loss: 0.09580
Epoch [30/30] Training [21/488] Loss: 0.32549
Epoch [30/30] Training [22/488] Loss: 0.12996
Epoch [30/30] Training [23/488] Loss: 0.22283
Epoch [30/30] Training [24/488] Loss: 0.13338
Epoch [30/30] Training [25/488] Loss: 0.09463
Epoch [30/30] Training [26/488] Loss: 0.44934
Epoch [30/30] Training [27/488] Loss: 0.10046
Epoch [30/30] Training [28/488] Loss: 0.08620
Epoch [30/30] Training [29/488] Loss: 0.25982
Epoch [30/30] Training [30/488] Loss: 0.09625
Epoch [30/30] Training [31/488] Loss: 0.22156
Epoch [30/30] Training [32/488] Loss: 0.07430
Epoch [30/30] Training [33/488] Loss: 0.11367
Epoch [30/30] Training [34/488] Loss: 0.14393
Epoch [30/30] Training [35/488] Loss: 0.31333
Epoch [30/30] Training [36/488] Loss: 0.12316
Epoch [30/30] Training [37/488] Loss: 0.15887
Epoch [30/30] Training [38/488] Loss: 0.09825
Epoch [30/30] Training [39/488] Loss: 0.49244
Epoch [30/30] Training [40/488] Loss: 0.12263
Epoch [30/30] Training [41/488] Loss: 0.10197
Epoch [30/30] Training [42/488] Loss: 0.10279
Epoch [30/30] Training [43/488] Loss: 0.27726
Epoch [30/30] Training [44/488] Loss: 0.16148
Epoch [30/30] Training [45/488] Loss: 0.11483
Epoch [30/30] Training [46/488] Loss: 0.11108
Epoch [30/30] Training [47/488] Loss: 0.15894
Epoch [30/30] Training [48/488] Loss: 0.08150
Epoch [30/30] Training [49/488] Loss: 0.13575
Epoch [30/30] Training [50/488] Loss: 0.10154
Epoch [30/30] Training [51/488] Loss: 0.33165
Epoch [30/30] Training [52/488] Loss: 0.11408
Epoch [30/30] Training [53/488] Loss: 0.08102
Epoch [30/30] Training [54/488] Loss: 0.44915
Epoch [30/30] Training [55/488] Loss: 0.21821
Epoch [30/30] Training [56/488] Loss: 0.17533
Epoch [30/30] Training [57/488] Loss: 0.14831
Epoch [30/30] Training [58/488] Loss: 0.16279
Epoch [30/30] Training [59/488] Loss: 0.19546
Epoch [30/30] Training [60/488] Loss: 0.11214
Epoch [30/30] Training [61/488] Loss: 0.09780
Epoch [30/30] Training [62/488] Loss: 0.22457
Epoch [30/30] Training [63/488] Loss: 0.10331
Epoch [30/30] Training [64/488] Loss: 0.09517
Epoch [30/30] Training [65/488] Loss: 0.13926
Epoch [30/30] Training [66/488] Loss: 0.32005
Epoch [30/30] Training [67/488] Loss: 0.16369
Epoch [30/30] Training [68/488] Loss: 0.08566
Epoch [30/30] Training [69/488] Loss: 0.15317
Epoch [30/30] Training [70/488] Loss: 0.09792
Epoch [30/30] Training [71/488] Loss: 0.20176
Epoch [30/30] Training [72/488] Loss: 0.09601
Epoch [30/30] Training [73/488] Loss: 0.10944
Epoch [30/30] Training [74/488] Loss: 0.13160
Epoch [30/30] Training [75/488] Loss: 0.07726
Epoch [30/30] Training [76/488] Loss: 0.12427
Epoch [30/30] Training [77/488] Loss: 0.42388
Epoch [30/30] Training [78/488] Loss: 0.18864
Epoch [30/30] Training [79/488] Loss: 0.10157
Epoch [30/30] Training [80/488] Loss: 0.09528
Epoch [30/30] Training [81/488] Loss: 0.10003
Epoch [30/30] Training [82/488] Loss: 0.13692
Epoch [30/30] Training [83/488] Loss: 0.09520
Epoch [30/30] Training [84/488] Loss: 0.08480
Epoch [30/30] Training [85/488] Loss: 0.13221
Epoch [30/30] Training [86/488] Loss: 0.12203
Epoch [30/30] Training [87/488] Loss: 0.15044
Epoch [30/30] Training [88/488] Loss: 0.11877
Epoch [30/30] Training [89/488] Loss: 0.15181
Epoch [30/30] Training [90/488] Loss: 0.11002
Epoch [30/30] Training [91/488] Loss: 0.17740
Epoch [30/30] Training [92/488] Loss: 0.09509
Epoch [30/30] Training [93/488] Loss: 0.14669
Epoch [30/30] Training [94/488] Loss: 0.12778
Epoch [30/30] Training [95/488] Loss: 0.09958
Epoch [30/30] Training [96/488] Loss: 0.10831
Epoch [30/30] Training [97/488] Loss: 0.10803
Epoch [30/30] Training [98/488] Loss: 0.34132
Epoch [30/30] Training [99/488] Loss: 0.14947
Epoch [30/30] Training [100/488] Loss: 0.21166
Epoch [30/30] Training [101/488] Loss: 0.14206
Epoch [30/30] Training [102/488] Loss: 0.11799
Epoch [30/30] Training [103/488] Loss: 0.13588
Epoch [30/30] Training [104/488] Loss: 0.14209
Epoch [30/30] Training [105/488] Loss: 0.16787
Epoch [30/30] Training [106/488] Loss: 0.21580
Epoch [30/30] Training [107/488] Loss: 0.32027
Epoch [30/30] Training [108/488] Loss: 0.09459
Epoch [30/30] Training [109/488] Loss: 0.14816
Epoch [30/30] Training [110/488] Loss: 0.13666
Epoch [30/30] Training [111/488] Loss: 0.10618
Epoch [30/30] Training [112/488] Loss: 0.07880
Epoch [30/30] Training [113/488] Loss: 0.12540
Epoch [30/30] Training [114/488] Loss: 0.15860
Epoch [30/30] Training [115/488] Loss: 0.28236
Epoch [30/30] Training [116/488] Loss: 0.12965
Epoch [30/30] Training [117/488] Loss: 0.09240
Epoch [30/30] Training [118/488] Loss: 0.13840
Epoch [30/30] Training [119/488] Loss: 0.07861
Epoch [30/30] Training [120/488] Loss: 0.09847
Epoch [30/30] Training [121/488] Loss: 0.16782
Epoch [30/30] Training [122/488] Loss: 0.09655
Epoch [30/30] Training [123/488] Loss: 0.11132
Epoch [30/30] Training [124/488] Loss: 0.08683
Epoch [30/30] Training [125/488] Loss: 0.08860
Epoch [30/30] Training [126/488] Loss: 0.28271
Epoch [30/30] Training [127/488] Loss: 0.07464
Epoch [30/30] Training [128/488] Loss: 0.22415
Epoch [30/30] Training [129/488] Loss: 0.16052
Epoch [30/30] Training [130/488] Loss: 0.09117
Epoch [30/30] Training [131/488] Loss: 0.71676
Epoch [30/30] Training [132/488] Loss: 0.07914
Epoch [30/30] Training [133/488] Loss: 0.12934
Epoch [30/30] Training [134/488] Loss: 0.10240
Epoch [30/30] Training [135/488] Loss: 0.09816
Epoch [30/30] Training [136/488] Loss: 0.09970
Epoch [30/30] Training [137/488] Loss: 0.39034
Epoch [30/30] Training [138/488] Loss: 0.18729
Epoch [30/30] Training [139/488] Loss: 0.11152
Epoch [30/30] Training [140/488] Loss: 0.30616
Epoch [30/30] Training [141/488] Loss: 0.09789
Epoch [30/30] Training [142/488] Loss: 0.11753
Epoch [30/30] Training [143/488] Loss: 0.51374
Epoch [30/30] Training [144/488] Loss: 0.33232
Epoch [30/30] Training [145/488] Loss: 0.12638
Epoch [30/30] Training [146/488] Loss: 0.11096
Epoch [30/30] Training [147/488] Loss: 0.12087
Epoch [30/30] Training [148/488] Loss: 0.11004
Epoch [30/30] Training [149/488] Loss: 0.18080
Epoch [30/30] Training [150/488] Loss: 0.09006
Epoch [30/30] Training [151/488] Loss: 0.11560
Epoch [30/30] Training [152/488] Loss: 0.10057
Epoch [30/30] Training [153/488] Loss: 0.14226
Epoch [30/30] Training [154/488] Loss: 0.25206
Epoch [30/30] Training [155/488] Loss: 0.18834
Epoch [30/30] Training [156/488] Loss: 0.39999
Epoch [30/30] Training [157/488] Loss: 0.24713
Epoch [30/30] Training [158/488] Loss: 0.14997
Epoch [30/30] Training [159/488] Loss: 0.30258
Epoch [30/30] Training [160/488] Loss: 0.17088
Epoch [30/30] Training [161/488] Loss: 0.12517
Epoch [30/30] Training [162/488] Loss: 0.11302
Epoch [30/30] Training [163/488] Loss: 0.09564
Epoch [30/30] Training [164/488] Loss: 0.09671
Epoch [30/30] Training [165/488] Loss: 0.17621
Epoch [30/30] Training [166/488] Loss: 0.50506
Epoch [30/30] Training [167/488] Loss: 0.15633
Epoch [30/30] Training [168/488] Loss: 0.06557
Epoch [30/30] Training [169/488] Loss: 0.07838
Epoch [30/30] Training [170/488] Loss: 0.12990
Epoch [30/30] Training [171/488] Loss: 0.13878
Epoch [30/30] Training [172/488] Loss: 0.19320
Epoch [30/30] Training [173/488] Loss: 0.10189
Epoch [30/30] Training [174/488] Loss: 0.08966
Epoch [30/30] Training [175/488] Loss: 0.12076
Epoch [30/30] Training [176/488] Loss: 0.09786
Epoch [30/30] Training [177/488] Loss: 0.09590
Epoch [30/30] Training [178/488] Loss: 0.14540
Epoch [30/30] Training [179/488] Loss: 0.08339
Epoch [30/30] Training [180/488] Loss: 0.08831
Epoch [30/30] Training [181/488] Loss: 0.22368
Epoch [30/30] Training [182/488] Loss: 0.13603
Epoch [30/30] Training [183/488] Loss: 0.18749
Epoch [30/30] Training [184/488] Loss: 0.12776
Epoch [30/30] Training [185/488] Loss: 0.11070
Epoch [30/30] Training [186/488] Loss: 0.16018
Epoch [30/30] Training [187/488] Loss: 0.22477
Epoch [30/30] Training [188/488] Loss: 0.12146
Epoch [30/30] Training [189/488] Loss: 0.09987
Epoch [30/30] Training [190/488] Loss: 0.19804
Epoch [30/30] Training [191/488] Loss: 0.10682
Epoch [30/30] Training [192/488] Loss: 0.11940
Epoch [30/30] Training [193/488] Loss: 0.10410
Epoch [30/30] Training [194/488] Loss: 0.10388
Epoch [30/30] Training [195/488] Loss: 0.11036
Epoch [30/30] Training [196/488] Loss: 0.08391
Epoch [30/30] Training [197/488] Loss: 0.25711
Epoch [30/30] Training [198/488] Loss: 0.11658
Epoch [30/30] Training [199/488] Loss: 0.08983
Epoch [30/30] Training [200/488] Loss: 0.23303
Epoch [30/30] Training [201/488] Loss: 0.07787
Epoch [30/30] Training [202/488] Loss: 0.09987
Epoch [30/30] Training [203/488] Loss: 0.13620
Epoch [30/30] Training [204/488] Loss: 0.07473
Epoch [30/30] Training [205/488] Loss: 0.28551
Epoch [30/30] Training [206/488] Loss: 0.10987
Epoch [30/30] Training [207/488] Loss: 0.25280
Epoch [30/30] Training [208/488] Loss: 0.08217
Epoch [30/30] Training [209/488] Loss: 0.07116
Epoch [30/30] Training [210/488] Loss: 0.08365
Epoch [30/30] Training [211/488] Loss: 0.08931
Epoch [30/30] Training [212/488] Loss: 0.40435
Epoch [30/30] Training [213/488] Loss: 0.08169
Epoch [30/30] Training [214/488] Loss: 0.10059
Epoch [30/30] Training [215/488] Loss: 0.11142
Epoch [30/30] Training [216/488] Loss: 0.09846
Epoch [30/30] Training [217/488] Loss: 0.08172
Epoch [30/30] Training [218/488] Loss: 0.08772
Epoch [30/30] Training [219/488] Loss: 0.07147
Epoch [30/30] Training [220/488] Loss: 0.13670
Epoch [30/30] Training [221/488] Loss: 0.10152
Epoch [30/30] Training [222/488] Loss: 0.11263
Epoch [30/30] Training [223/488] Loss: 0.21341
Epoch [30/30] Training [224/488] Loss: 0.08648
Epoch [30/30] Training [225/488] Loss: 0.19255
Epoch [30/30] Training [226/488] Loss: 0.21226
Epoch [30/30] Training [227/488] Loss: 0.12463
Epoch [30/30] Training [228/488] Loss: 0.11060
Epoch [30/30] Training [229/488] Loss: 0.13612
Epoch [30/30] Training [230/488] Loss: 0.11697
Epoch [30/30] Training [231/488] Loss: 0.39245
Epoch [30/30] Training [232/488] Loss: 0.06873
Epoch [30/30] Training [233/488] Loss: 0.21271
Epoch [30/30] Training [234/488] Loss: 0.10518
Epoch [30/30] Training [235/488] Loss: 0.19368
Epoch [30/30] Training [236/488] Loss: 0.71236
Epoch [30/30] Training [237/488] Loss: 0.34584
Epoch [30/30] Training [238/488] Loss: 0.16937
Epoch [30/30] Training [239/488] Loss: 0.07029
Epoch [30/30] Training [240/488] Loss: 0.10950
Epoch [30/30] Training [241/488] Loss: 0.16611
Epoch [30/30] Training [242/488] Loss: 0.15301
Epoch [30/30] Training [243/488] Loss: 0.10073
Epoch [30/30] Training [244/488] Loss: 0.10525
Epoch [30/30] Training [245/488] Loss: 0.10431
Epoch [30/30] Training [246/488] Loss: 0.12611
Epoch [30/30] Training [247/488] Loss: 0.15691
Epoch [30/30] Training [248/488] Loss: 0.16268
Epoch [30/30] Training [249/488] Loss: 0.08389
Epoch [30/30] Training [250/488] Loss: 0.14919
Epoch [30/30] Training [251/488] Loss: 0.09860
Epoch [30/30] Training [252/488] Loss: 0.08970
Epoch [30/30] Training [253/488] Loss: 0.09456
Epoch [30/30] Training [254/488] Loss: 0.12813
Epoch [30/30] Training [255/488] Loss: 0.09075
Epoch [30/30] Training [256/488] Loss: 0.53469
Epoch [30/30] Training [257/488] Loss: 0.12124
Epoch [30/30] Training [258/488] Loss: 0.10947
Epoch [30/30] Training [259/488] Loss: 0.13406
Epoch [30/30] Training [260/488] Loss: 0.20802
Epoch [30/30] Training [261/488] Loss: 0.14015
Epoch [30/30] Training [262/488] Loss: 0.16512
Epoch [30/30] Training [263/488] Loss: 0.19372
Epoch [30/30] Training [264/488] Loss: 0.37599
Epoch [30/30] Training [265/488] Loss: 0.09472
Epoch [30/30] Training [266/488] Loss: 0.10956
Epoch [30/30] Training [267/488] Loss: 0.14173
Epoch [30/30] Training [268/488] Loss: 0.34048
Epoch [30/30] Training [269/488] Loss: 0.11579
Epoch [30/30] Training [270/488] Loss: 0.13214
Epoch [30/30] Training [271/488] Loss: 0.13991
Epoch [30/30] Training [272/488] Loss: 0.14807
Epoch [30/30] Training [273/488] Loss: 0.08321
Epoch [30/30] Training [274/488] Loss: 0.10230
Epoch [30/30] Training [275/488] Loss: 0.14946
Epoch [30/30] Training [276/488] Loss: 0.08921
Epoch [30/30] Training [277/488] Loss: 0.13891
Epoch [30/30] Training [278/488] Loss: 0.12928
Epoch [30/30] Training [279/488] Loss: 0.08193
Epoch [30/30] Training [280/488] Loss: 0.06679
Epoch [30/30] Training [281/488] Loss: 0.11357
Epoch [30/30] Training [282/488] Loss: 0.11494
Epoch [30/30] Training [283/488] Loss: 0.08435
Epoch [30/30] Training [284/488] Loss: 0.10341
Epoch [30/30] Training [285/488] Loss: 0.11405
Epoch [30/30] Training [286/488] Loss: 0.10306
Epoch [30/30] Training [287/488] Loss: 0.13880
Epoch [30/30] Training [288/488] Loss: 0.24496
Epoch [30/30] Training [289/488] Loss: 0.12302
Epoch [30/30] Training [290/488] Loss: 0.09024
Epoch [30/30] Training [291/488] Loss: 0.12981
Epoch [30/30] Training [292/488] Loss: 0.64589
Epoch [30/30] Training [293/488] Loss: 0.08836
Epoch [30/30] Training [294/488] Loss: 0.12485
Epoch [30/30] Training [295/488] Loss: 0.13382
Epoch [30/30] Training [296/488] Loss: 0.09342
Epoch [30/30] Training [297/488] Loss: 0.45805
Epoch [30/30] Training [298/488] Loss: 0.22048
Epoch [30/30] Training [299/488] Loss: 0.13400
Epoch [30/30] Training [300/488] Loss: 0.09141
Epoch [30/30] Training [301/488] Loss: 0.31879
Epoch [30/30] Training [302/488] Loss: 0.37856
Epoch [30/30] Training [303/488] Loss: 0.31578
Epoch [30/30] Training [304/488] Loss: 0.33928
Epoch [30/30] Training [305/488] Loss: 0.19050
Epoch [30/30] Training [306/488] Loss: 0.10410
Epoch [30/30] Training [307/488] Loss: 0.08361
Epoch [30/30] Training [308/488] Loss: 0.10492
Epoch [30/30] Training [309/488] Loss: 0.20179
Epoch [30/30] Training [310/488] Loss: 0.15091
Epoch [30/30] Training [311/488] Loss: 0.15250
Epoch [30/30] Training [312/488] Loss: 0.16290
Epoch [30/30] Training [313/488] Loss: 0.11672
Epoch [30/30] Training [314/488] Loss: 0.13235
Epoch [30/30] Training [315/488] Loss: 0.12491
Epoch [30/30] Training [316/488] Loss: 0.13341
Epoch [30/30] Training [317/488] Loss: 0.28612
Epoch [30/30] Training [318/488] Loss: 0.09076
Epoch [30/30] Training [319/488] Loss: 0.10513
Epoch [30/30] Training [320/488] Loss: 0.21264
Epoch [30/30] Training [321/488] Loss: 0.20510
Epoch [30/30] Training [322/488] Loss: 0.13877
Epoch [30/30] Training [323/488] Loss: 0.09171
Epoch [30/30] Training [324/488] Loss: 0.16382
Epoch [30/30] Training [325/488] Loss: 0.09101
Epoch [30/30] Training [326/488] Loss: 0.24074
Epoch [30/30] Training [327/488] Loss: 0.13224
Epoch [30/30] Training [328/488] Loss: 0.13868
Epoch [30/30] Training [329/488] Loss: 0.28091
Epoch [30/30] Training [330/488] Loss: 0.28062
Epoch [30/30] Training [331/488] Loss: 0.09075
Epoch [30/30] Training [332/488] Loss: 0.44256
Epoch [30/30] Training [333/488] Loss: 0.16512
Epoch [30/30] Training [334/488] Loss: 0.12512
Epoch [30/30] Training [335/488] Loss: 0.20151
Epoch [30/30] Training [336/488] Loss: 0.28323
Epoch [30/30] Training [337/488] Loss: 0.08606
Epoch [30/30] Training [338/488] Loss: 0.11831
Epoch [30/30] Training [339/488] Loss: 0.10397
Epoch [30/30] Training [340/488] Loss: 0.18664
Epoch [30/30] Training [341/488] Loss: 0.13751
Epoch [30/30] Training [342/488] Loss: 0.09509
Epoch [30/30] Training [343/488] Loss: 0.11113
Epoch [30/30] Training [344/488] Loss: 0.20967
Epoch [30/30] Training [345/488] Loss: 0.33140
Epoch [30/30] Training [346/488] Loss: 0.08748
Epoch [30/30] Training [347/488] Loss: 0.10587
Epoch [30/30] Training [348/488] Loss: 0.11211
Epoch [30/30] Training [349/488] Loss: 0.15990
Epoch [30/30] Training [350/488] Loss: 0.44721
Epoch [30/30] Training [351/488] Loss: 0.18503
Epoch [30/30] Training [352/488] Loss: 0.12693
Epoch [30/30] Training [353/488] Loss: 0.10463
Epoch [30/30] Training [354/488] Loss: 0.18870
Epoch [30/30] Training [355/488] Loss: 0.08533
Epoch [30/30] Training [356/488] Loss: 0.56570
Epoch [30/30] Training [357/488] Loss: 0.10032
Epoch [30/30] Training [358/488] Loss: 0.11336
Epoch [30/30] Training [359/488] Loss: 0.23739
Epoch [30/30] Training [360/488] Loss: 0.12270
Epoch [30/30] Training [361/488] Loss: 0.15230
Epoch [30/30] Training [362/488] Loss: 0.08922
Epoch [30/30] Training [363/488] Loss: 0.09857
Epoch [30/30] Training [364/488] Loss: 0.09164
Epoch [30/30] Training [365/488] Loss: 0.31505
Epoch [30/30] Training [366/488] Loss: 0.10605
Epoch [30/30] Training [367/488] Loss: 0.21063
Epoch [30/30] Training [368/488] Loss: 0.08717
Epoch [30/30] Training [369/488] Loss: 0.09427
Epoch [30/30] Training [370/488] Loss: 0.42261
Epoch [30/30] Training [371/488] Loss: 0.10797
Epoch [30/30] Training [372/488] Loss: 0.11412
Epoch [30/30] Training [373/488] Loss: 0.17603
Epoch [30/30] Training [374/488] Loss: 0.14554
Epoch [30/30] Training [375/488] Loss: 0.11154
Epoch [30/30] Training [376/488] Loss: 0.16305
Epoch [30/30] Training [377/488] Loss: 0.13720
Epoch [30/30] Training [378/488] Loss: 0.09056
Epoch [30/30] Training [379/488] Loss: 0.11968
Epoch [30/30] Training [380/488] Loss: 0.13772
Epoch [30/30] Training [381/488] Loss: 0.13297
Epoch [30/30] Training [382/488] Loss: 0.15190
Epoch [30/30] Training [383/488] Loss: 0.09175
Epoch [30/30] Training [384/488] Loss: 0.29395
Epoch [30/30] Training [385/488] Loss: 0.11821
Epoch [30/30] Training [386/488] Loss: 0.16647
Epoch [30/30] Training [387/488] Loss: 0.11373
Epoch [30/30] Training [388/488] Loss: 0.10243
Epoch [30/30] Training [389/488] Loss: 0.10458
Epoch [30/30] Training [390/488] Loss: 0.20176
Epoch [30/30] Training [391/488] Loss: 0.09216
Epoch [30/30] Training [392/488] Loss: 0.31230
Epoch [30/30] Training [393/488] Loss: 0.13687
Epoch [30/30] Training [394/488] Loss: 0.12726
Epoch [30/30] Training [395/488] Loss: 0.10843
Epoch [30/30] Training [396/488] Loss: 0.14463
Epoch [30/30] Training [397/488] Loss: 0.55185
Epoch [30/30] Training [398/488] Loss: 0.13564
Epoch [30/30] Training [399/488] Loss: 0.13079
Epoch [30/30] Training [400/488] Loss: 0.09111
Epoch [30/30] Training [401/488] Loss: 0.12928
Epoch [30/30] Training [402/488] Loss: 0.08511
Epoch [30/30] Training [403/488] Loss: 0.12656
Epoch [30/30] Training [404/488] Loss: 0.08914
Epoch [30/30] Training [405/488] Loss: 0.10747
Epoch [30/30] Training [406/488] Loss: 0.14079
Epoch [30/30] Training [407/488] Loss: 0.09931
Epoch [30/30] Training [408/488] Loss: 0.11192
Epoch [30/30] Training [409/488] Loss: 0.22245
Epoch [30/30] Training [410/488] Loss: 0.13112
Epoch [30/30] Training [411/488] Loss: 0.12484
Epoch [30/30] Training [412/488] Loss: 0.07334
Epoch [30/30] Training [413/488] Loss: 0.16413
Epoch [30/30] Training [414/488] Loss: 0.10594
Epoch [30/30] Training [415/488] Loss: 0.14884
Epoch [30/30] Training [416/488] Loss: 0.08951
Epoch [30/30] Training [417/488] Loss: 0.24061
Epoch [30/30] Training [418/488] Loss: 0.10699
Epoch [30/30] Training [419/488] Loss: 0.13115
Epoch [30/30] Training [420/488] Loss: 0.24006
Epoch [30/30] Training [421/488] Loss: 0.16439
Epoch [30/30] Training [422/488] Loss: 0.09370
Epoch [30/30] Training [423/488] Loss: 0.22505
Epoch [30/30] Training [424/488] Loss: 0.11017
Epoch [30/30] Training [425/488] Loss: 0.23691
Epoch [30/30] Training [426/488] Loss: 0.09162
Epoch [30/30] Training [427/488] Loss: 0.15686
Epoch [30/30] Training [428/488] Loss: 0.18145
Epoch [30/30] Training [429/488] Loss: 0.15397
Epoch [30/30] Training [430/488] Loss: 0.14683
Epoch [30/30] Training [431/488] Loss: 0.13438
Epoch [30/30] Training [432/488] Loss: 0.13390
Epoch [30/30] Training [433/488] Loss: 0.14142
Epoch [30/30] Training [434/488] Loss: 0.10368
Epoch [30/30] Training [435/488] Loss: 0.08299
Epoch [30/30] Training [436/488] Loss: 0.06695
Epoch [30/30] Training [437/488] Loss: 0.12131
Epoch [30/30] Training [438/488] Loss: 0.10582
Epoch [30/30] Training [439/488] Loss: 0.10521
Epoch [30/30] Training [440/488] Loss: 0.16067
Epoch [30/30] Training [441/488] Loss: 0.09903
Epoch [30/30] Training [442/488] Loss: 0.40977
Epoch [30/30] Training [443/488] Loss: 0.20359
Epoch [30/30] Training [444/488] Loss: 0.12215
Epoch [30/30] Training [445/488] Loss: 0.11277
Epoch [30/30] Training [446/488] Loss: 0.08565
Epoch [30/30] Training [447/488] Loss: 0.11064
Epoch [30/30] Training [448/488] Loss: 0.14660
Epoch [30/30] Training [449/488] Loss: 0.10634
Epoch [30/30] Training [450/488] Loss: 0.08095
Epoch [30/30] Training [451/488] Loss: 0.12949
Epoch [30/30] Training [452/488] Loss: 0.11924
Epoch [30/30] Training [453/488] Loss: 0.12582
Epoch [30/30] Training [454/488] Loss: 0.24448
Epoch [30/30] Training [455/488] Loss: 0.08338
Epoch [30/30] Training [456/488] Loss: 0.11263
Epoch [30/30] Training [457/488] Loss: 0.11941
Epoch [30/30] Training [458/488] Loss: 0.13397
Epoch [30/30] Training [459/488] Loss: 0.10078
Epoch [30/30] Training [460/488] Loss: 0.32252
Epoch [30/30] Training [461/488] Loss: 0.12573
Epoch [30/30] Training [462/488] Loss: 0.23207
Epoch [30/30] Training [463/488] Loss: 0.15385
Epoch [30/30] Training [464/488] Loss: 0.12119
Epoch [30/30] Training [465/488] Loss: 0.25235
Epoch [30/30] Training [466/488] Loss: 0.12089
Epoch [30/30] Training [467/488] Loss: 0.22336
Epoch [30/30] Training [468/488] Loss: 0.08500
Epoch [30/30] Training [469/488] Loss: 0.11783
Epoch [30/30] Training [470/488] Loss: 0.15168
Epoch [30/30] Training [471/488] Loss: 0.14496
Epoch [30/30] Training [472/488] Loss: 0.11140
Epoch [30/30] Training [473/488] Loss: 0.70134
Epoch [30/30] Training [474/488] Loss: 0.14777
Epoch [30/30] Training [475/488] Loss: 0.13004
Epoch [30/30] Training [476/488] Loss: 0.09455
Epoch [30/30] Training [477/488] Loss: 0.15278
Epoch [30/30] Training [478/488] Loss: 0.10860
Epoch [30/30] Training [479/488] Loss: 0.23042
Epoch [30/30] Training [480/488] Loss: 0.17913
Epoch [30/30] Training [481/488] Loss: 0.20891
Epoch [30/30] Training [482/488] Loss: 0.09665
Epoch [30/30] Training [483/488] Loss: 0.09748
Epoch [30/30] Training [484/488] Loss: 0.16104
Epoch [30/30] Training [485/488] Loss: 0.24479
Epoch [30/30] Training [486/488] Loss: 0.11316
Epoch [30/30] Training [487/488] Loss: 0.08039
Epoch [30/30] Training [488/488] Loss: 0.08507
Epoch [30/30] Training metric {'Train/mean dice_metric': 0.9098237752914429, 'Train/TC dice_metric': 0.927878737449646, 'Train/WT dice_metric': 0.9440942406654358, 'Train/ET dice_metric': 0.857498288154602}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [30/30] Validation [1/123] Loss: 0.14269  focal_loss 0.00191  dice_loss 0.14078
Epoch [30/30] Validation [2/123] Loss: 0.30075  focal_loss 0.00124  dice_loss 0.29951
Epoch [30/30] Validation [3/123] Loss: 0.12166  focal_loss 0.00166  dice_loss 0.12001
Epoch [30/30] Validation [4/123] Loss: 0.18174  focal_loss 0.00117  dice_loss 0.18058
Epoch [30/30] Validation [5/123] Loss: 0.28955  focal_loss 0.01027  dice_loss 0.27927
Epoch [30/30] Validation [6/123] Loss: 0.26164  focal_loss 0.00196  dice_loss 0.25968
Epoch [30/30] Validation [7/123] Loss: 0.27837  focal_loss 0.00072  dice_loss 0.27766
Epoch [30/30] Validation [8/123] Loss: 0.30145  focal_loss 0.00160  dice_loss 0.29985
Epoch [30/30] Validation [9/123] Loss: 0.20051  focal_loss 0.00155  dice_loss 0.19895
Epoch [30/30] Validation [10/123] Loss: 0.40561  focal_loss 0.00303  dice_loss 0.40258
Epoch [30/30] Validation [11/123] Loss: 0.49897  focal_loss 0.00302  dice_loss 0.49595
Epoch [30/30] Validation [12/123] Loss: 0.14589  focal_loss 0.00160  dice_loss 0.14429
Epoch [30/30] Validation [13/123] Loss: 0.15472  focal_loss 0.00374  dice_loss 0.15098
Epoch [30/30] Validation [14/123] Loss: 0.14388  focal_loss 0.00080  dice_loss 0.14308
Epoch [30/30] Validation [15/123] Loss: 0.27707  focal_loss 0.00128  dice_loss 0.27579
Epoch [30/30] Validation [16/123] Loss: 0.45701  focal_loss 0.00243  dice_loss 0.45458
Epoch [30/30] Validation [17/123] Loss: 0.41041  focal_loss 0.00208  dice_loss 0.40833
Epoch [30/30] Validation [18/123] Loss: 0.30409  focal_loss 0.00431  dice_loss 0.29978
Epoch [30/30] Validation [19/123] Loss: 0.24907  focal_loss 0.01231  dice_loss 0.23676
Epoch [30/30] Validation [20/123] Loss: 0.36667  focal_loss 0.00079  dice_loss 0.36588
Epoch [30/30] Validation [21/123] Loss: 0.25505  focal_loss 0.00077  dice_loss 0.25428
Epoch [30/30] Validation [22/123] Loss: 0.60340  focal_loss 0.00999  dice_loss 0.59341
Epoch [30/30] Validation [23/123] Loss: 0.13704  focal_loss 0.00215  dice_loss 0.13488
Epoch [30/30] Validation [24/123] Loss: 0.21980  focal_loss 0.00322  dice_loss 0.21658
Epoch [30/30] Validation [25/123] Loss: 0.34217  focal_loss 0.00943  dice_loss 0.33274
Epoch [30/30] Validation [26/123] Loss: 0.14381  focal_loss 0.00193  dice_loss 0.14188
Epoch [30/30] Validation [27/123] Loss: 0.17112  focal_loss 0.00243  dice_loss 0.16869
Epoch [30/30] Validation [28/123] Loss: 0.47973  focal_loss 0.00661  dice_loss 0.47312
Epoch [30/30] Validation [29/123] Loss: 0.28813  focal_loss 0.00408  dice_loss 0.28405
Epoch [30/30] Validation [30/123] Loss: 0.18051  focal_loss 0.00333  dice_loss 0.17718
Epoch [30/30] Validation [31/123] Loss: 0.12801  focal_loss 0.00173  dice_loss 0.12628
Epoch [30/30] Validation [32/123] Loss: 0.22831  focal_loss 0.00386  dice_loss 0.22446
Epoch [30/30] Validation [33/123] Loss: 0.27618  focal_loss 0.00150  dice_loss 0.27468
Epoch [30/30] Validation [34/123] Loss: 0.21496  focal_loss 0.00104  dice_loss 0.21392
Epoch [30/30] Validation [35/123] Loss: 0.15935  focal_loss 0.00163  dice_loss 0.15772
Epoch [30/30] Validation [36/123] Loss: 0.18916  focal_loss 0.00127  dice_loss 0.18789
Epoch [30/30] Validation [37/123] Loss: 0.28160  focal_loss 0.00372  dice_loss 0.27789
Epoch [30/30] Validation [38/123] Loss: 0.13985  focal_loss 0.00151  dice_loss 0.13834
Epoch [30/30] Validation [39/123] Loss: 0.13981  focal_loss 0.00125  dice_loss 0.13856
Epoch [30/30] Validation [40/123] Loss: 0.23212  focal_loss 0.00086  dice_loss 0.23125
Epoch [30/30] Validation [41/123] Loss: 0.13895  focal_loss 0.00160  dice_loss 0.13735
Epoch [30/30] Validation [42/123] Loss: 0.12881  focal_loss 0.00159  dice_loss 0.12723
Epoch [30/30] Validation [43/123] Loss: 0.25267  focal_loss 0.02917  dice_loss 0.22350
Epoch [30/30] Validation [44/123] Loss: 0.55766  focal_loss 0.01243  dice_loss 0.54523
Epoch [30/30] Validation [45/123] Loss: 0.22631  focal_loss 0.00196  dice_loss 0.22435
Epoch [30/30] Validation [46/123] Loss: 0.26393  focal_loss 0.00292  dice_loss 0.26101
Epoch [30/30] Validation [47/123] Loss: 0.20948  focal_loss 0.00125  dice_loss 0.20823
Epoch [30/30] Validation [48/123] Loss: 0.36288  focal_loss 0.00552  dice_loss 0.35736
Epoch [30/30] Validation [49/123] Loss: 0.17235  focal_loss 0.01111  dice_loss 0.16123
Epoch [30/30] Validation [50/123] Loss: 0.15085  focal_loss 0.00235  dice_loss 0.14850
Epoch [30/30] Validation [51/123] Loss: 0.33214  focal_loss 0.01123  dice_loss 0.32091
Epoch [30/30] Validation [52/123] Loss: 0.15391  focal_loss 0.00085  dice_loss 0.15306
Epoch [30/30] Validation [53/123] Loss: 0.19721  focal_loss 0.00084  dice_loss 0.19637
Epoch [30/30] Validation [54/123] Loss: 0.25456  focal_loss 0.00133  dice_loss 0.25323
Epoch [30/30] Validation [55/123] Loss: 0.21285  focal_loss 0.00120  dice_loss 0.21165
Epoch [30/30] Validation [56/123] Loss: 0.16215  focal_loss 0.00379  dice_loss 0.15836
Epoch [30/30] Validation [57/123] Loss: 0.23315  focal_loss 0.00985  dice_loss 0.22330
Epoch [30/30] Validation [58/123] Loss: 0.18973  focal_loss 0.00195  dice_loss 0.18778
Epoch [30/30] Validation [59/123] Loss: 0.55262  focal_loss 0.00793  dice_loss 0.54470
Epoch [30/30] Validation [60/123] Loss: 0.18097  focal_loss 0.00294  dice_loss 0.17804
Epoch [30/30] Validation [61/123] Loss: 0.54074  focal_loss 0.00231  dice_loss 0.53843
Epoch [30/30] Validation [62/123] Loss: 0.45786  focal_loss 0.01909  dice_loss 0.43877
Epoch [30/30] Validation [63/123] Loss: 0.28824  focal_loss 0.00155  dice_loss 0.28669
Epoch [30/30] Validation [64/123] Loss: 0.34912  focal_loss 0.01132  dice_loss 0.33779
Epoch [30/30] Validation [65/123] Loss: 0.16568  focal_loss 0.00117  dice_loss 0.16450
Epoch [30/30] Validation [66/123] Loss: 0.16300  focal_loss 0.00126  dice_loss 0.16174
Epoch [30/30] Validation [67/123] Loss: 0.33678  focal_loss 0.00825  dice_loss 0.32853
Epoch [30/30] Validation [68/123] Loss: 0.28004  focal_loss 0.00094  dice_loss 0.27910
Epoch [30/30] Validation [69/123] Loss: 0.37029  focal_loss 0.00804  dice_loss 0.36225
Epoch [30/30] Validation [70/123] Loss: 0.27583  focal_loss 0.00245  dice_loss 0.27338
Epoch [30/30] Validation [71/123] Loss: 0.14441  focal_loss 0.00097  dice_loss 0.14344
Epoch [30/30] Validation [72/123] Loss: 0.14054  focal_loss 0.00168  dice_loss 0.13886
Epoch [30/30] Validation [73/123] Loss: 0.23128  focal_loss 0.00323  dice_loss 0.22805
Epoch [30/30] Validation [74/123] Loss: 0.22114  focal_loss 0.00180  dice_loss 0.21934
Epoch [30/30] Validation [75/123] Loss: 0.17175  focal_loss 0.00140  dice_loss 0.17036
Epoch [30/30] Validation [76/123] Loss: 0.44302  focal_loss 0.00520  dice_loss 0.43782
Epoch [30/30] Validation [77/123] Loss: 0.29103  focal_loss 0.00075  dice_loss 0.29028
Epoch [30/30] Validation [78/123] Loss: 0.19809  focal_loss 0.00139  dice_loss 0.19670
Epoch [30/30] Validation [79/123] Loss: 0.21370  focal_loss 0.00109  dice_loss 0.21260
Epoch [30/30] Validation [80/123] Loss: 0.15776  focal_loss 0.00252  dice_loss 0.15524
Epoch [30/30] Validation [81/123] Loss: 0.17748  focal_loss 0.00161  dice_loss 0.17587
Epoch [30/30] Validation [82/123] Loss: 0.14492  focal_loss 0.00122  dice_loss 0.14371
Epoch [30/30] Validation [83/123] Loss: 0.32529  focal_loss 0.01063  dice_loss 0.31466
Epoch [30/30] Validation [84/123] Loss: 0.18181  focal_loss 0.00134  dice_loss 0.18047
Epoch [30/30] Validation [85/123] Loss: 0.25653  focal_loss 0.00353  dice_loss 0.25300
Epoch [30/30] Validation [86/123] Loss: 0.15847  focal_loss 0.00123  dice_loss 0.15724
Epoch [30/30] Validation [87/123] Loss: 0.17130  focal_loss 0.00274  dice_loss 0.16856
Epoch [30/30] Validation [88/123] Loss: 0.16848  focal_loss 0.00160  dice_loss 0.16687
Epoch [30/30] Validation [89/123] Loss: 0.15107  focal_loss 0.00231  dice_loss 0.14875
Epoch [30/30] Validation [90/123] Loss: 0.20797  focal_loss 0.00175  dice_loss 0.20622
Epoch [30/30] Validation [91/123] Loss: 0.16565  focal_loss 0.00153  dice_loss 0.16412
Epoch [30/30] Validation [92/123] Loss: 0.13294  focal_loss 0.00142  dice_loss 0.13153
Epoch [30/30] Validation [93/123] Loss: 0.14022  focal_loss 0.00183  dice_loss 0.13839
Epoch [30/30] Validation [94/123] Loss: 0.27200  focal_loss 0.00153  dice_loss 0.27047
Epoch [30/30] Validation [95/123] Loss: 0.19102  focal_loss 0.00261  dice_loss 0.18841
Epoch [30/30] Validation [96/123] Loss: 0.24512  focal_loss 0.00198  dice_loss 0.24313
Epoch [30/30] Validation [97/123] Loss: 0.55837  focal_loss 0.00709  dice_loss 0.55128
Epoch [30/30] Validation [98/123] Loss: 0.23162  focal_loss 0.00082  dice_loss 0.23080
Epoch [30/30] Validation [99/123] Loss: 0.22191  focal_loss 0.00063  dice_loss 0.22128
Epoch [30/30] Validation [100/123] Loss: 0.25422  focal_loss 0.00105  dice_loss 0.25317
Epoch [30/30] Validation [101/123] Loss: 0.21847  focal_loss 0.00100  dice_loss 0.21747
Epoch [30/30] Validation [102/123] Loss: 0.25494  focal_loss 0.00068  dice_loss 0.25426
Epoch [30/30] Validation [103/123] Loss: 0.41003  focal_loss 0.00087  dice_loss 0.40916
Epoch [30/30] Validation [104/123] Loss: 0.35055  focal_loss 0.00504  dice_loss 0.34551
Epoch [30/30] Validation [105/123] Loss: 0.15322  focal_loss 0.00314  dice_loss 0.15009
Epoch [30/30] Validation [106/123] Loss: 0.14849  focal_loss 0.00095  dice_loss 0.14754
Epoch [30/30] Validation [107/123] Loss: 0.44545  focal_loss 0.00216  dice_loss 0.44329
Epoch [30/30] Validation [108/123] Loss: 0.16086  focal_loss 0.00102  dice_loss 0.15984
Epoch [30/30] Validation [109/123] Loss: 0.17171  focal_loss 0.00555  dice_loss 0.16616
Epoch [30/30] Validation [110/123] Loss: 0.28629  focal_loss 0.00325  dice_loss 0.28304
Epoch [30/30] Validation [111/123] Loss: 0.30090  focal_loss 0.00339  dice_loss 0.29751
Epoch [30/30] Validation [112/123] Loss: 0.23185  focal_loss 0.00088  dice_loss 0.23097
Epoch [30/30] Validation [113/123] Loss: 0.19343  focal_loss 0.00174  dice_loss 0.19170
Epoch [30/30] Validation [114/123] Loss: 0.27517  focal_loss 0.00526  dice_loss 0.26991
Epoch [30/30] Validation [115/123] Loss: 0.23127  focal_loss 0.00626  dice_loss 0.22501
Epoch [30/30] Validation [116/123] Loss: 0.17658  focal_loss 0.00059  dice_loss 0.17599
Epoch [30/30] Validation [117/123] Loss: 0.19629  focal_loss 0.00115  dice_loss 0.19514
Epoch [30/30] Validation [118/123] Loss: 0.12615  focal_loss 0.00210  dice_loss 0.12405
Epoch [30/30] Validation [119/123] Loss: 0.14580  focal_loss 0.00165  dice_loss 0.14415
Epoch [30/30] Validation [120/123] Loss: 0.17536  focal_loss 0.00191  dice_loss 0.17344
Epoch [30/30] Validation [121/123] Loss: 0.61515  focal_loss 0.02157  dice_loss 0.59358
Epoch [30/30] Validation [122/123] Loss: 0.47877  focal_loss 0.00060  dice_loss 0.47817
Epoch [30/30] Validation [123/123] Loss: 0.17496  focal_loss 0.00182  dice_loss 0.17314
Epoch [30/30] Validation metric {'Val/mean dice_metric': 0.9069671630859375, 'Val/TC dice_metric': 0.923249363899231, 'Val/WT dice_metric': 0.9417749047279358, 'Val/ET dice_metric': 0.855877161026001}
Epoch [30/30] lr = [3.942649342761117e-06, 3.942649342761117e-06] best acc: tensor([0.9066], device='cuda:0'), mean acc: tensor([0.9070], device='cuda:0'), mean class: tensor([0.9232, 0.9418, 0.8559], device='cuda:0')
best dice mean acc: tensor([0.9070], device='cuda:0')
best dice accs: tensor([0.9232, 0.9418, 0.8559], device='cuda:0')
PS D:\Luisa\luisa\Slim-UNETR-nuevo\Slim-UNETR-main>