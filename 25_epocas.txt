Epoch [14/25] Training [223/488] Loss: 0.43571
Epoch [14/25] Training [224/488] Loss: 0.32490
Epoch [14/25] Training [225/488] Loss: 0.38424
Epoch [14/25] Training [226/488] Loss: 0.58367
Epoch [14/25] Training [227/488] Loss: 0.35745
Epoch [14/25] Training [228/488] Loss: 0.53185
Epoch [14/25] Training [229/488] Loss: 0.35626
Epoch [14/25] Training [230/488] Loss: 0.24033
Epoch [14/25] Training [231/488] Loss: 0.30781
Epoch [14/25] Training [232/488] Loss: 0.40267
Epoch [14/25] Training [233/488] Loss: 0.23501
Epoch [14/25] Training [234/488] Loss: 0.40017
Epoch [14/25] Training [235/488] Loss: 0.25099
Epoch [14/25] Training [236/488] Loss: 0.75566
Epoch [14/25] Training [237/488] Loss: 0.53747
Epoch [14/25] Training [238/488] Loss: 0.31813
Epoch [14/25] Training [239/488] Loss: 0.34572
Epoch [14/25] Training [240/488] Loss: 0.36108
Epoch [14/25] Training [241/488] Loss: 0.37157
Epoch [14/25] Training [242/488] Loss: 0.39029
Epoch [14/25] Training [243/488] Loss: 0.35050
Epoch [14/25] Training [244/488] Loss: 0.44416
Epoch [14/25] Training [245/488] Loss: 0.21089
Epoch [14/25] Training [246/488] Loss: 0.26909
Epoch [14/25] Training [247/488] Loss: 0.62805
Epoch [14/25] Training [248/488] Loss: 0.30046
Epoch [14/25] Training [249/488] Loss: 0.24427
Epoch [14/25] Training [250/488] Loss: 0.32633
Epoch [14/25] Training [251/488] Loss: 0.46478
Epoch [14/25] Training [252/488] Loss: 0.46759
Epoch [14/25] Training [253/488] Loss: 0.56653
Epoch [14/25] Training [254/488] Loss: 0.74932
Epoch [14/25] Training [255/488] Loss: 0.61915
Epoch [14/25] Training [256/488] Loss: 0.27578
Epoch [14/25] Training [257/488] Loss: 0.25060
Epoch [14/25] Training [258/488] Loss: 0.28276
Epoch [14/25] Training [259/488] Loss: 0.28613
Epoch [14/25] Training [260/488] Loss: 0.44903
Epoch [14/25] Training [261/488] Loss: 0.32932
Epoch [14/25] Training [262/488] Loss: 0.32801
Epoch [14/25] Training [263/488] Loss: 0.27135
Epoch [14/25] Training [264/488] Loss: 0.27773
Epoch [14/25] Training [265/488] Loss: 0.42238
Epoch [14/25] Training [266/488] Loss: 0.42349
Epoch [14/25] Training [267/488] Loss: 0.58296
Epoch [14/25] Training [268/488] Loss: 0.27321
Epoch [14/25] Training [269/488] Loss: 0.42951
Epoch [14/25] Training [270/488] Loss: 0.35346
Epoch [14/25] Training [271/488] Loss: 0.23138
Epoch [14/25] Training [272/488] Loss: 0.30951
Epoch [14/25] Training [273/488] Loss: 0.49399
Epoch [14/25] Training [274/488] Loss: 0.33804
Epoch [14/25] Training [275/488] Loss: 0.29805
Epoch [14/25] Training [276/488] Loss: 0.31658
Epoch [14/25] Training [277/488] Loss: 0.35311
Epoch [14/25] Training [278/488] Loss: 0.45390
Epoch [14/25] Training [279/488] Loss: 0.46279
Epoch [14/25] Training [280/488] Loss: 0.26715
Epoch [14/25] Training [281/488] Loss: 0.23481
Epoch [14/25] Training [282/488] Loss: 0.52700
Epoch [14/25] Training [283/488] Loss: 0.74218
Epoch [14/25] Training [284/488] Loss: 0.37750
Epoch [14/25] Training [285/488] Loss: 0.40469
Epoch [14/25] Training [286/488] Loss: 0.50551
Epoch [14/25] Training [287/488] Loss: 0.58412
Epoch [14/25] Training [288/488] Loss: 0.40576
Epoch [14/25] Training [289/488] Loss: 0.35167
Epoch [14/25] Training [290/488] Loss: 0.44314
Epoch [14/25] Training [291/488] Loss: 0.40622
Epoch [14/25] Training [292/488] Loss: 0.32516
Epoch [14/25] Training [293/488] Loss: 0.42700
Epoch [14/25] Training [294/488] Loss: 0.31241
Epoch [14/25] Training [295/488] Loss: 0.22554
Epoch [14/25] Training [296/488] Loss: 0.25942
Epoch [14/25] Training [297/488] Loss: 0.44369
Epoch [14/25] Training [298/488] Loss: 0.30120
Epoch [14/25] Training [299/488] Loss: 0.35620
Epoch [14/25] Training [300/488] Loss: 0.26731
Epoch [14/25] Training [301/488] Loss: 0.41394
Epoch [14/25] Training [302/488] Loss: 0.27033
Epoch [14/25] Training [303/488] Loss: 0.49844
Epoch [14/25] Training [304/488] Loss: 0.28774
Epoch [14/25] Training [305/488] Loss: 0.24101
Epoch [14/25] Training [306/488] Loss: 0.43572
Epoch [14/25] Training [307/488] Loss: 0.24767
Epoch [14/25] Training [308/488] Loss: 0.30619
Epoch [14/25] Training [309/488] Loss: 0.56608
Epoch [14/25] Training [310/488] Loss: 0.25730
Epoch [14/25] Training [311/488] Loss: 0.57938
Epoch [14/25] Training [312/488] Loss: 0.30596
Epoch [14/25] Training [313/488] Loss: 0.27764
Epoch [14/25] Training [314/488] Loss: 0.30634
Epoch [14/25] Training [315/488] Loss: 0.21140
Epoch [14/25] Training [316/488] Loss: 0.26539
Epoch [14/25] Training [317/488] Loss: 0.57324
Epoch [14/25] Training [318/488] Loss: 0.36363
Epoch [14/25] Training [319/488] Loss: 0.26738
Epoch [14/25] Training [320/488] Loss: 0.31545
Epoch [14/25] Training [321/488] Loss: 0.39397
Epoch [14/25] Training [322/488] Loss: 0.56191
Epoch [14/25] Training [323/488] Loss: 0.39986
Epoch [14/25] Training [324/488] Loss: 0.47570
Epoch [14/25] Training [325/488] Loss: 0.22183
Epoch [14/25] Training [326/488] Loss: 0.24040
Epoch [14/25] Training [327/488] Loss: 0.40901
Epoch [14/25] Training [328/488] Loss: 0.23072
Epoch [14/25] Training [329/488] Loss: 0.65648
Epoch [14/25] Training [330/488] Loss: 0.49048
Epoch [14/25] Training [331/488] Loss: 0.26025
Epoch [14/25] Training [332/488] Loss: 0.27438
Epoch [14/25] Training [333/488] Loss: 0.41959
Epoch [14/25] Training [334/488] Loss: 0.36675
Epoch [14/25] Training [335/488] Loss: 0.50266
Epoch [14/25] Training [336/488] Loss: 0.37174
Epoch [14/25] Training [337/488] Loss: 0.55660
Epoch [14/25] Training [338/488] Loss: 0.35326
Epoch [14/25] Training [339/488] Loss: 0.31768
Epoch [14/25] Training [340/488] Loss: 0.45450
Epoch [14/25] Training [341/488] Loss: 0.35082
Epoch [14/25] Training [342/488] Loss: 0.42024
Epoch [14/25] Training [343/488] Loss: 0.25604
Epoch [14/25] Training [344/488] Loss: 0.28777
Epoch [14/25] Training [345/488] Loss: 0.30216
Epoch [14/25] Training [346/488] Loss: 0.39543
Epoch [14/25] Training [347/488] Loss: 0.34705
Epoch [14/25] Training [348/488] Loss: 0.40001
Epoch [14/25] Training [349/488] Loss: 0.37230
Epoch [14/25] Training [350/488] Loss: 0.53442
Epoch [14/25] Training [351/488] Loss: 0.69909
Epoch [14/25] Training [352/488] Loss: 0.29073
Epoch [14/25] Training [353/488] Loss: 0.23861
Epoch [14/25] Training [354/488] Loss: 0.85539
Epoch [14/25] Training [355/488] Loss: 0.40027
Epoch [14/25] Training [356/488] Loss: 0.40313
Epoch [14/25] Training [357/488] Loss: 0.34076
Epoch [14/25] Training [358/488] Loss: 0.29311
Epoch [14/25] Training [359/488] Loss: 0.27657
Epoch [14/25] Training [360/488] Loss: 0.54950
Epoch [14/25] Training [361/488] Loss: 0.19898
Epoch [14/25] Training [362/488] Loss: 0.28970
Epoch [14/25] Training [363/488] Loss: 0.22985
Epoch [14/25] Training [364/488] Loss: 0.42631
Epoch [14/25] Training [365/488] Loss: 0.27897
Epoch [14/25] Training [366/488] Loss: 0.32521
Epoch [14/25] Training [367/488] Loss: 0.41382
Epoch [14/25] Training [368/488] Loss: 0.58521
Epoch [14/25] Training [369/488] Loss: 0.30431
Epoch [14/25] Training [370/488] Loss: 0.30476
Epoch [14/25] Training [371/488] Loss: 0.25337
Epoch [14/25] Training [372/488] Loss: 0.66609
Epoch [14/25] Training [373/488] Loss: 0.32685
Epoch [14/25] Training [374/488] Loss: 0.31073
Epoch [14/25] Training [375/488] Loss: 0.32203
Epoch [14/25] Training [376/488] Loss: 0.20589
Epoch [14/25] Training [377/488] Loss: 0.47057
Epoch [14/25] Training [378/488] Loss: 0.66789
Epoch [14/25] Training [379/488] Loss: 0.22717
Epoch [14/25] Training [380/488] Loss: 0.33966
Epoch [14/25] Training [381/488] Loss: 0.29851
Epoch [14/25] Training [382/488] Loss: 0.29005
Epoch [14/25] Training [383/488] Loss: 0.36281
Epoch [14/25] Training [384/488] Loss: 0.47273
Epoch [14/25] Training [385/488] Loss: 0.24777
Epoch [14/25] Training [386/488] Loss: 0.23589
Epoch [14/25] Training [387/488] Loss: 0.28809
Epoch [14/25] Training [388/488] Loss: 0.37307
Epoch [14/25] Training [389/488] Loss: 0.31900
Epoch [14/25] Training [390/488] Loss: 0.33730
Epoch [14/25] Training [391/488] Loss: 0.56119
Epoch [14/25] Training [392/488] Loss: 0.29029
Epoch [14/25] Training [393/488] Loss: 0.41344
Epoch [14/25] Training [394/488] Loss: 0.20547
Epoch [14/25] Training [395/488] Loss: 0.31063
Epoch [14/25] Training [396/488] Loss: 0.35968
Epoch [14/25] Training [397/488] Loss: 0.39549
Epoch [14/25] Training [398/488] Loss: 0.29761
Epoch [14/25] Training [399/488] Loss: 0.34063
Epoch [14/25] Training [400/488] Loss: 0.26844
Epoch [14/25] Training [401/488] Loss: 0.48147
Epoch [14/25] Training [402/488] Loss: 0.41862
Epoch [14/25] Training [403/488] Loss: 0.55533
Epoch [14/25] Training [404/488] Loss: 0.34346
Epoch [14/25] Training [405/488] Loss: 0.38725
Epoch [14/25] Training [406/488] Loss: 0.41376
Epoch [14/25] Training [407/488] Loss: 0.38543
Epoch [14/25] Training [408/488] Loss: 0.72461
Epoch [14/25] Training [409/488] Loss: 0.20425
Epoch [14/25] Training [410/488] Loss: 0.32809
Epoch [14/25] Training [411/488] Loss: 0.35069
Epoch [14/25] Training [412/488] Loss: 0.46839
Epoch [14/25] Training [413/488] Loss: 0.26833
Epoch [14/25] Training [414/488] Loss: 0.44546
Epoch [14/25] Training [415/488] Loss: 0.30571
Epoch [14/25] Training [416/488] Loss: 0.26886
Epoch [14/25] Training [417/488] Loss: 0.27522
Epoch [14/25] Training [418/488] Loss: 0.38053
Epoch [14/25] Training [419/488] Loss: 0.21646
Epoch [14/25] Training [420/488] Loss: 0.23875
Epoch [14/25] Training [421/488] Loss: 0.23665
Epoch [14/25] Training [422/488] Loss: 0.40868
Epoch [14/25] Training [423/488] Loss: 0.32449
Epoch [14/25] Training [424/488] Loss: 0.49876
Epoch [14/25] Training [425/488] Loss: 0.62375
Epoch [14/25] Training [426/488] Loss: 0.37074
Epoch [14/25] Training [427/488] Loss: 0.35688
Epoch [14/25] Training [428/488] Loss: 0.39109
Epoch [14/25] Training [429/488] Loss: 0.35886
Epoch [14/25] Training [430/488] Loss: 0.31616
Epoch [14/25] Training [431/488] Loss: 0.28154
Epoch [14/25] Training [432/488] Loss: 0.24450
Epoch [14/25] Training [433/488] Loss: 0.31091
Epoch [14/25] Training [434/488] Loss: 0.29599
Epoch [14/25] Training [435/488] Loss: 0.23933
Epoch [14/25] Training [436/488] Loss: 0.26042
Epoch [14/25] Training [437/488] Loss: 0.45539
Epoch [14/25] Training [438/488] Loss: 0.30004
Epoch [14/25] Training [439/488] Loss: 0.43157
Epoch [14/25] Training [440/488] Loss: 0.40078
Epoch [14/25] Training [441/488] Loss: 0.28513
Epoch [14/25] Training [442/488] Loss: 0.45851
Epoch [14/25] Training [443/488] Loss: 0.36852
Epoch [14/25] Training [444/488] Loss: 0.32206
Epoch [14/25] Training [445/488] Loss: 0.20840
Epoch [14/25] Training [446/488] Loss: 0.38257
Epoch [14/25] Training [447/488] Loss: 0.25235
Epoch [14/25] Training [448/488] Loss: 0.33741
Epoch [14/25] Training [449/488] Loss: 0.30108
Epoch [14/25] Training [450/488] Loss: 0.20109
Epoch [14/25] Training [451/488] Loss: 0.27441
Epoch [14/25] Training [452/488] Loss: 0.30298
Epoch [14/25] Training [453/488] Loss: 0.30808
Epoch [14/25] Training [454/488] Loss: 0.91694
Epoch [14/25] Training [455/488] Loss: 0.51597
Epoch [14/25] Training [456/488] Loss: 0.22086
Epoch [14/25] Training [457/488] Loss: 0.68902
Epoch [14/25] Training [458/488] Loss: 0.24519
Epoch [14/25] Training [459/488] Loss: 0.35287
Epoch [14/25] Training [460/488] Loss: 0.28599
Epoch [14/25] Training [461/488] Loss: 0.28379
Epoch [14/25] Training [462/488] Loss: 0.29187
Epoch [14/25] Training [463/488] Loss: 0.40353
Epoch [14/25] Training [464/488] Loss: 0.34381
Epoch [14/25] Training [465/488] Loss: 0.40447
Epoch [14/25] Training [466/488] Loss: 0.26352
Epoch [14/25] Training [467/488] Loss: 0.54346
Epoch [14/25] Training [468/488] Loss: 0.35202
Epoch [14/25] Training [469/488] Loss: 0.60779
Epoch [14/25] Training [470/488] Loss: 0.27272
Epoch [14/25] Training [471/488] Loss: 0.27309
Epoch [14/25] Training [472/488] Loss: 0.28883
Epoch [14/25] Training [473/488] Loss: 0.38136
Epoch [14/25] Training [474/488] Loss: 0.35744
Epoch [14/25] Training [475/488] Loss: 0.41441
Epoch [14/25] Training [476/488] Loss: 0.27933
Epoch [14/25] Training [477/488] Loss: 0.28745
Epoch [14/25] Training [478/488] Loss: 0.34827
Epoch [14/25] Training [479/488] Loss: 0.26095
Epoch [14/25] Training [480/488] Loss: 0.22051
Epoch [14/25] Training [481/488] Loss: 0.43783
Epoch [14/25] Training [482/488] Loss: 0.35240
Epoch [14/25] Training [483/488] Loss: 0.28111
Epoch [14/25] Training [484/488] Loss: 0.72703
Epoch [14/25] Training [485/488] Loss: 0.35051
Epoch [14/25] Training [486/488] Loss: 0.41413
Epoch [14/25] Training [487/488] Loss: 0.30646
Epoch [14/25] Training [488/488] Loss: 0.46040
Epoch [14/25] Training metric {'Train/mean dice_metric': 0.8526660799980164, 'Train/TC dice_metric': 0.862673282623291, 'Train/WT dice_metric': 0.9232894778251648, 'Train/ET dice_metric': 0.7720353007316589}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [14/25] Validation [1/123] Loss: 0.35221  focal_loss 0.00209  dice_loss 0.35012
Epoch [14/25] Validation [2/123] Loss: 0.53842  focal_loss 0.00101  dice_loss 0.53741
Epoch [14/25] Validation [3/123] Loss: 0.34502  focal_loss 0.00166  dice_loss 0.34335
Epoch [14/25] Validation [4/123] Loss: 0.43316  focal_loss 0.00132  dice_loss 0.43185
Epoch [14/25] Validation [5/123] Loss: 0.45942  focal_loss 0.01054  dice_loss 0.44888
Epoch [14/25] Validation [6/123] Loss: 0.49388  focal_loss 0.00128  dice_loss 0.49261
Epoch [14/25] Validation [7/123] Loss: 0.53584  focal_loss 0.00048  dice_loss 0.53536
Epoch [14/25] Validation [8/123] Loss: 0.48155  focal_loss 0.00091  dice_loss 0.48065
Epoch [14/25] Validation [9/123] Loss: 0.40250  focal_loss 0.00162  dice_loss 0.40087
Epoch [14/25] Validation [10/123] Loss: 0.61806  focal_loss 0.00170  dice_loss 0.61637
Epoch [14/25] Validation [11/123] Loss: 0.65041  focal_loss 0.00175  dice_loss 0.64866
Epoch [14/25] Validation [12/123] Loss: 0.36149  focal_loss 0.00133  dice_loss 0.36015
Epoch [14/25] Validation [13/123] Loss: 0.31684  focal_loss 0.00191  dice_loss 0.31493
Epoch [14/25] Validation [14/123] Loss: 0.43196  focal_loss 0.00128  dice_loss 0.43068
Epoch [14/25] Validation [15/123] Loss: 0.48754  focal_loss 0.00087  dice_loss 0.48666
Epoch [14/25] Validation [16/123] Loss: 0.64904  focal_loss 0.00385  dice_loss 0.64518
Epoch [14/25] Validation [17/123] Loss: 0.70336  focal_loss 0.00080  dice_loss 0.70256
Epoch [14/25] Validation [18/123] Loss: 0.55135  focal_loss 0.01232  dice_loss 0.53902
Epoch [14/25] Validation [19/123] Loss: 0.44460  focal_loss 0.00200  dice_loss 0.44261
Epoch [14/25] Validation [20/123] Loss: 0.65626  focal_loss 0.00048  dice_loss 0.65579
Epoch [14/25] Validation [21/123] Loss: 0.51344  focal_loss 0.00089  dice_loss 0.51256
Epoch [14/25] Validation [22/123] Loss: 0.73947  focal_loss 0.00324  dice_loss 0.73622
Epoch [14/25] Validation [23/123] Loss: 0.36223  focal_loss 0.00143  dice_loss 0.36080
Epoch [14/25] Validation [24/123] Loss: 0.42590  focal_loss 0.00098  dice_loss 0.42492
Epoch [14/25] Validation [25/123] Loss: 0.53835  focal_loss 0.00382  dice_loss 0.53453
Epoch [14/25] Validation [26/123] Loss: 0.36941  focal_loss 0.00116  dice_loss 0.36826
Epoch [14/25] Validation [27/123] Loss: 0.41535  focal_loss 0.00199  dice_loss 0.41335
Epoch [14/25] Validation [28/123] Loss: 0.67846  focal_loss 0.00348  dice_loss 0.67498
Epoch [14/25] Validation [29/123] Loss: 0.50075  focal_loss 0.00062  dice_loss 0.50013
Epoch [14/25] Validation [30/123] Loss: 0.42146  focal_loss 0.00699  dice_loss 0.41447
Epoch [14/25] Validation [31/123] Loss: 0.35043  focal_loss 0.00163  dice_loss 0.34880
Epoch [14/25] Validation [32/123] Loss: 0.46247  focal_loss 0.00256  dice_loss 0.45991
Epoch [14/25] Validation [33/123] Loss: 0.52096  focal_loss 0.00168  dice_loss 0.51928
Epoch [14/25] Validation [34/123] Loss: 0.47822  focal_loss 0.00210  dice_loss 0.47612
Epoch [14/25] Validation [35/123] Loss: 0.41412  focal_loss 0.00188  dice_loss 0.41224
Epoch [14/25] Validation [36/123] Loss: 0.42446  focal_loss 0.00090  dice_loss 0.42355
Epoch [14/25] Validation [37/123] Loss: 0.52473  focal_loss 0.00124  dice_loss 0.52349
Epoch [14/25] Validation [38/123] Loss: 0.41311  focal_loss 0.00197  dice_loss 0.41114
Epoch [14/25] Validation [39/123] Loss: 0.36407  focal_loss 0.00135  dice_loss 0.36273
Epoch [14/25] Validation [40/123] Loss: 0.48514  focal_loss 0.00077  dice_loss 0.48437
Epoch [14/25] Validation [41/123] Loss: 0.39247  focal_loss 0.00351  dice_loss 0.38896
Epoch [14/25] Validation [42/123] Loss: 0.35544  focal_loss 0.00122  dice_loss 0.35421
Epoch [14/25] Validation [43/123] Loss: 0.44364  focal_loss 0.00476  dice_loss 0.43888
Epoch [14/25] Validation [44/123] Loss: 0.70231  focal_loss 0.00702  dice_loss 0.69530
Epoch [14/25] Validation [45/123] Loss: 0.46074  focal_loss 0.00124  dice_loss 0.45949
Epoch [14/25] Validation [46/123] Loss: 0.49330  focal_loss 0.00241  dice_loss 0.49089
Epoch [14/25] Validation [47/123] Loss: 0.45235  focal_loss 0.00130  dice_loss 0.45105
Epoch [14/25] Validation [48/123] Loss: 0.55050  focal_loss 0.00312  dice_loss 0.54738
Epoch [14/25] Validation [49/123] Loss: 0.38172  focal_loss 0.00131  dice_loss 0.38041
Epoch [14/25] Validation [50/123] Loss: 0.34934  focal_loss 0.00176  dice_loss 0.34759
Epoch [14/25] Validation [51/123] Loss: 0.53523  focal_loss 0.00953  dice_loss 0.52570
Epoch [14/25] Validation [52/123] Loss: 0.38984  focal_loss 0.00103  dice_loss 0.38882
Epoch [14/25] Validation [53/123] Loss: 0.45549  focal_loss 0.00104  dice_loss 0.45445
Epoch [14/25] Validation [54/123] Loss: 0.50642  focal_loss 0.00171  dice_loss 0.50470
Epoch [14/25] Validation [55/123] Loss: 0.44586  focal_loss 0.00199  dice_loss 0.44387
Epoch [14/25] Validation [56/123] Loss: 0.42135  focal_loss 0.00328  dice_loss 0.41807
Epoch [14/25] Validation [57/123] Loss: 0.45681  focal_loss 0.00114  dice_loss 0.45567
Epoch [14/25] Validation [58/123] Loss: 0.40415  focal_loss 0.00247  dice_loss 0.40168
Epoch [14/25] Validation [59/123] Loss: 0.78421  focal_loss 0.01138  dice_loss 0.77284
Epoch [14/25] Validation [60/123] Loss: 0.39885  focal_loss 0.00170  dice_loss 0.39715
Epoch [14/25] Validation [61/123] Loss: 0.72375  focal_loss 0.00050  dice_loss 0.72325
Epoch [14/25] Validation [62/123] Loss: 0.62706  focal_loss 0.00217  dice_loss 0.62489
Epoch [14/25] Validation [63/123] Loss: 0.55018  focal_loss 0.00089  dice_loss 0.54930
Epoch [14/25] Validation [64/123] Loss: 0.44726  focal_loss 0.00247  dice_loss 0.44479
Epoch [14/25] Validation [65/123] Loss: 0.39106  focal_loss 0.00106  dice_loss 0.39000
Epoch [14/25] Validation [66/123] Loss: 0.40755  focal_loss 0.00088  dice_loss 0.40667
Epoch [14/25] Validation [67/123] Loss: 0.51636  focal_loss 0.00700  dice_loss 0.50936
Epoch [14/25] Validation [68/123] Loss: 0.54099  focal_loss 0.00073  dice_loss 0.54027
Epoch [14/25] Validation [69/123] Loss: 0.42298  focal_loss 0.00297  dice_loss 0.42001
Epoch [14/25] Validation [70/123] Loss: 0.46659  focal_loss 0.00172  dice_loss 0.46487
Epoch [14/25] Validation [71/123] Loss: 0.41018  focal_loss 0.00098  dice_loss 0.40920
Epoch [14/25] Validation [72/123] Loss: 0.38438  focal_loss 0.00227  dice_loss 0.38211
Epoch [14/25] Validation [73/123] Loss: 0.49150  focal_loss 0.00358  dice_loss 0.48792
Epoch [14/25] Validation [74/123] Loss: 0.49131  focal_loss 0.00285  dice_loss 0.48846
Epoch [14/25] Validation [75/123] Loss: 0.46688  focal_loss 0.00166  dice_loss 0.46522
Epoch [14/25] Validation [76/123] Loss: 0.55088  focal_loss 0.00331  dice_loss 0.54757
Epoch [14/25] Validation [77/123] Loss: 0.54471  focal_loss 0.00087  dice_loss 0.54385
Epoch [14/25] Validation [78/123] Loss: 0.41304  focal_loss 0.00177  dice_loss 0.41127
Epoch [14/25] Validation [79/123] Loss: 0.48359  focal_loss 0.00168  dice_loss 0.48191
Epoch [14/25] Validation [80/123] Loss: 0.37226  focal_loss 0.00221  dice_loss 0.37005
Epoch [14/25] Validation [81/123] Loss: 0.44489  focal_loss 0.00283  dice_loss 0.44207
Epoch [14/25] Validation [82/123] Loss: 0.37156  focal_loss 0.00061  dice_loss 0.37095
Epoch [14/25] Validation [83/123] Loss: 0.47014  focal_loss 0.00797  dice_loss 0.46217
Epoch [14/25] Validation [84/123] Loss: 0.41909  focal_loss 0.00135  dice_loss 0.41774
Epoch [14/25] Validation [85/123] Loss: 0.46288  focal_loss 0.00242  dice_loss 0.46046
Epoch [14/25] Validation [86/123] Loss: 0.37441  focal_loss 0.00132  dice_loss 0.37309
Epoch [14/25] Validation [87/123] Loss: 0.32810  focal_loss 0.00175  dice_loss 0.32635
Epoch [14/25] Validation [88/123] Loss: 0.40128  focal_loss 0.00146  dice_loss 0.39982
Epoch [14/25] Validation [89/123] Loss: 0.33241  focal_loss 0.00153  dice_loss 0.33088
Epoch [14/25] Validation [90/123] Loss: 0.46465  focal_loss 0.00136  dice_loss 0.46330
Epoch [14/25] Validation [91/123] Loss: 0.40881  focal_loss 0.00157  dice_loss 0.40724
Epoch [14/25] Validation [92/123] Loss: 0.34244  focal_loss 0.00082  dice_loss 0.34162
Epoch [14/25] Validation [93/123] Loss: 0.38484  focal_loss 0.00188  dice_loss 0.38297
Epoch [14/25] Validation [94/123] Loss: 0.50421  focal_loss 0.00159  dice_loss 0.50262
Epoch [14/25] Validation [95/123] Loss: 0.37875  focal_loss 0.00180  dice_loss 0.37695
Epoch [14/25] Validation [96/123] Loss: 0.49339  focal_loss 0.00186  dice_loss 0.49153
Epoch [14/25] Validation [97/123] Loss: 0.67704  focal_loss 0.01021  dice_loss 0.66684
Epoch [14/25] Validation [98/123] Loss: 0.48619  focal_loss 0.00125  dice_loss 0.48495
Epoch [14/25] Validation [99/123] Loss: 0.49344  focal_loss 0.00068  dice_loss 0.49276
Epoch [14/25] Validation [100/123] Loss: 0.51793  focal_loss 0.00104  dice_loss 0.51689
Epoch [14/25] Validation [101/123] Loss: 0.44650  focal_loss 0.00116  dice_loss 0.44534
Epoch [14/25] Validation [102/123] Loss: 0.51446  focal_loss 0.00072  dice_loss 0.51374
Epoch [14/25] Validation [103/123] Loss: 0.61183  focal_loss 0.00032  dice_loss 0.61152
Epoch [14/25] Validation [104/123] Loss: 0.56685  focal_loss 0.00208  dice_loss 0.56478
Epoch [14/25] Validation [105/123] Loss: 0.33485  focal_loss 0.00233  dice_loss 0.33252
Epoch [14/25] Validation [106/123] Loss: 0.40453  focal_loss 0.00092  dice_loss 0.40361
Epoch [14/25] Validation [107/123] Loss: 0.67657  focal_loss 0.00217  dice_loss 0.67440
Epoch [14/25] Validation [108/123] Loss: 0.39641  focal_loss 0.00055  dice_loss 0.39586
Epoch [14/25] Validation [109/123] Loss: 0.32926  focal_loss 0.00319  dice_loss 0.32607
Epoch [14/25] Validation [110/123] Loss: 0.47845  focal_loss 0.00175  dice_loss 0.47671
Epoch [14/25] Validation [111/123] Loss: 0.53787  focal_loss 0.00234  dice_loss 0.53553
Epoch [14/25] Validation [112/123] Loss: 0.49439  focal_loss 0.00083  dice_loss 0.49356
Epoch [14/25] Validation [113/123] Loss: 0.44364  focal_loss 0.00262  dice_loss 0.44102
Epoch [14/25] Validation [114/123] Loss: 0.48269  focal_loss 0.00535  dice_loss 0.47734
Epoch [14/25] Validation [115/123] Loss: 0.39372  focal_loss 0.00387  dice_loss 0.38985
Epoch [14/25] Validation [116/123] Loss: 0.43512  focal_loss 0.00077  dice_loss 0.43435
Epoch [14/25] Validation [117/123] Loss: 0.41885  focal_loss 0.00123  dice_loss 0.41762
Epoch [14/25] Validation [118/123] Loss: 0.33436  focal_loss 0.00182  dice_loss 0.33254
Epoch [14/25] Validation [119/123] Loss: 0.37211  focal_loss 0.00117  dice_loss 0.37094
Epoch [14/25] Validation [120/123] Loss: 0.39776  focal_loss 0.00252  dice_loss 0.39523
Epoch [14/25] Validation [121/123] Loss: 0.69818  focal_loss 0.01662  dice_loss 0.68156
Epoch [14/25] Validation [122/123] Loss: 0.75102  focal_loss 0.00015  dice_loss 0.75087
Epoch [14/25] Validation [123/123] Loss: 0.36754  focal_loss 0.00140  dice_loss 0.36614
Epoch [14/25] Validation metric {'Val/mean dice_metric': 0.8521685600280762, 'Val/TC dice_metric': 0.8600653409957886, 'Val/WT dice_metric': 0.923202633857727, 'Val/ET dice_metric': 0.7732376456260681}
Epoch [14/25] lr = [0.0006545084971874737, 0.0006545084971874737] best acc: tensor([0.8448], device='cuda:0'), mean acc: tensor([0.8522], device='cuda:0'), mean class: tensor([0.8601, 0.9232, 0.7732], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [15/25] Training [1/488] Loss: 0.33265
Epoch [15/25] Training [2/488] Loss: 0.39906
Epoch [15/25] Training [3/488] Loss: 0.41684
Epoch [15/25] Training [4/488] Loss: 0.30267
Epoch [15/25] Training [5/488] Loss: 0.40747
Epoch [15/25] Training [6/488] Loss: 0.43832
Epoch [15/25] Training [7/488] Loss: 0.29886
Epoch [15/25] Training [8/488] Loss: 0.36407
Epoch [15/25] Training [9/488] Loss: 0.32884
Epoch [15/25] Training [10/488] Loss: 0.32624
Epoch [15/25] Training [11/488] Loss: 0.24906
Epoch [15/25] Training [12/488] Loss: 0.28549
Epoch [15/25] Training [13/488] Loss: 0.54623
Epoch [15/25] Training [14/488] Loss: 0.19795
Epoch [15/25] Training [15/488] Loss: 0.19431
Epoch [15/25] Training [16/488] Loss: 0.37852
Epoch [15/25] Training [17/488] Loss: 0.65122
Epoch [15/25] Training [18/488] Loss: 0.34550
Epoch [15/25] Training [19/488] Loss: 0.35426
Epoch [15/25] Training [20/488] Loss: 0.26682
Epoch [15/25] Training [21/488] Loss: 0.27366
Epoch [15/25] Training [22/488] Loss: 0.22983
Epoch [15/25] Training [23/488] Loss: 0.25275
Epoch [15/25] Training [24/488] Loss: 0.23385
Epoch [15/25] Training [25/488] Loss: 0.24824
Epoch [15/25] Training [26/488] Loss: 0.37136
Epoch [15/25] Training [27/488] Loss: 0.22463
Epoch [15/25] Training [28/488] Loss: 0.24092
Epoch [15/25] Training [29/488] Loss: 0.20544
Epoch [15/25] Training [30/488] Loss: 0.28405
Epoch [15/25] Training [31/488] Loss: 0.28868
Epoch [15/25] Training [32/488] Loss: 0.21138
Epoch [15/25] Training [33/488] Loss: 0.32920
Epoch [15/25] Training [34/488] Loss: 0.25751
Epoch [15/25] Training [35/488] Loss: 0.63492
Epoch [15/25] Training [36/488] Loss: 0.55995
Epoch [15/25] Training [37/488] Loss: 0.24406
Epoch [15/25] Training [38/488] Loss: 0.38357
Epoch [15/25] Training [39/488] Loss: 0.50528
Epoch [15/25] Training [40/488] Loss: 0.29476
Epoch [15/25] Training [41/488] Loss: 0.29564
Epoch [15/25] Training [42/488] Loss: 0.40644
Epoch [15/25] Training [43/488] Loss: 0.25559
Epoch [15/25] Training [44/488] Loss: 0.38254
Epoch [15/25] Training [45/488] Loss: 0.32999
Epoch [15/25] Training [46/488] Loss: 0.32755
Epoch [15/25] Training [47/488] Loss: 0.29414
Epoch [15/25] Training [48/488] Loss: 0.25128
Epoch [15/25] Training [49/488] Loss: 0.53834
Epoch [15/25] Training [50/488] Loss: 0.32654
Epoch [15/25] Training [51/488] Loss: 0.29477
Epoch [15/25] Training [52/488] Loss: 0.22044
Epoch [15/25] Training [53/488] Loss: 0.23652
Epoch [15/25] Training [54/488] Loss: 0.68982
Epoch [15/25] Training [55/488] Loss: 0.53557
Epoch [15/25] Training [56/488] Loss: 0.33369
Epoch [15/25] Training [57/488] Loss: 0.39308
Epoch [15/25] Training [58/488] Loss: 0.34809
Epoch [15/25] Training [59/488] Loss: 0.31618
Epoch [15/25] Training [60/488] Loss: 0.34535
Epoch [15/25] Training [61/488] Loss: 0.28045
Epoch [15/25] Training [62/488] Loss: 0.20858
Epoch [15/25] Training [63/488] Loss: 0.38081
Epoch [15/25] Training [64/488] Loss: 0.44343
Epoch [15/25] Training [65/488] Loss: 0.20393
Epoch [15/25] Training [66/488] Loss: 0.30854
Epoch [15/25] Training [67/488] Loss: 0.29826
Epoch [15/25] Training [68/488] Loss: 0.27036
Epoch [15/25] Training [69/488] Loss: 0.36951
Epoch [15/25] Training [70/488] Loss: 0.30105
Epoch [15/25] Training [71/488] Loss: 0.41584
Epoch [15/25] Training [72/488] Loss: 0.23835
Epoch [15/25] Training [73/488] Loss: 0.30469
Epoch [15/25] Training [74/488] Loss: 0.28002
Epoch [15/25] Training [75/488] Loss: 0.36380
Epoch [15/25] Training [76/488] Loss: 0.20780
Epoch [15/25] Training [77/488] Loss: 0.27476
Epoch [15/25] Training [78/488] Loss: 0.22516
Epoch [15/25] Training [79/488] Loss: 0.34436
Epoch [15/25] Training [80/488] Loss: 0.43672
Epoch [15/25] Training [81/488] Loss: 0.29975
Epoch [15/25] Training [82/488] Loss: 0.34806
Epoch [15/25] Training [83/488] Loss: 0.34367
Epoch [15/25] Training [84/488] Loss: 0.28553
Epoch [15/25] Training [85/488] Loss: 0.53530
Epoch [15/25] Training [86/488] Loss: 0.40183
Epoch [15/25] Training [87/488] Loss: 0.19912
Epoch [15/25] Training [88/488] Loss: 0.26838
Epoch [15/25] Training [89/488] Loss: 0.27495
Epoch [15/25] Training [90/488] Loss: 0.33282
Epoch [15/25] Training [91/488] Loss: 0.43839
Epoch [15/25] Training [92/488] Loss: 0.31733
Epoch [15/25] Training [93/488] Loss: 0.21551
Epoch [15/25] Training [94/488] Loss: 0.21276
Epoch [15/25] Training [95/488] Loss: 0.51205
Epoch [15/25] Training [96/488] Loss: 0.39149
Epoch [15/25] Training [97/488] Loss: 0.23409
Epoch [15/25] Training [98/488] Loss: 0.33903
Epoch [15/25] Training [99/488] Loss: 0.90543
Epoch [15/25] Training [100/488] Loss: 0.23018
Epoch [15/25] Training [101/488] Loss: 0.39465
Epoch [15/25] Training [102/488] Loss: 0.21312
Epoch [15/25] Training [103/488] Loss: 0.34791
Epoch [15/25] Training [104/488] Loss: 0.37971
Epoch [15/25] Training [105/488] Loss: 0.33390
Epoch [15/25] Training [106/488] Loss: 0.26005
Epoch [15/25] Training [107/488] Loss: 0.31547
Epoch [15/25] Training [108/488] Loss: 0.33608
Epoch [15/25] Training [109/488] Loss: 0.36779
Epoch [15/25] Training [110/488] Loss: 0.24173
Epoch [15/25] Training [111/488] Loss: 0.24791
Epoch [15/25] Training [112/488] Loss: 0.22720
Epoch [15/25] Training [113/488] Loss: 0.25001
Epoch [15/25] Training [114/488] Loss: 0.61090
Epoch [15/25] Training [115/488] Loss: 0.39301
Epoch [15/25] Training [116/488] Loss: 0.22540
Epoch [15/25] Training [117/488] Loss: 0.46506
Epoch [15/25] Training [118/488] Loss: 0.34888
Epoch [15/25] Training [119/488] Loss: 0.23544
Epoch [15/25] Training [120/488] Loss: 0.46337
Epoch [15/25] Training [121/488] Loss: 0.36417
Epoch [15/25] Training [122/488] Loss: 0.29588
Epoch [15/25] Training [123/488] Loss: 0.32299
Epoch [15/25] Training [124/488] Loss: 0.43978
Epoch [15/25] Training [125/488] Loss: 0.43785
Epoch [15/25] Training [126/488] Loss: 0.32289
Epoch [15/25] Training [127/488] Loss: 0.25060
Epoch [15/25] Training [128/488] Loss: 0.26541
Epoch [15/25] Training [129/488] Loss: 0.28780
Epoch [15/25] Training [130/488] Loss: 0.31881
Epoch [15/25] Training [131/488] Loss: 0.27450
Epoch [15/25] Training [132/488] Loss: 0.24796
Epoch [15/25] Training [133/488] Loss: 0.19045
Epoch [15/25] Training [134/488] Loss: 0.22388
Epoch [15/25] Training [135/488] Loss: 0.30973
Epoch [15/25] Training [136/488] Loss: 0.44634
Epoch [15/25] Training [137/488] Loss: 0.27732
Epoch [15/25] Training [138/488] Loss: 0.36900
Epoch [15/25] Training [139/488] Loss: 0.22302
Epoch [15/25] Training [140/488] Loss: 0.29690
Epoch [15/25] Training [141/488] Loss: 0.29291
Epoch [15/25] Training [142/488] Loss: 0.30497
Epoch [15/25] Training [143/488] Loss: 0.26971
Epoch [15/25] Training [144/488] Loss: 0.26871
Epoch [15/25] Training [145/488] Loss: 0.23620
Epoch [15/25] Training [146/488] Loss: 0.29871
Epoch [15/25] Training [147/488] Loss: 0.53202
Epoch [15/25] Training [148/488] Loss: 0.39245
Epoch [15/25] Training [149/488] Loss: 0.28193
Epoch [15/25] Training [150/488] Loss: 0.21651
Epoch [15/25] Training [151/488] Loss: 0.26921
Epoch [15/25] Training [152/488] Loss: 0.28337
Epoch [15/25] Training [153/488] Loss: 0.30417
Epoch [15/25] Training [154/488] Loss: 0.66930
Epoch [15/25] Training [155/488] Loss: 0.34835
Epoch [15/25] Training [156/488] Loss: 0.33148
Epoch [15/25] Training [157/488] Loss: 0.25480
Epoch [15/25] Training [158/488] Loss: 0.29435
Epoch [15/25] Training [159/488] Loss: 0.28993
Epoch [15/25] Training [160/488] Loss: 0.28608
Epoch [15/25] Training [161/488] Loss: 0.32828
Epoch [15/25] Training [162/488] Loss: 0.29388
Epoch [15/25] Training [163/488] Loss: 0.55154
Epoch [15/25] Training [164/488] Loss: 0.26837
Epoch [15/25] Training [165/488] Loss: 0.45653
Epoch [15/25] Training [166/488] Loss: 0.45070
Epoch [15/25] Training [167/488] Loss: 0.24422
Epoch [15/25] Training [168/488] Loss: 0.56457
Epoch [15/25] Training [169/488] Loss: 0.26939
Epoch [15/25] Training [170/488] Loss: 0.42947
Epoch [15/25] Training [171/488] Loss: 0.33818
Epoch [15/25] Training [172/488] Loss: 0.39383
Epoch [15/25] Training [173/488] Loss: 0.28437
Epoch [15/25] Training [174/488] Loss: 0.35670
Epoch [15/25] Training [175/488] Loss: 0.40243
Epoch [15/25] Training [176/488] Loss: 0.33569
Epoch [15/25] Training [177/488] Loss: 0.53742
Epoch [15/25] Training [178/488] Loss: 0.27835
Epoch [15/25] Training [179/488] Loss: 0.45131
Epoch [15/25] Training [180/488] Loss: 0.25078
Epoch [15/25] Training [181/488] Loss: 0.40783
Epoch [15/25] Training [182/488] Loss: 0.36930
Epoch [15/25] Training [183/488] Loss: 0.24991
Epoch [15/25] Training [184/488] Loss: 0.19849
Epoch [15/25] Training [185/488] Loss: 0.37028
Epoch [15/25] Training [186/488] Loss: 0.42328
Epoch [15/25] Training [187/488] Loss: 0.37353
Epoch [15/25] Training [188/488] Loss: 0.35002
Epoch [15/25] Training [189/488] Loss: 0.34204
Epoch [15/25] Training [190/488] Loss: 0.23158
Epoch [15/25] Training [191/488] Loss: 0.25087
Epoch [15/25] Training [192/488] Loss: 0.52276
Epoch [15/25] Training [193/488] Loss: 0.28031
Epoch [15/25] Training [194/488] Loss: 0.25903
Epoch [15/25] Training [195/488] Loss: 0.23024
Epoch [15/25] Training [196/488] Loss: 0.52891
Epoch [15/25] Training [197/488] Loss: 0.26882
Epoch [15/25] Training [198/488] Loss: 0.53888
Epoch [15/25] Training [199/488] Loss: 0.71128
Epoch [15/25] Training [200/488] Loss: 0.28910
Epoch [15/25] Training [201/488] Loss: 0.25408
Epoch [15/25] Training [202/488] Loss: 0.34930
Epoch [15/25] Training [203/488] Loss: 0.56254
Epoch [15/25] Training [204/488] Loss: 0.23165
Epoch [15/25] Training [205/488] Loss: 0.20570
Epoch [15/25] Training [206/488] Loss: 0.44194
Epoch [15/25] Training [207/488] Loss: 0.48179
Epoch [15/25] Training [208/488] Loss: 0.28670
Epoch [15/25] Training [209/488] Loss: 0.35397
Epoch [15/25] Training [210/488] Loss: 0.38720
Epoch [15/25] Training [211/488] Loss: 0.21266
Epoch [15/25] Training [212/488] Loss: 0.46009
Epoch [15/25] Training [213/488] Loss: 0.23230
Epoch [15/25] Training [214/488] Loss: 0.23746
Epoch [15/25] Training [215/488] Loss: 0.25044
Epoch [15/25] Training [216/488] Loss: 0.44974
Epoch [15/25] Training [217/488] Loss: 0.49432
Epoch [15/25] Training [218/488] Loss: 0.29863
Epoch [15/25] Training [219/488] Loss: 0.34488
Epoch [15/25] Training [220/488] Loss: 0.23998
Epoch [15/25] Training [221/488] Loss: 0.43567
Epoch [15/25] Training [222/488] Loss: 0.33578
Epoch [15/25] Training [223/488] Loss: 0.45077
Epoch [15/25] Training [224/488] Loss: 0.73974
Epoch [15/25] Training [225/488] Loss: 0.43922
Epoch [15/25] Training [226/488] Loss: 0.45983
Epoch [15/25] Training [227/488] Loss: 0.43818
Epoch [15/25] Training [228/488] Loss: 0.27827
Epoch [15/25] Training [229/488] Loss: 0.33462
Epoch [15/25] Training [230/488] Loss: 0.24659
Epoch [15/25] Training [231/488] Loss: 0.30856
Epoch [15/25] Training [232/488] Loss: 0.63171
Epoch [15/25] Training [233/488] Loss: 0.35486
Epoch [15/25] Training [234/488] Loss: 0.39798
Epoch [15/25] Training [235/488] Loss: 0.19426
Epoch [15/25] Training [236/488] Loss: 0.24033
Epoch [15/25] Training [237/488] Loss: 0.30556
Epoch [15/25] Training [238/488] Loss: 0.51983
Epoch [15/25] Training [239/488] Loss: 0.23279
Epoch [15/25] Training [240/488] Loss: 0.28080
Epoch [15/25] Training [241/488] Loss: 0.31916
Epoch [15/25] Training [242/488] Loss: 0.24240
Epoch [15/25] Training [243/488] Loss: 0.25450
Epoch [15/25] Training [244/488] Loss: 0.19764
Epoch [15/25] Training [245/488] Loss: 0.43839
Epoch [15/25] Training [246/488] Loss: 0.19728
Epoch [15/25] Training [247/488] Loss: 0.32171
Epoch [15/25] Training [248/488] Loss: 0.43267
Epoch [15/25] Training [249/488] Loss: 0.20338
Epoch [15/25] Training [250/488] Loss: 0.35982
Epoch [15/25] Training [251/488] Loss: 0.71079
Epoch [15/25] Training [252/488] Loss: 0.31878
Epoch [15/25] Training [253/488] Loss: 0.80973
Epoch [15/25] Training [254/488] Loss: 0.29358
Epoch [15/25] Training [255/488] Loss: 0.20166
Epoch [15/25] Training [256/488] Loss: 0.22685
Epoch [15/25] Training [257/488] Loss: 0.19750
Epoch [15/25] Training [258/488] Loss: 0.56249
Epoch [15/25] Training [259/488] Loss: 0.25229
Epoch [15/25] Training [260/488] Loss: 0.35263
Epoch [15/25] Training [261/488] Loss: 0.51859
Epoch [15/25] Training [262/488] Loss: 0.19577
Epoch [15/25] Training [263/488] Loss: 0.38948
Epoch [15/25] Training [264/488] Loss: 0.44491
Epoch [15/25] Training [265/488] Loss: 0.35471
Epoch [15/25] Training [266/488] Loss: 0.61862
Epoch [15/25] Training [267/488] Loss: 0.25644
Epoch [15/25] Training [268/488] Loss: 0.25035
Epoch [15/25] Training [269/488] Loss: 0.40024
Epoch [15/25] Training [270/488] Loss: 0.34037
Epoch [15/25] Training [271/488] Loss: 0.19250
Epoch [15/25] Training [272/488] Loss: 0.29121
Epoch [15/25] Training [273/488] Loss: 0.22720
Epoch [15/25] Training [274/488] Loss: 0.25934
Epoch [15/25] Training [275/488] Loss: 0.49790
Epoch [15/25] Training [276/488] Loss: 0.18205
Epoch [15/25] Training [277/488] Loss: 0.26576
Epoch [15/25] Training [278/488] Loss: 0.56842
Epoch [15/25] Training [279/488] Loss: 0.39730
Epoch [15/25] Training [280/488] Loss: 0.59345
Epoch [15/25] Training [281/488] Loss: 0.46488
Epoch [15/25] Training [282/488] Loss: 0.22410
Epoch [15/25] Training [283/488] Loss: 0.30924
Epoch [15/25] Training [284/488] Loss: 0.21384
Epoch [15/25] Training [285/488] Loss: 0.23482
Epoch [15/25] Training [286/488] Loss: 0.39289
Epoch [15/25] Training [287/488] Loss: 0.24160
Epoch [15/25] Training [288/488] Loss: 0.58118
Epoch [15/25] Training [289/488] Loss: 0.28895
Epoch [15/25] Training [290/488] Loss: 0.60126
Epoch [15/25] Training [291/488] Loss: 0.48961
Epoch [15/25] Training [292/488] Loss: 0.67746
Epoch [15/25] Training [293/488] Loss: 0.31329
Epoch [15/25] Training [294/488] Loss: 0.28394
Epoch [15/25] Training [295/488] Loss: 0.47237
Epoch [15/25] Training [296/488] Loss: 0.43029
Epoch [15/25] Training [297/488] Loss: 0.50446
Epoch [15/25] Training [298/488] Loss: 0.24140
Epoch [15/25] Training [299/488] Loss: 0.26080
Epoch [15/25] Training [300/488] Loss: 0.46146
Epoch [15/25] Training [301/488] Loss: 0.35764
Epoch [15/25] Training [302/488] Loss: 0.36172
Epoch [15/25] Training [303/488] Loss: 0.21692
Epoch [15/25] Training [304/488] Loss: 0.63982
Epoch [15/25] Training [305/488] Loss: 0.20674
Epoch [15/25] Training [306/488] Loss: 0.20218
Epoch [15/25] Training [307/488] Loss: 0.24831
Epoch [15/25] Training [308/488] Loss: 0.38272
Epoch [15/25] Training [309/488] Loss: 0.27715
Epoch [15/25] Training [310/488] Loss: 0.23113
Epoch [15/25] Training [311/488] Loss: 0.37933
Epoch [15/25] Training [312/488] Loss: 0.23343
Epoch [15/25] Training [313/488] Loss: 0.22552
Epoch [15/25] Training [314/488] Loss: 0.21868
Epoch [15/25] Training [315/488] Loss: 0.19994
Epoch [15/25] Training [316/488] Loss: 0.22781
Epoch [15/25] Training [317/488] Loss: 0.36532
Epoch [15/25] Training [318/488] Loss: 0.19697
Epoch [15/25] Training [319/488] Loss: 0.65156
Epoch [15/25] Training [320/488] Loss: 0.22849
Epoch [15/25] Training [321/488] Loss: 0.34859
Epoch [15/25] Training [322/488] Loss: 0.28010
Epoch [15/25] Training [323/488] Loss: 0.63797
Epoch [15/25] Training [324/488] Loss: 0.30935
Epoch [15/25] Training [325/488] Loss: 0.27551
Epoch [15/25] Training [326/488] Loss: 0.56397
Epoch [15/25] Training [327/488] Loss: 0.31328
Epoch [15/25] Training [328/488] Loss: 0.23887
Epoch [15/25] Training [329/488] Loss: 0.33411
Epoch [15/25] Training [330/488] Loss: 1.07305
Epoch [15/25] Training [331/488] Loss: 0.28533
Epoch [15/25] Training [332/488] Loss: 0.50163
Epoch [15/25] Training [333/488] Loss: 0.24019
Epoch [15/25] Training [334/488] Loss: 0.41335
Epoch [15/25] Training [335/488] Loss: 0.19762
Epoch [15/25] Training [336/488] Loss: 0.30872
Epoch [15/25] Training [337/488] Loss: 0.28798
Epoch [15/25] Training [338/488] Loss: 0.28403
Epoch [15/25] Training [339/488] Loss: 0.37028
Epoch [15/25] Training [340/488] Loss: 0.25497
Epoch [15/25] Training [341/488] Loss: 0.37116
Epoch [15/25] Training [342/488] Loss: 0.21172
Epoch [15/25] Training [343/488] Loss: 0.29370
Epoch [15/25] Training [344/488] Loss: 0.38266
Epoch [15/25] Training [345/488] Loss: 0.29371
Epoch [15/25] Training [346/488] Loss: 0.56738
Epoch [15/25] Training [347/488] Loss: 0.33741
Epoch [15/25] Training [348/488] Loss: 0.27026
Epoch [15/25] Training [349/488] Loss: 0.35434
Epoch [15/25] Training [350/488] Loss: 0.30323
Epoch [15/25] Training [351/488] Loss: 0.37126
Epoch [15/25] Training [352/488] Loss: 0.19310
Epoch [15/25] Training [353/488] Loss: 0.32789
Epoch [15/25] Training [354/488] Loss: 0.26241
Epoch [15/25] Training [355/488] Loss: 0.45717
Epoch [15/25] Training [356/488] Loss: 0.36056
Epoch [15/25] Training [357/488] Loss: 0.34688
Epoch [15/25] Training [358/488] Loss: 0.38337
Epoch [15/25] Training [359/488] Loss: 0.47911
Epoch [15/25] Training [360/488] Loss: 0.33327
Epoch [15/25] Training [361/488] Loss: 0.29509
Epoch [15/25] Training [362/488] Loss: 0.34007
Epoch [15/25] Training [363/488] Loss: 0.71196
Epoch [15/25] Training [364/488] Loss: 0.20967
Epoch [15/25] Training [365/488] Loss: 0.22145
Epoch [15/25] Training [366/488] Loss: 0.19474
Epoch [15/25] Training [367/488] Loss: 0.29929
Epoch [15/25] Training [368/488] Loss: 0.60392
Epoch [15/25] Training [369/488] Loss: 0.18813
Epoch [15/25] Training [370/488] Loss: 0.24646
Epoch [15/25] Training [371/488] Loss: 0.27202
Epoch [15/25] Training [372/488] Loss: 0.42799
Epoch [15/25] Training [373/488] Loss: 0.17326
Epoch [15/25] Training [374/488] Loss: 0.43213
Epoch [15/25] Training [375/488] Loss: 0.41732
Epoch [15/25] Training [376/488] Loss: 0.18034
Epoch [15/25] Training [377/488] Loss: 0.33998
Epoch [15/25] Training [378/488] Loss: 0.28487
Epoch [15/25] Training [379/488] Loss: 0.30198
Epoch [15/25] Training [380/488] Loss: 0.22882
Epoch [15/25] Training [381/488] Loss: 0.24999
Epoch [15/25] Training [382/488] Loss: 0.23372
Epoch [15/25] Training [383/488] Loss: 0.39244
Epoch [15/25] Training [384/488] Loss: 0.72505
Epoch [15/25] Training [385/488] Loss: 0.17774
Epoch [15/25] Training [386/488] Loss: 0.25097
Epoch [15/25] Training [387/488] Loss: 0.24615
Epoch [15/25] Training [388/488] Loss: 0.20005
Epoch [15/25] Training [389/488] Loss: 0.23203
Epoch [15/25] Training [390/488] Loss: 0.47996
Epoch [15/25] Training [391/488] Loss: 0.30248
Epoch [15/25] Training [392/488] Loss: 0.37393
Epoch [15/25] Training [393/488] Loss: 0.24953
Epoch [15/25] Training [394/488] Loss: 0.40677
Epoch [15/25] Training [395/488] Loss: 0.26893
Epoch [15/25] Training [396/488] Loss: 0.21235
Epoch [15/25] Training [397/488] Loss: 0.42497
Epoch [15/25] Training [398/488] Loss: 0.27785
Epoch [15/25] Training [399/488] Loss: 0.56968
Epoch [15/25] Training [400/488] Loss: 0.21579
Epoch [15/25] Training [401/488] Loss: 0.38406
Epoch [15/25] Training [402/488] Loss: 0.41300
Epoch [15/25] Training [403/488] Loss: 0.21018
Epoch [15/25] Training [404/488] Loss: 0.29456
Epoch [15/25] Training [405/488] Loss: 0.20079
Epoch [15/25] Training [406/488] Loss: 0.33898
Epoch [15/25] Training [407/488] Loss: 0.21056
Epoch [15/25] Training [408/488] Loss: 0.46938
Epoch [15/25] Training [409/488] Loss: 0.33401
Epoch [15/25] Training [410/488] Loss: 0.20855
Epoch [15/25] Training [411/488] Loss: 0.16635
Epoch [15/25] Training [412/488] Loss: 0.21818
Epoch [15/25] Training [413/488] Loss: 0.22242
Epoch [15/25] Training [414/488] Loss: 0.21728
Epoch [15/25] Training [415/488] Loss: 0.20977
Epoch [15/25] Training [416/488] Loss: 0.32056
Epoch [15/25] Training [417/488] Loss: 0.26940
Epoch [15/25] Training [418/488] Loss: 0.19825
Epoch [15/25] Training [419/488] Loss: 0.17545
Epoch [15/25] Training [420/488] Loss: 0.20205
Epoch [15/25] Training [421/488] Loss: 0.35128
Epoch [15/25] Training [422/488] Loss: 0.27727
Epoch [15/25] Training [423/488] Loss: 0.36746
Epoch [15/25] Training [424/488] Loss: 0.28884
Epoch [15/25] Training [425/488] Loss: 0.35247
Epoch [15/25] Training [426/488] Loss: 0.22384
Epoch [15/25] Training [427/488] Loss: 0.23244
Epoch [15/25] Training [428/488] Loss: 0.17804
Epoch [15/25] Training [429/488] Loss: 0.57816
Epoch [15/25] Training [430/488] Loss: 0.44349
Epoch [15/25] Training [431/488] Loss: 0.33664
Epoch [15/25] Training [432/488] Loss: 0.31127
Epoch [15/25] Training [433/488] Loss: 0.17742
Epoch [15/25] Training [434/488] Loss: 0.50352
Epoch [15/25] Training [435/488] Loss: 0.71029
Epoch [15/25] Training [436/488] Loss: 0.33599
Epoch [15/25] Training [437/488] Loss: 0.20303
Epoch [15/25] Training [438/488] Loss: 0.31461
Epoch [15/25] Training [439/488] Loss: 0.39985
Epoch [15/25] Training [440/488] Loss: 0.23235
Epoch [15/25] Training [441/488] Loss: 0.24423
Epoch [15/25] Training [442/488] Loss: 0.75636
Epoch [15/25] Training [443/488] Loss: 0.22761
Epoch [15/25] Training [444/488] Loss: 0.40303
Epoch [15/25] Training [445/488] Loss: 0.36968
Epoch [15/25] Training [446/488] Loss: 0.48286
Epoch [15/25] Training [447/488] Loss: 0.31863
Epoch [15/25] Training [448/488] Loss: 0.32086
Epoch [15/25] Training [449/488] Loss: 0.37371
Epoch [15/25] Training [450/488] Loss: 0.61369
Epoch [15/25] Training [451/488] Loss: 0.26990
Epoch [15/25] Training [452/488] Loss: 0.32701
Epoch [15/25] Training [453/488] Loss: 0.39592
Epoch [15/25] Training [454/488] Loss: 0.22711
Epoch [15/25] Training [455/488] Loss: 0.45308
Epoch [15/25] Training [456/488] Loss: 0.24955
Epoch [15/25] Training [457/488] Loss: 0.29394
Epoch [15/25] Training [458/488] Loss: 0.24602
Epoch [15/25] Training [459/488] Loss: 0.25644
Epoch [15/25] Training [460/488] Loss: 0.35049
Epoch [15/25] Training [461/488] Loss: 0.23171
Epoch [15/25] Training [462/488] Loss: 0.26804
Epoch [15/25] Training [463/488] Loss: 0.26877
Epoch [15/25] Training [464/488] Loss: 0.48121
Epoch [15/25] Training [465/488] Loss: 0.29366
Epoch [15/25] Training [466/488] Loss: 0.21923
Epoch [15/25] Training [467/488] Loss: 0.22449
Epoch [15/25] Training [468/488] Loss: 0.19652
Epoch [15/25] Training [469/488] Loss: 0.30525
Epoch [15/25] Training [470/488] Loss: 0.35280
Epoch [15/25] Training [471/488] Loss: 0.43609
Epoch [15/25] Training [472/488] Loss: 0.21682
Epoch [15/25] Training [473/488] Loss: 0.37946
Epoch [15/25] Training [474/488] Loss: 0.63499
Epoch [15/25] Training [475/488] Loss: 0.31439
Epoch [15/25] Training [476/488] Loss: 0.17557
Epoch [15/25] Training [477/488] Loss: 0.33312
Epoch [15/25] Training [478/488] Loss: 0.24643
Epoch [15/25] Training [479/488] Loss: 0.28637
Epoch [15/25] Training [480/488] Loss: 0.24821
Epoch [15/25] Training [481/488] Loss: 0.20607
Epoch [15/25] Training [482/488] Loss: 0.37396
Epoch [15/25] Training [483/488] Loss: 0.31692
Epoch [15/25] Training [484/488] Loss: 0.26358
Epoch [15/25] Training [485/488] Loss: 0.32121
Epoch [15/25] Training [486/488] Loss: 0.24251
Epoch [15/25] Training [487/488] Loss: 0.36136
Epoch [15/25] Training [488/488] Loss: 0.25802
Epoch [15/25] Training metric {'Train/mean dice_metric': 0.8611793518066406, 'Train/TC dice_metric': 0.8765720725059509, 'Train/WT dice_metric': 0.9254063963890076, 'Train/ET dice_metric': 0.7815596461296082}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [15/25] Validation [1/123] Loss: 0.31691  focal_loss 0.00206  dice_loss 0.31485
Epoch [15/25] Validation [2/123] Loss: 0.49283  focal_loss 0.00089  dice_loss 0.49194
Epoch [15/25] Validation [3/123] Loss: 0.31160  focal_loss 0.00168  dice_loss 0.30992
Epoch [15/25] Validation [4/123] Loss: 0.40020  focal_loss 0.00150  dice_loss 0.39870
Epoch [15/25] Validation [5/123] Loss: 0.41533  focal_loss 0.00792  dice_loss 0.40741
Epoch [15/25] Validation [6/123] Loss: 0.49218  focal_loss 0.00307  dice_loss 0.48911
Epoch [15/25] Validation [7/123] Loss: 0.49433  focal_loss 0.00059  dice_loss 0.49374
Epoch [15/25] Validation [8/123] Loss: 0.44770  focal_loss 0.00121  dice_loss 0.44649
Epoch [15/25] Validation [9/123] Loss: 0.37062  focal_loss 0.00135  dice_loss 0.36927
Epoch [15/25] Validation [10/123] Loss: 0.60946  focal_loss 0.00327  dice_loss 0.60619
Epoch [15/25] Validation [11/123] Loss: 0.59922  focal_loss 0.00170  dice_loss 0.59752
Epoch [15/25] Validation [12/123] Loss: 0.32924  focal_loss 0.00166  dice_loss 0.32757
Epoch [15/25] Validation [13/123] Loss: 0.30092  focal_loss 0.00301  dice_loss 0.29791
Epoch [15/25] Validation [14/123] Loss: 0.39332  focal_loss 0.00184  dice_loss 0.39148
Epoch [15/25] Validation [15/123] Loss: 0.47207  focal_loss 0.00131  dice_loss 0.47076
Epoch [15/25] Validation [16/123] Loss: 0.54899  focal_loss 0.00106  dice_loss 0.54794
Epoch [15/25] Validation [17/123] Loss: 0.62104  focal_loss 0.00105  dice_loss 0.61999
Epoch [15/25] Validation [18/123] Loss: 0.44242  focal_loss 0.00297  dice_loss 0.43945
Epoch [15/25] Validation [19/123] Loss: 0.40866  focal_loss 0.00316  dice_loss 0.40550
Epoch [15/25] Validation [20/123] Loss: 0.59648  focal_loss 0.00044  dice_loss 0.59604
Epoch [15/25] Validation [21/123] Loss: 0.53032  focal_loss 0.00221  dice_loss 0.52811
Epoch [15/25] Validation [22/123] Loss: 0.71895  focal_loss 0.00361  dice_loss 0.71534
Epoch [15/25] Validation [23/123] Loss: 0.32113  focal_loss 0.00178  dice_loss 0.31934
Epoch [15/25] Validation [24/123] Loss: 0.40266  focal_loss 0.00200  dice_loss 0.40065
Epoch [15/25] Validation [25/123] Loss: 0.47955  focal_loss 0.00273  dice_loss 0.47683
Epoch [15/25] Validation [26/123] Loss: 0.34158  focal_loss 0.00168  dice_loss 0.33990
Epoch [15/25] Validation [27/123] Loss: 0.41788  focal_loss 0.00493  dice_loss 0.41295
Epoch [15/25] Validation [28/123] Loss: 0.62447  focal_loss 0.00260  dice_loss 0.62187
Epoch [15/25] Validation [29/123] Loss: 0.55306  focal_loss 0.00548  dice_loss 0.54758
Epoch [15/25] Validation [30/123] Loss: 0.35448  focal_loss 0.00401  dice_loss 0.35047
Epoch [15/25] Validation [31/123] Loss: 0.31699  focal_loss 0.00153  dice_loss 0.31546
Epoch [15/25] Validation [32/123] Loss: 0.42445  focal_loss 0.00275  dice_loss 0.42171
Epoch [15/25] Validation [33/123] Loss: 0.45529  focal_loss 0.00109  dice_loss 0.45421
Epoch [15/25] Validation [34/123] Loss: 0.53980  focal_loss 0.01121  dice_loss 0.52859
Epoch [15/25] Validation [35/123] Loss: 0.35925  focal_loss 0.00130  dice_loss 0.35795
Epoch [15/25] Validation [36/123] Loss: 0.39140  focal_loss 0.00102  dice_loss 0.39038
Epoch [15/25] Validation [37/123] Loss: 0.52776  focal_loss 0.00581  dice_loss 0.52195
Epoch [15/25] Validation [38/123] Loss: 0.36103  focal_loss 0.00125  dice_loss 0.35978
Epoch [15/25] Validation [39/123] Loss: 0.32948  focal_loss 0.00148  dice_loss 0.32799
Epoch [15/25] Validation [40/123] Loss: 0.44167  focal_loss 0.00070  dice_loss 0.44097
Epoch [15/25] Validation [41/123] Loss: 0.33372  focal_loss 0.00141  dice_loss 0.33231
Epoch [15/25] Validation [42/123] Loss: 0.31063  focal_loss 0.00126  dice_loss 0.30937
Epoch [15/25] Validation [43/123] Loss: 0.42895  focal_loss 0.01033  dice_loss 0.41862
Epoch [15/25] Validation [44/123] Loss: 0.68955  focal_loss 0.00806  dice_loss 0.68150
Epoch [15/25] Validation [45/123] Loss: 0.43701  focal_loss 0.00176  dice_loss 0.43526
Epoch [15/25] Validation [46/123] Loss: 0.47894  focal_loss 0.00350  dice_loss 0.47544
Epoch [15/25] Validation [47/123] Loss: 0.41521  focal_loss 0.00116  dice_loss 0.41405
Epoch [15/25] Validation [48/123] Loss: 0.53363  focal_loss 0.00420  dice_loss 0.52943
Epoch [15/25] Validation [49/123] Loss: 0.34200  focal_loss 0.00129  dice_loss 0.34071
Epoch [15/25] Validation [50/123] Loss: 0.31661  focal_loss 0.00193  dice_loss 0.31469
Epoch [15/25] Validation [51/123] Loss: 0.49574  focal_loss 0.00799  dice_loss 0.48775
Epoch [15/25] Validation [52/123] Loss: 0.34867  focal_loss 0.00077  dice_loss 0.34790
Epoch [15/25] Validation [53/123] Loss: 0.41063  focal_loss 0.00081  dice_loss 0.40982
Epoch [15/25] Validation [54/123] Loss: 0.44464  focal_loss 0.00096  dice_loss 0.44368
Epoch [15/25] Validation [55/123] Loss: 0.39328  focal_loss 0.00118  dice_loss 0.39210
Epoch [15/25] Validation [56/123] Loss: 0.38178  focal_loss 0.00366  dice_loss 0.37812
Epoch [15/25] Validation [57/123] Loss: 0.42712  focal_loss 0.00306  dice_loss 0.42405
Epoch [15/25] Validation [58/123] Loss: 0.39316  focal_loss 0.00327  dice_loss 0.38989
Epoch [15/25] Validation [59/123] Loss: 0.78211  focal_loss 0.01433  dice_loss 0.76778
Epoch [15/25] Validation [60/123] Loss: 0.36731  focal_loss 0.00177  dice_loss 0.36554
Epoch [15/25] Validation [61/123] Loss: 0.73604  focal_loss 0.00200  dice_loss 0.73404
Epoch [15/25] Validation [62/123] Loss: 0.61670  focal_loss 0.00807  dice_loss 0.60862
Epoch [15/25] Validation [63/123] Loss: 0.50038  focal_loss 0.00079  dice_loss 0.49959
Epoch [15/25] Validation [64/123] Loss: 0.49982  focal_loss 0.00641  dice_loss 0.49341
Epoch [15/25] Validation [65/123] Loss: 0.36169  focal_loss 0.00122  dice_loss 0.36047
Epoch [15/25] Validation [66/123] Loss: 0.37428  focal_loss 0.00100  dice_loss 0.37329
Epoch [15/25] Validation [67/123] Loss: 0.45907  focal_loss 0.00356  dice_loss 0.45551
Epoch [15/25] Validation [68/123] Loss: 0.49067  focal_loss 0.00063  dice_loss 0.49003
Epoch [15/25] Validation [69/123] Loss: 0.41831  focal_loss 0.00442  dice_loss 0.41389
Epoch [15/25] Validation [70/123] Loss: 0.41893  focal_loss 0.00161  dice_loss 0.41732
Epoch [15/25] Validation [71/123] Loss: 0.36654  focal_loss 0.00082  dice_loss 0.36573
Epoch [15/25] Validation [72/123] Loss: 0.33230  focal_loss 0.00135  dice_loss 0.33095
Epoch [15/25] Validation [73/123] Loss: 0.45749  focal_loss 0.00427  dice_loss 0.45323
Epoch [15/25] Validation [74/123] Loss: 0.47995  focal_loss 0.00510  dice_loss 0.47486
Epoch [15/25] Validation [75/123] Loss: 0.41928  focal_loss 0.00161  dice_loss 0.41767
Epoch [15/25] Validation [76/123] Loss: 0.58305  focal_loss 0.00419  dice_loss 0.57885
Epoch [15/25] Validation [77/123] Loss: 0.49102  focal_loss 0.00070  dice_loss 0.49031
Epoch [15/25] Validation [78/123] Loss: 0.37625  focal_loss 0.00136  dice_loss 0.37489
Epoch [15/25] Validation [79/123] Loss: 0.46612  focal_loss 0.00145  dice_loss 0.46467
Epoch [15/25] Validation [80/123] Loss: 0.33419  focal_loss 0.00220  dice_loss 0.33198
Epoch [15/25] Validation [81/123] Loss: 0.39344  focal_loss 0.00154  dice_loss 0.39191
Epoch [15/25] Validation [82/123] Loss: 0.34560  focal_loss 0.00099  dice_loss 0.34461
Epoch [15/25] Validation [83/123] Loss: 0.48214  focal_loss 0.01006  dice_loss 0.47208
Epoch [15/25] Validation [84/123] Loss: 0.37908  focal_loss 0.00107  dice_loss 0.37801
Epoch [15/25] Validation [85/123] Loss: 0.42226  focal_loss 0.00283  dice_loss 0.41943
Epoch [15/25] Validation [86/123] Loss: 0.34441  focal_loss 0.00148  dice_loss 0.34293
Epoch [15/25] Validation [87/123] Loss: 0.31304  focal_loss 0.00333  dice_loss 0.30971
Epoch [15/25] Validation [88/123] Loss: 0.36956  focal_loss 0.00194  dice_loss 0.36763
Epoch [15/25] Validation [89/123] Loss: 0.30402  focal_loss 0.00163  dice_loss 0.30239
Epoch [15/25] Validation [90/123] Loss: 0.43204  focal_loss 0.00207  dice_loss 0.42997
Epoch [15/25] Validation [91/123] Loss: 0.35469  focal_loss 0.00102  dice_loss 0.35367
Epoch [15/25] Validation [92/123] Loss: 0.31164  focal_loss 0.00120  dice_loss 0.31044
Epoch [15/25] Validation [93/123] Loss: 0.32984  focal_loss 0.00131  dice_loss 0.32853
Epoch [15/25] Validation [94/123] Loss: 0.44891  focal_loss 0.00105  dice_loss 0.44786
Epoch [15/25] Validation [95/123] Loss: 0.36452  focal_loss 0.00265  dice_loss 0.36187
Epoch [15/25] Validation [96/123] Loss: 0.45140  focal_loss 0.00164  dice_loss 0.44976
Epoch [15/25] Validation [97/123] Loss: 0.63012  focal_loss 0.00512  dice_loss 0.62500
Epoch [15/25] Validation [98/123] Loss: 0.43783  focal_loss 0.00100  dice_loss 0.43683
Epoch [15/25] Validation [99/123] Loss: 0.45496  focal_loss 0.00064  dice_loss 0.45432
Epoch [15/25] Validation [100/123] Loss: 0.47177  focal_loss 0.00087  dice_loss 0.47089
Epoch [15/25] Validation [101/123] Loss: 0.41373  focal_loss 0.00139  dice_loss 0.41234
Epoch [15/25] Validation [102/123] Loss: 0.46472  focal_loss 0.00053  dice_loss 0.46419
Epoch [15/25] Validation [103/123] Loss: 0.56889  focal_loss 0.00039  dice_loss 0.56851
Epoch [15/25] Validation [104/123] Loss: 0.53777  focal_loss 0.00287  dice_loss 0.53490
Epoch [15/25] Validation [105/123] Loss: 0.32738  focal_loss 0.00353  dice_loss 0.32385
Epoch [15/25] Validation [106/123] Loss: 0.36488  focal_loss 0.00082  dice_loss 0.36406
Epoch [15/25] Validation [107/123] Loss: 0.65804  focal_loss 0.00351  dice_loss 0.65453
Epoch [15/25] Validation [108/123] Loss: 0.35904  focal_loss 0.00075  dice_loss 0.35829
Epoch [15/25] Validation [109/123] Loss: 0.31972  focal_loss 0.00516  dice_loss 0.31455
Epoch [15/25] Validation [110/123] Loss: 0.43906  focal_loss 0.00126  dice_loss 0.43780
Epoch [15/25] Validation [111/123] Loss: 0.48719  focal_loss 0.00249  dice_loss 0.48471
Epoch [15/25] Validation [112/123] Loss: 0.44849  focal_loss 0.00082  dice_loss 0.44768
Epoch [15/25] Validation [113/123] Loss: 0.36779  focal_loss 0.00105  dice_loss 0.36674
Epoch [15/25] Validation [114/123] Loss: 0.44793  focal_loss 0.00478  dice_loss 0.44315
Epoch [15/25] Validation [115/123] Loss: 0.40427  focal_loss 0.00679  dice_loss 0.39748
Epoch [15/25] Validation [116/123] Loss: 0.39248  focal_loss 0.00068  dice_loss 0.39180
Epoch [15/25] Validation [117/123] Loss: 0.38419  focal_loss 0.00117  dice_loss 0.38303
Epoch [15/25] Validation [118/123] Loss: 0.30002  focal_loss 0.00184  dice_loss 0.29818
Epoch [15/25] Validation [119/123] Loss: 0.33622  focal_loss 0.00162  dice_loss 0.33459
Epoch [15/25] Validation [120/123] Loss: 0.37713  focal_loss 0.00302  dice_loss 0.37411
Epoch [15/25] Validation [121/123] Loss: 0.67699  focal_loss 0.01336  dice_loss 0.66364
Epoch [15/25] Validation [122/123] Loss: 0.77736  focal_loss 0.00176  dice_loss 0.77560
Epoch [15/25] Validation [123/123] Loss: 0.35001  focal_loss 0.00191  dice_loss 0.34810
Epoch [15/25] Validation metric {'Val/mean dice_metric': 0.8599893450737, 'Val/TC dice_metric': 0.8755624294281006, 'Val/WT dice_metric': 0.9234273433685303, 'Val/ET dice_metric': 0.780978262424469}
Epoch [15/25] lr = [0.0005782172325201155, 0.0005782172325201155] best acc: tensor([0.8522], device='cuda:0'), mean acc: tensor([0.8600], device='cuda:0'), mean class: tensor([0.8756, 0.9234, 0.7810], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [16/25] Training [1/488] Loss: 0.24328
Epoch [16/25] Training [2/488] Loss: 0.50815
Epoch [16/25] Training [3/488] Loss: 0.25301
Epoch [16/25] Training [4/488] Loss: 0.34207
Epoch [16/25] Training [5/488] Loss: 0.41205
Epoch [16/25] Training [6/488] Loss: 0.21576
Epoch [16/25] Training [7/488] Loss: 0.25331
Epoch [16/25] Training [8/488] Loss: 0.31330
Epoch [16/25] Training [9/488] Loss: 0.18990
Epoch [16/25] Training [10/488] Loss: 0.59808
Epoch [16/25] Training [11/488] Loss: 0.22233
Epoch [16/25] Training [12/488] Loss: 0.26662
Epoch [16/25] Training [13/488] Loss: 0.27461
Epoch [16/25] Training [14/488] Loss: 0.41825
Epoch [16/25] Training [15/488] Loss: 0.23679
Epoch [16/25] Training [16/488] Loss: 0.40850
Epoch [16/25] Training [17/488] Loss: 0.21895
Epoch [16/25] Training [18/488] Loss: 0.47789
Epoch [16/25] Training [19/488] Loss: 0.44466
Epoch [16/25] Training [20/488] Loss: 0.19675
Epoch [16/25] Training [21/488] Loss: 0.37099
Epoch [16/25] Training [22/488] Loss: 0.29729
Epoch [16/25] Training [23/488] Loss: 0.42791
Epoch [16/25] Training [24/488] Loss: 0.27244
Epoch [16/25] Training [25/488] Loss: 0.51270
Epoch [16/25] Training [26/488] Loss: 0.18555
Epoch [16/25] Training [27/488] Loss: 0.55842
Epoch [16/25] Training [28/488] Loss: 0.20755
Epoch [16/25] Training [29/488] Loss: 0.61395
Epoch [16/25] Training [30/488] Loss: 0.38504
Epoch [16/25] Training [31/488] Loss: 0.22490
Epoch [16/25] Training [32/488] Loss: 0.35537
Epoch [16/25] Training [33/488] Loss: 0.42566
Epoch [16/25] Training [34/488] Loss: 0.22529
Epoch [16/25] Training [35/488] Loss: 0.17482
Epoch [16/25] Training [36/488] Loss: 0.35163
Epoch [16/25] Training [37/488] Loss: 0.27233
Epoch [16/25] Training [38/488] Loss: 0.42752
Epoch [16/25] Training [39/488] Loss: 0.23152
Epoch [16/25] Training [40/488] Loss: 0.82431
Epoch [16/25] Training [41/488] Loss: 0.33281
Epoch [16/25] Training [42/488] Loss: 0.22480
Epoch [16/25] Training [43/488] Loss: 0.30784
Epoch [16/25] Training [44/488] Loss: 0.25827
Epoch [16/25] Training [45/488] Loss: 0.43296
Epoch [16/25] Training [46/488] Loss: 0.31613
Epoch [16/25] Training [47/488] Loss: 0.26520
Epoch [16/25] Training [48/488] Loss: 0.20336
Epoch [16/25] Training [49/488] Loss: 0.23508
Epoch [16/25] Training [50/488] Loss: 0.30016
Epoch [16/25] Training [51/488] Loss: 0.32925
Epoch [16/25] Training [52/488] Loss: 0.35974
Epoch [16/25] Training [53/488] Loss: 0.46360
Epoch [16/25] Training [54/488] Loss: 0.19415
Epoch [16/25] Training [55/488] Loss: 0.34159
Epoch [16/25] Training [56/488] Loss: 0.19964
Epoch [16/25] Training [57/488] Loss: 0.24381
Epoch [16/25] Training [58/488] Loss: 0.19419
Epoch [16/25] Training [59/488] Loss: 0.25982
Epoch [16/25] Training [60/488] Loss: 0.20262
Epoch [16/25] Training [61/488] Loss: 0.27969
Epoch [16/25] Training [62/488] Loss: 0.28748
Epoch [16/25] Training [63/488] Loss: 0.28758
Epoch [16/25] Training [64/488] Loss: 0.47967
Epoch [16/25] Training [65/488] Loss: 0.33817
Epoch [16/25] Training [66/488] Loss: 0.24486
Epoch [16/25] Training [67/488] Loss: 0.30150
Epoch [16/25] Training [68/488] Loss: 0.31241
Epoch [16/25] Training [69/488] Loss: 0.47845
Epoch [16/25] Training [70/488] Loss: 0.36532
Epoch [16/25] Training [71/488] Loss: 0.31823
Epoch [16/25] Training [72/488] Loss: 0.26893
Epoch [16/25] Training [73/488] Loss: 0.20716
Epoch [16/25] Training [74/488] Loss: 0.36591
Epoch [16/25] Training [75/488] Loss: 0.25445
Epoch [16/25] Training [76/488] Loss: 0.25638
Epoch [16/25] Training [77/488] Loss: 0.23302
Epoch [16/25] Training [78/488] Loss: 0.29145
Epoch [16/25] Training [79/488] Loss: 0.62130
Epoch [16/25] Training [80/488] Loss: 0.27204
Epoch [16/25] Training [81/488] Loss: 0.18340
Epoch [16/25] Training [82/488] Loss: 0.57746
Epoch [16/25] Training [83/488] Loss: 0.25946
Epoch [16/25] Training [84/488] Loss: 0.19654
Epoch [16/25] Training [85/488] Loss: 0.63682
Epoch [16/25] Training [86/488] Loss: 0.31972
Epoch [16/25] Training [87/488] Loss: 0.29099
Epoch [16/25] Training [88/488] Loss: 0.17881
Epoch [16/25] Training [89/488] Loss: 0.19153
Epoch [16/25] Training [90/488] Loss: 0.28767
Epoch [16/25] Training [91/488] Loss: 0.26091
Epoch [16/25] Training [92/488] Loss: 0.31640
Epoch [16/25] Training [93/488] Loss: 0.24099
Epoch [16/25] Training [94/488] Loss: 0.45635
Epoch [16/25] Training [95/488] Loss: 0.17993
Epoch [16/25] Training [96/488] Loss: 0.36935
Epoch [16/25] Training [97/488] Loss: 0.31426
Epoch [16/25] Training [98/488] Loss: 0.37245
Epoch [16/25] Training [99/488] Loss: 0.33463
Epoch [16/25] Training [100/488] Loss: 0.40577
Epoch [16/25] Training [101/488] Loss: 0.25030
Epoch [16/25] Training [102/488] Loss: 0.40106
Epoch [16/25] Training [103/488] Loss: 0.30566
Epoch [16/25] Training [104/488] Loss: 0.25414
Epoch [16/25] Training [105/488] Loss: 0.38442
Epoch [16/25] Training [106/488] Loss: 0.33297
Epoch [16/25] Training [107/488] Loss: 0.36211
Epoch [16/25] Training [108/488] Loss: 0.48413
Epoch [16/25] Training [109/488] Loss: 0.17719
Epoch [16/25] Training [110/488] Loss: 0.40814
Epoch [16/25] Training [111/488] Loss: 0.58657
Epoch [16/25] Training [112/488] Loss: 0.29236
Epoch [16/25] Training [113/488] Loss: 0.20652
Epoch [16/25] Training [114/488] Loss: 0.69624
Epoch [16/25] Training [115/488] Loss: 0.30269
Epoch [16/25] Training [116/488] Loss: 0.45840
Epoch [16/25] Training [117/488] Loss: 0.22250
Epoch [16/25] Training [118/488] Loss: 0.18276
Epoch [16/25] Training [119/488] Loss: 0.27028
Epoch [16/25] Training [120/488] Loss: 0.42168
Epoch [16/25] Training [121/488] Loss: 0.29635
Epoch [16/25] Training [122/488] Loss: 0.31357
Epoch [16/25] Training [123/488] Loss: 0.24376
Epoch [16/25] Training [124/488] Loss: 0.35925
Epoch [16/25] Training [125/488] Loss: 0.40710
Epoch [16/25] Training [126/488] Loss: 0.23961
Epoch [16/25] Training [127/488] Loss: 0.44250
Epoch [16/25] Training [128/488] Loss: 0.18786
Epoch [16/25] Training [129/488] Loss: 0.26798
Epoch [16/25] Training [130/488] Loss: 0.21864
Epoch [16/25] Training [131/488] Loss: 0.24508
Epoch [16/25] Training [132/488] Loss: 0.25870
Epoch [16/25] Training [133/488] Loss: 0.22345
Epoch [16/25] Training [134/488] Loss: 0.36249
Epoch [16/25] Training [135/488] Loss: 0.52786
Epoch [16/25] Training [136/488] Loss: 0.42529
Epoch [16/25] Training [137/488] Loss: 0.26507
Epoch [16/25] Training [138/488] Loss: 0.34712
Epoch [16/25] Training [139/488] Loss: 0.19054
Epoch [16/25] Training [140/488] Loss: 0.50413
Epoch [16/25] Training [141/488] Loss: 0.34319
Epoch [16/25] Training [142/488] Loss: 0.26994
Epoch [16/25] Training [143/488] Loss: 0.26813
Epoch [16/25] Training [144/488] Loss: 0.16662
Epoch [16/25] Training [145/488] Loss: 0.45037
Epoch [16/25] Training [146/488] Loss: 0.20643
Epoch [16/25] Training [147/488] Loss: 0.20073
Epoch [16/25] Training [148/488] Loss: 0.28886
Epoch [16/25] Training [149/488] Loss: 0.32897
Epoch [16/25] Training [150/488] Loss: 0.24884
Epoch [16/25] Training [151/488] Loss: 0.33561
Epoch [16/25] Training [152/488] Loss: 0.51166
Epoch [16/25] Training [153/488] Loss: 0.17941
Epoch [16/25] Training [154/488] Loss: 0.21302
Epoch [16/25] Training [155/488] Loss: 0.63081
Epoch [16/25] Training [156/488] Loss: 0.16319
Epoch [16/25] Training [157/488] Loss: 0.21243
Epoch [16/25] Training [158/488] Loss: 0.25609
Epoch [16/25] Training [159/488] Loss: 0.22020
Epoch [16/25] Training [160/488] Loss: 0.16480
Epoch [16/25] Training [161/488] Loss: 0.31065
Epoch [16/25] Training [162/488] Loss: 0.49212
Epoch [16/25] Training [163/488] Loss: 0.20666
Epoch [16/25] Training [164/488] Loss: 0.23814
Epoch [16/25] Training [165/488] Loss: 0.35859
Epoch [16/25] Training [166/488] Loss: 0.27943
Epoch [16/25] Training [167/488] Loss: 0.25549
Epoch [16/25] Training [168/488] Loss: 0.19113
Epoch [16/25] Training [169/488] Loss: 0.51619
Epoch [16/25] Training [170/488] Loss: 0.23063
Epoch [16/25] Training [171/488] Loss: 0.27323
Epoch [16/25] Training [172/488] Loss: 0.41148
Epoch [16/25] Training [173/488] Loss: 0.48640
Epoch [16/25] Training [174/488] Loss: 0.45974
Epoch [16/25] Training [175/488] Loss: 0.37786
Epoch [16/25] Training [176/488] Loss: 0.35895
Epoch [16/25] Training [177/488] Loss: 0.26536
Epoch [16/25] Training [178/488] Loss: 0.27050
Epoch [16/25] Training [179/488] Loss: 0.31955
Epoch [16/25] Training [180/488] Loss: 0.19117
Epoch [16/25] Training [181/488] Loss: 0.25622
Epoch [16/25] Training [182/488] Loss: 0.19567
Epoch [16/25] Training [183/488] Loss: 0.31103
Epoch [16/25] Training [184/488] Loss: 0.37357
Epoch [16/25] Training [185/488] Loss: 0.19951
Epoch [16/25] Training [186/488] Loss: 0.19197
Epoch [16/25] Training [187/488] Loss: 0.50264
Epoch [16/25] Training [188/488] Loss: 0.34370
Epoch [16/25] Training [189/488] Loss: 0.17566
Epoch [16/25] Training [190/488] Loss: 0.28224
Epoch [16/25] Training [191/488] Loss: 0.21525
Epoch [16/25] Training [192/488] Loss: 0.52637
Epoch [16/25] Training [193/488] Loss: 0.53101
Epoch [16/25] Training [194/488] Loss: 0.47974
Epoch [16/25] Training [195/488] Loss: 0.46124
Epoch [16/25] Training [196/488] Loss: 0.67334
Epoch [16/25] Training [197/488] Loss: 0.64900
Epoch [16/25] Training [198/488] Loss: 0.49267
Epoch [16/25] Training [199/488] Loss: 0.72504
Epoch [16/25] Training [200/488] Loss: 0.42103
Epoch [16/25] Training [201/488] Loss: 0.18059
Epoch [16/25] Training [202/488] Loss: 0.32353
Epoch [16/25] Training [203/488] Loss: 0.35445
Epoch [16/25] Training [204/488] Loss: 0.51103
Epoch [16/25] Training [205/488] Loss: 0.25089
Epoch [16/25] Training [206/488] Loss: 0.63336
Epoch [16/25] Training [207/488] Loss: 0.47007
Epoch [16/25] Training [208/488] Loss: 0.21436
Epoch [16/25] Training [209/488] Loss: 0.39432
Epoch [16/25] Training [210/488] Loss: 0.25098
Epoch [16/25] Training [211/488] Loss: 0.34953
Epoch [16/25] Training [212/488] Loss: 0.55391
Epoch [16/25] Training [213/488] Loss: 0.21018
Epoch [16/25] Training [214/488] Loss: 0.68624
Epoch [16/25] Training [215/488] Loss: 0.23171
Epoch [16/25] Training [216/488] Loss: 0.24116
Epoch [16/25] Training [217/488] Loss: 0.96118
Epoch [16/25] Training [218/488] Loss: 0.21830
Epoch [16/25] Training [219/488] Loss: 0.16755
Epoch [16/25] Training [220/488] Loss: 0.26730
Epoch [16/25] Training [221/488] Loss: 0.32064
Epoch [16/25] Training [222/488] Loss: 0.26616
Epoch [16/25] Training [223/488] Loss: 0.22470
Epoch [16/25] Training [224/488] Loss: 0.28815
Epoch [16/25] Training [225/488] Loss: 0.25774
Epoch [16/25] Training [226/488] Loss: 0.40710
Epoch [16/25] Training [227/488] Loss: 0.24580
Epoch [16/25] Training [228/488] Loss: 0.21012
Epoch [16/25] Training [229/488] Loss: 0.16674
Epoch [16/25] Training [230/488] Loss: 0.23037
Epoch [16/25] Training [231/488] Loss: 0.23578
Epoch [16/25] Training [232/488] Loss: 0.44588
Epoch [16/25] Training [233/488] Loss: 0.23461
Epoch [16/25] Training [234/488] Loss: 0.26977
Epoch [16/25] Training [235/488] Loss: 0.26673
Epoch [16/25] Training [236/488] Loss: 0.24312
Epoch [16/25] Training [237/488] Loss: 0.20541
Epoch [16/25] Training [238/488] Loss: 0.50190
Epoch [16/25] Training [239/488] Loss: 0.19812
Epoch [16/25] Training [240/488] Loss: 0.18213
Epoch [16/25] Training [241/488] Loss: 0.27462
Epoch [16/25] Training [242/488] Loss: 0.29963
Epoch [16/25] Training [243/488] Loss: 0.30011
Epoch [16/25] Training [244/488] Loss: 0.48362
Epoch [16/25] Training [245/488] Loss: 0.18491
Epoch [16/25] Training [246/488] Loss: 0.38286
Epoch [16/25] Training [247/488] Loss: 0.24273
Epoch [16/25] Training [248/488] Loss: 0.23084
Epoch [16/25] Training [249/488] Loss: 0.24396
Epoch [16/25] Training [250/488] Loss: 0.20004
Epoch [16/25] Training [251/488] Loss: 0.24215
Epoch [16/25] Training [252/488] Loss: 0.25744
Epoch [16/25] Training [253/488] Loss: 0.24417
Epoch [16/25] Training [254/488] Loss: 0.26608
Epoch [16/25] Training [255/488] Loss: 0.29811
Epoch [16/25] Training [256/488] Loss: 0.15295
Epoch [16/25] Training [257/488] Loss: 0.16638
Epoch [16/25] Training [258/488] Loss: 0.22583
Epoch [16/25] Training [259/488] Loss: 0.85632
Epoch [16/25] Training [260/488] Loss: 0.27629
Epoch [16/25] Training [261/488] Loss: 0.34183
Epoch [16/25] Training [262/488] Loss: 0.20323
Epoch [16/25] Training [263/488] Loss: 0.27695
Epoch [16/25] Training [264/488] Loss: 0.27639
Epoch [16/25] Training [265/488] Loss: 0.17700
Epoch [16/25] Training [266/488] Loss: 0.25821
Epoch [16/25] Training [267/488] Loss: 0.24508
Epoch [16/25] Training [268/488] Loss: 0.27306
Epoch [16/25] Training [269/488] Loss: 0.36265
Epoch [16/25] Training [270/488] Loss: 0.49681
Epoch [16/25] Training [271/488] Loss: 0.24117
Epoch [16/25] Training [272/488] Loss: 0.26351
Epoch [16/25] Training [273/488] Loss: 0.15978
Epoch [16/25] Training [274/488] Loss: 0.32053
Epoch [16/25] Training [275/488] Loss: 0.35914
Epoch [16/25] Training [276/488] Loss: 0.18400
Epoch [16/25] Training [277/488] Loss: 0.22119
Epoch [16/25] Training [278/488] Loss: 0.28944
Epoch [16/25] Training [279/488] Loss: 0.19877
Epoch [16/25] Training [280/488] Loss: 0.18466
Epoch [16/25] Training [281/488] Loss: 0.62597
Epoch [16/25] Training [282/488] Loss: 0.20810
Epoch [16/25] Training [283/488] Loss: 0.26980
Epoch [16/25] Training [284/488] Loss: 0.32572
Epoch [16/25] Training [285/488] Loss: 0.25495
Epoch [16/25] Training [286/488] Loss: 0.26032
Epoch [16/25] Training [287/488] Loss: 0.27407
Epoch [16/25] Training [288/488] Loss: 0.25438
Epoch [16/25] Training [289/488] Loss: 0.29232
Epoch [16/25] Training [290/488] Loss: 0.19089
Epoch [16/25] Training [291/488] Loss: 0.22330
Epoch [16/25] Training [292/488] Loss: 0.34858
Epoch [16/25] Training [293/488] Loss: 0.18057
Epoch [16/25] Training [294/488] Loss: 0.19042
Epoch [16/25] Training [295/488] Loss: 0.34915
Epoch [16/25] Training [296/488] Loss: 0.17302
Epoch [16/25] Training [297/488] Loss: 0.81453
Epoch [16/25] Training [298/488] Loss: 0.30365
Epoch [16/25] Training [299/488] Loss: 0.28051
Epoch [16/25] Training [300/488] Loss: 0.22756
Epoch [16/25] Training [301/488] Loss: 0.22707
Epoch [16/25] Training [302/488] Loss: 0.52888
Epoch [16/25] Training [303/488] Loss: 0.34832
Epoch [16/25] Training [304/488] Loss: 0.41230
Epoch [16/25] Training [305/488] Loss: 0.38646
Epoch [16/25] Training [306/488] Loss: 0.33080
Epoch [16/25] Training [307/488] Loss: 0.21289
Epoch [16/25] Training [308/488] Loss: 0.26272
Epoch [16/25] Training [309/488] Loss: 0.59494
Epoch [16/25] Training [310/488] Loss: 0.32215
Epoch [16/25] Training [311/488] Loss: 0.21222
Epoch [16/25] Training [312/488] Loss: 0.48980
Epoch [16/25] Training [313/488] Loss: 0.34477
Epoch [16/25] Training [314/488] Loss: 0.37530
Epoch [16/25] Training [315/488] Loss: 0.24965
Epoch [16/25] Training [316/488] Loss: 0.30032
Epoch [16/25] Training [317/488] Loss: 0.30656
Epoch [16/25] Training [318/488] Loss: 0.30018
Epoch [16/25] Training [319/488] Loss: 0.34518
Epoch [16/25] Training [320/488] Loss: 0.42717
Epoch [16/25] Training [321/488] Loss: 0.37951
Epoch [16/25] Training [322/488] Loss: 0.21719
Epoch [16/25] Training [323/488] Loss: 0.29547
Epoch [16/25] Training [324/488] Loss: 0.17095
Epoch [16/25] Training [325/488] Loss: 0.17565
Epoch [16/25] Training [326/488] Loss: 0.17521
Epoch [16/25] Training [327/488] Loss: 0.25687
Epoch [16/25] Training [328/488] Loss: 0.33011
Epoch [16/25] Training [329/488] Loss: 0.23683
Epoch [16/25] Training [330/488] Loss: 0.16967
Epoch [16/25] Training [331/488] Loss: 0.38356
Epoch [16/25] Training [332/488] Loss: 0.22016
Epoch [16/25] Training [333/488] Loss: 0.31944
Epoch [16/25] Training [334/488] Loss: 0.45269
Epoch [16/25] Training [335/488] Loss: 0.19091
Epoch [16/25] Training [336/488] Loss: 0.31189
Epoch [16/25] Training [337/488] Loss: 0.23817
Epoch [16/25] Training [338/488] Loss: 0.41939
Epoch [16/25] Training [339/488] Loss: 0.38872
Epoch [16/25] Training [340/488] Loss: 0.41190
Epoch [16/25] Training [341/488] Loss: 0.32841
Epoch [16/25] Training [342/488] Loss: 0.27395
Epoch [16/25] Training [343/488] Loss: 0.20692
Epoch [16/25] Training [344/488] Loss: 0.18428
Epoch [16/25] Training [345/488] Loss: 0.31738
Epoch [16/25] Training [346/488] Loss: 0.51161
Epoch [16/25] Training [347/488] Loss: 0.29139
Epoch [16/25] Training [348/488] Loss: 0.34323
Epoch [16/25] Training [349/488] Loss: 0.18212
Epoch [16/25] Training [350/488] Loss: 0.17434
Epoch [16/25] Training [351/488] Loss: 0.37004
Epoch [16/25] Training [352/488] Loss: 0.23517
Epoch [16/25] Training [353/488] Loss: 0.18661
Epoch [16/25] Training [354/488] Loss: 0.34948
Epoch [16/25] Training [355/488] Loss: 0.23043
Epoch [16/25] Training [356/488] Loss: 0.20204
Epoch [16/25] Training [357/488] Loss: 0.20124
Epoch [16/25] Training [358/488] Loss: 0.31437
Epoch [16/25] Training [359/488] Loss: 0.18383
Epoch [16/25] Training [360/488] Loss: 0.19146
Epoch [16/25] Training [361/488] Loss: 0.23489
Epoch [16/25] Training [362/488] Loss: 0.27898
Epoch [16/25] Training [363/488] Loss: 0.30205
Epoch [16/25] Training [364/488] Loss: 0.18520
Epoch [16/25] Training [365/488] Loss: 0.18525
Epoch [16/25] Training [366/488] Loss: 0.27776
Epoch [16/25] Training [367/488] Loss: 0.23153
Epoch [16/25] Training [368/488] Loss: 0.44085
Epoch [16/25] Training [369/488] Loss: 0.42350
Epoch [16/25] Training [370/488] Loss: 0.73743
Epoch [16/25] Training [371/488] Loss: 0.18204
Epoch [16/25] Training [372/488] Loss: 0.18590
Epoch [16/25] Training [373/488] Loss: 0.32200
Epoch [16/25] Training [374/488] Loss: 0.25363
Epoch [16/25] Training [375/488] Loss: 0.28964
Epoch [16/25] Training [376/488] Loss: 0.23561
Epoch [16/25] Training [377/488] Loss: 0.35059
Epoch [16/25] Training [378/488] Loss: 0.21256
Epoch [16/25] Training [379/488] Loss: 0.16547
Epoch [16/25] Training [380/488] Loss: 0.39219
Epoch [16/25] Training [381/488] Loss: 0.18854
Epoch [16/25] Training [382/488] Loss: 0.51642
Epoch [16/25] Training [383/488] Loss: 0.34009
Epoch [16/25] Training [384/488] Loss: 0.51550
Epoch [16/25] Training [385/488] Loss: 0.18533
Epoch [16/25] Training [386/488] Loss: 0.47480
Epoch [16/25] Training [387/488] Loss: 0.29331
Epoch [16/25] Training [388/488] Loss: 0.26520
Epoch [16/25] Training [389/488] Loss: 0.23619
Epoch [16/25] Training [390/488] Loss: 0.27733
Epoch [16/25] Training [391/488] Loss: 0.18967
Epoch [16/25] Training [392/488] Loss: 0.52862
Epoch [16/25] Training [393/488] Loss: 0.24849
Epoch [16/25] Training [394/488] Loss: 0.28527
Epoch [16/25] Training [395/488] Loss: 0.17761
Epoch [16/25] Training [396/488] Loss: 0.20989
Epoch [16/25] Training [397/488] Loss: 0.31046
Epoch [16/25] Training [398/488] Loss: 0.28046
Epoch [16/25] Training [399/488] Loss: 0.31177
Epoch [16/25] Training [400/488] Loss: 0.40871
Epoch [16/25] Training [401/488] Loss: 0.21342
Epoch [16/25] Training [402/488] Loss: 0.19076
Epoch [16/25] Training [403/488] Loss: 0.28830
Epoch [16/25] Training [404/488] Loss: 0.26126
Epoch [16/25] Training [405/488] Loss: 0.19919
Epoch [16/25] Training [406/488] Loss: 0.30069
Epoch [16/25] Training [407/488] Loss: 0.21807
Epoch [16/25] Training [408/488] Loss: 0.21657
Epoch [16/25] Training [409/488] Loss: 0.16144
Epoch [16/25] Training [410/488] Loss: 0.30240
Epoch [16/25] Training [411/488] Loss: 0.44912
Epoch [16/25] Training [412/488] Loss: 0.20093
Epoch [16/25] Training [413/488] Loss: 0.57324
Epoch [16/25] Training [414/488] Loss: 0.18375
Epoch [16/25] Training [415/488] Loss: 0.26813
Epoch [16/25] Training [416/488] Loss: 0.21249
Epoch [16/25] Training [417/488] Loss: 0.38165
Epoch [16/25] Training [418/488] Loss: 0.68815
Epoch [16/25] Training [419/488] Loss: 0.40487
Epoch [16/25] Training [420/488] Loss: 0.20622
Epoch [16/25] Training [421/488] Loss: 0.42003
Epoch [16/25] Training [422/488] Loss: 0.20532
Epoch [16/25] Training [423/488] Loss: 0.25577
Epoch [16/25] Training [424/488] Loss: 0.49277
Epoch [16/25] Training [425/488] Loss: 0.21781
Epoch [16/25] Training [426/488] Loss: 0.27046
Epoch [16/25] Training [427/488] Loss: 0.29045
Epoch [16/25] Training [428/488] Loss: 0.21905
Epoch [16/25] Training [429/488] Loss: 0.24934
Epoch [16/25] Training [430/488] Loss: 0.34477
Epoch [16/25] Training [431/488] Loss: 0.32918
Epoch [16/25] Training [432/488] Loss: 0.20130
Epoch [16/25] Training [433/488] Loss: 0.20949
Epoch [16/25] Training [434/488] Loss: 0.24164
Epoch [16/25] Training [435/488] Loss: 0.24446
Epoch [16/25] Training [436/488] Loss: 0.23532
Epoch [16/25] Training [437/488] Loss: 0.28438
Epoch [16/25] Training [438/488] Loss: 0.23344
Epoch [16/25] Training [439/488] Loss: 0.20717
Epoch [16/25] Training [440/488] Loss: 0.16737
Epoch [16/25] Training [441/488] Loss: 0.39116
Epoch [16/25] Training [442/488] Loss: 0.38912
Epoch [16/25] Training [443/488] Loss: 0.28200
Epoch [16/25] Training [444/488] Loss: 0.19836
Epoch [16/25] Training [445/488] Loss: 0.19920
Epoch [16/25] Training [446/488] Loss: 0.28206
Epoch [16/25] Training [447/488] Loss: 0.30827
Epoch [16/25] Training [448/488] Loss: 0.24832
Epoch [16/25] Training [449/488] Loss: 0.21704
Epoch [16/25] Training [450/488] Loss: 0.19977
Epoch [16/25] Training [451/488] Loss: 0.28926
Epoch [16/25] Training [452/488] Loss: 0.29102
Epoch [16/25] Training [453/488] Loss: 0.72787
Epoch [16/25] Training [454/488] Loss: 0.20655
Epoch [16/25] Training [455/488] Loss: 0.35134
Epoch [16/25] Training [456/488] Loss: 0.19130
Epoch [16/25] Training [457/488] Loss: 0.19953
Epoch [16/25] Training [458/488] Loss: 0.24436
Epoch [16/25] Training [459/488] Loss: 0.35724
Epoch [16/25] Training [460/488] Loss: 0.28087
Epoch [16/25] Training [461/488] Loss: 0.18225
Epoch [16/25] Training [462/488] Loss: 0.19135
Epoch [16/25] Training [463/488] Loss: 0.34472
Epoch [16/25] Training [464/488] Loss: 0.34252
Epoch [16/25] Training [465/488] Loss: 0.18519
Epoch [16/25] Training [466/488] Loss: 0.44053
Epoch [16/25] Training [467/488] Loss: 0.18141
Epoch [16/25] Training [468/488] Loss: 0.45359
Epoch [16/25] Training [469/488] Loss: 0.19146
Epoch [16/25] Training [470/488] Loss: 0.30267
Epoch [16/25] Training [471/488] Loss: 0.33328
Epoch [16/25] Training [472/488] Loss: 0.22792
Epoch [16/25] Training [473/488] Loss: 0.32219
Epoch [16/25] Training [474/488] Loss: 0.32165
Epoch [16/25] Training [475/488] Loss: 0.15329
Epoch [16/25] Training [476/488] Loss: 0.29545
Epoch [16/25] Training [477/488] Loss: 0.28308
Epoch [16/25] Training [478/488] Loss: 0.38160
Epoch [16/25] Training [479/488] Loss: 0.18654
Epoch [16/25] Training [480/488] Loss: 0.32729
Epoch [16/25] Training [481/488] Loss: 0.18909
Epoch [16/25] Training [482/488] Loss: 0.41084
Epoch [16/25] Training [483/488] Loss: 0.32119
Epoch [16/25] Training [484/488] Loss: 0.20048
Epoch [16/25] Training [485/488] Loss: 0.53628
Epoch [16/25] Training [486/488] Loss: 0.19478
Epoch [16/25] Training [487/488] Loss: 0.22293
Epoch [16/25] Training [488/488] Loss: 0.18542
Epoch [16/25] Training metric {'Train/mean dice_metric': 0.8655070066452026, 'Train/TC dice_metric': 0.8819497227668762, 'Train/WT dice_metric': 0.9258509278297424, 'Train/ET dice_metric': 0.7887201905250549}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [16/25] Validation [1/123] Loss: 0.28916  focal_loss 0.00180  dice_loss 0.28736
Epoch [16/25] Validation [2/123] Loss: 0.46876  focal_loss 0.00154  dice_loss 0.46722
Epoch [16/25] Validation [3/123] Loss: 0.28146  focal_loss 0.00148  dice_loss 0.27997
Epoch [16/25] Validation [4/123] Loss: 0.37533  focal_loss 0.00177  dice_loss 0.37356
Epoch [16/25] Validation [5/123] Loss: 0.38249  focal_loss 0.00825  dice_loss 0.37424
Epoch [16/25] Validation [6/123] Loss: 0.42745  focal_loss 0.00136  dice_loss 0.42609
Epoch [16/25] Validation [7/123] Loss: 0.47572  focal_loss 0.00063  dice_loss 0.47509
Epoch [16/25] Validation [8/123] Loss: 0.42349  focal_loss 0.00121  dice_loss 0.42229
Epoch [16/25] Validation [9/123] Loss: 0.35346  focal_loss 0.00148  dice_loss 0.35198
Epoch [16/25] Validation [10/123] Loss: 0.55753  focal_loss 0.00252  dice_loss 0.55501
Epoch [16/25] Validation [11/123] Loss: 0.57261  focal_loss 0.00245  dice_loss 0.57016
Epoch [16/25] Validation [12/123] Loss: 0.30481  focal_loss 0.00152  dice_loss 0.30329
Epoch [16/25] Validation [13/123] Loss: 0.26374  focal_loss 0.00206  dice_loss 0.26168
Epoch [16/25] Validation [14/123] Loss: 0.36394  focal_loss 0.00153  dice_loss 0.36240
Epoch [16/25] Validation [15/123] Loss: 0.44860  focal_loss 0.00137  dice_loss 0.44723
Epoch [16/25] Validation [16/123] Loss: 0.53441  focal_loss 0.00204  dice_loss 0.53237
Epoch [16/25] Validation [17/123] Loss: 0.60329  focal_loss 0.00092  dice_loss 0.60237
Epoch [16/25] Validation [18/123] Loss: 0.45294  focal_loss 0.00627  dice_loss 0.44667
Epoch [16/25] Validation [19/123] Loss: 0.39488  focal_loss 0.00316  dice_loss 0.39172
Epoch [16/25] Validation [20/123] Loss: 0.58349  focal_loss 0.00092  dice_loss 0.58257
Epoch [16/25] Validation [21/123] Loss: 0.43564  focal_loss 0.00079  dice_loss 0.43485
Epoch [16/25] Validation [22/123] Loss: 0.72132  focal_loss 0.00776  dice_loss 0.71356
Epoch [16/25] Validation [23/123] Loss: 0.28669  focal_loss 0.00106  dice_loss 0.28563
Epoch [16/25] Validation [24/123] Loss: 0.38271  focal_loss 0.00233  dice_loss 0.38039
Epoch [16/25] Validation [25/123] Loss: 0.41384  focal_loss 0.00114  dice_loss 0.41269
Epoch [16/25] Validation [26/123] Loss: 0.30351  focal_loss 0.00104  dice_loss 0.30247
Epoch [16/25] Validation [27/123] Loss: 0.34215  focal_loss 0.00210  dice_loss 0.34005
Epoch [16/25] Validation [28/123] Loss: 0.56224  focal_loss 0.00263  dice_loss 0.55961
Epoch [16/25] Validation [29/123] Loss: 0.46412  focal_loss 0.00187  dice_loss 0.46226
Epoch [16/25] Validation [30/123] Loss: 0.32742  focal_loss 0.00321  dice_loss 0.32421
Epoch [16/25] Validation [31/123] Loss: 0.28464  focal_loss 0.00114  dice_loss 0.28349
Epoch [16/25] Validation [32/123] Loss: 0.41468  focal_loss 0.00364  dice_loss 0.41104
Epoch [16/25] Validation [33/123] Loss: 0.43805  focal_loss 0.00189  dice_loss 0.43617
Epoch [16/25] Validation [34/123] Loss: 0.43504  focal_loss 0.00357  dice_loss 0.43147
Epoch [16/25] Validation [35/123] Loss: 0.33360  focal_loss 0.00102  dice_loss 0.33258
Epoch [16/25] Validation [36/123] Loss: 0.36366  focal_loss 0.00084  dice_loss 0.36282
Epoch [16/25] Validation [37/123] Loss: 0.48875  focal_loss 0.00455  dice_loss 0.48420
Epoch [16/25] Validation [38/123] Loss: 0.33314  focal_loss 0.00125  dice_loss 0.33189
Epoch [16/25] Validation [39/123] Loss: 0.30222  focal_loss 0.00140  dice_loss 0.30082
Epoch [16/25] Validation [40/123] Loss: 0.41841  focal_loss 0.00080  dice_loss 0.41761
Epoch [16/25] Validation [41/123] Loss: 0.31575  focal_loss 0.00192  dice_loss 0.31384
Epoch [16/25] Validation [42/123] Loss: 0.28126  focal_loss 0.00075  dice_loss 0.28051
Epoch [16/25] Validation [43/123] Loss: 0.36175  focal_loss 0.00499  dice_loss 0.35676
Epoch [16/25] Validation [44/123] Loss: 0.60737  focal_loss 0.00476  dice_loss 0.60261
Epoch [16/25] Validation [45/123] Loss: 0.39237  focal_loss 0.00104  dice_loss 0.39133
Epoch [16/25] Validation [46/123] Loss: 0.43668  focal_loss 0.00272  dice_loss 0.43396
Epoch [16/25] Validation [47/123] Loss: 0.38867  focal_loss 0.00120  dice_loss 0.38747
Epoch [16/25] Validation [48/123] Loss: 0.49405  focal_loss 0.00368  dice_loss 0.49037
Epoch [16/25] Validation [49/123] Loss: 0.32176  focal_loss 0.00175  dice_loss 0.32001
Epoch [16/25] Validation [50/123] Loss: 0.29303  focal_loss 0.00168  dice_loss 0.29135
Epoch [16/25] Validation [51/123] Loss: 0.45056  focal_loss 0.00571  dice_loss 0.44484
Epoch [16/25] Validation [52/123] Loss: 0.32278  focal_loss 0.00089  dice_loss 0.32189
Epoch [16/25] Validation [53/123] Loss: 0.38224  focal_loss 0.00084  dice_loss 0.38140
Epoch [16/25] Validation [54/123] Loss: 0.42919  focal_loss 0.00122  dice_loss 0.42797
Epoch [16/25] Validation [55/123] Loss: 0.36741  focal_loss 0.00135  dice_loss 0.36606
Epoch [16/25] Validation [56/123] Loss: 0.32004  focal_loss 0.00164  dice_loss 0.31840
Epoch [16/25] Validation [57/123] Loss: 0.39252  focal_loss 0.00247  dice_loss 0.39005
Epoch [16/25] Validation [58/123] Loss: 0.35038  focal_loss 0.00202  dice_loss 0.34836
Epoch [16/25] Validation [59/123] Loss: 0.69234  focal_loss 0.00789  dice_loss 0.68445
Epoch [16/25] Validation [60/123] Loss: 0.35326  focal_loss 0.00402  dice_loss 0.34924
Epoch [16/25] Validation [61/123] Loss: 0.72505  focal_loss 0.00248  dice_loss 0.72257
Epoch [16/25] Validation [62/123] Loss: 0.58389  focal_loss 0.00867  dice_loss 0.57522
Epoch [16/25] Validation [63/123] Loss: 0.49083  focal_loss 0.00142  dice_loss 0.48940
Epoch [16/25] Validation [64/123] Loss: 0.43889  focal_loss 0.00617  dice_loss 0.43272
Epoch [16/25] Validation [65/123] Loss: 0.33574  focal_loss 0.00097  dice_loss 0.33477
Epoch [16/25] Validation [66/123] Loss: 0.35676  focal_loss 0.00122  dice_loss 0.35554
Epoch [16/25] Validation [67/123] Loss: 0.47481  focal_loss 0.00732  dice_loss 0.46749
Epoch [16/25] Validation [68/123] Loss: 0.47150  focal_loss 0.00085  dice_loss 0.47065
Epoch [16/25] Validation [69/123] Loss: 0.42003  focal_loss 0.00500  dice_loss 0.41503
Epoch [16/25] Validation [70/123] Loss: 0.40360  focal_loss 0.00178  dice_loss 0.40182
Epoch [16/25] Validation [71/123] Loss: 0.34275  focal_loss 0.00089  dice_loss 0.34187
Epoch [16/25] Validation [72/123] Loss: 0.30923  focal_loss 0.00144  dice_loss 0.30779
Epoch [16/25] Validation [73/123] Loss: 0.43342  focal_loss 0.00635  dice_loss 0.42708
Epoch [16/25] Validation [74/123] Loss: 0.46084  focal_loss 0.00688  dice_loss 0.45396
Epoch [16/25] Validation [75/123] Loss: 0.37583  focal_loss 0.00112  dice_loss 0.37471
Epoch [16/25] Validation [76/123] Loss: 0.55627  focal_loss 0.00489  dice_loss 0.55139
Epoch [16/25] Validation [77/123] Loss: 0.46672  focal_loss 0.00113  dice_loss 0.46558
Epoch [16/25] Validation [78/123] Loss: 0.36405  focal_loss 0.00194  dice_loss 0.36211
Epoch [16/25] Validation [79/123] Loss: 0.42202  focal_loss 0.00138  dice_loss 0.42064
Epoch [16/25] Validation [80/123] Loss: 0.30596  focal_loss 0.00180  dice_loss 0.30416
Epoch [16/25] Validation [81/123] Loss: 0.35747  focal_loss 0.00136  dice_loss 0.35611
Epoch [16/25] Validation [82/123] Loss: 0.31037  focal_loss 0.00057  dice_loss 0.30980
Epoch [16/25] Validation [83/123] Loss: 0.54662  focal_loss 0.01683  dice_loss 0.52979
Epoch [16/25] Validation [84/123] Loss: 0.35500  focal_loss 0.00130  dice_loss 0.35370
Epoch [16/25] Validation [85/123] Loss: 0.39003  focal_loss 0.00203  dice_loss 0.38800
Epoch [16/25] Validation [86/123] Loss: 0.33357  focal_loss 0.00220  dice_loss 0.33137
Epoch [16/25] Validation [87/123] Loss: 0.28123  focal_loss 0.00209  dice_loss 0.27914
Epoch [16/25] Validation [88/123] Loss: 0.34694  focal_loss 0.00229  dice_loss 0.34465
Epoch [16/25] Validation [89/123] Loss: 0.27489  focal_loss 0.00135  dice_loss 0.27353
Epoch [16/25] Validation [90/123] Loss: 0.40206  focal_loss 0.00239  dice_loss 0.39967
Epoch [16/25] Validation [91/123] Loss: 0.33253  focal_loss 0.00108  dice_loss 0.33145
Epoch [16/25] Validation [92/123] Loss: 0.28429  focal_loss 0.00083  dice_loss 0.28346
Epoch [16/25] Validation [93/123] Loss: 0.30718  focal_loss 0.00113  dice_loss 0.30605
Epoch [16/25] Validation [94/123] Loss: 0.42917  focal_loss 0.00166  dice_loss 0.42751
Epoch [16/25] Validation [95/123] Loss: 0.33969  focal_loss 0.00233  dice_loss 0.33736
Epoch [16/25] Validation [96/123] Loss: 0.42956  focal_loss 0.00173  dice_loss 0.42783
Epoch [16/25] Validation [97/123] Loss: 0.61112  focal_loss 0.00578  dice_loss 0.60534
Epoch [16/25] Validation [98/123] Loss: 0.42925  focal_loss 0.00141  dice_loss 0.42784
Epoch [16/25] Validation [99/123] Loss: 0.42707  focal_loss 0.00060  dice_loss 0.42647
Epoch [16/25] Validation [100/123] Loss: 0.45220  focal_loss 0.00099  dice_loss 0.45121
Epoch [16/25] Validation [101/123] Loss: 0.39307  focal_loss 0.00152  dice_loss 0.39155
Epoch [16/25] Validation [102/123] Loss: 0.44920  focal_loss 0.00082  dice_loss 0.44838
Epoch [16/25] Validation [103/123] Loss: 0.53037  focal_loss 0.00081  dice_loss 0.52956
Epoch [16/25] Validation [104/123] Loss: 0.51672  focal_loss 0.00608  dice_loss 0.51064
Epoch [16/25] Validation [105/123] Loss: 0.27883  focal_loss 0.00211  dice_loss 0.27672
Epoch [16/25] Validation [106/123] Loss: 0.33699  focal_loss 0.00080  dice_loss 0.33619
Epoch [16/25] Validation [107/123] Loss: 0.65323  focal_loss 0.00533  dice_loss 0.64790
Epoch [16/25] Validation [108/123] Loss: 0.33375  focal_loss 0.00046  dice_loss 0.33329
Epoch [16/25] Validation [109/123] Loss: 0.27235  focal_loss 0.00293  dice_loss 0.26942
Epoch [16/25] Validation [110/123] Loss: 0.44534  focal_loss 0.00260  dice_loss 0.44274
Epoch [16/25] Validation [111/123] Loss: 0.46801  focal_loss 0.00302  dice_loss 0.46499
Epoch [16/25] Validation [112/123] Loss: 0.42272  focal_loss 0.00052  dice_loss 0.42220
Epoch [16/25] Validation [113/123] Loss: 0.35087  focal_loss 0.00131  dice_loss 0.34956
Epoch [16/25] Validation [114/123] Loss: 0.42135  focal_loss 0.00451  dice_loss 0.41683
Epoch [16/25] Validation [115/123] Loss: 0.35421  focal_loss 0.00394  dice_loss 0.35028
Epoch [16/25] Validation [116/123] Loss: 0.38020  focal_loss 0.00070  dice_loss 0.37950
Epoch [16/25] Validation [117/123] Loss: 0.35912  focal_loss 0.00118  dice_loss 0.35794
Epoch [16/25] Validation [118/123] Loss: 0.27381  focal_loss 0.00158  dice_loss 0.27223
Epoch [16/25] Validation [119/123] Loss: 0.30012  focal_loss 0.00085  dice_loss 0.29927
Epoch [16/25] Validation [120/123] Loss: 0.32892  focal_loss 0.00167  dice_loss 0.32725
Epoch [16/25] Validation [121/123] Loss: 0.66365  focal_loss 0.01319  dice_loss 0.65047
Epoch [16/25] Validation [122/123] Loss: 0.75631  focal_loss 0.00111  dice_loss 0.75520
Epoch [16/25] Validation [123/123] Loss: 0.31857  focal_loss 0.00121  dice_loss 0.31736
Epoch [16/25] Validation metric {'Val/mean dice_metric': 0.8658258318901062, 'Val/TC dice_metric': 0.8824188709259033, 'Val/WT dice_metric': 0.9241443872451782, 'Val/ET dice_metric': 0.7909141778945923}
Epoch [16/25] lr = [0.0005, 0.0005] best acc: tensor([0.8600], device='cuda:0'), mean acc: tensor([0.8658], device='cuda:0'), mean class: tensor([0.8824, 0.9241, 0.7909], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [17/25] Training [1/488] Loss: 0.20488
Epoch [17/25] Training [2/488] Loss: 0.22142
Epoch [17/25] Training [3/488] Loss: 0.19330
Epoch [17/25] Training [4/488] Loss: 0.16980
Epoch [17/25] Training [5/488] Loss: 0.34526
Epoch [17/25] Training [6/488] Loss: 0.41132
Epoch [17/25] Training [7/488] Loss: 0.17823
Epoch [17/25] Training [8/488] Loss: 0.29004
Epoch [17/25] Training [9/488] Loss: 0.20616
Epoch [17/25] Training [10/488] Loss: 0.45430
Epoch [17/25] Training [11/488] Loss: 0.59576
Epoch [17/25] Training [12/488] Loss: 0.28891
Epoch [17/25] Training [13/488] Loss: 0.27965
Epoch [17/25] Training [14/488] Loss: 0.25798
Epoch [17/25] Training [15/488] Loss: 0.50040
Epoch [17/25] Training [16/488] Loss: 0.27849
Epoch [17/25] Training [17/488] Loss: 0.29216
Epoch [17/25] Training [18/488] Loss: 0.29519
Epoch [17/25] Training [19/488] Loss: 0.31639
Epoch [17/25] Training [20/488] Loss: 0.38415
Epoch [17/25] Training [21/488] Loss: 0.32580
Epoch [17/25] Training [22/488] Loss: 0.16883
Epoch [17/25] Training [23/488] Loss: 0.19964
Epoch [17/25] Training [24/488] Loss: 0.29804
Epoch [17/25] Training [25/488] Loss: 0.31895
Epoch [17/25] Training [26/488] Loss: 0.21061
Epoch [17/25] Training [27/488] Loss: 0.28581
Epoch [17/25] Training [28/488] Loss: 0.23755
Epoch [17/25] Training [29/488] Loss: 0.29852
Epoch [17/25] Training [30/488] Loss: 0.27288
Epoch [17/25] Training [31/488] Loss: 0.22651
Epoch [17/25] Training [32/488] Loss: 0.36290
Epoch [17/25] Training [33/488] Loss: 0.21040
Epoch [17/25] Training [34/488] Loss: 0.21229
Epoch [17/25] Training [35/488] Loss: 0.28189
Epoch [17/25] Training [36/488] Loss: 0.33423
Epoch [17/25] Training [37/488] Loss: 0.25666
Epoch [17/25] Training [38/488] Loss: 0.35949
Epoch [17/25] Training [39/488] Loss: 0.17200
Epoch [17/25] Training [40/488] Loss: 0.32863
Epoch [17/25] Training [41/488] Loss: 0.58351
Epoch [17/25] Training [42/488] Loss: 0.20295
Epoch [17/25] Training [43/488] Loss: 0.22627
Epoch [17/25] Training [44/488] Loss: 0.34177
Epoch [17/25] Training [45/488] Loss: 0.19712
Epoch [17/25] Training [46/488] Loss: 0.28434
Epoch [17/25] Training [47/488] Loss: 0.26417
Epoch [17/25] Training [48/488] Loss: 0.31789
Epoch [17/25] Training [49/488] Loss: 0.31655
Epoch [17/25] Training [50/488] Loss: 0.44897
Epoch [17/25] Training [51/488] Loss: 0.24464
Epoch [17/25] Training [52/488] Loss: 0.43008
Epoch [17/25] Training [53/488] Loss: 0.25447
Epoch [17/25] Training [54/488] Loss: 0.36002
Epoch [17/25] Training [55/488] Loss: 0.22768
Epoch [17/25] Training [56/488] Loss: 0.27461
Epoch [17/25] Training [57/488] Loss: 0.17396
Epoch [17/25] Training [58/488] Loss: 0.24742
Epoch [17/25] Training [59/488] Loss: 0.19697
Epoch [17/25] Training [60/488] Loss: 0.21743
Epoch [17/25] Training [61/488] Loss: 0.22884
Epoch [17/25] Training [62/488] Loss: 0.29485
Epoch [17/25] Training [63/488] Loss: 0.43612
Epoch [17/25] Training [64/488] Loss: 0.16069
Epoch [17/25] Training [65/488] Loss: 0.16133
Epoch [17/25] Training [66/488] Loss: 0.17290
Epoch [17/25] Training [67/488] Loss: 0.22125
Epoch [17/25] Training [68/488] Loss: 0.49760
Epoch [17/25] Training [69/488] Loss: 0.20232
Epoch [17/25] Training [70/488] Loss: 0.31913
Epoch [17/25] Training [71/488] Loss: 0.73972
Epoch [17/25] Training [72/488] Loss: 0.24988
Epoch [17/25] Training [73/488] Loss: 0.54736
Epoch [17/25] Training [74/488] Loss: 0.17176
Epoch [17/25] Training [75/488] Loss: 0.43501
Epoch [17/25] Training [76/488] Loss: 0.33538
Epoch [17/25] Training [77/488] Loss: 0.72968
Epoch [17/25] Training [78/488] Loss: 0.55290
Epoch [17/25] Training [79/488] Loss: 0.27785
Epoch [17/25] Training [80/488] Loss: 0.24736
Epoch [17/25] Training [81/488] Loss: 0.24779
Epoch [17/25] Training [82/488] Loss: 0.22445
Epoch [17/25] Training [83/488] Loss: 0.18504
Epoch [17/25] Training [84/488] Loss: 0.40219
Epoch [17/25] Training [85/488] Loss: 0.20854
Epoch [17/25] Training [86/488] Loss: 0.22701
Epoch [17/25] Training [87/488] Loss: 0.25276
Epoch [17/25] Training [88/488] Loss: 0.22468
Epoch [17/25] Training [89/488] Loss: 0.15974
Epoch [17/25] Training [90/488] Loss: 0.48570
Epoch [17/25] Training [91/488] Loss: 0.21767
Epoch [17/25] Training [92/488] Loss: 0.28408
Epoch [17/25] Training [93/488] Loss: 0.36936
Epoch [17/25] Training [94/488] Loss: 0.21864
Epoch [17/25] Training [95/488] Loss: 0.19698
Epoch [17/25] Training [96/488] Loss: 0.26731
Epoch [17/25] Training [97/488] Loss: 0.46842
Epoch [17/25] Training [98/488] Loss: 0.28857
Epoch [17/25] Training [99/488] Loss: 0.22759
Epoch [17/25] Training [100/488] Loss: 0.31266
Epoch [17/25] Training [101/488] Loss: 0.42149
Epoch [17/25] Training [102/488] Loss: 0.14725
Epoch [17/25] Training [103/488] Loss: 0.30493
Epoch [17/25] Training [104/488] Loss: 0.20808
Epoch [17/25] Training [105/488] Loss: 0.29181
Epoch [17/25] Training [106/488] Loss: 0.33156
Epoch [17/25] Training [107/488] Loss: 0.21892
Epoch [17/25] Training [108/488] Loss: 0.24126
Epoch [17/25] Training [109/488] Loss: 0.38790
Epoch [17/25] Training [110/488] Loss: 0.16206
Epoch [17/25] Training [111/488] Loss: 0.28230
Epoch [17/25] Training [112/488] Loss: 0.17017
Epoch [17/25] Training [113/488] Loss: 0.33471
Epoch [17/25] Training [114/488] Loss: 0.30010
Epoch [17/25] Training [115/488] Loss: 0.20307
Epoch [17/25] Training [116/488] Loss: 0.27643
Epoch [17/25] Training [117/488] Loss: 0.42695
Epoch [17/25] Training [118/488] Loss: 0.23908
Epoch [17/25] Training [119/488] Loss: 0.30873
Epoch [17/25] Training [120/488] Loss: 0.15603
Epoch [17/25] Training [121/488] Loss: 0.32365
Epoch [17/25] Training [122/488] Loss: 0.27709
Epoch [17/25] Training [123/488] Loss: 0.23952
Epoch [17/25] Training [124/488] Loss: 0.19083
Epoch [17/25] Training [125/488] Loss: 0.27357
Epoch [17/25] Training [126/488] Loss: 0.27675
Epoch [17/25] Training [127/488] Loss: 0.20600
Epoch [17/25] Training [128/488] Loss: 0.19433
Epoch [17/25] Training [129/488] Loss: 0.43090
Epoch [17/25] Training [130/488] Loss: 0.30841
Epoch [17/25] Training [131/488] Loss: 0.33495
Epoch [17/25] Training [132/488] Loss: 0.18049
Epoch [17/25] Training [133/488] Loss: 0.37653
Epoch [17/25] Training [134/488] Loss: 0.17788
Epoch [17/25] Training [135/488] Loss: 0.23419
Epoch [17/25] Training [136/488] Loss: 0.28547
Epoch [17/25] Training [137/488] Loss: 0.29233
Epoch [17/25] Training [138/488] Loss: 0.50502
Epoch [17/25] Training [139/488] Loss: 0.17209
Epoch [17/25] Training [140/488] Loss: 0.31699
Epoch [17/25] Training [141/488] Loss: 0.18182
Epoch [17/25] Training [142/488] Loss: 0.23336
Epoch [17/25] Training [143/488] Loss: 0.40395
Epoch [17/25] Training [144/488] Loss: 0.29976
Epoch [17/25] Training [145/488] Loss: 0.29867
Epoch [17/25] Training [146/488] Loss: 0.18401
Epoch [17/25] Training [147/488] Loss: 0.14998
Epoch [17/25] Training [148/488] Loss: 0.56664
Epoch [17/25] Training [149/488] Loss: 0.28648
Epoch [17/25] Training [150/488] Loss: 0.39630
Epoch [17/25] Training [151/488] Loss: 0.23930
Epoch [17/25] Training [152/488] Loss: 0.21304
Epoch [17/25] Training [153/488] Loss: 0.25402
Epoch [17/25] Training [154/488] Loss: 0.20285
Epoch [17/25] Training [155/488] Loss: 0.21298
Epoch [17/25] Training [156/488] Loss: 0.36827
Epoch [17/25] Training [157/488] Loss: 0.33027
Epoch [17/25] Training [158/488] Loss: 0.20929
Epoch [17/25] Training [159/488] Loss: 0.49246
Epoch [17/25] Training [160/488] Loss: 0.38457
Epoch [17/25] Training [161/488] Loss: 0.17276
Epoch [17/25] Training [162/488] Loss: 0.20553
Epoch [17/25] Training [163/488] Loss: 0.25421
Epoch [17/25] Training [164/488] Loss: 0.20494
Epoch [17/25] Training [165/488] Loss: 0.27290
Epoch [17/25] Training [166/488] Loss: 0.28716
Epoch [17/25] Training [167/488] Loss: 0.28451
Epoch [17/25] Training [168/488] Loss: 0.30159
Epoch [17/25] Training [169/488] Loss: 0.29372
Epoch [17/25] Training [170/488] Loss: 0.25993
Epoch [17/25] Training [171/488] Loss: 0.15345
Epoch [17/25] Training [172/488] Loss: 0.31353
Epoch [17/25] Training [173/488] Loss: 0.18789
Epoch [17/25] Training [174/488] Loss: 0.33291
Epoch [17/25] Training [175/488] Loss: 0.18173
Epoch [17/25] Training [176/488] Loss: 0.48535
Epoch [17/25] Training [177/488] Loss: 0.20975
Epoch [17/25] Training [178/488] Loss: 0.27546
Epoch [17/25] Training [179/488] Loss: 0.62677
Epoch [17/25] Training [180/488] Loss: 0.40241
Epoch [17/25] Training [181/488] Loss: 0.18788
Epoch [17/25] Training [182/488] Loss: 0.23267
Epoch [17/25] Training [183/488] Loss: 0.23050
Epoch [17/25] Training [184/488] Loss: 0.21101
Epoch [17/25] Training [185/488] Loss: 0.49472
Epoch [17/25] Training [186/488] Loss: 0.37054
Epoch [17/25] Training [187/488] Loss: 0.23611
Epoch [17/25] Training [188/488] Loss: 0.42482
Epoch [17/25] Training [189/488] Loss: 0.14994
Epoch [17/25] Training [190/488] Loss: 0.41056
Epoch [17/25] Training [191/488] Loss: 0.46958
Epoch [17/25] Training [192/488] Loss: 0.18878
Epoch [17/25] Training [193/488] Loss: 0.14236
Epoch [17/25] Training [194/488] Loss: 0.27361
Epoch [17/25] Training [195/488] Loss: 0.18984
Epoch [17/25] Training [196/488] Loss: 0.20317
Epoch [17/25] Training [197/488] Loss: 0.25698
Epoch [17/25] Training [198/488] Loss: 0.57857
Epoch [17/25] Training [199/488] Loss: 0.15856
Epoch [17/25] Training [200/488] Loss: 0.24447
Epoch [17/25] Training [201/488] Loss: 0.19786
Epoch [17/25] Training [202/488] Loss: 0.18647
Epoch [17/25] Training [203/488] Loss: 0.26604
Epoch [17/25] Training [204/488] Loss: 0.16746
Epoch [17/25] Training [205/488] Loss: 0.30928
Epoch [17/25] Training [206/488] Loss: 0.15501
Epoch [17/25] Training [207/488] Loss: 0.16367
Epoch [17/25] Training [208/488] Loss: 0.46880
Epoch [17/25] Training [209/488] Loss: 0.31331
Epoch [17/25] Training [210/488] Loss: 0.37600
Epoch [17/25] Training [211/488] Loss: 0.38248
Epoch [17/25] Training [212/488] Loss: 0.37001
Epoch [17/25] Training [213/488] Loss: 0.16979
Epoch [17/25] Training [214/488] Loss: 0.33323
Epoch [17/25] Training [215/488] Loss: 0.23230
Epoch [17/25] Training [216/488] Loss: 0.38239
Epoch [17/25] Training [217/488] Loss: 0.37401
Epoch [17/25] Training [218/488] Loss: 0.56687
Epoch [17/25] Training [219/488] Loss: 0.39753
Epoch [17/25] Training [220/488] Loss: 0.21394
Epoch [17/25] Training [221/488] Loss: 0.32716
Epoch [17/25] Training [222/488] Loss: 0.17451
Epoch [17/25] Training [223/488] Loss: 0.21622
Epoch [17/25] Training [224/488] Loss: 0.25673
Epoch [17/25] Training [225/488] Loss: 0.59368
Epoch [17/25] Training [226/488] Loss: 0.85383
Epoch [17/25] Training [227/488] Loss: 0.31245
Epoch [17/25] Training [228/488] Loss: 0.19634
Epoch [17/25] Training [229/488] Loss: 0.26982
Epoch [17/25] Training [230/488] Loss: 0.22914
Epoch [17/25] Training [231/488] Loss: 0.74513
Epoch [17/25] Training [232/488] Loss: 0.39792
Epoch [17/25] Training [233/488] Loss: 0.15724
Epoch [17/25] Training [234/488] Loss: 0.30903
Epoch [17/25] Training [235/488] Loss: 0.29971
Epoch [17/25] Training [236/488] Loss: 0.36365
Epoch [17/25] Training [237/488] Loss: 0.17518
Epoch [17/25] Training [238/488] Loss: 0.24774
Epoch [17/25] Training [239/488] Loss: 0.20490
Epoch [17/25] Training [240/488] Loss: 0.17852
Epoch [17/25] Training [241/488] Loss: 0.22987
Epoch [17/25] Training [242/488] Loss: 0.31774
Epoch [17/25] Training [243/488] Loss: 0.50173
Epoch [17/25] Training [244/488] Loss: 0.31535
Epoch [17/25] Training [245/488] Loss: 0.39175
Epoch [17/25] Training [246/488] Loss: 0.19885
Epoch [17/25] Training [247/488] Loss: 0.93749
Epoch [17/25] Training [248/488] Loss: 0.32063
Epoch [17/25] Training [249/488] Loss: 0.16126
Epoch [17/25] Training [250/488] Loss: 0.38085
Epoch [17/25] Training [251/488] Loss: 0.18886
Epoch [17/25] Training [252/488] Loss: 0.16680
Epoch [17/25] Training [253/488] Loss: 0.20707
Epoch [17/25] Training [254/488] Loss: 0.35322
Epoch [17/25] Training [255/488] Loss: 0.44578
Epoch [17/25] Training [256/488] Loss: 0.23806
Epoch [17/25] Training [257/488] Loss: 0.39222
Epoch [17/25] Training [258/488] Loss: 0.28119
Epoch [17/25] Training [259/488] Loss: 0.25612
Epoch [17/25] Training [260/488] Loss: 0.58003
Epoch [17/25] Training [261/488] Loss: 0.50979
Epoch [17/25] Training [262/488] Loss: 0.43472
Epoch [17/25] Training [263/488] Loss: 0.22005
Epoch [17/25] Training [264/488] Loss: 0.16371
Epoch [17/25] Training [265/488] Loss: 0.21797
Epoch [17/25] Training [266/488] Loss: 0.16518
Epoch [17/25] Training [267/488] Loss: 0.22883
Epoch [17/25] Training [268/488] Loss: 0.23992
Epoch [17/25] Training [269/488] Loss: 0.53584
Epoch [17/25] Training [270/488] Loss: 0.18595
Epoch [17/25] Training [271/488] Loss: 0.25639
Epoch [17/25] Training [272/488] Loss: 0.23289
Epoch [17/25] Training [273/488] Loss: 0.20873
Epoch [17/25] Training [274/488] Loss: 0.26188
Epoch [17/25] Training [275/488] Loss: 0.23748
Epoch [17/25] Training [276/488] Loss: 0.14868
Epoch [17/25] Training [277/488] Loss: 0.26287
Epoch [17/25] Training [278/488] Loss: 0.64446
Epoch [17/25] Training [279/488] Loss: 0.32255
Epoch [17/25] Training [280/488] Loss: 0.25988
Epoch [17/25] Training [281/488] Loss: 0.26326
Epoch [17/25] Training [282/488] Loss: 0.17237
Epoch [17/25] Training [283/488] Loss: 0.14966
Epoch [17/25] Training [284/488] Loss: 0.18448
Epoch [17/25] Training [285/488] Loss: 0.19353
Epoch [17/25] Training [286/488] Loss: 0.28590
Epoch [17/25] Training [287/488] Loss: 0.40014
Epoch [17/25] Training [288/488] Loss: 0.24323
Epoch [17/25] Training [289/488] Loss: 0.18167
Epoch [17/25] Training [290/488] Loss: 0.20147
Epoch [17/25] Training [291/488] Loss: 0.31458
Epoch [17/25] Training [292/488] Loss: 0.22354
Epoch [17/25] Training [293/488] Loss: 0.25976
Epoch [17/25] Training [294/488] Loss: 0.26817
Epoch [17/25] Training [295/488] Loss: 0.18289
Epoch [17/25] Training [296/488] Loss: 0.23572
Epoch [17/25] Training [297/488] Loss: 0.24439
Epoch [17/25] Training [298/488] Loss: 0.25258
Epoch [17/25] Training [299/488] Loss: 0.43699
Epoch [17/25] Training [300/488] Loss: 0.40814
Epoch [17/25] Training [301/488] Loss: 0.24821
Epoch [17/25] Training [302/488] Loss: 0.18014
Epoch [17/25] Training [303/488] Loss: 0.40875
Epoch [17/25] Training [304/488] Loss: 0.18501
Epoch [17/25] Training [305/488] Loss: 0.35453
Epoch [17/25] Training [306/488] Loss: 0.21201
Epoch [17/25] Training [307/488] Loss: 0.20840
Epoch [17/25] Training [308/488] Loss: 0.71293
Epoch [17/25] Training [309/488] Loss: 0.33116
Epoch [17/25] Training [310/488] Loss: 0.22222
Epoch [17/25] Training [311/488] Loss: 0.16850
Epoch [17/25] Training [312/488] Loss: 0.21935
Epoch [17/25] Training [313/488] Loss: 0.33700
Epoch [17/25] Training [314/488] Loss: 0.43709
Epoch [17/25] Training [315/488] Loss: 0.28215
Epoch [17/25] Training [316/488] Loss: 0.27798
Epoch [17/25] Training [317/488] Loss: 0.44313
Epoch [17/25] Training [318/488] Loss: 0.21070
Epoch [17/25] Training [319/488] Loss: 0.23329
Epoch [17/25] Training [320/488] Loss: 0.38152
Epoch [17/25] Training [321/488] Loss: 0.40800
Epoch [17/25] Training [322/488] Loss: 0.20615
Epoch [17/25] Training [323/488] Loss: 0.34413
Epoch [17/25] Training [324/488] Loss: 0.41210
Epoch [17/25] Training [325/488] Loss: 0.19636
Epoch [17/25] Training [326/488] Loss: 0.18509
Epoch [17/25] Training [327/488] Loss: 0.20040
Epoch [17/25] Training [328/488] Loss: 0.20794
Epoch [17/25] Training [329/488] Loss: 0.17415
Epoch [17/25] Training [330/488] Loss: 0.19580
Epoch [17/25] Training [331/488] Loss: 0.22735
Epoch [17/25] Training [332/488] Loss: 0.28482
Epoch [17/25] Training [333/488] Loss: 0.23806
Epoch [17/25] Training [334/488] Loss: 0.18209
Epoch [17/25] Training [335/488] Loss: 0.25528
Epoch [17/25] Training [336/488] Loss: 0.14616
Epoch [17/25] Training [337/488] Loss: 0.22195
Epoch [17/25] Training [338/488] Loss: 0.71631
Epoch [17/25] Training [339/488] Loss: 0.22390
Epoch [17/25] Training [340/488] Loss: 0.18843
Epoch [17/25] Training [341/488] Loss: 0.23386
Epoch [17/25] Training [342/488] Loss: 0.25298
Epoch [17/25] Training [343/488] Loss: 0.33555
Epoch [17/25] Training [344/488] Loss: 0.57124
Epoch [17/25] Training [345/488] Loss: 0.23342
Epoch [17/25] Training [346/488] Loss: 0.54910
Epoch [17/25] Training [347/488] Loss: 0.23416
Epoch [17/25] Training [348/488] Loss: 0.48242
Epoch [17/25] Training [349/488] Loss: 0.46077
Epoch [17/25] Training [350/488] Loss: 0.28261
Epoch [17/25] Training [351/488] Loss: 0.20941
Epoch [17/25] Training [352/488] Loss: 0.18516
Epoch [17/25] Training [353/488] Loss: 0.22119
Epoch [17/25] Training [354/488] Loss: 0.25099
Epoch [17/25] Training [355/488] Loss: 0.19817
Epoch [17/25] Training [356/488] Loss: 0.18133
Epoch [17/25] Training [357/488] Loss: 0.37112
Epoch [17/25] Training [358/488] Loss: 0.15281
Epoch [17/25] Training [359/488] Loss: 0.19947
Epoch [17/25] Training [360/488] Loss: 0.19151
Epoch [17/25] Training [361/488] Loss: 0.30046
Epoch [17/25] Training [362/488] Loss: 0.32169
Epoch [17/25] Training [363/488] Loss: 0.15637
Epoch [17/25] Training [364/488] Loss: 0.17917
Epoch [17/25] Training [365/488] Loss: 0.17822
Epoch [17/25] Training [366/488] Loss: 0.38368
Epoch [17/25] Training [367/488] Loss: 0.19682
Epoch [17/25] Training [368/488] Loss: 0.29041
Epoch [17/25] Training [369/488] Loss: 0.31705
Epoch [17/25] Training [370/488] Loss: 0.15445
Epoch [17/25] Training [371/488] Loss: 0.15802
Epoch [17/25] Training [372/488] Loss: 0.16997
Epoch [17/25] Training [373/488] Loss: 0.19738
Epoch [17/25] Training [374/488] Loss: 0.17134
Epoch [17/25] Training [375/488] Loss: 0.20524
Epoch [17/25] Training [376/488] Loss: 0.18854
Epoch [17/25] Training [377/488] Loss: 0.19983
Epoch [17/25] Training [378/488] Loss: 0.20876
Epoch [17/25] Training [379/488] Loss: 0.53188
Epoch [17/25] Training [380/488] Loss: 0.36398
Epoch [17/25] Training [381/488] Loss: 0.29117
Epoch [17/25] Training [382/488] Loss: 0.34578
Epoch [17/25] Training [383/488] Loss: 0.23588
Epoch [17/25] Training [384/488] Loss: 0.15388
Epoch [17/25] Training [385/488] Loss: 0.22767
Epoch [17/25] Training [386/488] Loss: 0.30817
Epoch [17/25] Training [387/488] Loss: 0.17015
Epoch [17/25] Training [388/488] Loss: 0.18905
Epoch [17/25] Training [389/488] Loss: 0.23743
Epoch [17/25] Training [390/488] Loss: 0.43200
Epoch [17/25] Training [391/488] Loss: 0.15704
Epoch [17/25] Training [392/488] Loss: 0.24587
Epoch [17/25] Training [393/488] Loss: 0.21598
Epoch [17/25] Training [394/488] Loss: 0.16528
Epoch [17/25] Training [395/488] Loss: 0.33691
Epoch [17/25] Training [396/488] Loss: 0.18108
Epoch [17/25] Training [397/488] Loss: 0.14412
Epoch [17/25] Training [398/488] Loss: 0.22994
Epoch [17/25] Training [399/488] Loss: 0.22837
Epoch [17/25] Training [400/488] Loss: 0.28476
Epoch [17/25] Training [401/488] Loss: 0.17092
Epoch [17/25] Training [402/488] Loss: 0.20818
Epoch [17/25] Training [403/488] Loss: 0.25518
Epoch [17/25] Training [404/488] Loss: 0.39854
Epoch [17/25] Training [405/488] Loss: 0.15502
Epoch [17/25] Training [406/488] Loss: 0.29237
Epoch [17/25] Training [407/488] Loss: 0.26217
Epoch [17/25] Training [408/488] Loss: 0.33266
Epoch [17/25] Training [409/488] Loss: 0.40858
Epoch [17/25] Training [410/488] Loss: 0.13488
Epoch [17/25] Training [411/488] Loss: 0.24444
Epoch [17/25] Training [412/488] Loss: 0.18064
Epoch [17/25] Training [413/488] Loss: 0.15772
Epoch [17/25] Training [414/488] Loss: 0.47748
Epoch [17/25] Training [415/488] Loss: 0.31401
Epoch [17/25] Training [416/488] Loss: 0.25015
Epoch [17/25] Training [417/488] Loss: 0.20379
Epoch [17/25] Training [418/488] Loss: 0.18638
Epoch [17/25] Training [419/488] Loss: 0.40366
Epoch [17/25] Training [420/488] Loss: 0.28746
Epoch [17/25] Training [421/488] Loss: 0.16334
Epoch [17/25] Training [422/488] Loss: 0.17781
Epoch [17/25] Training [423/488] Loss: 0.23329
Epoch [17/25] Training [424/488] Loss: 0.16886
Epoch [17/25] Training [425/488] Loss: 0.34066
Epoch [17/25] Training [426/488] Loss: 0.17904
Epoch [17/25] Training [427/488] Loss: 0.39662
Epoch [17/25] Training [428/488] Loss: 0.14614
Epoch [17/25] Training [429/488] Loss: 0.15448
Epoch [17/25] Training [430/488] Loss: 0.18914
Epoch [17/25] Training [431/488] Loss: 0.36540
Epoch [17/25] Training [432/488] Loss: 0.30903
Epoch [17/25] Training [433/488] Loss: 0.40143
Epoch [17/25] Training [434/488] Loss: 0.19793
Epoch [17/25] Training [435/488] Loss: 0.22000
Epoch [17/25] Training [436/488] Loss: 0.14227
Epoch [17/25] Training [437/488] Loss: 0.33888
Epoch [17/25] Training [438/488] Loss: 0.18217
Epoch [17/25] Training [439/488] Loss: 0.22028
Epoch [17/25] Training [440/488] Loss: 0.25927
Epoch [17/25] Training [441/488] Loss: 0.20154
Epoch [17/25] Training [442/488] Loss: 0.17901
Epoch [17/25] Training [443/488] Loss: 0.16519
Epoch [17/25] Training [444/488] Loss: 0.16876
Epoch [17/25] Training [445/488] Loss: 0.24743
Epoch [17/25] Training [446/488] Loss: 0.18048
Epoch [17/25] Training [447/488] Loss: 0.18312
Epoch [17/25] Training [448/488] Loss: 0.19470
Epoch [17/25] Training [449/488] Loss: 0.21022
Epoch [17/25] Training [450/488] Loss: 0.73598
Epoch [17/25] Training [451/488] Loss: 0.18128
Epoch [17/25] Training [452/488] Loss: 0.24954
Epoch [17/25] Training [453/488] Loss: 0.47802
Epoch [17/25] Training [454/488] Loss: 0.19686
Epoch [17/25] Training [455/488] Loss: 0.23419
Epoch [17/25] Training [456/488] Loss: 0.18170
Epoch [17/25] Training [457/488] Loss: 0.26720
Epoch [17/25] Training [458/488] Loss: 0.68962
Epoch [17/25] Training [459/488] Loss: 0.44498
Epoch [17/25] Training [460/488] Loss: 0.44795
Epoch [17/25] Training [461/488] Loss: 0.15884
Epoch [17/25] Training [462/488] Loss: 0.29790
Epoch [17/25] Training [463/488] Loss: 0.47150
Epoch [17/25] Training [464/488] Loss: 0.15875
Epoch [17/25] Training [465/488] Loss: 0.31106
Epoch [17/25] Training [466/488] Loss: 0.28654
Epoch [17/25] Training [467/488] Loss: 0.25092
Epoch [17/25] Training [468/488] Loss: 0.28665
Epoch [17/25] Training [469/488] Loss: 0.21144
Epoch [17/25] Training [470/488] Loss: 0.35740
Epoch [17/25] Training [471/488] Loss: 0.46104
Epoch [17/25] Training [472/488] Loss: 0.17943
Epoch [17/25] Training [473/488] Loss: 0.19129
Epoch [17/25] Training [474/488] Loss: 0.21177
Epoch [17/25] Training [475/488] Loss: 0.23497
Epoch [17/25] Training [476/488] Loss: 0.31413
Epoch [17/25] Training [477/488] Loss: 0.17313
Epoch [17/25] Training [478/488] Loss: 0.14020
Epoch [17/25] Training [479/488] Loss: 0.53234
Epoch [17/25] Training [480/488] Loss: 0.17611
Epoch [17/25] Training [481/488] Loss: 0.24048
Epoch [17/25] Training [482/488] Loss: 0.35646
Epoch [17/25] Training [483/488] Loss: 0.20157
Epoch [17/25] Training [484/488] Loss: 0.18200
Epoch [17/25] Training [485/488] Loss: 0.17629
Epoch [17/25] Training [486/488] Loss: 0.19713
Epoch [17/25] Training [487/488] Loss: 0.26379
Epoch [17/25] Training [488/488] Loss: 0.19603
Epoch [17/25] Training metric {'Train/mean dice_metric': 0.8751240968704224, 'Train/TC dice_metric': 0.8963580131530762, 'Train/WT dice_metric': 0.9296371936798096, 'Train/ET dice_metric': 0.7993770241737366}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [17/25] Validation [1/123] Loss: 0.26600  focal_loss 0.00187  dice_loss 0.26412
Epoch [17/25] Validation [2/123] Loss: 0.43433  focal_loss 0.00085  dice_loss 0.43349
Epoch [17/25] Validation [3/123] Loss: 0.25792  focal_loss 0.00142  dice_loss 0.25650
Epoch [17/25] Validation [4/123] Loss: 0.34967  focal_loss 0.00134  dice_loss 0.34833
Epoch [17/25] Validation [5/123] Loss: 0.35166  focal_loss 0.00847  dice_loss 0.34319
Epoch [17/25] Validation [6/123] Loss: 0.38491  focal_loss 0.00079  dice_loss 0.38411
Epoch [17/25] Validation [7/123] Loss: 0.43834  focal_loss 0.00052  dice_loss 0.43783
Epoch [17/25] Validation [8/123] Loss: 0.41722  focal_loss 0.00138  dice_loss 0.41584
Epoch [17/25] Validation [9/123] Loss: 0.33134  focal_loss 0.00131  dice_loss 0.33002
Epoch [17/25] Validation [10/123] Loss: 0.56661  focal_loss 0.00292  dice_loss 0.56368
Epoch [17/25] Validation [11/123] Loss: 0.49827  focal_loss 0.00096  dice_loss 0.49732
Epoch [17/25] Validation [12/123] Loss: 0.27778  focal_loss 0.00126  dice_loss 0.27652
Epoch [17/25] Validation [13/123] Loss: 0.25647  focal_loss 0.00332  dice_loss 0.25315
Epoch [17/25] Validation [14/123] Loss: 0.32681  focal_loss 0.00096  dice_loss 0.32585
Epoch [17/25] Validation [15/123] Loss: 0.42672  focal_loss 0.00114  dice_loss 0.42559
Epoch [17/25] Validation [16/123] Loss: 0.47705  focal_loss 0.00125  dice_loss 0.47580
Epoch [17/25] Validation [17/123] Loss: 0.56815  focal_loss 0.00083  dice_loss 0.56731
Epoch [17/25] Validation [18/123] Loss: 0.38697  focal_loss 0.00219  dice_loss 0.38478
Epoch [17/25] Validation [19/123] Loss: 0.35530  focal_loss 0.00193  dice_loss 0.35337
Epoch [17/25] Validation [20/123] Loss: 0.52692  focal_loss 0.00036  dice_loss 0.52656
Epoch [17/25] Validation [21/123] Loss: 0.41436  focal_loss 0.00076  dice_loss 0.41360
Epoch [17/25] Validation [22/123] Loss: 0.70788  focal_loss 0.00227  dice_loss 0.70561
Epoch [17/25] Validation [23/123] Loss: 0.26818  focal_loss 0.00169  dice_loss 0.26649
Epoch [17/25] Validation [24/123] Loss: 0.34269  focal_loss 0.00094  dice_loss 0.34176
Epoch [17/25] Validation [25/123] Loss: 0.36745  focal_loss 0.00097  dice_loss 0.36649
Epoch [17/25] Validation [26/123] Loss: 0.29343  focal_loss 0.00204  dice_loss 0.29139
Epoch [17/25] Validation [27/123] Loss: 0.31676  focal_loss 0.00153  dice_loss 0.31523
Epoch [17/25] Validation [28/123] Loss: 0.55052  focal_loss 0.00352  dice_loss 0.54700
Epoch [17/25] Validation [29/123] Loss: 0.40793  focal_loss 0.00084  dice_loss 0.40709
Epoch [17/25] Validation [30/123] Loss: 0.31352  focal_loss 0.00418  dice_loss 0.30934
Epoch [17/25] Validation [31/123] Loss: 0.26912  focal_loss 0.00147  dice_loss 0.26765
Epoch [17/25] Validation [32/123] Loss: 0.36683  focal_loss 0.00159  dice_loss 0.36524
Epoch [17/25] Validation [33/123] Loss: 0.39554  focal_loss 0.00093  dice_loss 0.39461
Epoch [17/25] Validation [34/123] Loss: 0.35330  focal_loss 0.00083  dice_loss 0.35247
Epoch [17/25] Validation [35/123] Loss: 0.30643  focal_loss 0.00131  dice_loss 0.30512
Epoch [17/25] Validation [36/123] Loss: 0.34521  focal_loss 0.00113  dice_loss 0.34408
Epoch [17/25] Validation [37/123] Loss: 0.42763  focal_loss 0.00117  dice_loss 0.42647
Epoch [17/25] Validation [38/123] Loss: 0.30619  focal_loss 0.00120  dice_loss 0.30499
Epoch [17/25] Validation [39/123] Loss: 0.27977  focal_loss 0.00141  dice_loss 0.27836
Epoch [17/25] Validation [40/123] Loss: 0.39280  focal_loss 0.00072  dice_loss 0.39209
Epoch [17/25] Validation [41/123] Loss: 0.29700  focal_loss 0.00271  dice_loss 0.29429
Epoch [17/25] Validation [42/123] Loss: 0.26073  focal_loss 0.00115  dice_loss 0.25959
Epoch [17/25] Validation [43/123] Loss: 0.32627  focal_loss 0.00338  dice_loss 0.32288
Epoch [17/25] Validation [44/123] Loss: 0.52215  focal_loss 0.00212  dice_loss 0.52004
Epoch [17/25] Validation [45/123] Loss: 0.38027  focal_loss 0.00145  dice_loss 0.37883
Epoch [17/25] Validation [46/123] Loss: 0.44025  focal_loss 0.00442  dice_loss 0.43583
Epoch [17/25] Validation [47/123] Loss: 0.36474  focal_loss 0.00100  dice_loss 0.36374
Epoch [17/25] Validation [48/123] Loss: 0.42877  focal_loss 0.00152  dice_loss 0.42725
Epoch [17/25] Validation [49/123] Loss: 0.29375  focal_loss 0.00160  dice_loss 0.29215
Epoch [17/25] Validation [50/123] Loss: 0.27075  focal_loss 0.00176  dice_loss 0.26899
Epoch [17/25] Validation [51/123] Loss: 0.42561  focal_loss 0.00449  dice_loss 0.42112
Epoch [17/25] Validation [52/123] Loss: 0.29914  focal_loss 0.00080  dice_loss 0.29834
Epoch [17/25] Validation [53/123] Loss: 0.35457  focal_loss 0.00074  dice_loss 0.35382
Epoch [17/25] Validation [54/123] Loss: 0.37964  focal_loss 0.00057  dice_loss 0.37907
Epoch [17/25] Validation [55/123] Loss: 0.35099  focal_loss 0.00120  dice_loss 0.34979
Epoch [17/25] Validation [56/123] Loss: 0.30706  focal_loss 0.00266  dice_loss 0.30440
Epoch [17/25] Validation [57/123] Loss: 0.36917  focal_loss 0.00119  dice_loss 0.36798
Epoch [17/25] Validation [58/123] Loss: 0.37731  focal_loss 0.00455  dice_loss 0.37275
Epoch [17/25] Validation [59/123] Loss: 0.65594  focal_loss 0.00347  dice_loss 0.65247
Epoch [17/25] Validation [60/123] Loss: 0.31536  focal_loss 0.00186  dice_loss 0.31350
Epoch [17/25] Validation [61/123] Loss: 0.67865  focal_loss 0.00042  dice_loss 0.67823
Epoch [17/25] Validation [62/123] Loss: 0.51506  focal_loss 0.00230  dice_loss 0.51276
Epoch [17/25] Validation [63/123] Loss: 0.44603  focal_loss 0.00065  dice_loss 0.44538
Epoch [17/25] Validation [64/123] Loss: 0.40519  focal_loss 0.00247  dice_loss 0.40272
Epoch [17/25] Validation [65/123] Loss: 0.31563  focal_loss 0.00109  dice_loss 0.31454
Epoch [17/25] Validation [66/123] Loss: 0.32865  focal_loss 0.00105  dice_loss 0.32760
Epoch [17/25] Validation [67/123] Loss: 0.46270  focal_loss 0.00721  dice_loss 0.45548
Epoch [17/25] Validation [68/123] Loss: 0.43411  focal_loss 0.00055  dice_loss 0.43356
Epoch [17/25] Validation [69/123] Loss: 0.40655  focal_loss 0.00467  dice_loss 0.40188
Epoch [17/25] Validation [70/123] Loss: 0.37184  focal_loss 0.00117  dice_loss 0.37067
Epoch [17/25] Validation [71/123] Loss: 0.31209  focal_loss 0.00081  dice_loss 0.31127
Epoch [17/25] Validation [72/123] Loss: 0.28796  focal_loss 0.00175  dice_loss 0.28621
Epoch [17/25] Validation [73/123] Loss: 0.39877  focal_loss 0.00342  dice_loss 0.39535
Epoch [17/25] Validation [74/123] Loss: 0.37578  focal_loss 0.00119  dice_loss 0.37459
Epoch [17/25] Validation [75/123] Loss: 0.35380  focal_loss 0.00157  dice_loss 0.35224
Epoch [17/25] Validation [76/123] Loss: 0.56197  focal_loss 0.00376  dice_loss 0.55820
Epoch [17/25] Validation [77/123] Loss: 0.43114  focal_loss 0.00062  dice_loss 0.43052
Epoch [17/25] Validation [78/123] Loss: 0.33145  focal_loss 0.00120  dice_loss 0.33025
Epoch [17/25] Validation [79/123] Loss: 0.37626  focal_loss 0.00082  dice_loss 0.37545
Epoch [17/25] Validation [80/123] Loss: 0.29885  focal_loss 0.00302  dice_loss 0.29583
Epoch [17/25] Validation [81/123] Loss: 0.34237  focal_loss 0.00148  dice_loss 0.34089
Epoch [17/25] Validation [82/123] Loss: 0.29651  focal_loss 0.00131  dice_loss 0.29519
Epoch [17/25] Validation [83/123] Loss: 0.59411  focal_loss 0.02140  dice_loss 0.57271
Epoch [17/25] Validation [84/123] Loss: 0.33322  focal_loss 0.00124  dice_loss 0.33197
Epoch [17/25] Validation [85/123] Loss: 0.36368  focal_loss 0.00151  dice_loss 0.36216
Epoch [17/25] Validation [86/123] Loss: 0.29533  focal_loss 0.00108  dice_loss 0.29425
Epoch [17/25] Validation [87/123] Loss: 0.27123  focal_loss 0.00286  dice_loss 0.26837
Epoch [17/25] Validation [88/123] Loss: 0.31464  focal_loss 0.00128  dice_loss 0.31335
Epoch [17/25] Validation [89/123] Loss: 0.26316  focal_loss 0.00195  dice_loss 0.26122
Epoch [17/25] Validation [90/123] Loss: 0.36961  focal_loss 0.00140  dice_loss 0.36821
Epoch [17/25] Validation [91/123] Loss: 0.30430  focal_loss 0.00091  dice_loss 0.30340
Epoch [17/25] Validation [92/123] Loss: 0.26685  focal_loss 0.00153  dice_loss 0.26532
Epoch [17/25] Validation [93/123] Loss: 0.28051  focal_loss 0.00121  dice_loss 0.27930
Epoch [17/25] Validation [94/123] Loss: 0.40227  focal_loss 0.00112  dice_loss 0.40115
Epoch [17/25] Validation [95/123] Loss: 0.32896  focal_loss 0.00283  dice_loss 0.32614
Epoch [17/25] Validation [96/123] Loss: 0.39647  focal_loss 0.00146  dice_loss 0.39500
Epoch [17/25] Validation [97/123] Loss: 0.59723  focal_loss 0.00281  dice_loss 0.59442
Epoch [17/25] Validation [98/123] Loss: 0.37714  focal_loss 0.00051  dice_loss 0.37663
Epoch [17/25] Validation [99/123] Loss: 0.39858  focal_loss 0.00057  dice_loss 0.39801
Epoch [17/25] Validation [100/123] Loss: 0.41115  focal_loss 0.00061  dice_loss 0.41053
Epoch [17/25] Validation [101/123] Loss: 0.35955  focal_loss 0.00090  dice_loss 0.35865
Epoch [17/25] Validation [102/123] Loss: 0.41298  focal_loss 0.00052  dice_loss 0.41246
Epoch [17/25] Validation [103/123] Loss: 0.49626  focal_loss 0.00039  dice_loss 0.49587
Epoch [17/25] Validation [104/123] Loss: 0.47197  focal_loss 0.00184  dice_loss 0.47013
Epoch [17/25] Validation [105/123] Loss: 0.26705  focal_loss 0.00290  dice_loss 0.26415
Epoch [17/25] Validation [106/123] Loss: 0.31890  focal_loss 0.00098  dice_loss 0.31792
Epoch [17/25] Validation [107/123] Loss: 0.57159  focal_loss 0.00117  dice_loss 0.57041
Epoch [17/25] Validation [108/123] Loss: 0.31139  focal_loss 0.00069  dice_loss 0.31071
Epoch [17/25] Validation [109/123] Loss: 0.27578  focal_loss 0.00520  dice_loss 0.27058
Epoch [17/25] Validation [110/123] Loss: 0.40683  focal_loss 0.00183  dice_loss 0.40500
Epoch [17/25] Validation [111/123] Loss: 0.42369  focal_loss 0.00170  dice_loss 0.42199
Epoch [17/25] Validation [112/123] Loss: 0.40795  focal_loss 0.00096  dice_loss 0.40699
Epoch [17/25] Validation [113/123] Loss: 0.32232  focal_loss 0.00115  dice_loss 0.32117
Epoch [17/25] Validation [114/123] Loss: 0.49959  focal_loss 0.01178  dice_loss 0.48781
Epoch [17/25] Validation [115/123] Loss: 0.36810  focal_loss 0.00726  dice_loss 0.36083
Epoch [17/25] Validation [116/123] Loss: 0.34407  focal_loss 0.00055  dice_loss 0.34352
Epoch [17/25] Validation [117/123] Loss: 0.33886  focal_loss 0.00119  dice_loss 0.33767
Epoch [17/25] Validation [118/123] Loss: 0.25632  focal_loss 0.00204  dice_loss 0.25428
Epoch [17/25] Validation [119/123] Loss: 0.28480  focal_loss 0.00146  dice_loss 0.28335
Epoch [17/25] Validation [120/123] Loss: 0.31011  focal_loss 0.00180  dice_loss 0.30831
Epoch [17/25] Validation [121/123] Loss: 0.59752  focal_loss 0.00402  dice_loss 0.59350
Epoch [17/25] Validation [122/123] Loss: 0.68201  focal_loss 0.00029  dice_loss 0.68172
Epoch [17/25] Validation [123/123] Loss: 0.30339  focal_loss 0.00160  dice_loss 0.30179
Epoch [17/25] Validation metric {'Val/mean dice_metric': 0.8758313059806824, 'Val/TC dice_metric': 0.8954615592956543, 'Val/WT dice_metric': 0.9292476177215576, 'Val/ET dice_metric': 0.80278480052948}
Epoch [17/25] lr = [0.0004217827674798847, 0.0004217827674798847] best acc: tensor([0.8658], device='cuda:0'), mean acc: tensor([0.8758], device='cuda:0'), mean class: tensor([0.8955, 0.9292, 0.8028], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [18/25] Training [1/488] Loss: 0.24564
Epoch [18/25] Training [2/488] Loss: 0.22874
Epoch [18/25] Training [3/488] Loss: 0.28788
Epoch [18/25] Training [4/488] Loss: 0.21750
Epoch [18/25] Training [5/488] Loss: 0.23388
Epoch [18/25] Training [6/488] Loss: 0.48043
Epoch [18/25] Training [7/488] Loss: 0.31738
Epoch [18/25] Training [8/488] Loss: 0.18198
Epoch [18/25] Training [9/488] Loss: 0.20655
Epoch [18/25] Training [10/488] Loss: 0.17799
Epoch [18/25] Training [11/488] Loss: 0.37895
Epoch [18/25] Training [12/488] Loss: 0.30399
Epoch [18/25] Training [13/488] Loss: 0.19953
Epoch [18/25] Training [14/488] Loss: 0.24962
Epoch [18/25] Training [15/488] Loss: 0.21837
Epoch [18/25] Training [16/488] Loss: 0.58536
Epoch [18/25] Training [17/488] Loss: 0.24026
Epoch [18/25] Training [18/488] Loss: 0.17724
Epoch [18/25] Training [19/488] Loss: 0.22270
Epoch [18/25] Training [20/488] Loss: 0.18638
Epoch [18/25] Training [21/488] Loss: 0.20748
Epoch [18/25] Training [22/488] Loss: 0.31442
Epoch [18/25] Training [23/488] Loss: 0.22908
Epoch [18/25] Training [24/488] Loss: 0.44556
Epoch [18/25] Training [25/488] Loss: 0.38781
Epoch [18/25] Training [26/488] Loss: 0.40488
Epoch [18/25] Training [27/488] Loss: 0.14138
Epoch [18/25] Training [28/488] Loss: 0.22266
Epoch [18/25] Training [29/488] Loss: 0.15900
Epoch [18/25] Training [30/488] Loss: 0.16148
Epoch [18/25] Training [31/488] Loss: 0.37504
Epoch [18/25] Training [32/488] Loss: 0.40755
Epoch [18/25] Training [33/488] Loss: 0.21125
Epoch [18/25] Training [34/488] Loss: 0.52176
Epoch [18/25] Training [35/488] Loss: 0.17350
Epoch [18/25] Training [36/488] Loss: 0.25325
Epoch [18/25] Training [37/488] Loss: 0.19140
Epoch [18/25] Training [38/488] Loss: 0.40047
Epoch [18/25] Training [39/488] Loss: 0.17232
Epoch [18/25] Training [40/488] Loss: 0.41640
Epoch [18/25] Training [41/488] Loss: 0.20623
Epoch [18/25] Training [42/488] Loss: 0.22232
Epoch [18/25] Training [43/488] Loss: 0.42210
Epoch [18/25] Training [44/488] Loss: 0.20076
Epoch [18/25] Training [45/488] Loss: 0.20780
Epoch [18/25] Training [46/488] Loss: 0.15861
Epoch [18/25] Training [47/488] Loss: 0.20315
Epoch [18/25] Training [48/488] Loss: 0.24101
Epoch [18/25] Training [49/488] Loss: 0.35677
Epoch [18/25] Training [50/488] Loss: 0.20156
Epoch [18/25] Training [51/488] Loss: 0.41796
Epoch [18/25] Training [52/488] Loss: 0.20790
Epoch [18/25] Training [53/488] Loss: 0.26057
Epoch [18/25] Training [54/488] Loss: 0.36419
Epoch [18/25] Training [55/488] Loss: 0.21414
Epoch [18/25] Training [56/488] Loss: 0.18338
Epoch [18/25] Training [57/488] Loss: 0.26353
Epoch [18/25] Training [58/488] Loss: 0.36265
Epoch [18/25] Training [59/488] Loss: 0.24055
Epoch [18/25] Training [60/488] Loss: 0.17407
Epoch [18/25] Training [61/488] Loss: 0.16377
Epoch [18/25] Training [62/488] Loss: 0.55986
Epoch [18/25] Training [63/488] Loss: 0.18056
Epoch [18/25] Training [64/488] Loss: 0.17500
Epoch [18/25] Training [65/488] Loss: 0.29085
Epoch [18/25] Training [66/488] Loss: 0.25592
Epoch [18/25] Training [67/488] Loss: 0.48539
Epoch [18/25] Training [68/488] Loss: 0.33319
Epoch [18/25] Training [69/488] Loss: 0.19654
Epoch [18/25] Training [70/488] Loss: 0.28547
Epoch [18/25] Training [71/488] Loss: 0.19128
Epoch [18/25] Training [72/488] Loss: 0.23598
Epoch [18/25] Training [73/488] Loss: 0.30171
Epoch [18/25] Training [74/488] Loss: 0.15236
Epoch [18/25] Training [75/488] Loss: 0.21340
Epoch [18/25] Training [76/488] Loss: 0.29883
Epoch [18/25] Training [77/488] Loss: 0.27258
Epoch [18/25] Training [78/488] Loss: 0.16454
Epoch [18/25] Training [79/488] Loss: 0.34400
Epoch [18/25] Training [80/488] Loss: 0.26098
Epoch [18/25] Training [81/488] Loss: 0.23069
Epoch [18/25] Training [82/488] Loss: 0.14936
Epoch [18/25] Training [83/488] Loss: 0.34177
Epoch [18/25] Training [84/488] Loss: 0.23110
Epoch [18/25] Training [85/488] Loss: 0.21271
Epoch [18/25] Training [86/488] Loss: 0.18913
Epoch [18/25] Training [87/488] Loss: 0.16362
Epoch [18/25] Training [88/488] Loss: 0.26586
Epoch [18/25] Training [89/488] Loss: 0.17877
Epoch [18/25] Training [90/488] Loss: 0.20461
Epoch [18/25] Training [91/488] Loss: 0.21116
Epoch [18/25] Training [92/488] Loss: 0.13398
Epoch [18/25] Training [93/488] Loss: 0.23196
Epoch [18/25] Training [94/488] Loss: 0.17286
Epoch [18/25] Training [95/488] Loss: 0.19927
Epoch [18/25] Training [96/488] Loss: 0.23951
Epoch [18/25] Training [97/488] Loss: 0.22627
Epoch [18/25] Training [98/488] Loss: 0.18986
Epoch [18/25] Training [99/488] Loss: 0.18697
Epoch [18/25] Training [100/488] Loss: 0.22235
Epoch [18/25] Training [101/488] Loss: 0.23319
Epoch [18/25] Training [102/488] Loss: 0.19497
Epoch [18/25] Training [103/488] Loss: 0.24244
Epoch [18/25] Training [104/488] Loss: 0.40413
Epoch [18/25] Training [105/488] Loss: 0.16465
Epoch [18/25] Training [106/488] Loss: 0.19514
Epoch [18/25] Training [107/488] Loss: 0.40049
Epoch [18/25] Training [108/488] Loss: 0.35632
Epoch [18/25] Training [109/488] Loss: 0.17031
Epoch [18/25] Training [110/488] Loss: 0.17474
Epoch [18/25] Training [111/488] Loss: 0.37578
Epoch [18/25] Training [112/488] Loss: 0.49974
Epoch [18/25] Training [113/488] Loss: 0.24778
Epoch [18/25] Training [114/488] Loss: 0.16776
Epoch [18/25] Training [115/488] Loss: 0.21396
Epoch [18/25] Training [116/488] Loss: 0.26300
Epoch [18/25] Training [117/488] Loss: 0.14265
Epoch [18/25] Training [118/488] Loss: 0.18958
Epoch [18/25] Training [119/488] Loss: 0.25796
Epoch [18/25] Training [120/488] Loss: 0.25477
Epoch [18/25] Training [121/488] Loss: 0.22510
Epoch [18/25] Training [122/488] Loss: 0.17842
Epoch [18/25] Training [123/488] Loss: 0.21478
Epoch [18/25] Training [124/488] Loss: 0.18339
Epoch [18/25] Training [125/488] Loss: 0.37055
Epoch [18/25] Training [126/488] Loss: 0.25458
Epoch [18/25] Training [127/488] Loss: 0.60055
Epoch [18/25] Training [128/488] Loss: 0.19710
Epoch [18/25] Training [129/488] Loss: 0.32400
Epoch [18/25] Training [130/488] Loss: 0.39953
Epoch [18/25] Training [131/488] Loss: 0.15312
Epoch [18/25] Training [132/488] Loss: 0.15376
Epoch [18/25] Training [133/488] Loss: 0.18111
Epoch [18/25] Training [134/488] Loss: 0.20416
Epoch [18/25] Training [135/488] Loss: 0.17020
Epoch [18/25] Training [136/488] Loss: 0.16422
Epoch [18/25] Training [137/488] Loss: 0.24488
Epoch [18/25] Training [138/488] Loss: 0.16167
Epoch [18/25] Training [139/488] Loss: 0.48155
Epoch [18/25] Training [140/488] Loss: 0.45412
Epoch [18/25] Training [141/488] Loss: 0.37802
Epoch [18/25] Training [142/488] Loss: 0.19508
Epoch [18/25] Training [143/488] Loss: 0.25847
Epoch [18/25] Training [144/488] Loss: 0.14162
Epoch [18/25] Training [145/488] Loss: 0.31311
Epoch [18/25] Training [146/488] Loss: 0.52706
Epoch [18/25] Training [147/488] Loss: 0.36259
Epoch [18/25] Training [148/488] Loss: 0.23618
Epoch [18/25] Training [149/488] Loss: 0.14965
Epoch [18/25] Training [150/488] Loss: 0.26987
Epoch [18/25] Training [151/488] Loss: 0.15713
Epoch [18/25] Training [152/488] Loss: 0.27267
Epoch [18/25] Training [153/488] Loss: 0.17908
Epoch [18/25] Training [154/488] Loss: 0.17980
Epoch [18/25] Training [155/488] Loss: 0.29581
Epoch [18/25] Training [156/488] Loss: 0.18537
Epoch [18/25] Training [157/488] Loss: 0.20630
Epoch [18/25] Training [158/488] Loss: 0.25506
Epoch [18/25] Training [159/488] Loss: 0.25140
Epoch [18/25] Training [160/488] Loss: 0.16291
Epoch [18/25] Training [161/488] Loss: 0.15490
Epoch [18/25] Training [162/488] Loss: 0.29763
Epoch [18/25] Training [163/488] Loss: 0.17633
Epoch [18/25] Training [164/488] Loss: 0.18270
Epoch [18/25] Training [165/488] Loss: 0.41004
Epoch [18/25] Training [166/488] Loss: 0.17205
Epoch [18/25] Training [167/488] Loss: 0.19391
Epoch [18/25] Training [168/488] Loss: 0.29176
Epoch [18/25] Training [169/488] Loss: 0.30945
Epoch [18/25] Training [170/488] Loss: 0.18895
Epoch [18/25] Training [171/488] Loss: 0.29306
Epoch [18/25] Training [172/488] Loss: 0.18442
Epoch [18/25] Training [173/488] Loss: 0.17606
Epoch [18/25] Training [174/488] Loss: 0.21387
Epoch [18/25] Training [175/488] Loss: 0.32795
Epoch [18/25] Training [176/488] Loss: 0.16520
Epoch [18/25] Training [177/488] Loss: 0.21836
Epoch [18/25] Training [178/488] Loss: 0.18952
Epoch [18/25] Training [179/488] Loss: 0.15010
Epoch [18/25] Training [180/488] Loss: 0.27688
Epoch [18/25] Training [181/488] Loss: 0.43995
Epoch [18/25] Training [182/488] Loss: 0.14888
Epoch [18/25] Training [183/488] Loss: 0.36718
Epoch [18/25] Training [184/488] Loss: 0.21033
Epoch [18/25] Training [185/488] Loss: 0.19129
Epoch [18/25] Training [186/488] Loss: 0.45755
Epoch [18/25] Training [187/488] Loss: 0.14746
Epoch [18/25] Training [188/488] Loss: 0.28096
Epoch [18/25] Training [189/488] Loss: 0.28210
Epoch [18/25] Training [190/488] Loss: 0.27435
Epoch [18/25] Training [191/488] Loss: 0.28793
Epoch [18/25] Training [192/488] Loss: 0.30395
Epoch [18/25] Training [193/488] Loss: 0.20484
Epoch [18/25] Training [194/488] Loss: 0.23605
Epoch [18/25] Training [195/488] Loss: 0.38336
Epoch [18/25] Training [196/488] Loss: 0.13840
Epoch [18/25] Training [197/488] Loss: 0.22000
Epoch [18/25] Training [198/488] Loss: 0.13538
Epoch [18/25] Training [199/488] Loss: 0.30477
Epoch [18/25] Training [200/488] Loss: 0.57358
Epoch [18/25] Training [201/488] Loss: 0.18595
Epoch [18/25] Training [202/488] Loss: 0.16286
Epoch [18/25] Training [203/488] Loss: 0.20017
Epoch [18/25] Training [204/488] Loss: 0.21864
Epoch [18/25] Training [205/488] Loss: 0.28397
Epoch [18/25] Training [206/488] Loss: 0.31723
Epoch [18/25] Training [207/488] Loss: 0.33302
Epoch [18/25] Training [208/488] Loss: 0.20814
Epoch [18/25] Training [209/488] Loss: 0.19141
Epoch [18/25] Training [210/488] Loss: 0.30047
Epoch [18/25] Training [211/488] Loss: 0.76390
Epoch [18/25] Training [212/488] Loss: 0.28426
Epoch [18/25] Training [213/488] Loss: 0.40541
Epoch [18/25] Training [214/488] Loss: 0.26141
Epoch [18/25] Training [215/488] Loss: 0.24947
Epoch [18/25] Training [216/488] Loss: 0.24355
Epoch [18/25] Training [217/488] Loss: 0.29566
Epoch [18/25] Training [218/488] Loss: 0.14720
Epoch [18/25] Training [219/488] Loss: 0.34741
Epoch [18/25] Training [220/488] Loss: 0.25382
Epoch [18/25] Training [221/488] Loss: 0.28532
Epoch [18/25] Training [222/488] Loss: 0.15089
Epoch [18/25] Training [223/488] Loss: 0.25418
Epoch [18/25] Training [224/488] Loss: 0.14389
Epoch [18/25] Training [225/488] Loss: 0.22239
Epoch [18/25] Training [226/488] Loss: 0.38237
Epoch [18/25] Training [227/488] Loss: 0.14507
Epoch [18/25] Training [228/488] Loss: 0.25153
Epoch [18/25] Training [229/488] Loss: 0.25283
Epoch [18/25] Training [230/488] Loss: 0.15551
Epoch [18/25] Training [231/488] Loss: 0.23510
Epoch [18/25] Training [232/488] Loss: 0.25730
Epoch [18/25] Training [233/488] Loss: 0.59726
Epoch [18/25] Training [234/488] Loss: 0.36595
Epoch [18/25] Training [235/488] Loss: 0.18307
Epoch [18/25] Training [236/488] Loss: 0.59184
Epoch [18/25] Training [237/488] Loss: 0.30795
Epoch [18/25] Training [238/488] Loss: 0.17014
Epoch [18/25] Training [239/488] Loss: 0.30741
Epoch [18/25] Training [240/488] Loss: 0.17268
Epoch [18/25] Training [241/488] Loss: 0.29888
Epoch [18/25] Training [242/488] Loss: 0.26254
Epoch [18/25] Training [243/488] Loss: 0.25862
Epoch [18/25] Training [244/488] Loss: 0.21545
Epoch [18/25] Training [245/488] Loss: 0.19710
Epoch [18/25] Training [246/488] Loss: 0.39970
Epoch [18/25] Training [247/488] Loss: 0.14253
Epoch [18/25] Training [248/488] Loss: 0.18339
Epoch [18/25] Training [249/488] Loss: 0.30506
Epoch [18/25] Training [250/488] Loss: 0.29944
Epoch [18/25] Training [251/488] Loss: 0.26177
Epoch [18/25] Training [252/488] Loss: 0.46758
Epoch [18/25] Training [253/488] Loss: 0.17163
Epoch [18/25] Training [254/488] Loss: 0.43702
Epoch [18/25] Training [255/488] Loss: 0.40607
Epoch [18/25] Training [256/488] Loss: 0.20425
Epoch [18/25] Training [257/488] Loss: 0.17073
Epoch [18/25] Training [258/488] Loss: 0.84351
Epoch [18/25] Training [259/488] Loss: 0.20305
Epoch [18/25] Training [260/488] Loss: 0.39813
Epoch [18/25] Training [261/488] Loss: 0.33404
Epoch [18/25] Training [262/488] Loss: 0.14885
Epoch [18/25] Training [263/488] Loss: 0.69906
Epoch [18/25] Training [264/488] Loss: 0.58859
Epoch [18/25] Training [265/488] Loss: 0.24238
Epoch [18/25] Training [266/488] Loss: 0.17084
Epoch [18/25] Training [267/488] Loss: 0.35502
Epoch [18/25] Training [268/488] Loss: 0.35273
Epoch [18/25] Training [269/488] Loss: 0.25549
Epoch [18/25] Training [270/488] Loss: 0.20491
Epoch [18/25] Training [271/488] Loss: 0.18426
Epoch [18/25] Training [272/488] Loss: 0.26398
Epoch [18/25] Training [273/488] Loss: 0.57471
Epoch [18/25] Training [274/488] Loss: 0.17862
Epoch [18/25] Training [275/488] Loss: 0.20995
Epoch [18/25] Training [276/488] Loss: 0.36204
Epoch [18/25] Training [277/488] Loss: 0.20432
Epoch [18/25] Training [278/488] Loss: 0.18409
Epoch [18/25] Training [279/488] Loss: 0.21542
Epoch [18/25] Training [280/488] Loss: 0.14701
Epoch [18/25] Training [281/488] Loss: 0.28786
Epoch [18/25] Training [282/488] Loss: 0.15080
Epoch [18/25] Training [283/488] Loss: 0.28429
Epoch [18/25] Training [284/488] Loss: 0.27443
Epoch [18/25] Training [285/488] Loss: 0.23421
Epoch [18/25] Training [286/488] Loss: 0.15608
Epoch [18/25] Training [287/488] Loss: 0.24331
Epoch [18/25] Training [288/488] Loss: 0.32063
Epoch [18/25] Training [289/488] Loss: 0.16354
Epoch [18/25] Training [290/488] Loss: 0.21343
Epoch [18/25] Training [291/488] Loss: 0.29473
Epoch [18/25] Training [292/488] Loss: 0.17310
Epoch [18/25] Training [293/488] Loss: 0.24754
Epoch [18/25] Training [294/488] Loss: 0.38316
Epoch [18/25] Training [295/488] Loss: 0.15683
Epoch [18/25] Training [296/488] Loss: 0.17915
Epoch [18/25] Training [297/488] Loss: 0.28914
Epoch [18/25] Training [298/488] Loss: 0.20076
Epoch [18/25] Training [299/488] Loss: 0.16999
Epoch [18/25] Training [300/488] Loss: 0.29813
Epoch [18/25] Training [301/488] Loss: 0.25499
Epoch [18/25] Training [302/488] Loss: 0.30034
Epoch [18/25] Training [303/488] Loss: 0.17857
Epoch [18/25] Training [304/488] Loss: 0.26787
Epoch [18/25] Training [305/488] Loss: 0.39186
Epoch [18/25] Training [306/488] Loss: 0.20367
Epoch [18/25] Training [307/488] Loss: 0.31169
Epoch [18/25] Training [308/488] Loss: 0.20266
Epoch [18/25] Training [309/488] Loss: 0.23988
Epoch [18/25] Training [310/488] Loss: 0.68420
Epoch [18/25] Training [311/488] Loss: 0.16987
Epoch [18/25] Training [312/488] Loss: 0.70899
Epoch [18/25] Training [313/488] Loss: 0.35667
Epoch [18/25] Training [314/488] Loss: 0.19797
Epoch [18/25] Training [315/488] Loss: 0.44819
Epoch [18/25] Training [316/488] Loss: 0.26348
Epoch [18/25] Training [317/488] Loss: 0.17162
Epoch [18/25] Training [318/488] Loss: 0.40638
Epoch [18/25] Training [319/488] Loss: 0.35411
Epoch [18/25] Training [320/488] Loss: 0.17087
Epoch [18/25] Training [321/488] Loss: 0.39437
Epoch [18/25] Training [322/488] Loss: 0.29123
Epoch [18/25] Training [323/488] Loss: 0.18387
Epoch [18/25] Training [324/488] Loss: 0.16139
Epoch [18/25] Training [325/488] Loss: 0.13987
Epoch [18/25] Training [326/488] Loss: 0.16308
Epoch [18/25] Training [327/488] Loss: 0.46441
Epoch [18/25] Training [328/488] Loss: 0.18738
Epoch [18/25] Training [329/488] Loss: 0.19199
Epoch [18/25] Training [330/488] Loss: 0.16844
Epoch [18/25] Training [331/488] Loss: 0.26047
Epoch [18/25] Training [332/488] Loss: 0.20892
Epoch [18/25] Training [333/488] Loss: 0.19345
Epoch [18/25] Training [334/488] Loss: 0.29092
Epoch [18/25] Training [335/488] Loss: 0.28357
Epoch [18/25] Training [336/488] Loss: 0.18577
Epoch [18/25] Training [337/488] Loss: 0.20413
Epoch [18/25] Training [338/488] Loss: 0.24574
Epoch [18/25] Training [339/488] Loss: 0.23555
Epoch [18/25] Training [340/488] Loss: 0.24339
Epoch [18/25] Training [341/488] Loss: 0.25716
Epoch [18/25] Training [342/488] Loss: 0.24373
Epoch [18/25] Training [343/488] Loss: 0.37539
Epoch [18/25] Training [344/488] Loss: 0.16867
Epoch [18/25] Training [345/488] Loss: 0.14076
Epoch [18/25] Training [346/488] Loss: 0.16732
Epoch [18/25] Training [347/488] Loss: 0.36212
Epoch [18/25] Training [348/488] Loss: 0.20218
Epoch [18/25] Training [349/488] Loss: 0.33182
Epoch [18/25] Training [350/488] Loss: 0.19822
Epoch [18/25] Training [351/488] Loss: 0.13181
Epoch [18/25] Training [352/488] Loss: 0.29677
Epoch [18/25] Training [353/488] Loss: 0.18640
Epoch [18/25] Training [354/488] Loss: 0.22353
Epoch [18/25] Training [355/488] Loss: 0.18937
Epoch [18/25] Training [356/488] Loss: 0.25638
Epoch [18/25] Training [357/488] Loss: 0.19447
Epoch [18/25] Training [358/488] Loss: 0.27906
Epoch [18/25] Training [359/488] Loss: 0.13392
Epoch [18/25] Training [360/488] Loss: 0.23205
Epoch [18/25] Training [361/488] Loss: 0.58293
Epoch [18/25] Training [362/488] Loss: 0.73702
Epoch [18/25] Training [363/488] Loss: 0.29311
Epoch [18/25] Training [364/488] Loss: 0.15443
Epoch [18/25] Training [365/488] Loss: 0.39914
Epoch [18/25] Training [366/488] Loss: 0.42547
Epoch [18/25] Training [367/488] Loss: 0.15791
Epoch [18/25] Training [368/488] Loss: 0.23566
Epoch [18/25] Training [369/488] Loss: 0.25475
Epoch [18/25] Training [370/488] Loss: 0.27385
Epoch [18/25] Training [371/488] Loss: 0.22388
Epoch [18/25] Training [372/488] Loss: 0.17774
Epoch [18/25] Training [373/488] Loss: 0.14430
Epoch [18/25] Training [374/488] Loss: 0.33271
Epoch [18/25] Training [375/488] Loss: 0.14921
Epoch [18/25] Training [376/488] Loss: 0.19695
Epoch [18/25] Training [377/488] Loss: 0.21691
Epoch [18/25] Training [378/488] Loss: 0.27591
Epoch [18/25] Training [379/488] Loss: 0.24955
Epoch [18/25] Training [380/488] Loss: 0.22273
Epoch [18/25] Training [381/488] Loss: 0.34914
Epoch [18/25] Training [382/488] Loss: 0.18027
Epoch [18/25] Training [383/488] Loss: 0.17628
Epoch [18/25] Training [384/488] Loss: 0.34916
Epoch [18/25] Training [385/488] Loss: 0.18700
Epoch [18/25] Training [386/488] Loss: 0.77790
Epoch [18/25] Training [387/488] Loss: 0.19902
Epoch [18/25] Training [388/488] Loss: 0.47606
Epoch [18/25] Training [389/488] Loss: 0.19552
Epoch [18/25] Training [390/488] Loss: 0.18678
Epoch [18/25] Training [391/488] Loss: 0.24368
Epoch [18/25] Training [392/488] Loss: 0.23616
Epoch [18/25] Training [393/488] Loss: 0.18030
Epoch [18/25] Training [394/488] Loss: 0.17793
Epoch [18/25] Training [395/488] Loss: 0.22437
Epoch [18/25] Training [396/488] Loss: 0.16866
Epoch [18/25] Training [397/488] Loss: 0.37204
Epoch [18/25] Training [398/488] Loss: 0.35608
Epoch [18/25] Training [399/488] Loss: 0.27450
Epoch [18/25] Training [400/488] Loss: 0.32968
Epoch [18/25] Training [401/488] Loss: 0.24353
Epoch [18/25] Training [402/488] Loss: 0.15426
Epoch [18/25] Training [403/488] Loss: 0.14864
Epoch [18/25] Training [404/488] Loss: 0.23527
Epoch [18/25] Training [405/488] Loss: 0.19930
Epoch [18/25] Training [406/488] Loss: 0.43509
Epoch [18/25] Training [407/488] Loss: 0.21066
Epoch [18/25] Training [408/488] Loss: 0.15949
Epoch [18/25] Training [409/488] Loss: 0.14340
Epoch [18/25] Training [410/488] Loss: 0.33777
Epoch [18/25] Training [411/488] Loss: 0.30018
Epoch [18/25] Training [412/488] Loss: 0.24099
Epoch [18/25] Training [413/488] Loss: 0.21258
Epoch [18/25] Training [414/488] Loss: 0.30344
Epoch [18/25] Training [415/488] Loss: 0.30683
Epoch [18/25] Training [416/488] Loss: 0.31443
Epoch [18/25] Training [417/488] Loss: 0.19225
Epoch [18/25] Training [418/488] Loss: 0.14555
Epoch [18/25] Training [419/488] Loss: 0.26182
Epoch [18/25] Training [420/488] Loss: 0.66295
Epoch [18/25] Training [421/488] Loss: 0.42201
Epoch [18/25] Training [422/488] Loss: 0.14041
Epoch [18/25] Training [423/488] Loss: 0.17594
Epoch [18/25] Training [424/488] Loss: 0.17548
Epoch [18/25] Training [425/488] Loss: 0.27318
Epoch [18/25] Training [426/488] Loss: 0.16788
Epoch [18/25] Training [427/488] Loss: 0.32454
Epoch [18/25] Training [428/488] Loss: 0.28940
Epoch [18/25] Training [429/488] Loss: 0.14567
Epoch [18/25] Training [430/488] Loss: 0.52337
Epoch [18/25] Training [431/488] Loss: 0.13157
Epoch [18/25] Training [432/488] Loss: 0.40574
Epoch [18/25] Training [433/488] Loss: 0.47007
Epoch [18/25] Training [434/488] Loss: 0.26960
Epoch [18/25] Training [435/488] Loss: 0.12882
Epoch [18/25] Training [436/488] Loss: 0.35357
Epoch [18/25] Training [437/488] Loss: 0.26113
Epoch [18/25] Training [438/488] Loss: 0.39424
Epoch [18/25] Training [439/488] Loss: 0.15327
Epoch [18/25] Training [440/488] Loss: 0.43637
Epoch [18/25] Training [441/488] Loss: 0.15676
Epoch [18/25] Training [442/488] Loss: 0.66150
Epoch [18/25] Training [443/488] Loss: 0.19085
Epoch [18/25] Training [444/488] Loss: 0.18442
Epoch [18/25] Training [445/488] Loss: 0.17306
Epoch [18/25] Training [446/488] Loss: 0.46211
Epoch [18/25] Training [447/488] Loss: 0.22221
Epoch [18/25] Training [448/488] Loss: 0.13816
Epoch [18/25] Training [449/488] Loss: 0.23349
Epoch [18/25] Training [450/488] Loss: 0.46055
Epoch [18/25] Training [451/488] Loss: 0.46820
Epoch [18/25] Training [452/488] Loss: 0.34768
Epoch [18/25] Training [453/488] Loss: 0.16077
Epoch [18/25] Training [454/488] Loss: 0.16745
Epoch [18/25] Training [455/488] Loss: 0.15048
Epoch [18/25] Training [456/488] Loss: 0.13639
Epoch [18/25] Training [457/488] Loss: 0.23439
Epoch [18/25] Training [458/488] Loss: 0.24595
Epoch [18/25] Training [459/488] Loss: 0.21988
Epoch [18/25] Training [460/488] Loss: 0.17902
Epoch [18/25] Training [461/488] Loss: 0.22389
Epoch [18/25] Training [462/488] Loss: 0.65361
Epoch [18/25] Training [463/488] Loss: 0.16010
Epoch [18/25] Training [464/488] Loss: 0.26363
Epoch [18/25] Training [465/488] Loss: 0.71743
Epoch [18/25] Training [466/488] Loss: 0.45918
Epoch [18/25] Training [467/488] Loss: 0.16772
Epoch [18/25] Training [468/488] Loss: 0.32955
Epoch [18/25] Training [469/488] Loss: 0.33545
Epoch [18/25] Training [470/488] Loss: 0.15016
Epoch [18/25] Training [471/488] Loss: 0.33565
Epoch [18/25] Training [472/488] Loss: 0.41034
Epoch [18/25] Training [473/488] Loss: 0.25011
Epoch [18/25] Training [474/488] Loss: 0.16671
Epoch [18/25] Training [475/488] Loss: 0.38019
Epoch [18/25] Training [476/488] Loss: 0.21091
Epoch [18/25] Training [477/488] Loss: 0.14581
Epoch [18/25] Training [478/488] Loss: 0.17525
Epoch [18/25] Training [479/488] Loss: 0.14270
Epoch [18/25] Training [480/488] Loss: 0.13191
Epoch [18/25] Training [481/488] Loss: 0.22960
Epoch [18/25] Training [482/488] Loss: 0.15837
Epoch [18/25] Training [483/488] Loss: 0.15888
Epoch [18/25] Training [484/488] Loss: 0.17921
Epoch [18/25] Training [485/488] Loss: 0.13733
Epoch [18/25] Training [486/488] Loss: 0.16853
Epoch [18/25] Training [487/488] Loss: 0.17164
Epoch [18/25] Training [488/488] Loss: 0.14659
Epoch [18/25] Training metric {'Train/mean dice_metric': 0.8790256977081299, 'Train/TC dice_metric': 0.899917721748352, 'Train/WT dice_metric': 0.9307851791381836, 'Train/ET dice_metric': 0.806374192237854}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [18/25] Validation [1/123] Loss: 0.24849  focal_loss 0.00185  dice_loss 0.24664
Epoch [18/25] Validation [2/123] Loss: 0.41421  focal_loss 0.00132  dice_loss 0.41289
Epoch [18/25] Validation [3/123] Loss: 0.23971  focal_loss 0.00151  dice_loss 0.23820
Epoch [18/25] Validation [4/123] Loss: 0.32797  focal_loss 0.00164  dice_loss 0.32633
Epoch [18/25] Validation [5/123] Loss: 0.37043  focal_loss 0.00889  dice_loss 0.36154
Epoch [18/25] Validation [6/123] Loss: 0.40597  focal_loss 0.00223  dice_loss 0.40374
Epoch [18/25] Validation [7/123] Loss: 0.41384  focal_loss 0.00064  dice_loss 0.41320
Epoch [18/25] Validation [8/123] Loss: 0.38085  focal_loss 0.00111  dice_loss 0.37974
Epoch [18/25] Validation [9/123] Loss: 0.31757  focal_loss 0.00149  dice_loss 0.31608
Epoch [18/25] Validation [10/123] Loss: 0.52766  focal_loss 0.00276  dice_loss 0.52490
Epoch [18/25] Validation [11/123] Loss: 0.49985  focal_loss 0.00174  dice_loss 0.49812
Epoch [18/25] Validation [12/123] Loss: 0.26516  focal_loss 0.00151  dice_loss 0.26365
Epoch [18/25] Validation [13/123] Loss: 0.22927  focal_loss 0.00216  dice_loss 0.22711
Epoch [18/25] Validation [14/123] Loss: 0.30243  focal_loss 0.00123  dice_loss 0.30119
Epoch [18/25] Validation [15/123] Loss: 0.40999  focal_loss 0.00163  dice_loss 0.40836
Epoch [18/25] Validation [16/123] Loss: 0.49546  focal_loss 0.00165  dice_loss 0.49381
Epoch [18/25] Validation [17/123] Loss: 0.54189  focal_loss 0.00131  dice_loss 0.54058
Epoch [18/25] Validation [18/123] Loss: 0.39903  focal_loss 0.00285  dice_loss 0.39618
Epoch [18/25] Validation [19/123] Loss: 0.37062  focal_loss 0.00500  dice_loss 0.36562
Epoch [18/25] Validation [20/123] Loss: 0.50156  focal_loss 0.00058  dice_loss 0.50099
Epoch [18/25] Validation [21/123] Loss: 0.38165  focal_loss 0.00082  dice_loss 0.38083
Epoch [18/25] Validation [22/123] Loss: 0.70608  focal_loss 0.00588  dice_loss 0.70021
Epoch [18/25] Validation [23/123] Loss: 0.24056  focal_loss 0.00099  dice_loss 0.23957
Epoch [18/25] Validation [24/123] Loss: 0.35411  focal_loss 0.00356  dice_loss 0.35055
Epoch [18/25] Validation [25/123] Loss: 0.36957  focal_loss 0.00187  dice_loss 0.36770
Epoch [18/25] Validation [26/123] Loss: 0.25036  focal_loss 0.00091  dice_loss 0.24944
Epoch [18/25] Validation [27/123] Loss: 0.29344  focal_loss 0.00224  dice_loss 0.29120
Epoch [18/25] Validation [28/123] Loss: 0.52689  focal_loss 0.00294  dice_loss 0.52395
Epoch [18/25] Validation [29/123] Loss: 0.39751  focal_loss 0.00166  dice_loss 0.39585
Epoch [18/25] Validation [30/123] Loss: 0.28412  focal_loss 0.00269  dice_loss 0.28143
Epoch [18/25] Validation [31/123] Loss: 0.24177  focal_loss 0.00095  dice_loss 0.24082
Epoch [18/25] Validation [32/123] Loss: 0.36997  focal_loss 0.00385  dice_loss 0.36612
Epoch [18/25] Validation [33/123] Loss: 0.38967  focal_loss 0.00166  dice_loss 0.38802
Epoch [18/25] Validation [34/123] Loss: 0.37860  focal_loss 0.00346  dice_loss 0.37514
Epoch [18/25] Validation [35/123] Loss: 0.28457  focal_loss 0.00108  dice_loss 0.28349
Epoch [18/25] Validation [36/123] Loss: 0.31316  focal_loss 0.00086  dice_loss 0.31231
Epoch [18/25] Validation [37/123] Loss: 0.43002  focal_loss 0.00330  dice_loss 0.42672
Epoch [18/25] Validation [38/123] Loss: 0.28200  focal_loss 0.00164  dice_loss 0.28036
Epoch [18/25] Validation [39/123] Loss: 0.25922  focal_loss 0.00141  dice_loss 0.25781
Epoch [18/25] Validation [40/123] Loss: 0.36435  focal_loss 0.00077  dice_loss 0.36358
Epoch [18/25] Validation [41/123] Loss: 0.26412  focal_loss 0.00174  dice_loss 0.26238
Epoch [18/25] Validation [42/123] Loss: 0.23403  focal_loss 0.00072  dice_loss 0.23331
Epoch [18/25] Validation [43/123] Loss: 0.34256  focal_loss 0.00845  dice_loss 0.33411
Epoch [18/25] Validation [44/123] Loss: 0.65089  focal_loss 0.00801  dice_loss 0.64288
Epoch [18/25] Validation [45/123] Loss: 0.34983  focal_loss 0.00129  dice_loss 0.34854
Epoch [18/25] Validation [46/123] Loss: 0.39659  focal_loss 0.00274  dice_loss 0.39384
Epoch [18/25] Validation [47/123] Loss: 0.34561  focal_loss 0.00123  dice_loss 0.34438
Epoch [18/25] Validation [48/123] Loss: 0.47096  focal_loss 0.00427  dice_loss 0.46670
Epoch [18/25] Validation [49/123] Loss: 0.26352  focal_loss 0.00116  dice_loss 0.26236
Epoch [18/25] Validation [50/123] Loss: 0.25440  focal_loss 0.00191  dice_loss 0.25249
Epoch [18/25] Validation [51/123] Loss: 0.43604  focal_loss 0.00818  dice_loss 0.42786
Epoch [18/25] Validation [52/123] Loss: 0.27671  focal_loss 0.00086  dice_loss 0.27586
Epoch [18/25] Validation [53/123] Loss: 0.33908  focal_loss 0.00102  dice_loss 0.33807
Epoch [18/25] Validation [54/123] Loss: 0.37719  focal_loss 0.00109  dice_loss 0.37610
Epoch [18/25] Validation [55/123] Loss: 0.33325  focal_loss 0.00142  dice_loss 0.33183
Epoch [18/25] Validation [56/123] Loss: 0.31401  focal_loss 0.00494  dice_loss 0.30907
Epoch [18/25] Validation [57/123] Loss: 0.34978  focal_loss 0.00242  dice_loss 0.34736
Epoch [18/25] Validation [58/123] Loss: 0.29780  focal_loss 0.00177  dice_loss 0.29603
Epoch [18/25] Validation [59/123] Loss: 0.68591  focal_loss 0.00939  dice_loss 0.67652
Epoch [18/25] Validation [60/123] Loss: 0.33053  focal_loss 0.00697  dice_loss 0.32355
Epoch [18/25] Validation [61/123] Loss: 0.67288  focal_loss 0.00212  dice_loss 0.67076
Epoch [18/25] Validation [62/123] Loss: 0.52848  focal_loss 0.00616  dice_loss 0.52233
Epoch [18/25] Validation [63/123] Loss: 0.44122  focal_loss 0.00181  dice_loss 0.43941
Epoch [18/25] Validation [64/123] Loss: 0.41913  focal_loss 0.00635  dice_loss 0.41278
Epoch [18/25] Validation [65/123] Loss: 0.28816  focal_loss 0.00097  dice_loss 0.28718
Epoch [18/25] Validation [66/123] Loss: 0.31556  focal_loss 0.00167  dice_loss 0.31389
Epoch [18/25] Validation [67/123] Loss: 0.44895  focal_loss 0.00699  dice_loss 0.44195
Epoch [18/25] Validation [68/123] Loss: 0.41293  focal_loss 0.00083  dice_loss 0.41210
Epoch [18/25] Validation [69/123] Loss: 0.41399  focal_loss 0.00644  dice_loss 0.40756
Epoch [18/25] Validation [70/123] Loss: 0.36923  focal_loss 0.00217  dice_loss 0.36706
Epoch [18/25] Validation [71/123] Loss: 0.28660  focal_loss 0.00085  dice_loss 0.28575
Epoch [18/25] Validation [72/123] Loss: 0.25887  focal_loss 0.00124  dice_loss 0.25763
Epoch [18/25] Validation [73/123] Loss: 0.39751  focal_loss 0.00603  dice_loss 0.39149
Epoch [18/25] Validation [74/123] Loss: 0.41277  focal_loss 0.00588  dice_loss 0.40689
Epoch [18/25] Validation [75/123] Loss: 0.31786  focal_loss 0.00105  dice_loss 0.31681
Epoch [18/25] Validation [76/123] Loss: 0.52978  focal_loss 0.00645  dice_loss 0.52333
Epoch [18/25] Validation [77/123] Loss: 0.41664  focal_loss 0.00112  dice_loss 0.41552
Epoch [18/25] Validation [78/123] Loss: 0.31844  focal_loss 0.00157  dice_loss 0.31686
Epoch [18/25] Validation [79/123] Loss: 0.47691  focal_loss 0.00631  dice_loss 0.47060
Epoch [18/25] Validation [80/123] Loss: 0.26637  focal_loss 0.00207  dice_loss 0.26430
Epoch [18/25] Validation [81/123] Loss: 0.31218  focal_loss 0.00133  dice_loss 0.31085
Epoch [18/25] Validation [82/123] Loss: 0.26058  focal_loss 0.00065  dice_loss 0.25993
Epoch [18/25] Validation [83/123] Loss: 0.43017  focal_loss 0.01215  dice_loss 0.41802
Epoch [18/25] Validation [84/123] Loss: 0.31165  focal_loss 0.00127  dice_loss 0.31038
Epoch [18/25] Validation [85/123] Loss: 0.41226  focal_loss 0.00813  dice_loss 0.40412
Epoch [18/25] Validation [86/123] Loss: 0.28411  focal_loss 0.00145  dice_loss 0.28267
Epoch [18/25] Validation [87/123] Loss: 0.24879  focal_loss 0.00199  dice_loss 0.24679
Epoch [18/25] Validation [88/123] Loss: 0.30393  focal_loss 0.00240  dice_loss 0.30153
Epoch [18/25] Validation [89/123] Loss: 0.23984  focal_loss 0.00144  dice_loss 0.23840
Epoch [18/25] Validation [90/123] Loss: 0.35352  focal_loss 0.00186  dice_loss 0.35166
Epoch [18/25] Validation [91/123] Loss: 0.29273  focal_loss 0.00142  dice_loss 0.29131
Epoch [18/25] Validation [92/123] Loss: 0.24170  focal_loss 0.00109  dice_loss 0.24061
Epoch [18/25] Validation [93/123] Loss: 0.26535  focal_loss 0.00137  dice_loss 0.26398
Epoch [18/25] Validation [94/123] Loss: 0.38783  focal_loss 0.00168  dice_loss 0.38615
Epoch [18/25] Validation [95/123] Loss: 0.29670  focal_loss 0.00201  dice_loss 0.29469
Epoch [18/25] Validation [96/123] Loss: 0.38525  focal_loss 0.00191  dice_loss 0.38334
Epoch [18/25] Validation [97/123] Loss: 0.57822  focal_loss 0.00580  dice_loss 0.57242
Epoch [18/25] Validation [98/123] Loss: 0.37449  focal_loss 0.00133  dice_loss 0.37316
Epoch [18/25] Validation [99/123] Loss: 0.37458  focal_loss 0.00064  dice_loss 0.37394
Epoch [18/25] Validation [100/123] Loss: 0.38866  focal_loss 0.00089  dice_loss 0.38777
Epoch [18/25] Validation [101/123] Loss: 0.34574  focal_loss 0.00134  dice_loss 0.34439
Epoch [18/25] Validation [102/123] Loss: 0.38821  focal_loss 0.00073  dice_loss 0.38748
Epoch [18/25] Validation [103/123] Loss: 0.47579  focal_loss 0.00072  dice_loss 0.47507
Epoch [18/25] Validation [104/123] Loss: 0.46481  focal_loss 0.00495  dice_loss 0.45985
Epoch [18/25] Validation [105/123] Loss: 0.24323  focal_loss 0.00232  dice_loss 0.24091
Epoch [18/25] Validation [106/123] Loss: 0.28921  focal_loss 0.00084  dice_loss 0.28837
Epoch [18/25] Validation [107/123] Loss: 0.53041  focal_loss 0.00150  dice_loss 0.52891
Epoch [18/25] Validation [108/123] Loss: 0.28352  focal_loss 0.00047  dice_loss 0.28305
Epoch [18/25] Validation [109/123] Loss: 0.24093  focal_loss 0.00304  dice_loss 0.23789
Epoch [18/25] Validation [110/123] Loss: 0.44141  focal_loss 0.00443  dice_loss 0.43698
Epoch [18/25] Validation [111/123] Loss: 0.42069  focal_loss 0.00291  dice_loss 0.41778
Epoch [18/25] Validation [112/123] Loss: 0.36719  focal_loss 0.00064  dice_loss 0.36655
Epoch [18/25] Validation [113/123] Loss: 0.31409  focal_loss 0.00144  dice_loss 0.31266
Epoch [18/25] Validation [114/123] Loss: 0.36175  focal_loss 0.00392  dice_loss 0.35783
Epoch [18/25] Validation [115/123] Loss: 0.31968  focal_loss 0.00414  dice_loss 0.31555
Epoch [18/25] Validation [116/123] Loss: 0.32285  focal_loss 0.00060  dice_loss 0.32225
Epoch [18/25] Validation [117/123] Loss: 0.32075  focal_loss 0.00119  dice_loss 0.31957
Epoch [18/25] Validation [118/123] Loss: 0.22717  focal_loss 0.00162  dice_loss 0.22555
Epoch [18/25] Validation [119/123] Loss: 0.25550  focal_loss 0.00100  dice_loss 0.25450
Epoch [18/25] Validation [120/123] Loss: 0.28972  focal_loss 0.00173  dice_loss 0.28799
Epoch [18/25] Validation [121/123] Loss: 0.67252  focal_loss 0.01809  dice_loss 0.65443
Epoch [18/25] Validation [122/123] Loss: 0.64611  focal_loss 0.00039  dice_loss 0.64572
Epoch [18/25] Validation [123/123] Loss: 0.27850  focal_loss 0.00121  dice_loss 0.27729
Epoch [18/25] Validation metric {'Val/mean dice_metric': 0.8779594302177429, 'Val/TC dice_metric': 0.8979594111442566, 'Val/WT dice_metric': 0.9287562966346741, 'Val/ET dice_metric': 0.8071625232696533}
Epoch [18/25] lr = [0.00034549150281252633, 0.00034549150281252633] best acc: tensor([0.8758], device='cuda:0'), mean acc: tensor([0.8780], device='cuda:0'), mean class: tensor([0.8980, 0.9288, 0.8072], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [19/25] Training [1/488] Loss: 0.33306
Epoch [19/25] Training [2/488] Loss: 0.26354
Epoch [19/25] Training [3/488] Loss: 0.22217
Epoch [19/25] Training [4/488] Loss: 0.24105
Epoch [19/25] Training [5/488] Loss: 0.22140
Epoch [19/25] Training [6/488] Loss: 0.18305
Epoch [19/25] Training [7/488] Loss: 0.14911
Epoch [19/25] Training [8/488] Loss: 0.54359
Epoch [19/25] Training [9/488] Loss: 0.23761
Epoch [19/25] Training [10/488] Loss: 0.21241
Epoch [19/25] Training [11/488] Loss: 0.17474
Epoch [19/25] Training [12/488] Loss: 0.29203
Epoch [19/25] Training [13/488] Loss: 0.28295
Epoch [19/25] Training [14/488] Loss: 0.36577
Epoch [19/25] Training [15/488] Loss: 0.43075
Epoch [19/25] Training [16/488] Loss: 0.20741
Epoch [19/25] Training [17/488] Loss: 0.28181
Epoch [19/25] Training [18/488] Loss: 0.48014
Epoch [19/25] Training [19/488] Loss: 0.14490
Epoch [19/25] Training [20/488] Loss: 0.33043
Epoch [19/25] Training [21/488] Loss: 0.28442
Epoch [19/25] Training [22/488] Loss: 0.14234
Epoch [19/25] Training [23/488] Loss: 0.24070
Epoch [19/25] Training [24/488] Loss: 0.16790
Epoch [19/25] Training [25/488] Loss: 0.17469
Epoch [19/25] Training [26/488] Loss: 0.20547
Epoch [19/25] Training [27/488] Loss: 0.29078
Epoch [19/25] Training [28/488] Loss: 0.23739
Epoch [19/25] Training [29/488] Loss: 0.26172
Epoch [19/25] Training [30/488] Loss: 0.14421
Epoch [19/25] Training [31/488] Loss: 0.15905
Epoch [19/25] Training [32/488] Loss: 0.23608
Epoch [19/25] Training [33/488] Loss: 0.50613
Epoch [19/25] Training [34/488] Loss: 0.29745
Epoch [19/25] Training [35/488] Loss: 0.16263
Epoch [19/25] Training [36/488] Loss: 0.14305
Epoch [19/25] Training [37/488] Loss: 0.32970
Epoch [19/25] Training [38/488] Loss: 0.30164
Epoch [19/25] Training [39/488] Loss: 0.19316
Epoch [19/25] Training [40/488] Loss: 0.21305
Epoch [19/25] Training [41/488] Loss: 0.35961
Epoch [19/25] Training [42/488] Loss: 0.31838
Epoch [19/25] Training [43/488] Loss: 0.18116
Epoch [19/25] Training [44/488] Loss: 0.17986
Epoch [19/25] Training [45/488] Loss: 0.34809
Epoch [19/25] Training [46/488] Loss: 0.18472
Epoch [19/25] Training [47/488] Loss: 0.16847
Epoch [19/25] Training [48/488] Loss: 0.19699
Epoch [19/25] Training [49/488] Loss: 0.19855
Epoch [19/25] Training [50/488] Loss: 0.29074
Epoch [19/25] Training [51/488] Loss: 0.16270
Epoch [19/25] Training [52/488] Loss: 0.32896
Epoch [19/25] Training [53/488] Loss: 0.17938
Epoch [19/25] Training [54/488] Loss: 0.37798
Epoch [19/25] Training [55/488] Loss: 0.17035
Epoch [19/25] Training [56/488] Loss: 0.17186
Epoch [19/25] Training [57/488] Loss: 0.43213
Epoch [19/25] Training [58/488] Loss: 0.15576
Epoch [19/25] Training [59/488] Loss: 0.32281
Epoch [19/25] Training [60/488] Loss: 0.24264
Epoch [19/25] Training [61/488] Loss: 0.20858
Epoch [19/25] Training [62/488] Loss: 0.18402
Epoch [19/25] Training [63/488] Loss: 0.40930
Epoch [19/25] Training [64/488] Loss: 0.24989
Epoch [19/25] Training [65/488] Loss: 0.24338
Epoch [19/25] Training [66/488] Loss: 0.53826
Epoch [19/25] Training [67/488] Loss: 0.15635
Epoch [19/25] Training [68/488] Loss: 0.60993
Epoch [19/25] Training [69/488] Loss: 0.15816
Epoch [19/25] Training [70/488] Loss: 0.27857
Epoch [19/25] Training [71/488] Loss: 0.49929
Epoch [19/25] Training [72/488] Loss: 0.22851
Epoch [19/25] Training [73/488] Loss: 0.22157
Epoch [19/25] Training [74/488] Loss: 0.37830
Epoch [19/25] Training [75/488] Loss: 0.17787
Epoch [19/25] Training [76/488] Loss: 0.37833
Epoch [19/25] Training [77/488] Loss: 0.34651
Epoch [19/25] Training [78/488] Loss: 0.15774
Epoch [19/25] Training [79/488] Loss: 0.17811
Epoch [19/25] Training [80/488] Loss: 0.19708
Epoch [19/25] Training [81/488] Loss: 0.13780
Epoch [19/25] Training [82/488] Loss: 0.34018
Epoch [19/25] Training [83/488] Loss: 0.20955
Epoch [19/25] Training [84/488] Loss: 0.18458
Epoch [19/25] Training [85/488] Loss: 0.12563
Epoch [19/25] Training [86/488] Loss: 0.43165
Epoch [19/25] Training [87/488] Loss: 0.20196
Epoch [19/25] Training [88/488] Loss: 0.30105
Epoch [19/25] Training [89/488] Loss: 0.17845
Epoch [19/25] Training [90/488] Loss: 0.21115
Epoch [19/25] Training [91/488] Loss: 0.15013
Epoch [19/25] Training [92/488] Loss: 0.18670
Epoch [19/25] Training [93/488] Loss: 0.28991
Epoch [19/25] Training [94/488] Loss: 0.17236
Epoch [19/25] Training [95/488] Loss: 0.13157
Epoch [19/25] Training [96/488] Loss: 0.16807
Epoch [19/25] Training [97/488] Loss: 0.20994
Epoch [19/25] Training [98/488] Loss: 0.23306
Epoch [19/25] Training [99/488] Loss: 0.45144
Epoch [19/25] Training [100/488] Loss: 0.16600
Epoch [19/25] Training [101/488] Loss: 0.17667
Epoch [19/25] Training [102/488] Loss: 0.17714
Epoch [19/25] Training [103/488] Loss: 0.14167
Epoch [19/25] Training [104/488] Loss: 0.29340
Epoch [19/25] Training [105/488] Loss: 0.16416
Epoch [19/25] Training [106/488] Loss: 0.21806
Epoch [19/25] Training [107/488] Loss: 0.22172
Epoch [19/25] Training [108/488] Loss: 0.19186
Epoch [19/25] Training [109/488] Loss: 0.16067
Epoch [19/25] Training [110/488] Loss: 0.45606
Epoch [19/25] Training [111/488] Loss: 0.19453
Epoch [19/25] Training [112/488] Loss: 0.19122
Epoch [19/25] Training [113/488] Loss: 0.15841
Epoch [19/25] Training [114/488] Loss: 0.15603
Epoch [19/25] Training [115/488] Loss: 0.17937
Epoch [19/25] Training [116/488] Loss: 0.23472
Epoch [19/25] Training [117/488] Loss: 0.22568
Epoch [19/25] Training [118/488] Loss: 0.36370
Epoch [19/25] Training [119/488] Loss: 0.14464
Epoch [19/25] Training [120/488] Loss: 0.21394
Epoch [19/25] Training [121/488] Loss: 0.16719
Epoch [19/25] Training [122/488] Loss: 0.23827
Epoch [19/25] Training [123/488] Loss: 0.35191
Epoch [19/25] Training [124/488] Loss: 0.47091
Epoch [19/25] Training [125/488] Loss: 0.16416
Epoch [19/25] Training [126/488] Loss: 0.12900
Epoch [19/25] Training [127/488] Loss: 0.13056
Epoch [19/25] Training [128/488] Loss: 0.26525
Epoch [19/25] Training [129/488] Loss: 0.14381
Epoch [19/25] Training [130/488] Loss: 0.18023
Epoch [19/25] Training [131/488] Loss: 0.17075
Epoch [19/25] Training [132/488] Loss: 0.19747
Epoch [19/25] Training [133/488] Loss: 0.25284
Epoch [19/25] Training [134/488] Loss: 0.14817
Epoch [19/25] Training [135/488] Loss: 0.28567
Epoch [19/25] Training [136/488] Loss: 0.38647
Epoch [19/25] Training [137/488] Loss: 0.26161
Epoch [19/25] Training [138/488] Loss: 0.43210
Epoch [19/25] Training [139/488] Loss: 0.13684
Epoch [19/25] Training [140/488] Loss: 0.37299
Epoch [19/25] Training [141/488] Loss: 0.42921
Epoch [19/25] Training [142/488] Loss: 0.14936
Epoch [19/25] Training [143/488] Loss: 0.34739
Epoch [19/25] Training [144/488] Loss: 0.14594
Epoch [19/25] Training [145/488] Loss: 0.22539
Epoch [19/25] Training [146/488] Loss: 0.32962
Epoch [19/25] Training [147/488] Loss: 0.67415
Epoch [19/25] Training [148/488] Loss: 0.22697
Epoch [19/25] Training [149/488] Loss: 0.28897
Epoch [19/25] Training [150/488] Loss: 0.15638
Epoch [19/25] Training [151/488] Loss: 0.15884
Epoch [19/25] Training [152/488] Loss: 0.35226
Epoch [19/25] Training [153/488] Loss: 0.16030
Epoch [19/25] Training [154/488] Loss: 0.26834
Epoch [19/25] Training [155/488] Loss: 0.21508
Epoch [19/25] Training [156/488] Loss: 0.18767
Epoch [19/25] Training [157/488] Loss: 0.40013
Epoch [19/25] Training [158/488] Loss: 0.14013
Epoch [19/25] Training [159/488] Loss: 0.21217
Epoch [19/25] Training [160/488] Loss: 0.15697
Epoch [19/25] Training [161/488] Loss: 0.17850
Epoch [19/25] Training [162/488] Loss: 0.20100
Epoch [19/25] Training [163/488] Loss: 0.22150
Epoch [19/25] Training [164/488] Loss: 0.12861
Epoch [19/25] Training [165/488] Loss: 0.18357
Epoch [19/25] Training [166/488] Loss: 0.16221
Epoch [19/25] Training [167/488] Loss: 0.26642
Epoch [19/25] Training [168/488] Loss: 0.22868
Epoch [19/25] Training [169/488] Loss: 0.16844
Epoch [19/25] Training [170/488] Loss: 0.29875
Epoch [19/25] Training [171/488] Loss: 0.56522
Epoch [19/25] Training [172/488] Loss: 0.23721
Epoch [19/25] Training [173/488] Loss: 0.29352
Epoch [19/25] Training [174/488] Loss: 0.26332
Epoch [19/25] Training [175/488] Loss: 0.15194
Epoch [19/25] Training [176/488] Loss: 0.24436
Epoch [19/25] Training [177/488] Loss: 0.18704
Epoch [19/25] Training [178/488] Loss: 0.16001
Epoch [19/25] Training [179/488] Loss: 0.18897
Epoch [19/25] Training [180/488] Loss: 0.32191
Epoch [19/25] Training [181/488] Loss: 0.13511
Epoch [19/25] Training [182/488] Loss: 0.16417
Epoch [19/25] Training [183/488] Loss: 0.20631
Epoch [19/25] Training [184/488] Loss: 0.32227
Epoch [19/25] Training [185/488] Loss: 0.17454
Epoch [19/25] Training [186/488] Loss: 0.13145
Epoch [19/25] Training [187/488] Loss: 0.14676
Epoch [19/25] Training [188/488] Loss: 0.16690
Epoch [19/25] Training [189/488] Loss: 0.23786
Epoch [19/25] Training [190/488] Loss: 0.17029
Epoch [19/25] Training [191/488] Loss: 0.16918
Epoch [19/25] Training [192/488] Loss: 0.22813
Epoch [19/25] Training [193/488] Loss: 0.25194
Epoch [19/25] Training [194/488] Loss: 0.12837
Epoch [19/25] Training [195/488] Loss: 0.17697
Epoch [19/25] Training [196/488] Loss: 0.22946
Epoch [19/25] Training [197/488] Loss: 0.25186
Epoch [19/25] Training [198/488] Loss: 0.17050
Epoch [19/25] Training [199/488] Loss: 0.26862
Epoch [19/25] Training [200/488] Loss: 0.28808
Epoch [19/25] Training [201/488] Loss: 0.29341
Epoch [19/25] Training [202/488] Loss: 0.15281
Epoch [19/25] Training [203/488] Loss: 0.16930
Epoch [19/25] Training [204/488] Loss: 0.13648
Epoch [19/25] Training [205/488] Loss: 0.39007
Epoch [19/25] Training [206/488] Loss: 0.24928
Epoch [19/25] Training [207/488] Loss: 0.17869
Epoch [19/25] Training [208/488] Loss: 0.18229
Epoch [19/25] Training [209/488] Loss: 0.44969
Epoch [19/25] Training [210/488] Loss: 0.12966
Epoch [19/25] Training [211/488] Loss: 0.15902
Epoch [19/25] Training [212/488] Loss: 0.53658
Epoch [19/25] Training [213/488] Loss: 0.21476
Epoch [19/25] Training [214/488] Loss: 0.18354
Epoch [19/25] Training [215/488] Loss: 0.19233
Epoch [19/25] Training [216/488] Loss: 0.32698
Epoch [19/25] Training [217/488] Loss: 0.19992
Epoch [19/25] Training [218/488] Loss: 0.16156
Epoch [19/25] Training [219/488] Loss: 0.17289
Epoch [19/25] Training [220/488] Loss: 0.16104
Epoch [19/25] Training [221/488] Loss: 0.16784
Epoch [19/25] Training [222/488] Loss: 0.24583
Epoch [19/25] Training [223/488] Loss: 0.13206
Epoch [19/25] Training [224/488] Loss: 0.28085
Epoch [19/25] Training [225/488] Loss: 0.27023
Epoch [19/25] Training [226/488] Loss: 0.27337
Epoch [19/25] Training [227/488] Loss: 0.12313
Epoch [19/25] Training [228/488] Loss: 0.28338
Epoch [19/25] Training [229/488] Loss: 0.31261
Epoch [19/25] Training [230/488] Loss: 0.33681
Epoch [19/25] Training [231/488] Loss: 0.19529
Epoch [19/25] Training [232/488] Loss: 0.46832
Epoch [19/25] Training [233/488] Loss: 0.20563
Epoch [19/25] Training [234/488] Loss: 0.44020
Epoch [19/25] Training [235/488] Loss: 0.66223
Epoch [19/25] Training [236/488] Loss: 0.26101
Epoch [19/25] Training [237/488] Loss: 0.21998
Epoch [19/25] Training [238/488] Loss: 0.12501
Epoch [19/25] Training [239/488] Loss: 0.27072
Epoch [19/25] Training [240/488] Loss: 0.25312
Epoch [19/25] Training [241/488] Loss: 0.19286
Epoch [19/25] Training [242/488] Loss: 0.27106
Epoch [19/25] Training [243/488] Loss: 0.35382
Epoch [19/25] Training [244/488] Loss: 0.33659
Epoch [19/25] Training [245/488] Loss: 0.17926
Epoch [19/25] Training [246/488] Loss: 0.29246
Epoch [19/25] Training [247/488] Loss: 0.46994
Epoch [19/25] Training [248/488] Loss: 0.39435
Epoch [19/25] Training [249/488] Loss: 0.18856
Epoch [19/25] Training [250/488] Loss: 0.26395
Epoch [19/25] Training [251/488] Loss: 0.17615
Epoch [19/25] Training [252/488] Loss: 0.14155
Epoch [19/25] Training [253/488] Loss: 0.16404
Epoch [19/25] Training [254/488] Loss: 0.15654
Epoch [19/25] Training [255/488] Loss: 0.21107
Epoch [19/25] Training [256/488] Loss: 0.54321
Epoch [19/25] Training [257/488] Loss: 0.27811
Epoch [19/25] Training [258/488] Loss: 0.36798
Epoch [19/25] Training [259/488] Loss: 0.20918
Epoch [19/25] Training [260/488] Loss: 0.13868
Epoch [19/25] Training [261/488] Loss: 0.20219
Epoch [19/25] Training [262/488] Loss: 0.13353
Epoch [19/25] Training [263/488] Loss: 0.16193
Epoch [19/25] Training [264/488] Loss: 0.14021
Epoch [19/25] Training [265/488] Loss: 0.25237
Epoch [19/25] Training [266/488] Loss: 0.14470
Epoch [19/25] Training [267/488] Loss: 0.16719
Epoch [19/25] Training [268/488] Loss: 0.39489
Epoch [19/25] Training [269/488] Loss: 0.48742
Epoch [19/25] Training [270/488] Loss: 0.43996
Epoch [19/25] Training [271/488] Loss: 0.23881
Epoch [19/25] Training [272/488] Loss: 0.48030
Epoch [19/25] Training [273/488] Loss: 0.44292
Epoch [19/25] Training [274/488] Loss: 0.18694
Epoch [19/25] Training [275/488] Loss: 0.22215
Epoch [19/25] Training [276/488] Loss: 0.30614
Epoch [19/25] Training [277/488] Loss: 0.13542
Epoch [19/25] Training [278/488] Loss: 0.21203
Epoch [19/25] Training [279/488] Loss: 0.18810
Epoch [19/25] Training [280/488] Loss: 0.17648
Epoch [19/25] Training [281/488] Loss: 0.13241
Epoch [19/25] Training [282/488] Loss: 0.19640
Epoch [19/25] Training [283/488] Loss: 0.17596
Epoch [19/25] Training [284/488] Loss: 0.16336
Epoch [19/25] Training [285/488] Loss: 0.37798
Epoch [19/25] Training [286/488] Loss: 0.62422
Epoch [19/25] Training [287/488] Loss: 0.26494
Epoch [19/25] Training [288/488] Loss: 0.12240
Epoch [19/25] Training [289/488] Loss: 0.71969
Epoch [19/25] Training [290/488] Loss: 0.24182
Epoch [19/25] Training [291/488] Loss: 0.20604
Epoch [19/25] Training [292/488] Loss: 0.23664
Epoch [19/25] Training [293/488] Loss: 0.30026
Epoch [19/25] Training [294/488] Loss: 0.24149
Epoch [19/25] Training [295/488] Loss: 0.20594
Epoch [19/25] Training [296/488] Loss: 0.22575
Epoch [19/25] Training [297/488] Loss: 0.34018
Epoch [19/25] Training [298/488] Loss: 0.17717
Epoch [19/25] Training [299/488] Loss: 0.16266
Epoch [19/25] Training [300/488] Loss: 0.26183
Epoch [19/25] Training [301/488] Loss: 0.19111
Epoch [19/25] Training [302/488] Loss: 0.16421
Epoch [19/25] Training [303/488] Loss: 0.13284
Epoch [19/25] Training [304/488] Loss: 0.34763
Epoch [19/25] Training [305/488] Loss: 0.15823
Epoch [19/25] Training [306/488] Loss: 0.24771
Epoch [19/25] Training [307/488] Loss: 0.15851
Epoch [19/25] Training [308/488] Loss: 0.41072
Epoch [19/25] Training [309/488] Loss: 0.14407
Epoch [19/25] Training [310/488] Loss: 0.19448
Epoch [19/25] Training [311/488] Loss: 0.25119
Epoch [19/25] Training [312/488] Loss: 0.15241
Epoch [19/25] Training [313/488] Loss: 0.19524
Epoch [19/25] Training [314/488] Loss: 0.15866
Epoch [19/25] Training [315/488] Loss: 0.18093
Epoch [19/25] Training [316/488] Loss: 0.14937
Epoch [19/25] Training [317/488] Loss: 0.37866
Epoch [19/25] Training [318/488] Loss: 0.12099
Epoch [19/25] Training [319/488] Loss: 0.13091
Epoch [19/25] Training [320/488] Loss: 0.49608
Epoch [19/25] Training [321/488] Loss: 0.72466
Epoch [19/25] Training [322/488] Loss: 0.17637
Epoch [19/25] Training [323/488] Loss: 0.37447
Epoch [19/25] Training [324/488] Loss: 0.28235
Epoch [19/25] Training [325/488] Loss: 0.36339
Epoch [19/25] Training [326/488] Loss: 0.72132
Epoch [19/25] Training [327/488] Loss: 0.35379
Epoch [19/25] Training [328/488] Loss: 0.21666
Epoch [19/25] Training [329/488] Loss: 0.22439
Epoch [19/25] Training [330/488] Loss: 1.00483
Epoch [19/25] Training [331/488] Loss: 0.17786
Epoch [19/25] Training [332/488] Loss: 0.26284
Epoch [19/25] Training [333/488] Loss: 0.18043
Epoch [19/25] Training [334/488] Loss: 0.23814
Epoch [19/25] Training [335/488] Loss: 0.15128
Epoch [19/25] Training [336/488] Loss: 0.70941
Epoch [19/25] Training [337/488] Loss: 0.23490
Epoch [19/25] Training [338/488] Loss: 0.50875
Epoch [19/25] Training [339/488] Loss: 0.41260
Epoch [19/25] Training [340/488] Loss: 0.23350
Epoch [19/25] Training [341/488] Loss: 0.21834
Epoch [19/25] Training [342/488] Loss: 0.21752
Epoch [19/25] Training [343/488] Loss: 0.14351
Epoch [19/25] Training [344/488] Loss: 0.17717
Epoch [19/25] Training [345/488] Loss: 0.18022
Epoch [19/25] Training [346/488] Loss: 0.20607
Epoch [19/25] Training [347/488] Loss: 0.27398
Epoch [19/25] Training [348/488] Loss: 0.33854
Epoch [19/25] Training [349/488] Loss: 0.24258
Epoch [19/25] Training [350/488] Loss: 0.22915
Epoch [19/25] Training [351/488] Loss: 0.17091
Epoch [19/25] Training [352/488] Loss: 0.17746
Epoch [19/25] Training [353/488] Loss: 0.27380
Epoch [19/25] Training [354/488] Loss: 0.19890
Epoch [19/25] Training [355/488] Loss: 0.23710
Epoch [19/25] Training [356/488] Loss: 0.16101
Epoch [19/25] Training [357/488] Loss: 0.14953
Epoch [19/25] Training [358/488] Loss: 0.22114
Epoch [19/25] Training [359/488] Loss: 0.25003
Epoch [19/25] Training [360/488] Loss: 0.54488
Epoch [19/25] Training [361/488] Loss: 0.28589
Epoch [19/25] Training [362/488] Loss: 0.18197
Epoch [19/25] Training [363/488] Loss: 0.37537
Epoch [19/25] Training [364/488] Loss: 0.24201
Epoch [19/25] Training [365/488] Loss: 0.17934
Epoch [19/25] Training [366/488] Loss: 0.35587
Epoch [19/25] Training [367/488] Loss: 0.26460
Epoch [19/25] Training [368/488] Loss: 0.28147
Epoch [19/25] Training [369/488] Loss: 0.22433
Epoch [19/25] Training [370/488] Loss: 0.25685
Epoch [19/25] Training [371/488] Loss: 0.14057
Epoch [19/25] Training [372/488] Loss: 0.21047
Epoch [19/25] Training [373/488] Loss: 0.21542
Epoch [19/25] Training [374/488] Loss: 0.36074
Epoch [19/25] Training [375/488] Loss: 0.34300
Epoch [19/25] Training [376/488] Loss: 0.21667
Epoch [19/25] Training [377/488] Loss: 0.34279
Epoch [19/25] Training [378/488] Loss: 0.15028
Epoch [19/25] Training [379/488] Loss: 0.17348
Epoch [19/25] Training [380/488] Loss: 0.14763
Epoch [19/25] Training [381/488] Loss: 0.13750
Epoch [19/25] Training [382/488] Loss: 0.14898
Epoch [19/25] Training [383/488] Loss: 0.22558
Epoch [19/25] Training [384/488] Loss: 0.21661
Epoch [19/25] Training [385/488] Loss: 0.15798
Epoch [19/25] Training [386/488] Loss: 0.16417
Epoch [19/25] Training [387/488] Loss: 0.34336
Epoch [19/25] Training [388/488] Loss: 0.14316
Epoch [19/25] Training [389/488] Loss: 0.18450
Epoch [19/25] Training [390/488] Loss: 0.30005
Epoch [19/25] Training [391/488] Loss: 0.19874
Epoch [19/25] Training [392/488] Loss: 0.22722
Epoch [19/25] Training [393/488] Loss: 0.26367
Epoch [19/25] Training [394/488] Loss: 0.15168
Epoch [19/25] Training [395/488] Loss: 0.36666
Epoch [19/25] Training [396/488] Loss: 0.12408
Epoch [19/25] Training [397/488] Loss: 0.14603
Epoch [19/25] Training [398/488] Loss: 0.16291
Epoch [19/25] Training [399/488] Loss: 0.22220
Epoch [19/25] Training [400/488] Loss: 0.21964
Epoch [19/25] Training [401/488] Loss: 0.52608
Epoch [19/25] Training [402/488] Loss: 0.13495
Epoch [19/25] Training [403/488] Loss: 0.17072
Epoch [19/25] Training [404/488] Loss: 0.16421
Epoch [19/25] Training [405/488] Loss: 0.21164
Epoch [19/25] Training [406/488] Loss: 0.26452
Epoch [19/25] Training [407/488] Loss: 0.21176
Epoch [19/25] Training [408/488] Loss: 0.19256
Epoch [19/25] Training [409/488] Loss: 0.27714
Epoch [19/25] Training [410/488] Loss: 0.26944
Epoch [19/25] Training [411/488] Loss: 0.15775
Epoch [19/25] Training [412/488] Loss: 0.14680
Epoch [19/25] Training [413/488] Loss: 0.14334
Epoch [19/25] Training [414/488] Loss: 0.37712
Epoch [19/25] Training [415/488] Loss: 0.34350
Epoch [19/25] Training [416/488] Loss: 0.25673
Epoch [19/25] Training [417/488] Loss: 0.14778
Epoch [19/25] Training [418/488] Loss: 0.33940
Epoch [19/25] Training [419/488] Loss: 0.16603
Epoch [19/25] Training [420/488] Loss: 0.19779
Epoch [19/25] Training [421/488] Loss: 0.50028
Epoch [19/25] Training [422/488] Loss: 0.50959
Epoch [19/25] Training [423/488] Loss: 0.63212
Epoch [19/25] Training [424/488] Loss: 0.26672
Epoch [19/25] Training [425/488] Loss: 0.41407
Epoch [19/25] Training [426/488] Loss: 0.14809
Epoch [19/25] Training [427/488] Loss: 0.12557
Epoch [19/25] Training [428/488] Loss: 0.30871
Epoch [19/25] Training [429/488] Loss: 0.14525
Epoch [19/25] Training [430/488] Loss: 0.33462
Epoch [19/25] Training [431/488] Loss: 0.24464
Epoch [19/25] Training [432/488] Loss: 0.17000
Epoch [19/25] Training [433/488] Loss: 0.20838
Epoch [19/25] Training [434/488] Loss: 0.21222
Epoch [19/25] Training [435/488] Loss: 0.21848
Epoch [19/25] Training [436/488] Loss: 0.12352
Epoch [19/25] Training [437/488] Loss: 0.32679
Epoch [19/25] Training [438/488] Loss: 0.15642
Epoch [19/25] Training [439/488] Loss: 0.15379
Epoch [19/25] Training [440/488] Loss: 0.13787
Epoch [19/25] Training [441/488] Loss: 0.38914
Epoch [19/25] Training [442/488] Loss: 0.19545
Epoch [19/25] Training [443/488] Loss: 0.22351
Epoch [19/25] Training [444/488] Loss: 0.23409
Epoch [19/25] Training [445/488] Loss: 0.37994
Epoch [19/25] Training [446/488] Loss: 0.34179
Epoch [19/25] Training [447/488] Loss: 0.23036
Epoch [19/25] Training [448/488] Loss: 0.17424
Epoch [19/25] Training [449/488] Loss: 0.21617
Epoch [19/25] Training [450/488] Loss: 0.26430
Epoch [19/25] Training [451/488] Loss: 0.25435
Epoch [19/25] Training [452/488] Loss: 0.20468
Epoch [19/25] Training [453/488] Loss: 0.22360
Epoch [19/25] Training [454/488] Loss: 0.41107
Epoch [19/25] Training [455/488] Loss: 0.20185
Epoch [19/25] Training [456/488] Loss: 0.19991
Epoch [19/25] Training [457/488] Loss: 0.17557
Epoch [19/25] Training [458/488] Loss: 0.17245
Epoch [19/25] Training [459/488] Loss: 0.18216
Epoch [19/25] Training [460/488] Loss: 0.34681
Epoch [19/25] Training [461/488] Loss: 0.18375
Epoch [19/25] Training [462/488] Loss: 0.40985
Epoch [19/25] Training [463/488] Loss: 0.19140
Epoch [19/25] Training [464/488] Loss: 0.15797
Epoch [19/25] Training [465/488] Loss: 0.13151
Epoch [19/25] Training [466/488] Loss: 0.29248
Epoch [19/25] Training [467/488] Loss: 0.22346
Epoch [19/25] Training [468/488] Loss: 0.24295
Epoch [19/25] Training [469/488] Loss: 0.14716
Epoch [19/25] Training [470/488] Loss: 0.17900
Epoch [19/25] Training [471/488] Loss: 0.13755
Epoch [19/25] Training [472/488] Loss: 0.14312
Epoch [19/25] Training [473/488] Loss: 0.11492
Epoch [19/25] Training [474/488] Loss: 0.16948
Epoch [19/25] Training [475/488] Loss: 0.11527
Epoch [19/25] Training [476/488] Loss: 0.19300
Epoch [19/25] Training [477/488] Loss: 0.29738
Epoch [19/25] Training [478/488] Loss: 0.18877
Epoch [19/25] Training [479/488] Loss: 0.21070
Epoch [19/25] Training [480/488] Loss: 0.17871
Epoch [19/25] Training [481/488] Loss: 0.32367
Epoch [19/25] Training [482/488] Loss: 0.16703
Epoch [19/25] Training [483/488] Loss: 0.12910
Epoch [19/25] Training [484/488] Loss: 0.17386
Epoch [19/25] Training [485/488] Loss: 0.27549
Epoch [19/25] Training [486/488] Loss: 0.41215
Epoch [19/25] Training [487/488] Loss: 0.24705
Epoch [19/25] Training [488/488] Loss: 0.15629
Epoch [19/25] Training metric {'Train/mean dice_metric': 0.885528564453125, 'Train/TC dice_metric': 0.9075896739959717, 'Train/WT dice_metric': 0.9351098537445068, 'Train/ET dice_metric': 0.813886284828186}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [19/25] Validation [1/123] Loss: 0.23721  focal_loss 0.00197  dice_loss 0.23523
Epoch [19/25] Validation [2/123] Loss: 0.40276  focal_loss 0.00129  dice_loss 0.40147
Epoch [19/25] Validation [3/123] Loss: 0.21914  focal_loss 0.00143  dice_loss 0.21772
Epoch [19/25] Validation [4/123] Loss: 0.31014  focal_loss 0.00157  dice_loss 0.30857
Epoch [19/25] Validation [5/123] Loss: 0.36043  focal_loss 0.00955  dice_loss 0.35088
Epoch [19/25] Validation [6/123] Loss: 0.39772  focal_loss 0.00225  dice_loss 0.39547
Epoch [19/25] Validation [7/123] Loss: 0.39358  focal_loss 0.00054  dice_loss 0.39304
Epoch [19/25] Validation [8/123] Loss: 0.37007  focal_loss 0.00122  dice_loss 0.36886
Epoch [19/25] Validation [9/123] Loss: 0.30255  focal_loss 0.00147  dice_loss 0.30108
Epoch [19/25] Validation [10/123] Loss: 0.51217  focal_loss 0.00275  dice_loss 0.50942
Epoch [19/25] Validation [11/123] Loss: 0.51076  focal_loss 0.00184  dice_loss 0.50892
Epoch [19/25] Validation [12/123] Loss: 0.25047  focal_loss 0.00145  dice_loss 0.24902
Epoch [19/25] Validation [13/123] Loss: 0.22649  focal_loss 0.00277  dice_loss 0.22371
Epoch [19/25] Validation [14/123] Loss: 0.28653  focal_loss 0.00147  dice_loss 0.28506
Epoch [19/25] Validation [15/123] Loss: 0.39036  focal_loss 0.00139  dice_loss 0.38897
Epoch [19/25] Validation [16/123] Loss: 0.47575  focal_loss 0.00176  dice_loss 0.47399
Epoch [19/25] Validation [17/123] Loss: 0.52547  focal_loss 0.00134  dice_loss 0.52413
Epoch [19/25] Validation [18/123] Loss: 0.39080  focal_loss 0.00390  dice_loss 0.38689
Epoch [19/25] Validation [19/123] Loss: 0.32691  focal_loss 0.00262  dice_loss 0.32429
Epoch [19/25] Validation [20/123] Loss: 0.50430  focal_loss 0.00084  dice_loss 0.50346
Epoch [19/25] Validation [21/123] Loss: 0.41549  focal_loss 0.00249  dice_loss 0.41300
Epoch [19/25] Validation [22/123] Loss: 0.63039  focal_loss 0.00518  dice_loss 0.62521
Epoch [19/25] Validation [23/123] Loss: 0.22912  focal_loss 0.00137  dice_loss 0.22775
Epoch [19/25] Validation [24/123] Loss: 0.33428  focal_loss 0.00284  dice_loss 0.33144
Epoch [19/25] Validation [25/123] Loss: 0.42144  focal_loss 0.00535  dice_loss 0.41609
Epoch [19/25] Validation [26/123] Loss: 0.23943  focal_loss 0.00117  dice_loss 0.23826
Epoch [19/25] Validation [27/123] Loss: 0.28837  focal_loss 0.00248  dice_loss 0.28589
Epoch [19/25] Validation [28/123] Loss: 0.53879  focal_loss 0.00296  dice_loss 0.53583
Epoch [19/25] Validation [29/123] Loss: 0.40322  focal_loss 0.00189  dice_loss 0.40133
Epoch [19/25] Validation [30/123] Loss: 0.28575  focal_loss 0.00389  dice_loss 0.28186
Epoch [19/25] Validation [31/123] Loss: 0.22918  focal_loss 0.00118  dice_loss 0.22800
Epoch [19/25] Validation [32/123] Loss: 0.35645  focal_loss 0.00407  dice_loss 0.35238
Epoch [19/25] Validation [33/123] Loss: 0.38188  focal_loss 0.00162  dice_loss 0.38026
Epoch [19/25] Validation [34/123] Loss: 0.38239  focal_loss 0.00329  dice_loss 0.37910
Epoch [19/25] Validation [35/123] Loss: 0.26672  focal_loss 0.00104  dice_loss 0.26569
Epoch [19/25] Validation [36/123] Loss: 0.29742  focal_loss 0.00084  dice_loss 0.29658
Epoch [19/25] Validation [37/123] Loss: 0.42174  focal_loss 0.00494  dice_loss 0.41680
Epoch [19/25] Validation [38/123] Loss: 0.25742  focal_loss 0.00121  dice_loss 0.25621
Epoch [19/25] Validation [39/123] Loss: 0.24149  focal_loss 0.00122  dice_loss 0.24028
Epoch [19/25] Validation [40/123] Loss: 0.35109  focal_loss 0.00083  dice_loss 0.35025
Epoch [19/25] Validation [41/123] Loss: 0.24310  focal_loss 0.00153  dice_loss 0.24157
Epoch [19/25] Validation [42/123] Loss: 0.22178  focal_loss 0.00090  dice_loss 0.22088
Epoch [19/25] Validation [43/123] Loss: 0.33858  focal_loss 0.00741  dice_loss 0.33118
Epoch [19/25] Validation [44/123] Loss: 0.63376  focal_loss 0.00793  dice_loss 0.62583
Epoch [19/25] Validation [45/123] Loss: 0.33403  focal_loss 0.00126  dice_loss 0.33278
Epoch [19/25] Validation [46/123] Loss: 0.38371  focal_loss 0.00260  dice_loss 0.38111
Epoch [19/25] Validation [47/123] Loss: 0.33446  focal_loss 0.00126  dice_loss 0.33320
Epoch [19/25] Validation [48/123] Loss: 0.47950  focal_loss 0.00569  dice_loss 0.47381
Epoch [19/25] Validation [49/123] Loss: 0.24864  focal_loss 0.00114  dice_loss 0.24750
Epoch [19/25] Validation [50/123] Loss: 0.24175  focal_loss 0.00197  dice_loss 0.23978
Epoch [19/25] Validation [51/123] Loss: 0.43252  focal_loss 0.00909  dice_loss 0.42343
Epoch [19/25] Validation [52/123] Loss: 0.25976  focal_loss 0.00074  dice_loss 0.25901
Epoch [19/25] Validation [53/123] Loss: 0.32121  focal_loss 0.00075  dice_loss 0.32046
Epoch [19/25] Validation [54/123] Loss: 0.36168  focal_loss 0.00092  dice_loss 0.36075
Epoch [19/25] Validation [55/123] Loss: 0.31530  focal_loss 0.00125  dice_loss 0.31404
Epoch [19/25] Validation [56/123] Loss: 0.28451  focal_loss 0.00345  dice_loss 0.28106
Epoch [19/25] Validation [57/123] Loss: 0.33235  focal_loss 0.00252  dice_loss 0.32984
Epoch [19/25] Validation [58/123] Loss: 0.28859  focal_loss 0.00199  dice_loss 0.28660
Epoch [19/25] Validation [59/123] Loss: 0.69640  focal_loss 0.01248  dice_loss 0.68391
Epoch [19/25] Validation [60/123] Loss: 0.28700  focal_loss 0.00255  dice_loss 0.28445
Epoch [19/25] Validation [61/123] Loss: 0.62786  focal_loss 0.00123  dice_loss 0.62663
Epoch [19/25] Validation [62/123] Loss: 0.52109  focal_loss 0.00776  dice_loss 0.51333
Epoch [19/25] Validation [63/123] Loss: 0.41712  focal_loss 0.00128  dice_loss 0.41583
Epoch [19/25] Validation [64/123] Loss: 0.40652  focal_loss 0.00651  dice_loss 0.40001
Epoch [19/25] Validation [65/123] Loss: 0.27156  focal_loss 0.00095  dice_loss 0.27060
Epoch [19/25] Validation [66/123] Loss: 0.28178  focal_loss 0.00098  dice_loss 0.28080
Epoch [19/25] Validation [67/123] Loss: 0.46862  focal_loss 0.01126  dice_loss 0.45736
Epoch [19/25] Validation [68/123] Loss: 0.40038  focal_loss 0.00094  dice_loss 0.39944
Epoch [19/25] Validation [69/123] Loss: 0.40921  focal_loss 0.00661  dice_loss 0.40260
Epoch [19/25] Validation [70/123] Loss: 0.35123  focal_loss 0.00179  dice_loss 0.34944
Epoch [19/25] Validation [71/123] Loss: 0.26748  focal_loss 0.00073  dice_loss 0.26676
Epoch [19/25] Validation [72/123] Loss: 0.24862  focal_loss 0.00161  dice_loss 0.24700
Epoch [19/25] Validation [73/123] Loss: 0.36411  focal_loss 0.00385  dice_loss 0.36026
Epoch [19/25] Validation [74/123] Loss: 0.38834  focal_loss 0.00490  dice_loss 0.38344
Epoch [19/25] Validation [75/123] Loss: 0.30768  focal_loss 0.00118  dice_loss 0.30650
Epoch [19/25] Validation [76/123] Loss: 0.50816  focal_loss 0.00412  dice_loss 0.50404
Epoch [19/25] Validation [77/123] Loss: 0.40032  focal_loss 0.00089  dice_loss 0.39943
Epoch [19/25] Validation [78/123] Loss: 0.30476  focal_loss 0.00151  dice_loss 0.30325
Epoch [19/25] Validation [79/123] Loss: 0.35397  focal_loss 0.00130  dice_loss 0.35267
Epoch [19/25] Validation [80/123] Loss: 0.25240  focal_loss 0.00220  dice_loss 0.25019
Epoch [19/25] Validation [81/123] Loss: 0.29885  focal_loss 0.00164  dice_loss 0.29721
Epoch [19/25] Validation [82/123] Loss: 0.24868  focal_loss 0.00078  dice_loss 0.24790
Epoch [19/25] Validation [83/123] Loss: 0.48173  focal_loss 0.01422  dice_loss 0.46750
Epoch [19/25] Validation [84/123] Loss: 0.29340  focal_loss 0.00114  dice_loss 0.29227
Epoch [19/25] Validation [85/123] Loss: 0.35846  focal_loss 0.00309  dice_loss 0.35537
Epoch [19/25] Validation [86/123] Loss: 0.26676  focal_loss 0.00138  dice_loss 0.26538
Epoch [19/25] Validation [87/123] Loss: 0.24125  focal_loss 0.00234  dice_loss 0.23891
Epoch [19/25] Validation [88/123] Loss: 0.27889  focal_loss 0.00151  dice_loss 0.27739
Epoch [19/25] Validation [89/123] Loss: 0.22808  focal_loss 0.00172  dice_loss 0.22635
Epoch [19/25] Validation [90/123] Loss: 0.35253  focal_loss 0.00209  dice_loss 0.35044
Epoch [19/25] Validation [91/123] Loss: 0.26997  focal_loss 0.00097  dice_loss 0.26899
Epoch [19/25] Validation [92/123] Loss: 0.22842  focal_loss 0.00115  dice_loss 0.22727
Epoch [19/25] Validation [93/123] Loss: 0.24512  focal_loss 0.00109  dice_loss 0.24403
Epoch [19/25] Validation [94/123] Loss: 0.37032  focal_loss 0.00143  dice_loss 0.36888
Epoch [19/25] Validation [95/123] Loss: 0.28358  focal_loss 0.00218  dice_loss 0.28140
Epoch [19/25] Validation [96/123] Loss: 0.34851  focal_loss 0.00111  dice_loss 0.34741
Epoch [19/25] Validation [97/123] Loss: 0.63295  focal_loss 0.00933  dice_loss 0.62362
Epoch [19/25] Validation [98/123] Loss: 0.36119  focal_loss 0.00122  dice_loss 0.35997
Epoch [19/25] Validation [99/123] Loss: 0.36445  focal_loss 0.00066  dice_loss 0.36379
Epoch [19/25] Validation [100/123] Loss: 0.38418  focal_loss 0.00105  dice_loss 0.38313
Epoch [19/25] Validation [101/123] Loss: 0.33062  focal_loss 0.00130  dice_loss 0.32932
Epoch [19/25] Validation [102/123] Loss: 0.37263  focal_loss 0.00062  dice_loss 0.37201
Epoch [19/25] Validation [103/123] Loss: 0.47475  focal_loss 0.00065  dice_loss 0.47410
Epoch [19/25] Validation [104/123] Loss: 0.43824  focal_loss 0.00367  dice_loss 0.43457
Epoch [19/25] Validation [105/123] Loss: 0.23121  focal_loss 0.00256  dice_loss 0.22865
Epoch [19/25] Validation [106/123] Loss: 0.27251  focal_loss 0.00082  dice_loss 0.27169
Epoch [19/25] Validation [107/123] Loss: 0.56901  focal_loss 0.00335  dice_loss 0.56566
Epoch [19/25] Validation [108/123] Loss: 0.26529  focal_loss 0.00052  dice_loss 0.26477
Epoch [19/25] Validation [109/123] Loss: 0.23877  focal_loss 0.00437  dice_loss 0.23440
Epoch [19/25] Validation [110/123] Loss: 0.40647  focal_loss 0.00313  dice_loss 0.40334
Epoch [19/25] Validation [111/123] Loss: 0.40490  focal_loss 0.00289  dice_loss 0.40201
Epoch [19/25] Validation [112/123] Loss: 0.35028  focal_loss 0.00061  dice_loss 0.34967
Epoch [19/25] Validation [113/123] Loss: 0.30026  focal_loss 0.00131  dice_loss 0.29895
Epoch [19/25] Validation [114/123] Loss: 0.38831  focal_loss 0.00568  dice_loss 0.38263
Epoch [19/25] Validation [115/123] Loss: 0.30182  focal_loss 0.00443  dice_loss 0.29739
Epoch [19/25] Validation [116/123] Loss: 0.30416  focal_loss 0.00060  dice_loss 0.30357
Epoch [19/25] Validation [117/123] Loss: 0.30397  focal_loss 0.00106  dice_loss 0.30292
Epoch [19/25] Validation [118/123] Loss: 0.21401  focal_loss 0.00163  dice_loss 0.21238
Epoch [19/25] Validation [119/123] Loss: 0.24226  focal_loss 0.00105  dice_loss 0.24121
Epoch [19/25] Validation [120/123] Loss: 0.27475  focal_loss 0.00180  dice_loss 0.27296
Epoch [19/25] Validation [121/123] Loss: 0.67718  focal_loss 0.02204  dice_loss 0.65513
Epoch [19/25] Validation [122/123] Loss: 0.61532  focal_loss 0.00046  dice_loss 0.61486
Epoch [19/25] Validation [123/123] Loss: 0.26625  focal_loss 0.00135  dice_loss 0.26490
Epoch [19/25] Validation metric {'Val/mean dice_metric': 0.8835455775260925, 'Val/TC dice_metric': 0.9036684036254883, 'Val/WT dice_metric': 0.9337723851203918, 'Val/ET dice_metric': 0.8131960034370422}
Epoch [19/25] lr = [0.00027300475013022663, 0.00027300475013022663] best acc: tensor([0.8780], device='cuda:0'), mean acc: tensor([0.8835], device='cuda:0'), mean class: tensor([0.9037, 0.9338, 0.8132], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [20/25] Training [1/488] Loss: 0.14629
Epoch [20/25] Training [2/488] Loss: 0.33042
Epoch [20/25] Training [3/488] Loss: 0.21724
Epoch [20/25] Training [4/488] Loss: 0.53710
Epoch [20/25] Training [5/488] Loss: 0.15950
Epoch [20/25] Training [6/488] Loss: 0.13694
Epoch [20/25] Training [7/488] Loss: 0.34281
Epoch [20/25] Training [8/488] Loss: 0.26839
Epoch [20/25] Training [9/488] Loss: 0.24039
Epoch [20/25] Training [10/488] Loss: 0.26338
Epoch [20/25] Training [11/488] Loss: 0.12664
Epoch [20/25] Training [12/488] Loss: 0.30542
Epoch [20/25] Training [13/488] Loss: 0.12366
Epoch [20/25] Training [14/488] Loss: 0.23865
Epoch [20/25] Training [15/488] Loss: 0.17677
Epoch [20/25] Training [16/488] Loss: 0.17992
Epoch [20/25] Training [17/488] Loss: 0.29829
Epoch [20/25] Training [18/488] Loss: 0.18781
Epoch [20/25] Training [19/488] Loss: 0.31481
Epoch [20/25] Training [20/488] Loss: 0.15383
Epoch [20/25] Training [21/488] Loss: 0.23598
Epoch [20/25] Training [22/488] Loss: 0.12136
Epoch [20/25] Training [23/488] Loss: 0.25170
Epoch [20/25] Training [24/488] Loss: 0.12627
Epoch [20/25] Training [25/488] Loss: 0.16813
Epoch [20/25] Training [26/488] Loss: 0.12872
Epoch [20/25] Training [27/488] Loss: 0.16183
Epoch [20/25] Training [28/488] Loss: 0.13783
Epoch [20/25] Training [29/488] Loss: 0.15752
Epoch [20/25] Training [30/488] Loss: 0.13632
Epoch [20/25] Training [31/488] Loss: 0.33415
Epoch [20/25] Training [32/488] Loss: 0.15525
Epoch [20/25] Training [33/488] Loss: 0.18052
Epoch [20/25] Training [34/488] Loss: 0.37438
Epoch [20/25] Training [35/488] Loss: 0.13005
Epoch [20/25] Training [36/488] Loss: 0.19109
Epoch [20/25] Training [37/488] Loss: 0.23170
Epoch [20/25] Training [38/488] Loss: 0.11557
Epoch [20/25] Training [39/488] Loss: 0.19160
Epoch [20/25] Training [40/488] Loss: 0.41479
Epoch [20/25] Training [41/488] Loss: 0.17919
Epoch [20/25] Training [42/488] Loss: 0.15322
Epoch [20/25] Training [43/488] Loss: 0.17888
Epoch [20/25] Training [44/488] Loss: 0.16595
Epoch [20/25] Training [45/488] Loss: 0.21577
Epoch [20/25] Training [46/488] Loss: 0.33173
Epoch [20/25] Training [47/488] Loss: 0.19319
Epoch [20/25] Training [48/488] Loss: 0.14030
Epoch [20/25] Training [49/488] Loss: 0.38978
Epoch [20/25] Training [50/488] Loss: 0.14533
Epoch [20/25] Training [51/488] Loss: 0.27184
Epoch [20/25] Training [52/488] Loss: 0.28355
Epoch [20/25] Training [53/488] Loss: 0.42654
Epoch [20/25] Training [54/488] Loss: 0.16944
Epoch [20/25] Training [55/488] Loss: 0.43577
Epoch [20/25] Training [56/488] Loss: 0.14704
Epoch [20/25] Training [57/488] Loss: 0.31427
Epoch [20/25] Training [58/488] Loss: 0.13707
Epoch [20/25] Training [59/488] Loss: 0.14854
Epoch [20/25] Training [60/488] Loss: 0.30567
Epoch [20/25] Training [61/488] Loss: 0.67473
Epoch [20/25] Training [62/488] Loss: 0.22638
Epoch [20/25] Training [63/488] Loss: 0.14462
Epoch [20/25] Training [64/488] Loss: 0.21504
Epoch [20/25] Training [65/488] Loss: 0.23303
Epoch [20/25] Training [66/488] Loss: 0.16189
Epoch [20/25] Training [67/488] Loss: 0.13661
Epoch [20/25] Training [68/488] Loss: 0.35519
Epoch [20/25] Training [69/488] Loss: 0.22164
Epoch [20/25] Training [70/488] Loss: 0.32110
Epoch [20/25] Training [71/488] Loss: 0.42049
Epoch [20/25] Training [72/488] Loss: 0.45122
Epoch [20/25] Training [73/488] Loss: 0.43726
Epoch [20/25] Training [74/488] Loss: 0.24779
Epoch [20/25] Training [75/488] Loss: 0.27231
Epoch [20/25] Training [76/488] Loss: 0.47966
Epoch [20/25] Training [77/488] Loss: 0.22901
Epoch [20/25] Training [78/488] Loss: 0.12248
Epoch [20/25] Training [79/488] Loss: 0.27070
Epoch [20/25] Training [80/488] Loss: 0.17460
Epoch [20/25] Training [81/488] Loss: 0.14394
Epoch [20/25] Training [82/488] Loss: 0.25885
Epoch [20/25] Training [83/488] Loss: 0.13556
Epoch [20/25] Training [84/488] Loss: 0.43212
Epoch [20/25] Training [85/488] Loss: 0.56788
Epoch [20/25] Training [86/488] Loss: 0.27772
Epoch [20/25] Training [87/488] Loss: 0.32724
Epoch [20/25] Training [88/488] Loss: 0.22366
Epoch [20/25] Training [89/488] Loss: 0.12890
Epoch [20/25] Training [90/488] Loss: 0.27144
Epoch [20/25] Training [91/488] Loss: 0.23943
Epoch [20/25] Training [92/488] Loss: 0.14298
Epoch [20/25] Training [93/488] Loss: 0.27170
Epoch [20/25] Training [94/488] Loss: 0.44965
Epoch [20/25] Training [95/488] Loss: 0.30481
Epoch [20/25] Training [96/488] Loss: 0.27148
Epoch [20/25] Training [97/488] Loss: 0.31881
Epoch [20/25] Training [98/488] Loss: 0.18786
Epoch [20/25] Training [99/488] Loss: 0.26489
Epoch [20/25] Training [100/488] Loss: 0.22975
Epoch [20/25] Training [101/488] Loss: 0.28820
Epoch [20/25] Training [102/488] Loss: 0.16957
Epoch [20/25] Training [103/488] Loss: 0.23729
Epoch [20/25] Training [104/488] Loss: 0.18681
Epoch [20/25] Training [105/488] Loss: 0.11313
Epoch [20/25] Training [106/488] Loss: 0.21794
Epoch [20/25] Training [107/488] Loss: 0.24754
Epoch [20/25] Training [108/488] Loss: 0.35083
Epoch [20/25] Training [109/488] Loss: 0.36065
Epoch [20/25] Training [110/488] Loss: 0.18782
Epoch [20/25] Training [111/488] Loss: 0.17222
Epoch [20/25] Training [112/488] Loss: 0.14700
Epoch [20/25] Training [113/488] Loss: 0.34141
Epoch [20/25] Training [114/488] Loss: 0.33033
Epoch [20/25] Training [115/488] Loss: 0.37390
Epoch [20/25] Training [116/488] Loss: 0.17226
Epoch [20/25] Training [117/488] Loss: 0.20124
Epoch [20/25] Training [118/488] Loss: 0.25955
Epoch [20/25] Training [119/488] Loss: 0.21092
Epoch [20/25] Training [120/488] Loss: 0.17987
Epoch [20/25] Training [121/488] Loss: 0.14883
Epoch [20/25] Training [122/488] Loss: 0.25420
Epoch [20/25] Training [123/488] Loss: 0.50947
Epoch [20/25] Training [124/488] Loss: 0.30686
Epoch [20/25] Training [125/488] Loss: 0.23498
Epoch [20/25] Training [126/488] Loss: 0.13968
Epoch [20/25] Training [127/488] Loss: 0.16696
Epoch [20/25] Training [128/488] Loss: 0.20968
Epoch [20/25] Training [129/488] Loss: 0.15260
Epoch [20/25] Training [130/488] Loss: 0.27782
Epoch [20/25] Training [131/488] Loss: 0.20798
Epoch [20/25] Training [132/488] Loss: 0.32541
Epoch [20/25] Training [133/488] Loss: 0.58537
Epoch [20/25] Training [134/488] Loss: 0.18760
Epoch [20/25] Training [135/488] Loss: 0.27125
Epoch [20/25] Training [136/488] Loss: 0.47395
Epoch [20/25] Training [137/488] Loss: 0.19905
Epoch [20/25] Training [138/488] Loss: 0.35419
Epoch [20/25] Training [139/488] Loss: 0.19792
Epoch [20/25] Training [140/488] Loss: 0.14300
Epoch [20/25] Training [141/488] Loss: 0.25041
Epoch [20/25] Training [142/488] Loss: 0.17499
Epoch [20/25] Training [143/488] Loss: 0.11903
Epoch [20/25] Training [144/488] Loss: 0.19520
Epoch [20/25] Training [145/488] Loss: 0.25433
Epoch [20/25] Training [146/488] Loss: 0.17417
Epoch [20/25] Training [147/488] Loss: 0.15531
Epoch [20/25] Training [148/488] Loss: 0.15995
Epoch [20/25] Training [149/488] Loss: 0.23498
Epoch [20/25] Training [150/488] Loss: 0.24112
Epoch [20/25] Training [151/488] Loss: 0.24527
Epoch [20/25] Training [152/488] Loss: 0.28893
Epoch [20/25] Training [153/488] Loss: 0.14610
Epoch [20/25] Training [154/488] Loss: 0.24193
Epoch [20/25] Training [155/488] Loss: 0.16896
Epoch [20/25] Training [156/488] Loss: 0.14349
Epoch [20/25] Training [157/488] Loss: 0.34538
Epoch [20/25] Training [158/488] Loss: 0.17742
Epoch [20/25] Training [159/488] Loss: 0.15817
Epoch [20/25] Training [160/488] Loss: 0.47293
Epoch [20/25] Training [161/488] Loss: 0.18127
Epoch [20/25] Training [162/488] Loss: 0.18395
Epoch [20/25] Training [163/488] Loss: 0.15576
Epoch [20/25] Training [164/488] Loss: 0.25538
Epoch [20/25] Training [165/488] Loss: 0.18346
Epoch [20/25] Training [166/488] Loss: 0.16597
Epoch [20/25] Training [167/488] Loss: 0.33433
Epoch [20/25] Training [168/488] Loss: 0.20936
Epoch [20/25] Training [169/488] Loss: 0.25589
Epoch [20/25] Training [170/488] Loss: 0.29900
Epoch [20/25] Training [171/488] Loss: 0.18143
Epoch [20/25] Training [172/488] Loss: 0.19388
Epoch [20/25] Training [173/488] Loss: 0.20787
Epoch [20/25] Training [174/488] Loss: 0.22003
Epoch [20/25] Training [175/488] Loss: 0.31614
Epoch [20/25] Training [176/488] Loss: 0.20382
Epoch [20/25] Training [177/488] Loss: 0.12843
Epoch [20/25] Training [178/488] Loss: 0.15720
Epoch [20/25] Training [179/488] Loss: 0.65053
Epoch [20/25] Training [180/488] Loss: 0.26013
Epoch [20/25] Training [181/488] Loss: 0.19821
Epoch [20/25] Training [182/488] Loss: 0.20116
Epoch [20/25] Training [183/488] Loss: 0.11935
Epoch [20/25] Training [184/488] Loss: 0.14579
Epoch [20/25] Training [185/488] Loss: 0.33086
Epoch [20/25] Training [186/488] Loss: 0.17966
Epoch [20/25] Training [187/488] Loss: 0.12730
Epoch [20/25] Training [188/488] Loss: 0.12420
Epoch [20/25] Training [189/488] Loss: 0.21506
Epoch [20/25] Training [190/488] Loss: 0.15207
Epoch [20/25] Training [191/488] Loss: 0.15504
Epoch [20/25] Training [192/488] Loss: 0.21701
Epoch [20/25] Training [193/488] Loss: 0.19536
Epoch [20/25] Training [194/488] Loss: 0.12842
Epoch [20/25] Training [195/488] Loss: 0.12237
Epoch [20/25] Training [196/488] Loss: 0.37782
Epoch [20/25] Training [197/488] Loss: 0.16600
Epoch [20/25] Training [198/488] Loss: 0.42568
Epoch [20/25] Training [199/488] Loss: 0.25317
Epoch [20/25] Training [200/488] Loss: 0.17620
Epoch [20/25] Training [201/488] Loss: 0.15229
Epoch [20/25] Training [202/488] Loss: 0.14670
Epoch [20/25] Training [203/488] Loss: 0.30387
Epoch [20/25] Training [204/488] Loss: 0.19346
Epoch [20/25] Training [205/488] Loss: 0.30998
Epoch [20/25] Training [206/488] Loss: 0.29554
Epoch [20/25] Training [207/488] Loss: 0.15295
Epoch [20/25] Training [208/488] Loss: 0.58846
Epoch [20/25] Training [209/488] Loss: 0.15561
Epoch [20/25] Training [210/488] Loss: 0.20452
Epoch [20/25] Training [211/488] Loss: 0.31760
Epoch [20/25] Training [212/488] Loss: 0.19354
Epoch [20/25] Training [213/488] Loss: 0.41681
Epoch [20/25] Training [214/488] Loss: 0.18178
Epoch [20/25] Training [215/488] Loss: 0.18250
Epoch [20/25] Training [216/488] Loss: 0.13984
Epoch [20/25] Training [217/488] Loss: 0.19721
Epoch [20/25] Training [218/488] Loss: 0.39781
Epoch [20/25] Training [219/488] Loss: 0.16179
Epoch [20/25] Training [220/488] Loss: 0.14326
Epoch [20/25] Training [221/488] Loss: 0.18737
Epoch [20/25] Training [222/488] Loss: 0.19633
Epoch [20/25] Training [223/488] Loss: 0.24590
Epoch [20/25] Training [224/488] Loss: 0.26276
Epoch [20/25] Training [225/488] Loss: 0.14404
Epoch [20/25] Training [226/488] Loss: 0.19661
Epoch [20/25] Training [227/488] Loss: 0.21979
Epoch [20/25] Training [228/488] Loss: 0.20924
Epoch [20/25] Training [229/488] Loss: 0.25065
Epoch [20/25] Training [230/488] Loss: 0.30999
Epoch [20/25] Training [231/488] Loss: 0.17103
Epoch [20/25] Training [232/488] Loss: 0.27664
Epoch [20/25] Training [233/488] Loss: 0.12329
Epoch [20/25] Training [234/488] Loss: 0.15267
Epoch [20/25] Training [235/488] Loss: 0.23099
Epoch [20/25] Training [236/488] Loss: 0.21788
Epoch [20/25] Training [237/488] Loss: 0.14959
Epoch [20/25] Training [238/488] Loss: 0.12445
Epoch [20/25] Training [239/488] Loss: 0.21929
Epoch [20/25] Training [240/488] Loss: 0.53579
Epoch [20/25] Training [241/488] Loss: 0.22539
Epoch [20/25] Training [242/488] Loss: 0.19905
Epoch [20/25] Training [243/488] Loss: 0.51849
Epoch [20/25] Training [244/488] Loss: 0.19923
Epoch [20/25] Training [245/488] Loss: 0.35914
Epoch [20/25] Training [246/488] Loss: 0.15878
Epoch [20/25] Training [247/488] Loss: 0.28139
Epoch [20/25] Training [248/488] Loss: 0.22529
Epoch [20/25] Training [249/488] Loss: 0.21764
Epoch [20/25] Training [250/488] Loss: 0.13109
Epoch [20/25] Training [251/488] Loss: 0.43913
Epoch [20/25] Training [252/488] Loss: 0.17706
Epoch [20/25] Training [253/488] Loss: 0.29473
Epoch [20/25] Training [254/488] Loss: 0.35674
Epoch [20/25] Training [255/488] Loss: 0.17713
Epoch [20/25] Training [256/488] Loss: 0.26616
Epoch [20/25] Training [257/488] Loss: 0.47283
Epoch [20/25] Training [258/488] Loss: 0.34201
Epoch [20/25] Training [259/488] Loss: 0.17816
Epoch [20/25] Training [260/488] Loss: 0.17965
Epoch [20/25] Training [261/488] Loss: 0.37803
Epoch [20/25] Training [262/488] Loss: 0.18690
Epoch [20/25] Training [263/488] Loss: 0.40141
Epoch [20/25] Training [264/488] Loss: 0.32650
Epoch [20/25] Training [265/488] Loss: 0.42020
Epoch [20/25] Training [266/488] Loss: 0.22375
Epoch [20/25] Training [267/488] Loss: 0.15546
Epoch [20/25] Training [268/488] Loss: 0.49874
Epoch [20/25] Training [269/488] Loss: 0.19500
Epoch [20/25] Training [270/488] Loss: 0.17916
Epoch [20/25] Training [271/488] Loss: 0.22334
Epoch [20/25] Training [272/488] Loss: 0.31274
Epoch [20/25] Training [273/488] Loss: 0.35035
Epoch [20/25] Training [274/488] Loss: 0.15721
Epoch [20/25] Training [275/488] Loss: 0.50210
Epoch [20/25] Training [276/488] Loss: 0.17616
Epoch [20/25] Training [277/488] Loss: 0.14221
Epoch [20/25] Training [278/488] Loss: 0.19263
Epoch [20/25] Training [279/488] Loss: 0.19035
Epoch [20/25] Training [280/488] Loss: 0.15615
Epoch [20/25] Training [281/488] Loss: 0.16173
Epoch [20/25] Training [282/488] Loss: 0.21186
Epoch [20/25] Training [283/488] Loss: 0.23271
Epoch [20/25] Training [284/488] Loss: 0.13565
Epoch [20/25] Training [285/488] Loss: 0.39385
Epoch [20/25] Training [286/488] Loss: 0.12432
Epoch [20/25] Training [287/488] Loss: 0.12298
Epoch [20/25] Training [288/488] Loss: 0.16840
Epoch [20/25] Training [289/488] Loss: 0.19243
Epoch [20/25] Training [290/488] Loss: 0.18775
Epoch [20/25] Training [291/488] Loss: 0.36231
Epoch [20/25] Training [292/488] Loss: 0.23467
Epoch [20/25] Training [293/488] Loss: 0.48342
Epoch [20/25] Training [294/488] Loss: 0.19681
Epoch [20/25] Training [295/488] Loss: 0.24662
Epoch [20/25] Training [296/488] Loss: 0.16280
Epoch [20/25] Training [297/488] Loss: 0.14938
Epoch [20/25] Training [298/488] Loss: 0.16828
Epoch [20/25] Training [299/488] Loss: 0.27214
Epoch [20/25] Training [300/488] Loss: 0.24372
Epoch [20/25] Training [301/488] Loss: 0.25886
Epoch [20/25] Training [302/488] Loss: 0.93388
Epoch [20/25] Training [303/488] Loss: 0.15726
Epoch [20/25] Training [304/488] Loss: 0.31683
Epoch [20/25] Training [305/488] Loss: 0.32926
Epoch [20/25] Training [306/488] Loss: 0.14069
Epoch [20/25] Training [307/488] Loss: 0.25853
Epoch [20/25] Training [308/488] Loss: 0.13130
Epoch [20/25] Training [309/488] Loss: 0.18437
Epoch [20/25] Training [310/488] Loss: 0.13641
Epoch [20/25] Training [311/488] Loss: 0.27778
Epoch [20/25] Training [312/488] Loss: 0.21150
Epoch [20/25] Training [313/488] Loss: 0.30987
Epoch [20/25] Training [314/488] Loss: 0.14588
Epoch [20/25] Training [315/488] Loss: 0.25280
Epoch [20/25] Training [316/488] Loss: 0.26720
Epoch [20/25] Training [317/488] Loss: 0.24689
Epoch [20/25] Training [318/488] Loss: 0.23646
Epoch [20/25] Training [319/488] Loss: 0.16174
Epoch [20/25] Training [320/488] Loss: 0.18588
Epoch [20/25] Training [321/488] Loss: 0.19960
Epoch [20/25] Training [322/488] Loss: 0.15120
Epoch [20/25] Training [323/488] Loss: 0.13798
Epoch [20/25] Training [324/488] Loss: 0.18497
Epoch [20/25] Training [325/488] Loss: 0.41685
Epoch [20/25] Training [326/488] Loss: 0.27966
Epoch [20/25] Training [327/488] Loss: 0.20613
Epoch [20/25] Training [328/488] Loss: 0.28532
Epoch [20/25] Training [329/488] Loss: 0.14767
Epoch [20/25] Training [330/488] Loss: 0.26422
Epoch [20/25] Training [331/488] Loss: 0.22791
Epoch [20/25] Training [332/488] Loss: 0.38480
Epoch [20/25] Training [333/488] Loss: 0.15883
Epoch [20/25] Training [334/488] Loss: 0.17962
Epoch [20/25] Training [335/488] Loss: 0.21265
Epoch [20/25] Training [336/488] Loss: 0.39095
Epoch [20/25] Training [337/488] Loss: 0.19929
Epoch [20/25] Training [338/488] Loss: 0.15553
Epoch [20/25] Training [339/488] Loss: 0.13925
Epoch [20/25] Training [340/488] Loss: 0.15631
Epoch [20/25] Training [341/488] Loss: 0.21307
Epoch [20/25] Training [342/488] Loss: 0.16008
Epoch [20/25] Training [343/488] Loss: 0.22617
Epoch [20/25] Training [344/488] Loss: 0.15265
Epoch [20/25] Training [345/488] Loss: 0.12387
Epoch [20/25] Training [346/488] Loss: 0.15760
Epoch [20/25] Training [347/488] Loss: 0.39268
Epoch [20/25] Training [348/488] Loss: 0.15098
Epoch [20/25] Training [349/488] Loss: 0.22354
Epoch [20/25] Training [350/488] Loss: 0.28397
Epoch [20/25] Training [351/488] Loss: 0.14056
Epoch [20/25] Training [352/488] Loss: 0.15131
Epoch [20/25] Training [353/488] Loss: 0.17348
Epoch [20/25] Training [354/488] Loss: 0.17039
Epoch [20/25] Training [355/488] Loss: 0.24309
Epoch [20/25] Training [356/488] Loss: 0.12892
Epoch [20/25] Training [357/488] Loss: 0.14945
Epoch [20/25] Training [358/488] Loss: 0.21926
Epoch [20/25] Training [359/488] Loss: 0.32398
Epoch [20/25] Training [360/488] Loss: 0.13772
Epoch [20/25] Training [361/488] Loss: 0.15034
Epoch [20/25] Training [362/488] Loss: 0.15502
Epoch [20/25] Training [363/488] Loss: 0.13649
Epoch [20/25] Training [364/488] Loss: 0.13097
Epoch [20/25] Training [365/488] Loss: 0.12153
Epoch [20/25] Training [366/488] Loss: 0.33774
Epoch [20/25] Training [367/488] Loss: 0.13293
Epoch [20/25] Training [368/488] Loss: 0.15579
Epoch [20/25] Training [369/488] Loss: 0.12747
Epoch [20/25] Training [370/488] Loss: 0.16571
Epoch [20/25] Training [371/488] Loss: 0.26220
Epoch [20/25] Training [372/488] Loss: 0.17661
Epoch [20/25] Training [373/488] Loss: 0.16648
Epoch [20/25] Training [374/488] Loss: 0.15969
Epoch [20/25] Training [375/488] Loss: 0.15545
Epoch [20/25] Training [376/488] Loss: 0.19107
Epoch [20/25] Training [377/488] Loss: 0.31912
Epoch [20/25] Training [378/488] Loss: 0.14991
Epoch [20/25] Training [379/488] Loss: 0.16447
Epoch [20/25] Training [380/488] Loss: 0.17985
Epoch [20/25] Training [381/488] Loss: 0.19952
Epoch [20/25] Training [382/488] Loss: 0.14772
Epoch [20/25] Training [383/488] Loss: 0.15484
Epoch [20/25] Training [384/488] Loss: 0.11328
Epoch [20/25] Training [385/488] Loss: 0.28356
Epoch [20/25] Training [386/488] Loss: 0.24261
Epoch [20/25] Training [387/488] Loss: 0.18489
Epoch [20/25] Training [388/488] Loss: 0.40980
Epoch [20/25] Training [389/488] Loss: 0.21677
Epoch [20/25] Training [390/488] Loss: 0.18063
Epoch [20/25] Training [391/488] Loss: 0.50724
Epoch [20/25] Training [392/488] Loss: 0.15937
Epoch [20/25] Training [393/488] Loss: 0.16388
Epoch [20/25] Training [394/488] Loss: 0.19843
Epoch [20/25] Training [395/488] Loss: 0.13042
Epoch [20/25] Training [396/488] Loss: 0.19194
Epoch [20/25] Training [397/488] Loss: 0.15553
Epoch [20/25] Training [398/488] Loss: 0.14559
Epoch [20/25] Training [399/488] Loss: 0.14836
Epoch [20/25] Training [400/488] Loss: 0.23424
Epoch [20/25] Training [401/488] Loss: 0.15369
Epoch [20/25] Training [402/488] Loss: 0.12474
Epoch [20/25] Training [403/488] Loss: 0.13462
Epoch [20/25] Training [404/488] Loss: 0.14635
Epoch [20/25] Training [405/488] Loss: 0.15142
Epoch [20/25] Training [406/488] Loss: 0.12495
Epoch [20/25] Training [407/488] Loss: 0.35156
Epoch [20/25] Training [408/488] Loss: 0.15853
Epoch [20/25] Training [409/488] Loss: 0.12567
Epoch [20/25] Training [410/488] Loss: 0.30535
Epoch [20/25] Training [411/488] Loss: 0.19703
Epoch [20/25] Training [412/488] Loss: 0.18578
Epoch [20/25] Training [413/488] Loss: 0.16393
Epoch [20/25] Training [414/488] Loss: 0.19028
Epoch [20/25] Training [415/488] Loss: 0.20241
Epoch [20/25] Training [416/488] Loss: 0.56389
Epoch [20/25] Training [417/488] Loss: 0.21564
Epoch [20/25] Training [418/488] Loss: 0.18051
Epoch [20/25] Training [419/488] Loss: 0.13821
Epoch [20/25] Training [420/488] Loss: 0.31775
Epoch [20/25] Training [421/488] Loss: 0.18284
Epoch [20/25] Training [422/488] Loss: 0.35460
Epoch [20/25] Training [423/488] Loss: 0.37107
Epoch [20/25] Training [424/488] Loss: 0.22619
Epoch [20/25] Training [425/488] Loss: 0.36427
Epoch [20/25] Training [426/488] Loss: 0.15137
Epoch [20/25] Training [427/488] Loss: 0.15426
Epoch [20/25] Training [428/488] Loss: 0.23731
Epoch [20/25] Training [429/488] Loss: 0.15352
Epoch [20/25] Training [430/488] Loss: 0.27168
Epoch [20/25] Training [431/488] Loss: 0.71216
Epoch [20/25] Training [432/488] Loss: 0.32634
Epoch [20/25] Training [433/488] Loss: 0.19036
Epoch [20/25] Training [434/488] Loss: 0.21828
Epoch [20/25] Training [435/488] Loss: 0.24499
Epoch [20/25] Training [436/488] Loss: 0.16029
Epoch [20/25] Training [437/488] Loss: 0.17012
Epoch [20/25] Training [438/488] Loss: 0.15106
Epoch [20/25] Training [439/488] Loss: 0.21402
Epoch [20/25] Training [440/488] Loss: 0.23763
Epoch [20/25] Training [441/488] Loss: 0.49458
Epoch [20/25] Training [442/488] Loss: 0.25692
Epoch [20/25] Training [443/488] Loss: 0.14448
Epoch [20/25] Training [444/488] Loss: 0.12312
Epoch [20/25] Training [445/488] Loss: 0.12954
Epoch [20/25] Training [446/488] Loss: 0.41083
Epoch [20/25] Training [447/488] Loss: 0.40457
Epoch [20/25] Training [448/488] Loss: 0.21940
Epoch [20/25] Training [449/488] Loss: 0.14490
Epoch [20/25] Training [450/488] Loss: 0.13997
Epoch [20/25] Training [451/488] Loss: 0.13365
Epoch [20/25] Training [452/488] Loss: 0.71638
Epoch [20/25] Training [453/488] Loss: 0.40542
Epoch [20/25] Training [454/488] Loss: 0.33268
Epoch [20/25] Training [455/488] Loss: 0.15029
Epoch [20/25] Training [456/488] Loss: 0.22067
Epoch [20/25] Training [457/488] Loss: 0.24549
Epoch [20/25] Training [458/488] Loss: 0.68448
Epoch [20/25] Training [459/488] Loss: 0.18030
Epoch [20/25] Training [460/488] Loss: 0.16468
Epoch [20/25] Training [461/488] Loss: 0.44926
Epoch [20/25] Training [462/488] Loss: 0.40093
Epoch [20/25] Training [463/488] Loss: 0.20900
Epoch [20/25] Training [464/488] Loss: 0.15865
Epoch [20/25] Training [465/488] Loss: 0.25062
Epoch [20/25] Training [466/488] Loss: 0.70744
Epoch [20/25] Training [467/488] Loss: 0.13273
Epoch [20/25] Training [468/488] Loss: 0.17114
Epoch [20/25] Training [469/488] Loss: 0.20653
Epoch [20/25] Training [470/488] Loss: 0.14808
Epoch [20/25] Training [471/488] Loss: 0.13988
Epoch [20/25] Training [472/488] Loss: 0.19866
Epoch [20/25] Training [473/488] Loss: 0.16624
Epoch [20/25] Training [474/488] Loss: 0.18684
Epoch [20/25] Training [475/488] Loss: 0.22926
Epoch [20/25] Training [476/488] Loss: 0.18597
Epoch [20/25] Training [477/488] Loss: 0.62061
Epoch [20/25] Training [478/488] Loss: 0.12558
Epoch [20/25] Training [479/488] Loss: 0.17242
Epoch [20/25] Training [480/488] Loss: 0.16105
Epoch [20/25] Training [481/488] Loss: 0.14542
Epoch [20/25] Training [482/488] Loss: 0.15093
Epoch [20/25] Training [483/488] Loss: 0.26484
Epoch [20/25] Training [484/488] Loss: 0.13512
Epoch [20/25] Training [485/488] Loss: 0.39284
Epoch [20/25] Training [486/488] Loss: 0.13985
Epoch [20/25] Training [487/488] Loss: 0.13967
Epoch [20/25] Training [488/488] Loss: 0.16004
Epoch [20/25] Training metric {'Train/mean dice_metric': 0.8894749879837036, 'Train/TC dice_metric': 0.9126987457275391, 'Train/WT dice_metric': 0.936508297920227, 'Train/ET dice_metric': 0.8192178010940552}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [20/25] Validation [1/123] Loss: 0.22410  focal_loss 0.00181  dice_loss 0.22229
Epoch [20/25] Validation [2/123] Loss: 0.39411  focal_loss 0.00137  dice_loss 0.39274
Epoch [20/25] Validation [3/123] Loss: 0.20686  focal_loss 0.00138  dice_loss 0.20548
Epoch [20/25] Validation [4/123] Loss: 0.29247  focal_loss 0.00127  dice_loss 0.29120
Epoch [20/25] Validation [5/123] Loss: 0.35942  focal_loss 0.01001  dice_loss 0.34940
Epoch [20/25] Validation [6/123] Loss: 0.35152  focal_loss 0.00127  dice_loss 0.35025
Epoch [20/25] Validation [7/123] Loss: 0.37426  focal_loss 0.00051  dice_loss 0.37375
Epoch [20/25] Validation [8/123] Loss: 0.37469  focal_loss 0.00157  dice_loss 0.37312
Epoch [20/25] Validation [9/123] Loss: 0.28827  focal_loss 0.00132  dice_loss 0.28695
Epoch [20/25] Validation [10/123] Loss: 0.50288  focal_loss 0.00283  dice_loss 0.50005
Epoch [20/25] Validation [11/123] Loss: 0.46117  focal_loss 0.00155  dice_loss 0.45962
Epoch [20/25] Validation [12/123] Loss: 0.23962  focal_loss 0.00139  dice_loss 0.23822
Epoch [20/25] Validation [13/123] Loss: 0.22159  focal_loss 0.00297  dice_loss 0.21862
Epoch [20/25] Validation [14/123] Loss: 0.26376  focal_loss 0.00093  dice_loss 0.26283
Epoch [20/25] Validation [15/123] Loss: 0.37177  focal_loss 0.00118  dice_loss 0.37060
Epoch [20/25] Validation [16/123] Loss: 0.45430  focal_loss 0.00155  dice_loss 0.45275
Epoch [20/25] Validation [17/123] Loss: 0.50745  focal_loss 0.00124  dice_loss 0.50622
Epoch [20/25] Validation [18/123] Loss: 0.41364  focal_loss 0.00786  dice_loss 0.40578
Epoch [20/25] Validation [19/123] Loss: 0.30671  focal_loss 0.00221  dice_loss 0.30450
Epoch [20/25] Validation [20/123] Loss: 0.45986  focal_loss 0.00049  dice_loss 0.45937
Epoch [20/25] Validation [21/123] Loss: 0.34947  focal_loss 0.00069  dice_loss 0.34878
Epoch [20/25] Validation [22/123] Loss: 0.67509  focal_loss 0.00349  dice_loss 0.67159
Epoch [20/25] Validation [23/123] Loss: 0.21835  focal_loss 0.00145  dice_loss 0.21690
Epoch [20/25] Validation [24/123] Loss: 0.30409  focal_loss 0.00140  dice_loss 0.30269
Epoch [20/25] Validation [25/123] Loss: 0.38961  focal_loss 0.00465  dice_loss 0.38496
Epoch [20/25] Validation [26/123] Loss: 0.22815  focal_loss 0.00136  dice_loss 0.22679
Epoch [20/25] Validation [27/123] Loss: 0.26313  focal_loss 0.00169  dice_loss 0.26145
Epoch [20/25] Validation [28/123] Loss: 0.49613  focal_loss 0.00364  dice_loss 0.49250
Epoch [20/25] Validation [29/123] Loss: 0.34874  focal_loss 0.00094  dice_loss 0.34780
Epoch [20/25] Validation [30/123] Loss: 0.29697  focal_loss 0.00575  dice_loss 0.29122
Epoch [20/25] Validation [31/123] Loss: 0.21941  focal_loss 0.00121  dice_loss 0.21820
Epoch [20/25] Validation [32/123] Loss: 0.31984  focal_loss 0.00247  dice_loss 0.31737
Epoch [20/25] Validation [33/123] Loss: 0.36925  focal_loss 0.00152  dice_loss 0.36773
Epoch [20/25] Validation [34/123] Loss: 0.29497  focal_loss 0.00060  dice_loss 0.29437
Epoch [20/25] Validation [35/123] Loss: 0.25198  focal_loss 0.00090  dice_loss 0.25108
Epoch [20/25] Validation [36/123] Loss: 0.28741  focal_loss 0.00094  dice_loss 0.28647
Epoch [20/25] Validation [37/123] Loss: 0.37353  focal_loss 0.00129  dice_loss 0.37224
Epoch [20/25] Validation [38/123] Loss: 0.24204  focal_loss 0.00112  dice_loss 0.24093
Epoch [20/25] Validation [39/123] Loss: 0.22880  focal_loss 0.00110  dice_loss 0.22770
Epoch [20/25] Validation [40/123] Loss: 0.33364  focal_loss 0.00068  dice_loss 0.33297
Epoch [20/25] Validation [41/123] Loss: 0.25002  focal_loss 0.00364  dice_loss 0.24637
Epoch [20/25] Validation [42/123] Loss: 0.21558  focal_loss 0.00109  dice_loss 0.21449
Epoch [20/25] Validation [43/123] Loss: 0.28224  focal_loss 0.00403  dice_loss 0.27822
Epoch [20/25] Validation [44/123] Loss: 0.50448  focal_loss 0.00307  dice_loss 0.50140
Epoch [20/25] Validation [45/123] Loss: 0.32294  focal_loss 0.00128  dice_loss 0.32165
Epoch [20/25] Validation [46/123] Loss: 0.36207  focal_loss 0.00266  dice_loss 0.35941
Epoch [20/25] Validation [47/123] Loss: 0.31997  focal_loss 0.00106  dice_loss 0.31891
Epoch [20/25] Validation [48/123] Loss: 0.42039  focal_loss 0.00341  dice_loss 0.41698
Epoch [20/25] Validation [49/123] Loss: 0.23326  focal_loss 0.00107  dice_loss 0.23219
Epoch [20/25] Validation [50/123] Loss: 0.22748  focal_loss 0.00173  dice_loss 0.22575
Epoch [20/25] Validation [51/123] Loss: 0.42766  focal_loss 0.01027  dice_loss 0.41739
Epoch [20/25] Validation [52/123] Loss: 0.24796  focal_loss 0.00069  dice_loss 0.24727
Epoch [20/25] Validation [53/123] Loss: 0.30946  focal_loss 0.00080  dice_loss 0.30865
Epoch [20/25] Validation [54/123] Loss: 0.34008  focal_loss 0.00075  dice_loss 0.33933
Epoch [20/25] Validation [55/123] Loss: 0.30349  focal_loss 0.00112  dice_loss 0.30237
Epoch [20/25] Validation [56/123] Loss: 0.24300  focal_loss 0.00163  dice_loss 0.24137
Epoch [20/25] Validation [57/123] Loss: 0.31282  focal_loss 0.00080  dice_loss 0.31202
Epoch [20/25] Validation [58/123] Loss: 0.28359  focal_loss 0.00240  dice_loss 0.28119
Epoch [20/25] Validation [59/123] Loss: 0.59430  focal_loss 0.00443  dice_loss 0.58987
Epoch [20/25] Validation [60/123] Loss: 0.26814  focal_loss 0.00189  dice_loss 0.26625
Epoch [20/25] Validation [61/123] Loss: 0.61076  focal_loss 0.00049  dice_loss 0.61027
Epoch [20/25] Validation [62/123] Loss: 0.50986  focal_loss 0.00366  dice_loss 0.50620
Epoch [20/25] Validation [63/123] Loss: 0.39045  focal_loss 0.00090  dice_loss 0.38956
Epoch [20/25] Validation [64/123] Loss: 0.37703  focal_loss 0.00333  dice_loss 0.37371
Epoch [20/25] Validation [65/123] Loss: 0.26310  focal_loss 0.00098  dice_loss 0.26212
Epoch [20/25] Validation [66/123] Loss: 0.26719  focal_loss 0.00084  dice_loss 0.26635
Epoch [20/25] Validation [67/123] Loss: 0.46404  focal_loss 0.01345  dice_loss 0.45058
Epoch [20/25] Validation [68/123] Loss: 0.37559  focal_loss 0.00069  dice_loss 0.37490
Epoch [20/25] Validation [69/123] Loss: 0.39540  focal_loss 0.00581  dice_loss 0.38959
Epoch [20/25] Validation [70/123] Loss: 0.33124  focal_loss 0.00144  dice_loss 0.32979
Epoch [20/25] Validation [71/123] Loss: 0.25298  focal_loss 0.00072  dice_loss 0.25225
Epoch [20/25] Validation [72/123] Loss: 0.23484  focal_loss 0.00143  dice_loss 0.23341
Epoch [20/25] Validation [73/123] Loss: 0.35086  focal_loss 0.00354  dice_loss 0.34732
Epoch [20/25] Validation [74/123] Loss: 0.33878  focal_loss 0.00241  dice_loss 0.33637
Epoch [20/25] Validation [75/123] Loss: 0.29111  focal_loss 0.00128  dice_loss 0.28984
Epoch [20/25] Validation [76/123] Loss: 0.49710  focal_loss 0.00351  dice_loss 0.49359
Epoch [20/25] Validation [77/123] Loss: 0.38131  focal_loss 0.00075  dice_loss 0.38057
Epoch [20/25] Validation [78/123] Loss: 0.29192  focal_loss 0.00134  dice_loss 0.29059
Epoch [20/25] Validation [79/123] Loss: 0.33069  focal_loss 0.00098  dice_loss 0.32971
Epoch [20/25] Validation [80/123] Loss: 0.24787  focal_loss 0.00255  dice_loss 0.24533
Epoch [20/25] Validation [81/123] Loss: 0.28074  focal_loss 0.00135  dice_loss 0.27940
Epoch [20/25] Validation [82/123] Loss: 0.23681  focal_loss 0.00084  dice_loss 0.23597
Epoch [20/25] Validation [83/123] Loss: 0.41224  focal_loss 0.01084  dice_loss 0.40141
Epoch [20/25] Validation [84/123] Loss: 0.28175  focal_loss 0.00106  dice_loss 0.28069
Epoch [20/25] Validation [85/123] Loss: 0.37003  focal_loss 0.00549  dice_loss 0.36453
Epoch [20/25] Validation [86/123] Loss: 0.24990  focal_loss 0.00105  dice_loss 0.24885
Epoch [20/25] Validation [87/123] Loss: 0.23594  focal_loss 0.00241  dice_loss 0.23353
Epoch [20/25] Validation [88/123] Loss: 0.26430  focal_loss 0.00124  dice_loss 0.26307
Epoch [20/25] Validation [89/123] Loss: 0.21857  focal_loss 0.00162  dice_loss 0.21695
Epoch [20/25] Validation [90/123] Loss: 0.32349  focal_loss 0.00151  dice_loss 0.32198
Epoch [20/25] Validation [91/123] Loss: 0.25883  focal_loss 0.00094  dice_loss 0.25789
Epoch [20/25] Validation [92/123] Loss: 0.21423  focal_loss 0.00108  dice_loss 0.21315
Epoch [20/25] Validation [93/123] Loss: 0.23549  focal_loss 0.00108  dice_loss 0.23441
Epoch [20/25] Validation [94/123] Loss: 0.36057  focal_loss 0.00141  dice_loss 0.35916
Epoch [20/25] Validation [95/123] Loss: 0.27227  focal_loss 0.00193  dice_loss 0.27033
Epoch [20/25] Validation [96/123] Loss: 0.33520  focal_loss 0.00118  dice_loss 0.33402
Epoch [20/25] Validation [97/123] Loss: 0.61444  focal_loss 0.00642  dice_loss 0.60802
Epoch [20/25] Validation [98/123] Loss: 0.33634  focal_loss 0.00088  dice_loss 0.33546
Epoch [20/25] Validation [99/123] Loss: 0.33800  focal_loss 0.00054  dice_loss 0.33746
Epoch [20/25] Validation [100/123] Loss: 0.35572  focal_loss 0.00074  dice_loss 0.35498
Epoch [20/25] Validation [101/123] Loss: 0.31899  focal_loss 0.00123  dice_loss 0.31776
Epoch [20/25] Validation [102/123] Loss: 0.35090  focal_loss 0.00050  dice_loss 0.35040
Epoch [20/25] Validation [103/123] Loss: 0.44465  focal_loss 0.00052  dice_loss 0.44413
Epoch [20/25] Validation [104/123] Loss: 0.42380  focal_loss 0.00270  dice_loss 0.42110
Epoch [20/25] Validation [105/123] Loss: 0.22369  focal_loss 0.00253  dice_loss 0.22116
Epoch [20/25] Validation [106/123] Loss: 0.26049  focal_loss 0.00077  dice_loss 0.25972
Epoch [20/25] Validation [107/123] Loss: 0.51892  focal_loss 0.00171  dice_loss 0.51721
Epoch [20/25] Validation [108/123] Loss: 0.25175  focal_loss 0.00056  dice_loss 0.25119
Epoch [20/25] Validation [109/123] Loss: 0.22879  focal_loss 0.00408  dice_loss 0.22471
Epoch [20/25] Validation [110/123] Loss: 0.38027  focal_loss 0.00265  dice_loss 0.37761
Epoch [20/25] Validation [111/123] Loss: 0.38701  focal_loss 0.00252  dice_loss 0.38449
Epoch [20/25] Validation [112/123] Loss: 0.34084  focal_loss 0.00078  dice_loss 0.34006
Epoch [20/25] Validation [113/123] Loss: 0.29585  focal_loss 0.00142  dice_loss 0.29443
Epoch [20/25] Validation [114/123] Loss: 0.34933  focal_loss 0.00427  dice_loss 0.34506
Epoch [20/25] Validation [115/123] Loss: 0.29346  focal_loss 0.00408  dice_loss 0.28938
Epoch [20/25] Validation [116/123] Loss: 0.28571  focal_loss 0.00052  dice_loss 0.28519
Epoch [20/25] Validation [117/123] Loss: 0.29474  focal_loss 0.00104  dice_loss 0.29371
Epoch [20/25] Validation [118/123] Loss: 0.20328  focal_loss 0.00167  dice_loss 0.20161
Epoch [20/25] Validation [119/123] Loss: 0.23277  focal_loss 0.00106  dice_loss 0.23171
Epoch [20/25] Validation [120/123] Loss: 0.26153  focal_loss 0.00168  dice_loss 0.25984
Epoch [20/25] Validation [121/123] Loss: 0.61871  focal_loss 0.01195  dice_loss 0.60676
Epoch [20/25] Validation [122/123] Loss: 0.59186  focal_loss 0.00030  dice_loss 0.59157
Epoch [20/25] Validation [123/123] Loss: 0.25458  focal_loss 0.00137  dice_loss 0.25321
Epoch [20/25] Validation metric {'Val/mean dice_metric': 0.8888897895812988, 'Val/TC dice_metric': 0.9106658697128296, 'Val/WT dice_metric': 0.9357584714889526, 'Val/ET dice_metric': 0.8202448487281799}
Epoch [20/25] lr = [0.00020610737385376348, 0.00020610737385376348] best acc: tensor([0.8835], device='cuda:0'), mean acc: tensor([0.8889], device='cuda:0'), mean class: tensor([0.9107, 0.9358, 0.8202], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [21/25] Training [1/488] Loss: 0.27576
Epoch [21/25] Training [2/488] Loss: 0.15643
Epoch [21/25] Training [3/488] Loss: 0.20184
Epoch [21/25] Training [4/488] Loss: 0.22895
Epoch [21/25] Training [5/488] Loss: 0.14599
Epoch [21/25] Training [6/488] Loss: 0.15286
Epoch [21/25] Training [7/488] Loss: 0.13187
Epoch [21/25] Training [8/488] Loss: 0.15585
Epoch [21/25] Training [9/488] Loss: 0.13823
Epoch [21/25] Training [10/488] Loss: 0.32075
Epoch [21/25] Training [11/488] Loss: 0.20982
Epoch [21/25] Training [12/488] Loss: 0.22425
Epoch [21/25] Training [13/488] Loss: 0.22685
Epoch [21/25] Training [14/488] Loss: 0.12357
Epoch [21/25] Training [15/488] Loss: 0.15324
Epoch [21/25] Training [16/488] Loss: 0.25322
Epoch [21/25] Training [17/488] Loss: 0.32779
Epoch [21/25] Training [18/488] Loss: 0.25663
Epoch [21/25] Training [19/488] Loss: 0.26469
Epoch [21/25] Training [20/488] Loss: 0.12387
Epoch [21/25] Training [21/488] Loss: 0.12550
Epoch [21/25] Training [22/488] Loss: 0.31740
Epoch [21/25] Training [23/488] Loss: 0.32502
Epoch [21/25] Training [24/488] Loss: 0.24186
Epoch [21/25] Training [25/488] Loss: 0.29593
Epoch [21/25] Training [26/488] Loss: 0.31985
Epoch [21/25] Training [27/488] Loss: 0.25019
Epoch [21/25] Training [28/488] Loss: 0.13663
Epoch [21/25] Training [29/488] Loss: 0.14043
Epoch [21/25] Training [30/488] Loss: 0.24443
Epoch [21/25] Training [31/488] Loss: 0.20335
Epoch [21/25] Training [32/488] Loss: 0.14667
Epoch [21/25] Training [33/488] Loss: 0.14618
Epoch [21/25] Training [34/488] Loss: 0.54597
Epoch [21/25] Training [35/488] Loss: 0.15409
Epoch [21/25] Training [36/488] Loss: 0.23212
Epoch [21/25] Training [37/488] Loss: 0.18975
Epoch [21/25] Training [38/488] Loss: 0.11979
Epoch [21/25] Training [39/488] Loss: 0.18299
Epoch [21/25] Training [40/488] Loss: 0.26633
Epoch [21/25] Training [41/488] Loss: 0.15708
Epoch [21/25] Training [42/488] Loss: 0.15968
Epoch [21/25] Training [43/488] Loss: 0.11807
Epoch [21/25] Training [44/488] Loss: 0.18004
Epoch [21/25] Training [45/488] Loss: 0.31666
Epoch [21/25] Training [46/488] Loss: 0.26179
Epoch [21/25] Training [47/488] Loss: 0.14238
Epoch [21/25] Training [48/488] Loss: 0.33936
Epoch [21/25] Training [49/488] Loss: 0.15560
Epoch [21/25] Training [50/488] Loss: 0.14336
Epoch [21/25] Training [51/488] Loss: 0.41420
Epoch [21/25] Training [52/488] Loss: 0.12561
Epoch [21/25] Training [53/488] Loss: 0.22942
Epoch [21/25] Training [54/488] Loss: 0.38084
Epoch [21/25] Training [55/488] Loss: 0.18225
Epoch [21/25] Training [56/488] Loss: 0.17176
Epoch [21/25] Training [57/488] Loss: 0.20607
Epoch [21/25] Training [58/488] Loss: 0.21289
Epoch [21/25] Training [59/488] Loss: 0.36023
Epoch [21/25] Training [60/488] Loss: 0.13110
Epoch [21/25] Training [61/488] Loss: 0.33828
Epoch [21/25] Training [62/488] Loss: 0.15995
Epoch [21/25] Training [63/488] Loss: 0.15602
Epoch [21/25] Training [64/488] Loss: 0.21558
Epoch [21/25] Training [65/488] Loss: 0.40793
Epoch [21/25] Training [66/488] Loss: 0.14129
Epoch [21/25] Training [67/488] Loss: 0.22027
Epoch [21/25] Training [68/488] Loss: 0.25878
Epoch [21/25] Training [69/488] Loss: 0.12821
Epoch [21/25] Training [70/488] Loss: 0.22209
Epoch [21/25] Training [71/488] Loss: 0.17068
Epoch [21/25] Training [72/488] Loss: 0.26462
Epoch [21/25] Training [73/488] Loss: 0.15383
Epoch [21/25] Training [74/488] Loss: 0.33753
Epoch [21/25] Training [75/488] Loss: 0.15189
Epoch [21/25] Training [76/488] Loss: 0.30113
Epoch [21/25] Training [77/488] Loss: 0.25255
Epoch [21/25] Training [78/488] Loss: 0.12258
Epoch [21/25] Training [79/488] Loss: 0.49138
Epoch [21/25] Training [80/488] Loss: 0.16652
Epoch [21/25] Training [81/488] Loss: 0.17171
Epoch [21/25] Training [82/488] Loss: 0.12106
Epoch [21/25] Training [83/488] Loss: 0.18405
Epoch [21/25] Training [84/488] Loss: 0.32667
Epoch [21/25] Training [85/488] Loss: 0.15519
Epoch [21/25] Training [86/488] Loss: 0.34914
Epoch [21/25] Training [87/488] Loss: 0.40846
Epoch [21/25] Training [88/488] Loss: 0.41575
Epoch [21/25] Training [89/488] Loss: 0.32979
Epoch [21/25] Training [90/488] Loss: 0.16415
Epoch [21/25] Training [91/488] Loss: 0.14878
Epoch [21/25] Training [92/488] Loss: 0.21514
Epoch [21/25] Training [93/488] Loss: 0.44558
Epoch [21/25] Training [94/488] Loss: 0.11656
Epoch [21/25] Training [95/488] Loss: 0.18205
Epoch [21/25] Training [96/488] Loss: 0.20063
Epoch [21/25] Training [97/488] Loss: 0.15049
Epoch [21/25] Training [98/488] Loss: 0.16676
Epoch [21/25] Training [99/488] Loss: 0.15182
Epoch [21/25] Training [100/488] Loss: 0.13849
Epoch [21/25] Training [101/488] Loss: 0.16321
Epoch [21/25] Training [102/488] Loss: 0.17144
Epoch [21/25] Training [103/488] Loss: 0.19206
Epoch [21/25] Training [104/488] Loss: 0.26075
Epoch [21/25] Training [105/488] Loss: 0.16865
Epoch [21/25] Training [106/488] Loss: 0.27878
Epoch [21/25] Training [107/488] Loss: 0.14498
Epoch [21/25] Training [108/488] Loss: 0.26555
Epoch [21/25] Training [109/488] Loss: 0.14934
Epoch [21/25] Training [110/488] Loss: 0.16012
Epoch [21/25] Training [111/488] Loss: 0.14958
Epoch [21/25] Training [112/488] Loss: 0.27311
Epoch [21/25] Training [113/488] Loss: 0.22213
Epoch [21/25] Training [114/488] Loss: 0.45348
Epoch [21/25] Training [115/488] Loss: 0.62092
Epoch [21/25] Training [116/488] Loss: 0.15698
Epoch [21/25] Training [117/488] Loss: 0.17520
Epoch [21/25] Training [118/488] Loss: 0.21230
Epoch [21/25] Training [119/488] Loss: 0.15465
Epoch [21/25] Training [120/488] Loss: 0.15076
Epoch [21/25] Training [121/488] Loss: 0.15812
Epoch [21/25] Training [122/488] Loss: 0.13100
Epoch [21/25] Training [123/488] Loss: 0.17832
Epoch [21/25] Training [124/488] Loss: 0.30316
Epoch [21/25] Training [125/488] Loss: 0.14187
Epoch [21/25] Training [126/488] Loss: 0.35505
Epoch [21/25] Training [127/488] Loss: 0.21971
Epoch [21/25] Training [128/488] Loss: 0.20740
Epoch [21/25] Training [129/488] Loss: 0.16589
Epoch [21/25] Training [130/488] Loss: 0.43788
Epoch [21/25] Training [131/488] Loss: 0.20139
Epoch [21/25] Training [132/488] Loss: 0.21313
Epoch [21/25] Training [133/488] Loss: 0.25210
Epoch [21/25] Training [134/488] Loss: 0.17456
Epoch [21/25] Training [135/488] Loss: 0.37827
Epoch [21/25] Training [136/488] Loss: 0.17872
Epoch [21/25] Training [137/488] Loss: 0.15346
Epoch [21/25] Training [138/488] Loss: 0.20174
Epoch [21/25] Training [139/488] Loss: 0.20259
Epoch [21/25] Training [140/488] Loss: 0.19625
Epoch [21/25] Training [141/488] Loss: 0.28053
Epoch [21/25] Training [142/488] Loss: 0.13272
Epoch [21/25] Training [143/488] Loss: 0.22090
Epoch [21/25] Training [144/488] Loss: 0.25177
Epoch [21/25] Training [145/488] Loss: 0.21212
Epoch [21/25] Training [146/488] Loss: 0.26291
Epoch [21/25] Training [147/488] Loss: 0.11729
Epoch [21/25] Training [148/488] Loss: 0.12935
Epoch [21/25] Training [149/488] Loss: 0.41368
Epoch [21/25] Training [150/488] Loss: 0.12787
Epoch [21/25] Training [151/488] Loss: 0.33894
Epoch [21/25] Training [152/488] Loss: 0.22529
Epoch [21/25] Training [153/488] Loss: 0.38691
Epoch [21/25] Training [154/488] Loss: 0.30794
Epoch [21/25] Training [155/488] Loss: 0.26099
Epoch [21/25] Training [156/488] Loss: 0.35852
Epoch [21/25] Training [157/488] Loss: 0.46775
Epoch [21/25] Training [158/488] Loss: 0.64196
Epoch [21/25] Training [159/488] Loss: 0.17057
Epoch [21/25] Training [160/488] Loss: 0.31689
Epoch [21/25] Training [161/488] Loss: 0.16106
Epoch [21/25] Training [162/488] Loss: 0.11502
Epoch [21/25] Training [163/488] Loss: 0.21227
Epoch [21/25] Training [164/488] Loss: 0.20400
Epoch [21/25] Training [165/488] Loss: 0.19017
Epoch [21/25] Training [166/488] Loss: 0.20967
Epoch [21/25] Training [167/488] Loss: 0.17891
Epoch [21/25] Training [168/488] Loss: 0.14155
Epoch [21/25] Training [169/488] Loss: 0.29038
Epoch [21/25] Training [170/488] Loss: 0.16796
Epoch [21/25] Training [171/488] Loss: 0.52876
Epoch [21/25] Training [172/488] Loss: 0.16682
Epoch [21/25] Training [173/488] Loss: 0.61680
Epoch [21/25] Training [174/488] Loss: 0.16010
Epoch [21/25] Training [175/488] Loss: 0.22935
Epoch [21/25] Training [176/488] Loss: 0.18725
Epoch [21/25] Training [177/488] Loss: 0.40538
Epoch [21/25] Training [178/488] Loss: 0.16373
Epoch [21/25] Training [179/488] Loss: 0.15775
Epoch [21/25] Training [180/488] Loss: 0.13606
Epoch [21/25] Training [181/488] Loss: 0.26062
Epoch [21/25] Training [182/488] Loss: 0.18871
Epoch [21/25] Training [183/488] Loss: 0.32128
Epoch [21/25] Training [184/488] Loss: 0.13861
Epoch [21/25] Training [185/488] Loss: 0.21688
Epoch [21/25] Training [186/488] Loss: 0.10827
Epoch [21/25] Training [187/488] Loss: 0.12095
Epoch [21/25] Training [188/488] Loss: 0.13935
Epoch [21/25] Training [189/488] Loss: 0.22834
Epoch [21/25] Training [190/488] Loss: 0.18884
Epoch [21/25] Training [191/488] Loss: 0.15559
Epoch [21/25] Training [192/488] Loss: 0.17382
Epoch [21/25] Training [193/488] Loss: 0.24222
Epoch [21/25] Training [194/488] Loss: 0.44413
Epoch [21/25] Training [195/488] Loss: 0.15975
Epoch [21/25] Training [196/488] Loss: 0.14533
Epoch [21/25] Training [197/488] Loss: 0.71986
Epoch [21/25] Training [198/488] Loss: 0.13585
Epoch [21/25] Training [199/488] Loss: 0.23756
Epoch [21/25] Training [200/488] Loss: 0.24690
Epoch [21/25] Training [201/488] Loss: 0.18293
Epoch [21/25] Training [202/488] Loss: 0.18300
Epoch [21/25] Training [203/488] Loss: 0.14849
Epoch [21/25] Training [204/488] Loss: 0.17048
Epoch [21/25] Training [205/488] Loss: 0.22955
Epoch [21/25] Training [206/488] Loss: 0.14986
Epoch [21/25] Training [207/488] Loss: 0.20639
Epoch [21/25] Training [208/488] Loss: 0.14096
Epoch [21/25] Training [209/488] Loss: 0.14841
Epoch [21/25] Training [210/488] Loss: 0.50670
Epoch [21/25] Training [211/488] Loss: 0.15777
Epoch [21/25] Training [212/488] Loss: 0.47060
Epoch [21/25] Training [213/488] Loss: 0.22431
Epoch [21/25] Training [214/488] Loss: 0.17832
Epoch [21/25] Training [215/488] Loss: 0.31407
Epoch [21/25] Training [216/488] Loss: 0.30626
Epoch [21/25] Training [217/488] Loss: 0.25498
Epoch [21/25] Training [218/488] Loss: 0.28715
Epoch [21/25] Training [219/488] Loss: 0.17725
Epoch [21/25] Training [220/488] Loss: 0.32354
Epoch [21/25] Training [221/488] Loss: 0.19550
Epoch [21/25] Training [222/488] Loss: 0.14996
Epoch [21/25] Training [223/488] Loss: 0.15461
Epoch [21/25] Training [224/488] Loss: 0.16072
Epoch [21/25] Training [225/488] Loss: 0.18799
Epoch [21/25] Training [226/488] Loss: 0.13771
Epoch [21/25] Training [227/488] Loss: 0.18517
Epoch [21/25] Training [228/488] Loss: 0.31793
Epoch [21/25] Training [229/488] Loss: 0.19251
Epoch [21/25] Training [230/488] Loss: 0.13548
Epoch [21/25] Training [231/488] Loss: 0.12187
Epoch [21/25] Training [232/488] Loss: 0.41144
Epoch [21/25] Training [233/488] Loss: 0.35057
Epoch [21/25] Training [234/488] Loss: 0.25392
Epoch [21/25] Training [235/488] Loss: 0.21081
Epoch [21/25] Training [236/488] Loss: 0.12194
Epoch [21/25] Training [237/488] Loss: 0.16475
Epoch [21/25] Training [238/488] Loss: 0.15815
Epoch [21/25] Training [239/488] Loss: 0.14839
Epoch [21/25] Training [240/488] Loss: 0.21069
Epoch [21/25] Training [241/488] Loss: 0.16585
Epoch [21/25] Training [242/488] Loss: 0.16121
Epoch [21/25] Training [243/488] Loss: 0.13728
Epoch [21/25] Training [244/488] Loss: 0.14131
Epoch [21/25] Training [245/488] Loss: 0.12094
Epoch [21/25] Training [246/488] Loss: 0.23768
Epoch [21/25] Training [247/488] Loss: 0.18625
Epoch [21/25] Training [248/488] Loss: 0.18202
Epoch [21/25] Training [249/488] Loss: 0.29617
Epoch [21/25] Training [250/488] Loss: 0.10785
Epoch [21/25] Training [251/488] Loss: 0.19735
Epoch [21/25] Training [252/488] Loss: 0.17716
Epoch [21/25] Training [253/488] Loss: 0.15485
Epoch [21/25] Training [254/488] Loss: 0.40675
Epoch [21/25] Training [255/488] Loss: 0.58643
Epoch [21/25] Training [256/488] Loss: 0.20807
Epoch [21/25] Training [257/488] Loss: 0.14407
Epoch [21/25] Training [258/488] Loss: 0.14449
Epoch [21/25] Training [259/488] Loss: 0.14675
Epoch [21/25] Training [260/488] Loss: 0.12329
Epoch [21/25] Training [261/488] Loss: 0.37818
Epoch [21/25] Training [262/488] Loss: 0.21963
Epoch [21/25] Training [263/488] Loss: 0.23286
Epoch [21/25] Training [264/488] Loss: 0.16420
Epoch [21/25] Training [265/488] Loss: 0.18484
Epoch [21/25] Training [266/488] Loss: 0.16969
Epoch [21/25] Training [267/488] Loss: 0.17485
Epoch [21/25] Training [268/488] Loss: 0.15944
Epoch [21/25] Training [269/488] Loss: 0.14999
Epoch [21/25] Training [270/488] Loss: 0.62959
Epoch [21/25] Training [271/488] Loss: 0.24679
Epoch [21/25] Training [272/488] Loss: 0.12256
Epoch [21/25] Training [273/488] Loss: 0.17810
Epoch [21/25] Training [274/488] Loss: 0.15481
Epoch [21/25] Training [275/488] Loss: 0.14437
Epoch [21/25] Training [276/488] Loss: 0.22563
Epoch [21/25] Training [277/488] Loss: 0.14097
Epoch [21/25] Training [278/488] Loss: 0.24314
Epoch [21/25] Training [279/488] Loss: 0.45015
Epoch [21/25] Training [280/488] Loss: 0.13367
Epoch [21/25] Training [281/488] Loss: 0.23320
Epoch [21/25] Training [282/488] Loss: 0.22951
Epoch [21/25] Training [283/488] Loss: 0.18799
Epoch [21/25] Training [284/488] Loss: 0.71869
Epoch [21/25] Training [285/488] Loss: 0.13177
Epoch [21/25] Training [286/488] Loss: 0.14385
Epoch [21/25] Training [287/488] Loss: 0.17639
Epoch [21/25] Training [288/488] Loss: 0.56526
Epoch [21/25] Training [289/488] Loss: 0.16425
Epoch [21/25] Training [290/488] Loss: 0.13155
Epoch [21/25] Training [291/488] Loss: 0.11913
Epoch [21/25] Training [292/488] Loss: 0.17269
Epoch [21/25] Training [293/488] Loss: 0.11973
Epoch [21/25] Training [294/488] Loss: 0.19220
Epoch [21/25] Training [295/488] Loss: 0.48007
Epoch [21/25] Training [296/488] Loss: 0.19111
Epoch [21/25] Training [297/488] Loss: 0.17390
Epoch [21/25] Training [298/488] Loss: 0.17920
Epoch [21/25] Training [299/488] Loss: 0.18317
Epoch [21/25] Training [300/488] Loss: 0.14473
Epoch [21/25] Training [301/488] Loss: 0.36409
Epoch [21/25] Training [302/488] Loss: 0.28344
Epoch [21/25] Training [303/488] Loss: 0.19299
Epoch [21/25] Training [304/488] Loss: 0.13724
Epoch [21/25] Training [305/488] Loss: 0.26540
Epoch [21/25] Training [306/488] Loss: 0.13030
Epoch [21/25] Training [307/488] Loss: 0.19936
Epoch [21/25] Training [308/488] Loss: 0.51612
Epoch [21/25] Training [309/488] Loss: 0.28256
Epoch [21/25] Training [310/488] Loss: 0.39874
Epoch [21/25] Training [311/488] Loss: 0.13022
Epoch [21/25] Training [312/488] Loss: 0.29975
Epoch [21/25] Training [313/488] Loss: 0.15936
Epoch [21/25] Training [314/488] Loss: 0.14698
Epoch [21/25] Training [315/488] Loss: 0.30662
Epoch [21/25] Training [316/488] Loss: 0.19996
Epoch [21/25] Training [317/488] Loss: 0.10933
Epoch [21/25] Training [318/488] Loss: 0.24815
Epoch [21/25] Training [319/488] Loss: 0.21994
Epoch [21/25] Training [320/488] Loss: 0.33950
Epoch [21/25] Training [321/488] Loss: 0.15272
Epoch [21/25] Training [322/488] Loss: 0.18005
Epoch [21/25] Training [323/488] Loss: 0.23060
Epoch [21/25] Training [324/488] Loss: 0.34478
Epoch [21/25] Training [325/488] Loss: 0.24013
Epoch [21/25] Training [326/488] Loss: 0.18784
Epoch [21/25] Training [327/488] Loss: 0.50665
Epoch [21/25] Training [328/488] Loss: 0.32050
Epoch [21/25] Training [329/488] Loss: 0.12021
Epoch [21/25] Training [330/488] Loss: 0.22315
Epoch [21/25] Training [331/488] Loss: 0.17766
Epoch [21/25] Training [332/488] Loss: 0.25218
Epoch [21/25] Training [333/488] Loss: 0.18914
Epoch [21/25] Training [334/488] Loss: 0.26153
Epoch [21/25] Training [335/488] Loss: 0.43655
Epoch [21/25] Training [336/488] Loss: 0.34425
Epoch [21/25] Training [337/488] Loss: 0.34788
Epoch [21/25] Training [338/488] Loss: 0.70813
Epoch [21/25] Training [339/488] Loss: 0.31311
Epoch [21/25] Training [340/488] Loss: 0.14814
Epoch [21/25] Training [341/488] Loss: 0.19600
Epoch [21/25] Training [342/488] Loss: 0.19075
Epoch [21/25] Training [343/488] Loss: 0.11140
Epoch [21/25] Training [344/488] Loss: 0.12726
Epoch [21/25] Training [345/488] Loss: 0.25552
Epoch [21/25] Training [346/488] Loss: 0.30396
Epoch [21/25] Training [347/488] Loss: 0.22890
Epoch [21/25] Training [348/488] Loss: 0.24528
Epoch [21/25] Training [349/488] Loss: 0.15262
Epoch [21/25] Training [350/488] Loss: 0.33988
Epoch [21/25] Training [351/488] Loss: 0.14830
Epoch [21/25] Training [352/488] Loss: 0.16823
Epoch [21/25] Training [353/488] Loss: 0.18187
Epoch [21/25] Training [354/488] Loss: 0.18913
Epoch [21/25] Training [355/488] Loss: 0.17631
Epoch [21/25] Training [356/488] Loss: 0.14691
Epoch [21/25] Training [357/488] Loss: 0.18861
Epoch [21/25] Training [358/488] Loss: 0.12989
Epoch [21/25] Training [359/488] Loss: 0.30551
Epoch [21/25] Training [360/488] Loss: 0.18851
Epoch [21/25] Training [361/488] Loss: 0.35638
Epoch [21/25] Training [362/488] Loss: 0.12159
Epoch [21/25] Training [363/488] Loss: 0.35083
Epoch [21/25] Training [364/488] Loss: 0.12133
Epoch [21/25] Training [365/488] Loss: 0.20724
Epoch [21/25] Training [366/488] Loss: 0.13931
Epoch [21/25] Training [367/488] Loss: 0.13287
Epoch [21/25] Training [368/488] Loss: 0.13722
Epoch [21/25] Training [369/488] Loss: 0.14359
Epoch [21/25] Training [370/488] Loss: 0.13994
Epoch [21/25] Training [371/488] Loss: 0.13923
Epoch [21/25] Training [372/488] Loss: 0.16507
Epoch [21/25] Training [373/488] Loss: 0.41718
Epoch [21/25] Training [374/488] Loss: 0.30036
Epoch [21/25] Training [375/488] Loss: 0.39191
Epoch [21/25] Training [376/488] Loss: 0.15603
Epoch [21/25] Training [377/488] Loss: 0.27025
Epoch [21/25] Training [378/488] Loss: 0.14819
Epoch [21/25] Training [379/488] Loss: 0.11571
Epoch [21/25] Training [380/488] Loss: 0.13607
Epoch [21/25] Training [381/488] Loss: 0.17911
Epoch [21/25] Training [382/488] Loss: 0.12024
Epoch [21/25] Training [383/488] Loss: 0.33831
Epoch [21/25] Training [384/488] Loss: 0.21484
Epoch [21/25] Training [385/488] Loss: 0.12832
Epoch [21/25] Training [386/488] Loss: 0.29899
Epoch [21/25] Training [387/488] Loss: 0.58957
Epoch [21/25] Training [388/488] Loss: 0.19217
Epoch [21/25] Training [389/488] Loss: 0.18855
Epoch [21/25] Training [390/488] Loss: 0.36928
Epoch [21/25] Training [391/488] Loss: 0.11457
Epoch [21/25] Training [392/488] Loss: 0.14112
Epoch [21/25] Training [393/488] Loss: 0.14430
Epoch [21/25] Training [394/488] Loss: 0.19260
Epoch [21/25] Training [395/488] Loss: 0.31304
Epoch [21/25] Training [396/488] Loss: 0.49609
Epoch [21/25] Training [397/488] Loss: 0.14016
Epoch [21/25] Training [398/488] Loss: 0.20461
Epoch [21/25] Training [399/488] Loss: 0.24123
Epoch [21/25] Training [400/488] Loss: 0.54132
Epoch [21/25] Training [401/488] Loss: 0.11090
Epoch [21/25] Training [402/488] Loss: 0.20900
Epoch [21/25] Training [403/488] Loss: 0.19259
Epoch [21/25] Training [404/488] Loss: 0.16404
Epoch [21/25] Training [405/488] Loss: 0.12982
Epoch [21/25] Training [406/488] Loss: 0.43419
Epoch [21/25] Training [407/488] Loss: 0.13038
Epoch [21/25] Training [408/488] Loss: 0.14313
Epoch [21/25] Training [409/488] Loss: 0.17320
Epoch [21/25] Training [410/488] Loss: 0.14369
Epoch [21/25] Training [411/488] Loss: 0.30422
Epoch [21/25] Training [412/488] Loss: 0.19918
Epoch [21/25] Training [413/488] Loss: 0.20608
Epoch [21/25] Training [414/488] Loss: 0.14143
Epoch [21/25] Training [415/488] Loss: 0.12447
Epoch [21/25] Training [416/488] Loss: 0.14336
Epoch [21/25] Training [417/488] Loss: 0.21732
Epoch [21/25] Training [418/488] Loss: 0.11555
Epoch [21/25] Training [419/488] Loss: 0.14740
Epoch [21/25] Training [420/488] Loss: 0.13516
Epoch [21/25] Training [421/488] Loss: 0.13420
Epoch [21/25] Training [422/488] Loss: 0.23947
Epoch [21/25] Training [423/488] Loss: 0.21568
Epoch [21/25] Training [424/488] Loss: 0.22084
Epoch [21/25] Training [425/488] Loss: 0.31816
Epoch [21/25] Training [426/488] Loss: 0.17717
Epoch [21/25] Training [427/488] Loss: 0.20103
Epoch [21/25] Training [428/488] Loss: 0.15335
Epoch [21/25] Training [429/488] Loss: 0.18926
Epoch [21/25] Training [430/488] Loss: 0.26500
Epoch [21/25] Training [431/488] Loss: 0.23454
Epoch [21/25] Training [432/488] Loss: 0.12150
Epoch [21/25] Training [433/488] Loss: 0.23319
Epoch [21/25] Training [434/488] Loss: 0.27020
Epoch [21/25] Training [435/488] Loss: 0.16108
Epoch [21/25] Training [436/488] Loss: 0.15779
Epoch [21/25] Training [437/488] Loss: 0.14232
Epoch [21/25] Training [438/488] Loss: 0.14722
Epoch [21/25] Training [439/488] Loss: 0.29288
Epoch [21/25] Training [440/488] Loss: 0.54461
Epoch [21/25] Training [441/488] Loss: 0.32693
Epoch [21/25] Training [442/488] Loss: 0.24121
Epoch [21/25] Training [443/488] Loss: 0.13071
Epoch [21/25] Training [444/488] Loss: 0.13371
Epoch [21/25] Training [445/488] Loss: 0.15742
Epoch [21/25] Training [446/488] Loss: 0.14418
Epoch [21/25] Training [447/488] Loss: 0.18408
Epoch [21/25] Training [448/488] Loss: 0.23747
Epoch [21/25] Training [449/488] Loss: 0.13891
Epoch [21/25] Training [450/488] Loss: 0.13662
Epoch [21/25] Training [451/488] Loss: 0.34781
Epoch [21/25] Training [452/488] Loss: 0.33576
Epoch [21/25] Training [453/488] Loss: 0.14931
Epoch [21/25] Training [454/488] Loss: 0.41845
Epoch [21/25] Training [455/488] Loss: 0.31182
Epoch [21/25] Training [456/488] Loss: 0.13773
Epoch [21/25] Training [457/488] Loss: 0.19034
Epoch [21/25] Training [458/488] Loss: 0.20853
Epoch [21/25] Training [459/488] Loss: 0.36188
Epoch [21/25] Training [460/488] Loss: 0.13294
Epoch [21/25] Training [461/488] Loss: 0.14599
Epoch [21/25] Training [462/488] Loss: 0.12792
Epoch [21/25] Training [463/488] Loss: 0.25941
Epoch [21/25] Training [464/488] Loss: 0.24067
Epoch [21/25] Training [465/488] Loss: 0.12390
Epoch [21/25] Training [466/488] Loss: 0.22311
Epoch [21/25] Training [467/488] Loss: 0.12990
Epoch [21/25] Training [468/488] Loss: 0.20458
Epoch [21/25] Training [469/488] Loss: 0.12750
Epoch [21/25] Training [470/488] Loss: 0.19340
Epoch [21/25] Training [471/488] Loss: 0.29829
Epoch [21/25] Training [472/488] Loss: 0.17326
Epoch [21/25] Training [473/488] Loss: 0.14324
Epoch [21/25] Training [474/488] Loss: 0.18971
Epoch [21/25] Training [475/488] Loss: 0.21380
Epoch [21/25] Training [476/488] Loss: 0.25853
Epoch [21/25] Training [477/488] Loss: 0.13910
Epoch [21/25] Training [478/488] Loss: 0.10742
Epoch [21/25] Training [479/488] Loss: 0.17597
Epoch [21/25] Training [480/488] Loss: 0.23572
Epoch [21/25] Training [481/488] Loss: 0.17463
Epoch [21/25] Training [482/488] Loss: 0.34708
Epoch [21/25] Training [483/488] Loss: 0.19651
Epoch [21/25] Training [484/488] Loss: 0.44690
Epoch [21/25] Training [485/488] Loss: 0.46019
Epoch [21/25] Training [486/488] Loss: 0.21062
Epoch [21/25] Training [487/488] Loss: 0.38440
Epoch [21/25] Training [488/488] Loss: 0.17040
Epoch [21/25] Training metric {'Train/mean dice_metric': 0.8934483528137207, 'Train/TC dice_metric': 0.9171392917633057, 'Train/WT dice_metric': 0.9389784336090088, 'Train/ET dice_metric': 0.8242273926734924}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [21/25] Validation [1/123] Loss: 0.21615  focal_loss 0.00182  dice_loss 0.21433
Epoch [21/25] Validation [2/123] Loss: 0.39067  focal_loss 0.00151  dice_loss 0.38916
Epoch [21/25] Validation [3/123] Loss: 0.19855  focal_loss 0.00141  dice_loss 0.19714
Epoch [21/25] Validation [4/123] Loss: 0.28482  focal_loss 0.00148  dice_loss 0.28335
Epoch [21/25] Validation [5/123] Loss: 0.33614  focal_loss 0.01012  dice_loss 0.32603
Epoch [21/25] Validation [6/123] Loss: 0.34990  focal_loss 0.00156  dice_loss 0.34834
Epoch [21/25] Validation [7/123] Loss: 0.36498  focal_loss 0.00053  dice_loss 0.36445
Epoch [21/25] Validation [8/123] Loss: 0.36153  focal_loss 0.00139  dice_loss 0.36015
Epoch [21/25] Validation [9/123] Loss: 0.28414  focal_loss 0.00140  dice_loss 0.28275
Epoch [21/25] Validation [10/123] Loss: 0.47901  focal_loss 0.00251  dice_loss 0.47650
Epoch [21/25] Validation [11/123] Loss: 0.46624  focal_loss 0.00185  dice_loss 0.46439
Epoch [21/25] Validation [12/123] Loss: 0.22443  focal_loss 0.00120  dice_loss 0.22322
Epoch [21/25] Validation [13/123] Loss: 0.20724  focal_loss 0.00288  dice_loss 0.20436
Epoch [21/25] Validation [14/123] Loss: 0.25904  focal_loss 0.00161  dice_loss 0.25743
Epoch [21/25] Validation [15/123] Loss: 0.36827  focal_loss 0.00137  dice_loss 0.36690
Epoch [21/25] Validation [16/123] Loss: 0.46219  focal_loss 0.00175  dice_loss 0.46044
Epoch [21/25] Validation [17/123] Loss: 0.50376  focal_loss 0.00170  dice_loss 0.50206
Epoch [21/25] Validation [18/123] Loss: 0.35728  focal_loss 0.00332  dice_loss 0.35396
Epoch [21/25] Validation [19/123] Loss: 0.30073  focal_loss 0.00256  dice_loss 0.29817
Epoch [21/25] Validation [20/123] Loss: 0.46272  focal_loss 0.00071  dice_loss 0.46200
Epoch [21/25] Validation [21/123] Loss: 0.34850  focal_loss 0.00077  dice_loss 0.34772
Epoch [21/25] Validation [22/123] Loss: 0.61755  focal_loss 0.00577  dice_loss 0.61178
Epoch [21/25] Validation [23/123] Loss: 0.20832  focal_loss 0.00129  dice_loss 0.20703
Epoch [21/25] Validation [24/123] Loss: 0.30346  focal_loss 0.00209  dice_loss 0.30137
Epoch [21/25] Validation [25/123] Loss: 0.30181  focal_loss 0.00112  dice_loss 0.30070
Epoch [21/25] Validation [26/123] Loss: 0.21748  focal_loss 0.00120  dice_loss 0.21628
Epoch [21/25] Validation [27/123] Loss: 0.25350  focal_loss 0.00197  dice_loss 0.25154
Epoch [21/25] Validation [28/123] Loss: 0.48997  focal_loss 0.00283  dice_loss 0.48713
Epoch [21/25] Validation [29/123] Loss: 0.35098  focal_loss 0.00131  dice_loss 0.34967
Epoch [21/25] Validation [30/123] Loss: 0.26409  focal_loss 0.00375  dice_loss 0.26034
Epoch [21/25] Validation [31/123] Loss: 0.20822  focal_loss 0.00124  dice_loss 0.20698
Epoch [21/25] Validation [32/123] Loss: 0.31848  focal_loss 0.00320  dice_loss 0.31528
Epoch [21/25] Validation [33/123] Loss: 0.36382  focal_loss 0.00152  dice_loss 0.36230
Epoch [21/25] Validation [34/123] Loss: 0.29033  focal_loss 0.00072  dice_loss 0.28961
Epoch [21/25] Validation [35/123] Loss: 0.24342  focal_loss 0.00097  dice_loss 0.24245
Epoch [21/25] Validation [36/123] Loss: 0.27417  focal_loss 0.00077  dice_loss 0.27340
Epoch [21/25] Validation [37/123] Loss: 0.38410  focal_loss 0.00290  dice_loss 0.38120
Epoch [21/25] Validation [38/123] Loss: 0.23621  focal_loss 0.00140  dice_loss 0.23480
Epoch [21/25] Validation [39/123] Loss: 0.22030  focal_loss 0.00114  dice_loss 0.21916
Epoch [21/25] Validation [40/123] Loss: 0.32629  focal_loss 0.00078  dice_loss 0.32552
Epoch [21/25] Validation [41/123] Loss: 0.22287  focal_loss 0.00167  dice_loss 0.22120
Epoch [21/25] Validation [42/123] Loss: 0.20067  focal_loss 0.00097  dice_loss 0.19970
Epoch [21/25] Validation [43/123] Loss: 0.27675  focal_loss 0.00587  dice_loss 0.27088
Epoch [21/25] Validation [44/123] Loss: 0.50360  focal_loss 0.00342  dice_loss 0.50018
Epoch [21/25] Validation [45/123] Loss: 0.31089  focal_loss 0.00108  dice_loss 0.30981
Epoch [21/25] Validation [46/123] Loss: 0.35365  focal_loss 0.00279  dice_loss 0.35086
Epoch [21/25] Validation [47/123] Loss: 0.31311  focal_loss 0.00125  dice_loss 0.31186
Epoch [21/25] Validation [48/123] Loss: 0.43038  focal_loss 0.00434  dice_loss 0.42604
Epoch [21/25] Validation [49/123] Loss: 0.22443  focal_loss 0.00102  dice_loss 0.22340
Epoch [21/25] Validation [50/123] Loss: 0.21869  focal_loss 0.00160  dice_loss 0.21709
Epoch [21/25] Validation [51/123] Loss: 0.40909  focal_loss 0.01064  dice_loss 0.39845
Epoch [21/25] Validation [52/123] Loss: 0.24006  focal_loss 0.00076  dice_loss 0.23930
Epoch [21/25] Validation [53/123] Loss: 0.30172  focal_loss 0.00073  dice_loss 0.30099
Epoch [21/25] Validation [54/123] Loss: 0.34272  focal_loss 0.00099  dice_loss 0.34173
Epoch [21/25] Validation [55/123] Loss: 0.29972  focal_loss 0.00130  dice_loss 0.29842
Epoch [21/25] Validation [56/123] Loss: 0.23441  focal_loss 0.00168  dice_loss 0.23274
Epoch [21/25] Validation [57/123] Loss: 0.31268  focal_loss 0.00216  dice_loss 0.31052
Epoch [21/25] Validation [58/123] Loss: 0.28980  focal_loss 0.00274  dice_loss 0.28706
Epoch [21/25] Validation [59/123] Loss: 0.58927  focal_loss 0.00579  dice_loss 0.58348
Epoch [21/25] Validation [60/123] Loss: 0.26569  focal_loss 0.00252  dice_loss 0.26317
Epoch [21/25] Validation [61/123] Loss: 0.60173  focal_loss 0.00108  dice_loss 0.60065
Epoch [21/25] Validation [62/123] Loss: 0.49052  focal_loss 0.00586  dice_loss 0.48465
Epoch [21/25] Validation [63/123] Loss: 0.38750  focal_loss 0.00113  dice_loss 0.38637
Epoch [21/25] Validation [64/123] Loss: 0.39100  focal_loss 0.00646  dice_loss 0.38454
Epoch [21/25] Validation [65/123] Loss: 0.24987  focal_loss 0.00093  dice_loss 0.24894
Epoch [21/25] Validation [66/123] Loss: 0.25882  focal_loss 0.00102  dice_loss 0.25780
Epoch [21/25] Validation [67/123] Loss: 0.44468  focal_loss 0.01243  dice_loss 0.43225
Epoch [21/25] Validation [68/123] Loss: 0.37292  focal_loss 0.00087  dice_loss 0.37204
Epoch [21/25] Validation [69/123] Loss: 0.41036  focal_loss 0.00778  dice_loss 0.40259
Epoch [21/25] Validation [70/123] Loss: 0.33095  focal_loss 0.00161  dice_loss 0.32934
Epoch [21/25] Validation [71/123] Loss: 0.24138  focal_loss 0.00069  dice_loss 0.24069
Epoch [21/25] Validation [72/123] Loss: 0.22247  focal_loss 0.00129  dice_loss 0.22119
Epoch [21/25] Validation [73/123] Loss: 0.34081  focal_loss 0.00383  dice_loss 0.33698
Epoch [21/25] Validation [74/123] Loss: 0.34218  focal_loss 0.00338  dice_loss 0.33880
Epoch [21/25] Validation [75/123] Loss: 0.27982  focal_loss 0.00128  dice_loss 0.27854
Epoch [21/25] Validation [76/123] Loss: 0.50928  focal_loss 0.00507  dice_loss 0.50421
Epoch [21/25] Validation [77/123] Loss: 0.37878  focal_loss 0.00090  dice_loss 0.37788
Epoch [21/25] Validation [78/123] Loss: 0.28588  focal_loss 0.00139  dice_loss 0.28449
Epoch [21/25] Validation [79/123] Loss: 0.33130  focal_loss 0.00131  dice_loss 0.32998
Epoch [21/25] Validation [80/123] Loss: 0.23549  focal_loss 0.00224  dice_loss 0.23325
Epoch [21/25] Validation [81/123] Loss: 0.27480  focal_loss 0.00166  dice_loss 0.27314
Epoch [21/25] Validation [82/123] Loss: 0.22793  focal_loss 0.00085  dice_loss 0.22708
Epoch [21/25] Validation [83/123] Loss: 0.36529  focal_loss 0.00816  dice_loss 0.35713
Epoch [21/25] Validation [84/123] Loss: 0.27361  focal_loss 0.00111  dice_loss 0.27250
Epoch [21/25] Validation [85/123] Loss: 0.35959  focal_loss 0.00530  dice_loss 0.35429
Epoch [21/25] Validation [86/123] Loss: 0.24579  focal_loss 0.00118  dice_loss 0.24461
Epoch [21/25] Validation [87/123] Loss: 0.22892  focal_loss 0.00244  dice_loss 0.22648
Epoch [21/25] Validation [88/123] Loss: 0.26151  focal_loss 0.00173  dice_loss 0.25978
Epoch [21/25] Validation [89/123] Loss: 0.21055  focal_loss 0.00171  dice_loss 0.20884
Epoch [21/25] Validation [90/123] Loss: 0.31663  focal_loss 0.00183  dice_loss 0.31479
Epoch [21/25] Validation [91/123] Loss: 0.24624  focal_loss 0.00090  dice_loss 0.24535
Epoch [21/25] Validation [92/123] Loss: 0.20733  focal_loss 0.00110  dice_loss 0.20623
Epoch [21/25] Validation [93/123] Loss: 0.22857  focal_loss 0.00135  dice_loss 0.22722
Epoch [21/25] Validation [94/123] Loss: 0.35361  focal_loss 0.00158  dice_loss 0.35204
Epoch [21/25] Validation [95/123] Loss: 0.26805  focal_loss 0.00234  dice_loss 0.26572
Epoch [21/25] Validation [96/123] Loss: 0.34234  focal_loss 0.00149  dice_loss 0.34085
Epoch [21/25] Validation [97/123] Loss: 0.60795  focal_loss 0.00778  dice_loss 0.60016
Epoch [21/25] Validation [98/123] Loss: 0.33333  focal_loss 0.00104  dice_loss 0.33229
Epoch [21/25] Validation [99/123] Loss: 0.33083  focal_loss 0.00058  dice_loss 0.33025
Epoch [21/25] Validation [100/123] Loss: 0.36035  focal_loss 0.00109  dice_loss 0.35927
Epoch [21/25] Validation [101/123] Loss: 0.31107  focal_loss 0.00128  dice_loss 0.30979
Epoch [21/25] Validation [102/123] Loss: 0.34853  focal_loss 0.00062  dice_loss 0.34792
Epoch [21/25] Validation [103/123] Loss: 0.49633  focal_loss 0.00100  dice_loss 0.49533
Epoch [21/25] Validation [104/123] Loss: 0.42474  focal_loss 0.00459  dice_loss 0.42015
Epoch [21/25] Validation [105/123] Loss: 0.21249  focal_loss 0.00262  dice_loss 0.20986
Epoch [21/25] Validation [106/123] Loss: 0.25150  focal_loss 0.00088  dice_loss 0.25062
Epoch [21/25] Validation [107/123] Loss: 0.56170  focal_loss 0.00459  dice_loss 0.55711
Epoch [21/25] Validation [108/123] Loss: 0.24224  focal_loss 0.00055  dice_loss 0.24169
Epoch [21/25] Validation [109/123] Loss: 0.22146  focal_loss 0.00428  dice_loss 0.21718
Epoch [21/25] Validation [110/123] Loss: 0.38019  focal_loss 0.00341  dice_loss 0.37678
Epoch [21/25] Validation [111/123] Loss: 0.38957  focal_loss 0.00319  dice_loss 0.38637
Epoch [21/25] Validation [112/123] Loss: 0.32732  focal_loss 0.00066  dice_loss 0.32666
Epoch [21/25] Validation [113/123] Loss: 0.30043  focal_loss 0.00197  dice_loss 0.29847
Epoch [21/25] Validation [114/123] Loss: 0.34681  focal_loss 0.00449  dice_loss 0.34232
Epoch [21/25] Validation [115/123] Loss: 0.28951  focal_loss 0.00504  dice_loss 0.28447
Epoch [21/25] Validation [116/123] Loss: 0.27856  focal_loss 0.00053  dice_loss 0.27802
Epoch [21/25] Validation [117/123] Loss: 0.28649  focal_loss 0.00104  dice_loss 0.28545
Epoch [21/25] Validation [118/123] Loss: 0.19240  focal_loss 0.00154  dice_loss 0.19086
Epoch [21/25] Validation [119/123] Loss: 0.22236  focal_loss 0.00109  dice_loss 0.22127
Epoch [21/25] Validation [120/123] Loss: 0.25388  focal_loss 0.00177  dice_loss 0.25211
Epoch [21/25] Validation [121/123] Loss: 0.61807  focal_loss 0.01282  dice_loss 0.60524
Epoch [21/25] Validation [122/123] Loss: 0.57867  focal_loss 0.00040  dice_loss 0.57827
Epoch [21/25] Validation [123/123] Loss: 0.24869  focal_loss 0.00132  dice_loss 0.24737
Epoch [21/25] Validation metric {'Val/mean dice_metric': 0.8924590349197388, 'Val/TC dice_metric': 0.9146407842636108, 'Val/WT dice_metric': 0.937807023525238, 'Val/ET dice_metric': 0.8249291777610779}
Epoch [21/25] lr = [0.00014644660940672628, 0.00014644660940672628] best acc: tensor([0.8889], device='cuda:0'), mean acc: tensor([0.8925], device='cuda:0'), mean class: tensor([0.9146, 0.9378, 0.8249], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [22/25] Training [1/488] Loss: 0.11404
Epoch [22/25] Training [2/488] Loss: 0.26111
Epoch [22/25] Training [3/488] Loss: 0.17815
Epoch [22/25] Training [4/488] Loss: 0.13501
Epoch [22/25] Training [5/488] Loss: 0.14792
Epoch [22/25] Training [6/488] Loss: 0.72268
Epoch [22/25] Training [7/488] Loss: 0.17584
Epoch [22/25] Training [8/488] Loss: 0.35488
Epoch [22/25] Training [9/488] Loss: 0.16830
Epoch [22/25] Training [10/488] Loss: 0.14644
Epoch [22/25] Training [11/488] Loss: 0.15287
Epoch [22/25] Training [12/488] Loss: 0.28695
Epoch [22/25] Training [13/488] Loss: 0.31893
Epoch [22/25] Training [14/488] Loss: 0.33850
Epoch [22/25] Training [15/488] Loss: 0.35663
Epoch [22/25] Training [16/488] Loss: 0.40745
Epoch [22/25] Training [17/488] Loss: 0.12636
Epoch [22/25] Training [18/488] Loss: 0.20440
Epoch [22/25] Training [19/488] Loss: 0.14130
Epoch [22/25] Training [20/488] Loss: 0.30092
Epoch [22/25] Training [21/488] Loss: 0.32425
Epoch [22/25] Training [22/488] Loss: 0.19590
Epoch [22/25] Training [23/488] Loss: 0.13400
Epoch [22/25] Training [24/488] Loss: 0.11848
Epoch [22/25] Training [25/488] Loss: 0.35483
Epoch [22/25] Training [26/488] Loss: 0.14157
Epoch [22/25] Training [27/488] Loss: 0.13482
Epoch [22/25] Training [28/488] Loss: 0.36560
Epoch [22/25] Training [29/488] Loss: 0.23539
Epoch [22/25] Training [30/488] Loss: 0.21917
Epoch [22/25] Training [31/488] Loss: 0.14962
Epoch [22/25] Training [32/488] Loss: 0.25492
Epoch [22/25] Training [33/488] Loss: 0.40506
Epoch [22/25] Training [34/488] Loss: 0.64549
Epoch [22/25] Training [35/488] Loss: 0.14349
Epoch [22/25] Training [36/488] Loss: 0.11566
Epoch [22/25] Training [37/488] Loss: 0.23157
Epoch [22/25] Training [38/488] Loss: 0.22372
Epoch [22/25] Training [39/488] Loss: 0.18457
Epoch [22/25] Training [40/488] Loss: 0.19984
Epoch [22/25] Training [41/488] Loss: 0.17084
Epoch [22/25] Training [42/488] Loss: 0.21950
Epoch [22/25] Training [43/488] Loss: 0.58175
Epoch [22/25] Training [44/488] Loss: 0.43313
Epoch [22/25] Training [45/488] Loss: 0.29883
Epoch [22/25] Training [46/488] Loss: 0.26072
Epoch [22/25] Training [47/488] Loss: 0.26798
Epoch [22/25] Training [48/488] Loss: 0.15494
Epoch [22/25] Training [49/488] Loss: 0.28915
Epoch [22/25] Training [50/488] Loss: 0.20941
Epoch [22/25] Training [51/488] Loss: 0.16184
Epoch [22/25] Training [52/488] Loss: 0.18708
Epoch [22/25] Training [53/488] Loss: 0.34432
Epoch [22/25] Training [54/488] Loss: 0.16012
Epoch [22/25] Training [55/488] Loss: 0.22752
Epoch [22/25] Training [56/488] Loss: 0.15067
Epoch [22/25] Training [57/488] Loss: 0.30195
Epoch [22/25] Training [58/488] Loss: 0.16421
Epoch [22/25] Training [59/488] Loss: 0.21097
Epoch [22/25] Training [60/488] Loss: 0.24097
Epoch [22/25] Training [61/488] Loss: 0.15075
Epoch [22/25] Training [62/488] Loss: 0.15357
Epoch [22/25] Training [63/488] Loss: 0.20172
Epoch [22/25] Training [64/488] Loss: 0.18349
Epoch [22/25] Training [65/488] Loss: 0.70747
Epoch [22/25] Training [66/488] Loss: 0.20666
Epoch [22/25] Training [67/488] Loss: 0.14286
Epoch [22/25] Training [68/488] Loss: 0.31698
Epoch [22/25] Training [69/488] Loss: 0.15690
Epoch [22/25] Training [70/488] Loss: 0.52693
Epoch [22/25] Training [71/488] Loss: 0.37974
Epoch [22/25] Training [72/488] Loss: 0.40483
Epoch [22/25] Training [73/488] Loss: 0.12162
Epoch [22/25] Training [74/488] Loss: 0.12616
Epoch [22/25] Training [75/488] Loss: 0.20392
Epoch [22/25] Training [76/488] Loss: 0.15565
Epoch [22/25] Training [77/488] Loss: 0.19503
Epoch [22/25] Training [78/488] Loss: 0.41360
Epoch [22/25] Training [79/488] Loss: 0.12864
Epoch [22/25] Training [80/488] Loss: 0.20258
Epoch [22/25] Training [81/488] Loss: 0.12493
Epoch [22/25] Training [82/488] Loss: 0.19013
Epoch [22/25] Training [83/488] Loss: 0.15771
Epoch [22/25] Training [84/488] Loss: 0.24099
Epoch [22/25] Training [85/488] Loss: 0.12547
Epoch [22/25] Training [86/488] Loss: 0.15792
Epoch [22/25] Training [87/488] Loss: 0.47067
Epoch [22/25] Training [88/488] Loss: 0.15526
Epoch [22/25] Training [89/488] Loss: 0.24834
Epoch [22/25] Training [90/488] Loss: 0.22574
Epoch [22/25] Training [91/488] Loss: 0.12534
Epoch [22/25] Training [92/488] Loss: 0.17326
Epoch [22/25] Training [93/488] Loss: 0.14217
Epoch [22/25] Training [94/488] Loss: 0.10780
Epoch [22/25] Training [95/488] Loss: 0.21798
Epoch [22/25] Training [96/488] Loss: 0.29494
Epoch [22/25] Training [97/488] Loss: 0.15147
Epoch [22/25] Training [98/488] Loss: 0.31980
Epoch [22/25] Training [99/488] Loss: 0.13054
Epoch [22/25] Training [100/488] Loss: 0.17604
Epoch [22/25] Training [101/488] Loss: 0.13728
Epoch [22/25] Training [102/488] Loss: 0.21352
Epoch [22/25] Training [103/488] Loss: 0.15462
Epoch [22/25] Training [104/488] Loss: 0.18602
Epoch [22/25] Training [105/488] Loss: 0.14683
Epoch [22/25] Training [106/488] Loss: 0.15126
Epoch [22/25] Training [107/488] Loss: 0.17808
Epoch [22/25] Training [108/488] Loss: 0.40883
Epoch [22/25] Training [109/488] Loss: 0.23817
Epoch [22/25] Training [110/488] Loss: 0.11226
Epoch [22/25] Training [111/488] Loss: 0.13306
Epoch [22/25] Training [112/488] Loss: 0.45356
Epoch [22/25] Training [113/488] Loss: 0.13993
Epoch [22/25] Training [114/488] Loss: 0.49187
Epoch [22/25] Training [115/488] Loss: 0.17420
Epoch [22/25] Training [116/488] Loss: 0.20214
Epoch [22/25] Training [117/488] Loss: 0.24882
Epoch [22/25] Training [118/488] Loss: 0.25080
Epoch [22/25] Training [119/488] Loss: 0.12105
Epoch [22/25] Training [120/488] Loss: 0.19834
Epoch [22/25] Training [121/488] Loss: 0.18250
Epoch [22/25] Training [122/488] Loss: 0.12772
Epoch [22/25] Training [123/488] Loss: 0.25698
Epoch [22/25] Training [124/488] Loss: 0.15578
Epoch [22/25] Training [125/488] Loss: 0.19700
Epoch [22/25] Training [126/488] Loss: 0.61463
Epoch [22/25] Training [127/488] Loss: 0.31541
Epoch [22/25] Training [128/488] Loss: 0.13906
Epoch [22/25] Training [129/488] Loss: 0.12988
Epoch [22/25] Training [130/488] Loss: 0.16343
Epoch [22/25] Training [131/488] Loss: 0.15515
Epoch [22/25] Training [132/488] Loss: 0.18398
Epoch [22/25] Training [133/488] Loss: 0.24630
Epoch [22/25] Training [134/488] Loss: 0.23836
Epoch [22/25] Training [135/488] Loss: 0.17403
Epoch [22/25] Training [136/488] Loss: 0.10379
Epoch [22/25] Training [137/488] Loss: 0.17460
Epoch [22/25] Training [138/488] Loss: 0.19148
Epoch [22/25] Training [139/488] Loss: 0.14103
Epoch [22/25] Training [140/488] Loss: 0.24768
Epoch [22/25] Training [141/488] Loss: 0.31442
Epoch [22/25] Training [142/488] Loss: 0.19517
Epoch [22/25] Training [143/488] Loss: 0.23560
Epoch [22/25] Training [144/488] Loss: 0.14375
Epoch [22/25] Training [145/488] Loss: 0.22904
Epoch [22/25] Training [146/488] Loss: 0.14021
Epoch [22/25] Training [147/488] Loss: 0.40854
Epoch [22/25] Training [148/488] Loss: 0.11209
Epoch [22/25] Training [149/488] Loss: 0.35329
Epoch [22/25] Training [150/488] Loss: 0.17152
Epoch [22/25] Training [151/488] Loss: 0.29627
Epoch [22/25] Training [152/488] Loss: 0.13665
Epoch [22/25] Training [153/488] Loss: 0.17928
Epoch [22/25] Training [154/488] Loss: 0.10876
Epoch [22/25] Training [155/488] Loss: 0.21191
Epoch [22/25] Training [156/488] Loss: 0.59216
Epoch [22/25] Training [157/488] Loss: 0.17412
Epoch [22/25] Training [158/488] Loss: 0.33911
Epoch [22/25] Training [159/488] Loss: 0.13024
Epoch [22/25] Training [160/488] Loss: 0.49201
Epoch [22/25] Training [161/488] Loss: 0.15993
Epoch [22/25] Training [162/488] Loss: 0.19000
Epoch [22/25] Training [163/488] Loss: 0.17291
Epoch [22/25] Training [164/488] Loss: 0.19907
Epoch [22/25] Training [165/488] Loss: 0.35554
Epoch [22/25] Training [166/488] Loss: 0.16533
Epoch [22/25] Training [167/488] Loss: 0.20617
Epoch [22/25] Training [168/488] Loss: 0.30407
Epoch [22/25] Training [169/488] Loss: 0.13607
Epoch [22/25] Training [170/488] Loss: 0.12133
Epoch [22/25] Training [171/488] Loss: 0.16215
Epoch [22/25] Training [172/488] Loss: 0.14818
Epoch [22/25] Training [173/488] Loss: 0.13493
Epoch [22/25] Training [174/488] Loss: 0.42819
Epoch [22/25] Training [175/488] Loss: 0.12832
Epoch [22/25] Training [176/488] Loss: 0.21106
Epoch [22/25] Training [177/488] Loss: 0.38715
Epoch [22/25] Training [178/488] Loss: 0.17258
Epoch [22/25] Training [179/488] Loss: 0.15217
Epoch [22/25] Training [180/488] Loss: 0.11743
Epoch [22/25] Training [181/488] Loss: 0.16953
Epoch [22/25] Training [182/488] Loss: 0.16901
Epoch [22/25] Training [183/488] Loss: 0.41596
Epoch [22/25] Training [184/488] Loss: 0.15656
Epoch [22/25] Training [185/488] Loss: 0.14188
Epoch [22/25] Training [186/488] Loss: 0.17672
Epoch [22/25] Training [187/488] Loss: 0.18738
Epoch [22/25] Training [188/488] Loss: 0.21207
Epoch [22/25] Training [189/488] Loss: 0.17138
Epoch [22/25] Training [190/488] Loss: 0.15308
Epoch [22/25] Training [191/488] Loss: 0.21692
Epoch [22/25] Training [192/488] Loss: 0.30569
Epoch [22/25] Training [193/488] Loss: 0.39784
Epoch [22/25] Training [194/488] Loss: 0.19116
Epoch [22/25] Training [195/488] Loss: 0.15546
Epoch [22/25] Training [196/488] Loss: 0.15097
Epoch [22/25] Training [197/488] Loss: 0.18347
Epoch [22/25] Training [198/488] Loss: 0.20811
Epoch [22/25] Training [199/488] Loss: 0.16835
Epoch [22/25] Training [200/488] Loss: 0.14043
Epoch [22/25] Training [201/488] Loss: 0.14660
Epoch [22/25] Training [202/488] Loss: 0.14398
Epoch [22/25] Training [203/488] Loss: 0.20163
Epoch [22/25] Training [204/488] Loss: 0.21885
Epoch [22/25] Training [205/488] Loss: 0.18079
Epoch [22/25] Training [206/488] Loss: 0.30335
Epoch [22/25] Training [207/488] Loss: 0.26062
Epoch [22/25] Training [208/488] Loss: 0.18823
Epoch [22/25] Training [209/488] Loss: 0.30613
Epoch [22/25] Training [210/488] Loss: 0.18075
Epoch [22/25] Training [211/488] Loss: 0.27841
Epoch [22/25] Training [212/488] Loss: 0.69084
Epoch [22/25] Training [213/488] Loss: 0.15324
Epoch [22/25] Training [214/488] Loss: 0.40801
Epoch [22/25] Training [215/488] Loss: 0.11544
Epoch [22/25] Training [216/488] Loss: 0.23210
Epoch [22/25] Training [217/488] Loss: 0.13256
Epoch [22/25] Training [218/488] Loss: 0.14363
Epoch [22/25] Training [219/488] Loss: 0.16326
Epoch [22/25] Training [220/488] Loss: 0.48906
Epoch [22/25] Training [221/488] Loss: 0.18534
Epoch [22/25] Training [222/488] Loss: 0.13790
Epoch [22/25] Training [223/488] Loss: 0.33970
Epoch [22/25] Training [224/488] Loss: 0.11205
Epoch [22/25] Training [225/488] Loss: 0.14281
Epoch [22/25] Training [226/488] Loss: 0.13185
Epoch [22/25] Training [227/488] Loss: 0.20768
Epoch [22/25] Training [228/488] Loss: 0.15678
Epoch [22/25] Training [229/488] Loss: 0.13551
Epoch [22/25] Training [230/488] Loss: 0.15547
Epoch [22/25] Training [231/488] Loss: 0.13833
Epoch [22/25] Training [232/488] Loss: 0.19084
Epoch [22/25] Training [233/488] Loss: 0.17569
Epoch [22/25] Training [234/488] Loss: 0.16404
Epoch [22/25] Training [235/488] Loss: 0.14211
Epoch [22/25] Training [236/488] Loss: 0.16705
Epoch [22/25] Training [237/488] Loss: 0.16563
Epoch [22/25] Training [238/488] Loss: 0.14124
Epoch [22/25] Training [239/488] Loss: 0.17161
Epoch [22/25] Training [240/488] Loss: 0.15394
Epoch [22/25] Training [241/488] Loss: 0.14813
Epoch [22/25] Training [242/488] Loss: 0.13835
Epoch [22/25] Training [243/488] Loss: 0.18710
Epoch [22/25] Training [244/488] Loss: 0.13864
Epoch [22/25] Training [245/488] Loss: 0.14592
Epoch [22/25] Training [246/488] Loss: 0.35427
Epoch [22/25] Training [247/488] Loss: 0.20198
Epoch [22/25] Training [248/488] Loss: 0.18403
Epoch [22/25] Training [249/488] Loss: 0.13215
Epoch [22/25] Training [250/488] Loss: 0.30052
Epoch [22/25] Training [251/488] Loss: 0.39492
Epoch [22/25] Training [252/488] Loss: 0.16347
Epoch [22/25] Training [253/488] Loss: 0.13165
Epoch [22/25] Training [254/488] Loss: 0.15533
Epoch [22/25] Training [255/488] Loss: 0.11071
Epoch [22/25] Training [256/488] Loss: 0.24517
Epoch [22/25] Training [257/488] Loss: 0.14977
Epoch [22/25] Training [258/488] Loss: 0.14049
Epoch [22/25] Training [259/488] Loss: 0.12832
Epoch [22/25] Training [260/488] Loss: 0.17990
Epoch [22/25] Training [261/488] Loss: 0.12105
Epoch [22/25] Training [262/488] Loss: 0.18185
Epoch [22/25] Training [263/488] Loss: 0.24451
Epoch [22/25] Training [264/488] Loss: 0.22069
Epoch [22/25] Training [265/488] Loss: 0.11378
Epoch [22/25] Training [266/488] Loss: 0.33129
Epoch [22/25] Training [267/488] Loss: 0.16845
Epoch [22/25] Training [268/488] Loss: 0.24608
Epoch [22/25] Training [269/488] Loss: 0.13398
Epoch [22/25] Training [270/488] Loss: 0.24024
Epoch [22/25] Training [271/488] Loss: 0.31484
Epoch [22/25] Training [272/488] Loss: 0.24029
Epoch [22/25] Training [273/488] Loss: 0.13083
Epoch [22/25] Training [274/488] Loss: 0.33596
Epoch [22/25] Training [275/488] Loss: 0.11887
Epoch [22/25] Training [276/488] Loss: 0.19721
Epoch [22/25] Training [277/488] Loss: 0.14151
Epoch [22/25] Training [278/488] Loss: 0.17713
Epoch [22/25] Training [279/488] Loss: 0.21605
Epoch [22/25] Training [280/488] Loss: 0.28986
Epoch [22/25] Training [281/488] Loss: 0.20508
Epoch [22/25] Training [282/488] Loss: 0.20657
Epoch [22/25] Training [283/488] Loss: 0.13180
Epoch [22/25] Training [284/488] Loss: 0.15580
Epoch [22/25] Training [285/488] Loss: 0.38359
Epoch [22/25] Training [286/488] Loss: 0.13758
Epoch [22/25] Training [287/488] Loss: 0.16442
Epoch [22/25] Training [288/488] Loss: 0.11306
Epoch [22/25] Training [289/488] Loss: 0.14769
Epoch [22/25] Training [290/488] Loss: 0.19516
Epoch [22/25] Training [291/488] Loss: 0.37790
Epoch [22/25] Training [292/488] Loss: 0.15919
Epoch [22/25] Training [293/488] Loss: 0.21830
Epoch [22/25] Training [294/488] Loss: 0.16879
Epoch [22/25] Training [295/488] Loss: 0.14023
Epoch [22/25] Training [296/488] Loss: 0.14694
Epoch [22/25] Training [297/488] Loss: 0.18012
Epoch [22/25] Training [298/488] Loss: 0.25333
Epoch [22/25] Training [299/488] Loss: 0.14499
Epoch [22/25] Training [300/488] Loss: 0.28964
Epoch [22/25] Training [301/488] Loss: 0.12919
Epoch [22/25] Training [302/488] Loss: 0.24112
Epoch [22/25] Training [303/488] Loss: 0.13430
Epoch [22/25] Training [304/488] Loss: 0.17694
Epoch [22/25] Training [305/488] Loss: 0.26149
Epoch [22/25] Training [306/488] Loss: 0.29295
Epoch [22/25] Training [307/488] Loss: 0.13663
Epoch [22/25] Training [308/488] Loss: 0.15139
Epoch [22/25] Training [309/488] Loss: 0.24918
Epoch [22/25] Training [310/488] Loss: 0.13918
Epoch [22/25] Training [311/488] Loss: 0.19201
Epoch [22/25] Training [312/488] Loss: 0.47361
Epoch [22/25] Training [313/488] Loss: 0.21804
Epoch [22/25] Training [314/488] Loss: 0.16040
Epoch [22/25] Training [315/488] Loss: 0.50912
Epoch [22/25] Training [316/488] Loss: 0.19310
Epoch [22/25] Training [317/488] Loss: 0.18271
Epoch [22/25] Training [318/488] Loss: 0.32141
Epoch [22/25] Training [319/488] Loss: 0.11551
Epoch [22/25] Training [320/488] Loss: 0.12966
Epoch [22/25] Training [321/488] Loss: 0.11394
Epoch [22/25] Training [322/488] Loss: 0.22093
Epoch [22/25] Training [323/488] Loss: 0.11813
Epoch [22/25] Training [324/488] Loss: 0.24325
Epoch [22/25] Training [325/488] Loss: 0.15745
Epoch [22/25] Training [326/488] Loss: 0.20235
Epoch [22/25] Training [327/488] Loss: 0.32184
Epoch [22/25] Training [328/488] Loss: 0.16264
Epoch [22/25] Training [329/488] Loss: 0.23438
Epoch [22/25] Training [330/488] Loss: 0.32671
Epoch [22/25] Training [331/488] Loss: 0.15547
Epoch [22/25] Training [332/488] Loss: 0.15475
Epoch [22/25] Training [333/488] Loss: 0.31666
Epoch [22/25] Training [334/488] Loss: 0.33708
Epoch [22/25] Training [335/488] Loss: 0.15528
Epoch [22/25] Training [336/488] Loss: 0.30392
Epoch [22/25] Training [337/488] Loss: 0.49205
Epoch [22/25] Training [338/488] Loss: 0.12587
Epoch [22/25] Training [339/488] Loss: 0.33755
Epoch [22/25] Training [340/488] Loss: 0.10280
Epoch [22/25] Training [341/488] Loss: 0.12293
Epoch [22/25] Training [342/488] Loss: 0.10613
Epoch [22/25] Training [343/488] Loss: 0.45899
Epoch [22/25] Training [344/488] Loss: 0.28585
Epoch [22/25] Training [345/488] Loss: 0.34679
Epoch [22/25] Training [346/488] Loss: 0.14537
Epoch [22/25] Training [347/488] Loss: 0.21518
Epoch [22/25] Training [348/488] Loss: 0.25372
Epoch [22/25] Training [349/488] Loss: 0.18781
Epoch [22/25] Training [350/488] Loss: 0.15115
Epoch [22/25] Training [351/488] Loss: 0.12518
Epoch [22/25] Training [352/488] Loss: 0.11124
Epoch [22/25] Training [353/488] Loss: 0.20231
Epoch [22/25] Training [354/488] Loss: 0.20304
Epoch [22/25] Training [355/488] Loss: 0.17978
Epoch [22/25] Training [356/488] Loss: 0.20896
Epoch [22/25] Training [357/488] Loss: 0.29473
Epoch [22/25] Training [358/488] Loss: 0.17229
Epoch [22/25] Training [359/488] Loss: 0.13758
Epoch [22/25] Training [360/488] Loss: 0.14469
Epoch [22/25] Training [361/488] Loss: 0.40120
Epoch [22/25] Training [362/488] Loss: 0.28258
Epoch [22/25] Training [363/488] Loss: 0.25530
Epoch [22/25] Training [364/488] Loss: 0.16248
Epoch [22/25] Training [365/488] Loss: 0.11717
Epoch [22/25] Training [366/488] Loss: 0.12976
Epoch [22/25] Training [367/488] Loss: 0.42305
Epoch [22/25] Training [368/488] Loss: 0.11801
Epoch [22/25] Training [369/488] Loss: 0.12942
Epoch [22/25] Training [370/488] Loss: 0.39534
Epoch [22/25] Training [371/488] Loss: 0.24243
Epoch [22/25] Training [372/488] Loss: 0.18744
Epoch [22/25] Training [373/488] Loss: 0.31183
Epoch [22/25] Training [374/488] Loss: 0.30235
Epoch [22/25] Training [375/488] Loss: 0.22645
Epoch [22/25] Training [376/488] Loss: 0.11611
Epoch [22/25] Training [377/488] Loss: 0.11246
Epoch [22/25] Training [378/488] Loss: 0.24732
Epoch [22/25] Training [379/488] Loss: 0.14169
Epoch [22/25] Training [380/488] Loss: 0.14548
Epoch [22/25] Training [381/488] Loss: 0.13921
Epoch [22/25] Training [382/488] Loss: 0.14039
Epoch [22/25] Training [383/488] Loss: 0.16508
Epoch [22/25] Training [384/488] Loss: 0.24609
Epoch [22/25] Training [385/488] Loss: 0.14813
Epoch [22/25] Training [386/488] Loss: 0.15193
Epoch [22/25] Training [387/488] Loss: 0.12528
Epoch [22/25] Training [388/488] Loss: 0.13672
Epoch [22/25] Training [389/488] Loss: 0.18527
Epoch [22/25] Training [390/488] Loss: 0.22220
Epoch [22/25] Training [391/488] Loss: 0.12197
Epoch [22/25] Training [392/488] Loss: 0.31618
Epoch [22/25] Training [393/488] Loss: 0.13395
Epoch [22/25] Training [394/488] Loss: 0.22169
Epoch [22/25] Training [395/488] Loss: 0.62399
Epoch [22/25] Training [396/488] Loss: 0.14210
Epoch [22/25] Training [397/488] Loss: 0.16847
Epoch [22/25] Training [398/488] Loss: 0.23089
Epoch [22/25] Training [399/488] Loss: 0.13557
Epoch [22/25] Training [400/488] Loss: 0.16811
Epoch [22/25] Training [401/488] Loss: 0.16218
Epoch [22/25] Training [402/488] Loss: 0.17508
Epoch [22/25] Training [403/488] Loss: 0.15132
Epoch [22/25] Training [404/488] Loss: 0.24223
Epoch [22/25] Training [405/488] Loss: 0.23579
Epoch [22/25] Training [406/488] Loss: 0.27107
Epoch [22/25] Training [407/488] Loss: 0.21241
Epoch [22/25] Training [408/488] Loss: 0.22341
Epoch [22/25] Training [409/488] Loss: 0.25255
Epoch [22/25] Training [410/488] Loss: 0.30892
Epoch [22/25] Training [411/488] Loss: 0.13856
Epoch [22/25] Training [412/488] Loss: 0.13181
Epoch [22/25] Training [413/488] Loss: 0.11442
Epoch [22/25] Training [414/488] Loss: 0.18153
Epoch [22/25] Training [415/488] Loss: 0.13019
Epoch [22/25] Training [416/488] Loss: 0.44115
Epoch [22/25] Training [417/488] Loss: 0.27619
Epoch [22/25] Training [418/488] Loss: 0.18411
Epoch [22/25] Training [419/488] Loss: 0.15563
Epoch [22/25] Training [420/488] Loss: 0.19611
Epoch [22/25] Training [421/488] Loss: 0.14180
Epoch [22/25] Training [422/488] Loss: 0.25699
Epoch [22/25] Training [423/488] Loss: 0.12060
Epoch [22/25] Training [424/488] Loss: 0.24479
Epoch [22/25] Training [425/488] Loss: 0.19908
Epoch [22/25] Training [426/488] Loss: 0.19200
Epoch [22/25] Training [427/488] Loss: 0.21836
Epoch [22/25] Training [428/488] Loss: 0.12728
Epoch [22/25] Training [429/488] Loss: 0.71264
Epoch [22/25] Training [430/488] Loss: 0.10083
Epoch [22/25] Training [431/488] Loss: 0.20039
Epoch [22/25] Training [432/488] Loss: 0.38988
Epoch [22/25] Training [433/488] Loss: 0.11933
Epoch [22/25] Training [434/488] Loss: 0.12809
Epoch [22/25] Training [435/488] Loss: 0.20046
Epoch [22/25] Training [436/488] Loss: 0.51198
Epoch [22/25] Training [437/488] Loss: 0.36838
Epoch [22/25] Training [438/488] Loss: 0.37802
Epoch [22/25] Training [439/488] Loss: 0.29362
Epoch [22/25] Training [440/488] Loss: 0.53220
Epoch [22/25] Training [441/488] Loss: 0.39168
Epoch [22/25] Training [442/488] Loss: 0.14408
Epoch [22/25] Training [443/488] Loss: 0.22990
Epoch [22/25] Training [444/488] Loss: 0.30764
Epoch [22/25] Training [445/488] Loss: 0.12181
Epoch [22/25] Training [446/488] Loss: 0.13014
Epoch [22/25] Training [447/488] Loss: 0.33145
Epoch [22/25] Training [448/488] Loss: 0.14433
Epoch [22/25] Training [449/488] Loss: 0.30787
Epoch [22/25] Training [450/488] Loss: 0.21550
Epoch [22/25] Training [451/488] Loss: 0.23799
Epoch [22/25] Training [452/488] Loss: 0.29374
Epoch [22/25] Training [453/488] Loss: 0.20396
Epoch [22/25] Training [454/488] Loss: 0.26392
Epoch [22/25] Training [455/488] Loss: 0.15753
Epoch [22/25] Training [456/488] Loss: 0.20721
Epoch [22/25] Training [457/488] Loss: 0.14241
Epoch [22/25] Training [458/488] Loss: 0.14071
Epoch [22/25] Training [459/488] Loss: 0.12577
Epoch [22/25] Training [460/488] Loss: 0.35015
Epoch [22/25] Training [461/488] Loss: 0.26607
Epoch [22/25] Training [462/488] Loss: 0.23041
Epoch [22/25] Training [463/488] Loss: 0.12810
Epoch [22/25] Training [464/488] Loss: 0.21583
Epoch [22/25] Training [465/488] Loss: 0.24481
Epoch [22/25] Training [466/488] Loss: 0.12857
Epoch [22/25] Training [467/488] Loss: 0.13436
Epoch [22/25] Training [468/488] Loss: 0.12711
Epoch [22/25] Training [469/488] Loss: 0.18305
Epoch [22/25] Training [470/488] Loss: 0.12193
Epoch [22/25] Training [471/488] Loss: 0.14748
Epoch [22/25] Training [472/488] Loss: 0.15058
Epoch [22/25] Training [473/488] Loss: 0.23034
Epoch [22/25] Training [474/488] Loss: 0.17373
Epoch [22/25] Training [475/488] Loss: 0.15551
Epoch [22/25] Training [476/488] Loss: 0.16621
Epoch [22/25] Training [477/488] Loss: 0.11862
Epoch [22/25] Training [478/488] Loss: 0.45827
Epoch [22/25] Training [479/488] Loss: 0.11108
Epoch [22/25] Training [480/488] Loss: 0.17246
Epoch [22/25] Training [481/488] Loss: 0.24209
Epoch [22/25] Training [482/488] Loss: 0.14101
Epoch [22/25] Training [483/488] Loss: 0.33723
Epoch [22/25] Training [484/488] Loss: 0.18838
Epoch [22/25] Training [485/488] Loss: 0.21347
Epoch [22/25] Training [486/488] Loss: 0.14545
Epoch [22/25] Training [487/488] Loss: 0.23325
Epoch [22/25] Training [488/488] Loss: 0.58269
Epoch [22/25] Training metric {'Train/mean dice_metric': 0.8967778086662292, 'Train/TC dice_metric': 0.920451283454895, 'Train/WT dice_metric': 0.9403204917907715, 'Train/ET dice_metric': 0.8295616507530212}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [22/25] Validation [1/123] Loss: 0.21222  focal_loss 0.00195  dice_loss 0.21027
Epoch [22/25] Validation [2/123] Loss: 0.38288  focal_loss 0.00147  dice_loss 0.38141
Epoch [22/25] Validation [3/123] Loss: 0.19228  focal_loss 0.00140  dice_loss 0.19088
Epoch [22/25] Validation [4/123] Loss: 0.27699  focal_loss 0.00120  dice_loss 0.27578
Epoch [22/25] Validation [5/123] Loss: 0.32044  focal_loss 0.00904  dice_loss 0.31140
Epoch [22/25] Validation [6/123] Loss: 0.34266  focal_loss 0.00150  dice_loss 0.34117
Epoch [22/25] Validation [7/123] Loss: 0.35984  focal_loss 0.00054  dice_loss 0.35930
Epoch [22/25] Validation [8/123] Loss: 0.35481  focal_loss 0.00136  dice_loss 0.35345
Epoch [22/25] Validation [9/123] Loss: 0.27399  focal_loss 0.00125  dice_loss 0.27274
Epoch [22/25] Validation [10/123] Loss: 0.48519  focal_loss 0.00293  dice_loss 0.48226
Epoch [22/25] Validation [11/123] Loss: 0.46620  focal_loss 0.00179  dice_loss 0.46441
Epoch [22/25] Validation [12/123] Loss: 0.22088  focal_loss 0.00146  dice_loss 0.21942
Epoch [22/25] Validation [13/123] Loss: 0.20696  focal_loss 0.00335  dice_loss 0.20361
Epoch [22/25] Validation [14/123] Loss: 0.24908  focal_loss 0.00128  dice_loss 0.24780
Epoch [22/25] Validation [15/123] Loss: 0.36406  focal_loss 0.00127  dice_loss 0.36279
Epoch [22/25] Validation [16/123] Loss: 0.45028  focal_loss 0.00179  dice_loss 0.44849
Epoch [22/25] Validation [17/123] Loss: 0.49027  focal_loss 0.00152  dice_loss 0.48874
Epoch [22/25] Validation [18/123] Loss: 0.30854  focal_loss 0.00167  dice_loss 0.30687
Epoch [22/25] Validation [19/123] Loss: 0.28545  focal_loss 0.00218  dice_loss 0.28326
Epoch [22/25] Validation [20/123] Loss: 0.45301  focal_loss 0.00055  dice_loss 0.45245
Epoch [22/25] Validation [21/123] Loss: 0.33481  focal_loss 0.00067  dice_loss 0.33414
Epoch [22/25] Validation [22/123] Loss: 0.61808  focal_loss 0.00647  dice_loss 0.61161
Epoch [22/25] Validation [23/123] Loss: 0.20752  focal_loss 0.00170  dice_loss 0.20582
Epoch [22/25] Validation [24/123] Loss: 0.29681  focal_loss 0.00215  dice_loss 0.29466
Epoch [22/25] Validation [25/123] Loss: 0.29066  focal_loss 0.00089  dice_loss 0.28977
Epoch [22/25] Validation [26/123] Loss: 0.21776  focal_loss 0.00151  dice_loss 0.21625
Epoch [22/25] Validation [27/123] Loss: 0.25735  focal_loss 0.00209  dice_loss 0.25527
Epoch [22/25] Validation [28/123] Loss: 0.49733  focal_loss 0.00332  dice_loss 0.49401
Epoch [22/25] Validation [29/123] Loss: 0.33835  focal_loss 0.00112  dice_loss 0.33722
Epoch [22/25] Validation [30/123] Loss: 0.25257  focal_loss 0.00347  dice_loss 0.24910
Epoch [22/25] Validation [31/123] Loss: 0.20520  focal_loss 0.00135  dice_loss 0.20385
Epoch [22/25] Validation [32/123] Loss: 0.30603  focal_loss 0.00262  dice_loss 0.30341
Epoch [22/25] Validation [33/123] Loss: 0.35297  focal_loss 0.00124  dice_loss 0.35173
Epoch [22/25] Validation [34/123] Loss: 0.30080  focal_loss 0.00131  dice_loss 0.29949
Epoch [22/25] Validation [35/123] Loss: 0.23872  focal_loss 0.00098  dice_loss 0.23774
Epoch [22/25] Validation [36/123] Loss: 0.27070  focal_loss 0.00085  dice_loss 0.26985
Epoch [22/25] Validation [37/123] Loss: 0.37874  focal_loss 0.00333  dice_loss 0.37541
Epoch [22/25] Validation [38/123] Loss: 0.22535  focal_loss 0.00113  dice_loss 0.22422
Epoch [22/25] Validation [39/123] Loss: 0.21862  focal_loss 0.00120  dice_loss 0.21742
Epoch [22/25] Validation [40/123] Loss: 0.32120  focal_loss 0.00074  dice_loss 0.32047
Epoch [22/25] Validation [41/123] Loss: 0.21344  focal_loss 0.00140  dice_loss 0.21204
Epoch [22/25] Validation [42/123] Loss: 0.19917  focal_loss 0.00121  dice_loss 0.19796
Epoch [22/25] Validation [43/123] Loss: 0.27311  focal_loss 0.00519  dice_loss 0.26792
Epoch [22/25] Validation [44/123] Loss: 0.50246  focal_loss 0.00357  dice_loss 0.49889
Epoch [22/25] Validation [45/123] Loss: 0.31084  focal_loss 0.00141  dice_loss 0.30944
Epoch [22/25] Validation [46/123] Loss: 0.34074  focal_loss 0.00252  dice_loss 0.33823
Epoch [22/25] Validation [47/123] Loss: 0.30603  focal_loss 0.00116  dice_loss 0.30487
Epoch [22/25] Validation [48/123] Loss: 0.41869  focal_loss 0.00405  dice_loss 0.41464
Epoch [22/25] Validation [49/123] Loss: 0.22199  focal_loss 0.00119  dice_loss 0.22080
Epoch [22/25] Validation [50/123] Loss: 0.21704  focal_loss 0.00190  dice_loss 0.21514
Epoch [22/25] Validation [51/123] Loss: 0.38371  focal_loss 0.00782  dice_loss 0.37589
Epoch [22/25] Validation [52/123] Loss: 0.23448  focal_loss 0.00069  dice_loss 0.23379
Epoch [22/25] Validation [53/123] Loss: 0.29325  focal_loss 0.00069  dice_loss 0.29255
Epoch [22/25] Validation [54/123] Loss: 0.33321  focal_loss 0.00082  dice_loss 0.33239
Epoch [22/25] Validation [55/123] Loss: 0.29462  focal_loss 0.00124  dice_loss 0.29338
Epoch [22/25] Validation [56/123] Loss: 0.23583  focal_loss 0.00222  dice_loss 0.23361
Epoch [22/25] Validation [57/123] Loss: 0.31204  focal_loss 0.00271  dice_loss 0.30934
Epoch [22/25] Validation [58/123] Loss: 0.29371  focal_loss 0.00319  dice_loss 0.29052
Epoch [22/25] Validation [59/123] Loss: 0.59806  focal_loss 0.00667  dice_loss 0.59139
Epoch [22/25] Validation [60/123] Loss: 0.26337  focal_loss 0.00327  dice_loss 0.26010
Epoch [22/25] Validation [61/123] Loss: 0.60531  focal_loss 0.00155  dice_loss 0.60376
Epoch [22/25] Validation [62/123] Loss: 0.49498  focal_loss 0.00779  dice_loss 0.48719
Epoch [22/25] Validation [63/123] Loss: 0.37938  focal_loss 0.00114  dice_loss 0.37824
Epoch [22/25] Validation [64/123] Loss: 0.42108  focal_loss 0.00633  dice_loss 0.41474
Epoch [22/25] Validation [65/123] Loss: 0.24425  focal_loss 0.00090  dice_loss 0.24334
Epoch [22/25] Validation [66/123] Loss: 0.25405  focal_loss 0.00109  dice_loss 0.25296
Epoch [22/25] Validation [67/123] Loss: 0.36551  focal_loss 0.00291  dice_loss 0.36260
Epoch [22/25] Validation [68/123] Loss: 0.36701  focal_loss 0.00089  dice_loss 0.36612
Epoch [22/25] Validation [69/123] Loss: 0.39059  focal_loss 0.00620  dice_loss 0.38439
Epoch [22/25] Validation [70/123] Loss: 0.31973  focal_loss 0.00150  dice_loss 0.31823
Epoch [22/25] Validation [71/123] Loss: 0.23466  focal_loss 0.00068  dice_loss 0.23398
Epoch [22/25] Validation [72/123] Loss: 0.21821  focal_loss 0.00132  dice_loss 0.21689
Epoch [22/25] Validation [73/123] Loss: 0.33514  focal_loss 0.00390  dice_loss 0.33124
Epoch [22/25] Validation [74/123] Loss: 0.33419  focal_loss 0.00399  dice_loss 0.33019
Epoch [22/25] Validation [75/123] Loss: 0.27266  focal_loss 0.00120  dice_loss 0.27146
Epoch [22/25] Validation [76/123] Loss: 0.54423  focal_loss 0.00598  dice_loss 0.53825
Epoch [22/25] Validation [77/123] Loss: 0.37568  focal_loss 0.00097  dice_loss 0.37471
Epoch [22/25] Validation [78/123] Loss: 0.27873  focal_loss 0.00130  dice_loss 0.27744
Epoch [22/25] Validation [79/123] Loss: 0.31940  focal_loss 0.00112  dice_loss 0.31827
Epoch [22/25] Validation [80/123] Loss: 0.23354  focal_loss 0.00253  dice_loss 0.23101
Epoch [22/25] Validation [81/123] Loss: 0.26084  focal_loss 0.00120  dice_loss 0.25964
Epoch [22/25] Validation [82/123] Loss: 0.22346  focal_loss 0.00091  dice_loss 0.22254
Epoch [22/25] Validation [83/123] Loss: 0.35347  focal_loss 0.00683  dice_loss 0.34664
Epoch [22/25] Validation [84/123] Loss: 0.26868  focal_loss 0.00114  dice_loss 0.26754
Epoch [22/25] Validation [85/123] Loss: 0.32383  focal_loss 0.00298  dice_loss 0.32085
Epoch [22/25] Validation [86/123] Loss: 0.23489  focal_loss 0.00098  dice_loss 0.23391
Epoch [22/25] Validation [87/123] Loss: 0.22835  focal_loss 0.00275  dice_loss 0.22560
Epoch [22/25] Validation [88/123] Loss: 0.25281  focal_loss 0.00140  dice_loss 0.25140
Epoch [22/25] Validation [89/123] Loss: 0.20952  focal_loss 0.00200  dice_loss 0.20752
Epoch [22/25] Validation [90/123] Loss: 0.30675  focal_loss 0.00160  dice_loss 0.30515
Epoch [22/25] Validation [91/123] Loss: 0.23710  focal_loss 0.00086  dice_loss 0.23624
Epoch [22/25] Validation [92/123] Loss: 0.20213  focal_loss 0.00110  dice_loss 0.20103
Epoch [22/25] Validation [93/123] Loss: 0.21998  focal_loss 0.00122  dice_loss 0.21876
Epoch [22/25] Validation [94/123] Loss: 0.34559  focal_loss 0.00148  dice_loss 0.34411
Epoch [22/25] Validation [95/123] Loss: 0.26214  focal_loss 0.00224  dice_loss 0.25990
Epoch [22/25] Validation [96/123] Loss: 0.31536  focal_loss 0.00103  dice_loss 0.31433
Epoch [22/25] Validation [97/123] Loss: 0.58579  focal_loss 0.00613  dice_loss 0.57965
Epoch [22/25] Validation [98/123] Loss: 0.32397  focal_loss 0.00095  dice_loss 0.32302
Epoch [22/25] Validation [99/123] Loss: 0.32422  focal_loss 0.00056  dice_loss 0.32366
Epoch [22/25] Validation [100/123] Loss: 0.34890  focal_loss 0.00092  dice_loss 0.34797
Epoch [22/25] Validation [101/123] Loss: 0.30454  focal_loss 0.00123  dice_loss 0.30331
Epoch [22/25] Validation [102/123] Loss: 0.33679  focal_loss 0.00048  dice_loss 0.33632
Epoch [22/25] Validation [103/123] Loss: 0.47091  focal_loss 0.00076  dice_loss 0.47015
Epoch [22/25] Validation [104/123] Loss: 0.42151  focal_loss 0.00465  dice_loss 0.41686
Epoch [22/25] Validation [105/123] Loss: 0.21335  focal_loss 0.00297  dice_loss 0.21039
Epoch [22/25] Validation [106/123] Loss: 0.24251  focal_loss 0.00080  dice_loss 0.24171
Epoch [22/25] Validation [107/123] Loss: 0.52690  focal_loss 0.00276  dice_loss 0.52414
Epoch [22/25] Validation [108/123] Loss: 0.23538  focal_loss 0.00051  dice_loss 0.23488
Epoch [22/25] Validation [109/123] Loss: 0.22440  focal_loss 0.00493  dice_loss 0.21947
Epoch [22/25] Validation [110/123] Loss: 0.34720  focal_loss 0.00202  dice_loss 0.34518
Epoch [22/25] Validation [111/123] Loss: 0.38441  focal_loss 0.00323  dice_loss 0.38118
Epoch [22/25] Validation [112/123] Loss: 0.32433  focal_loss 0.00072  dice_loss 0.32361
Epoch [22/25] Validation [113/123] Loss: 0.27537  focal_loss 0.00122  dice_loss 0.27414
Epoch [22/25] Validation [114/123] Loss: 0.33809  focal_loss 0.00410  dice_loss 0.33399
Epoch [22/25] Validation [115/123] Loss: 0.28429  focal_loss 0.00486  dice_loss 0.27943
Epoch [22/25] Validation [116/123] Loss: 0.26891  focal_loss 0.00045  dice_loss 0.26847
Epoch [22/25] Validation [117/123] Loss: 0.28033  focal_loss 0.00103  dice_loss 0.27930
Epoch [22/25] Validation [118/123] Loss: 0.18949  focal_loss 0.00172  dice_loss 0.18777
Epoch [22/25] Validation [119/123] Loss: 0.22130  focal_loss 0.00129  dice_loss 0.22000
Epoch [22/25] Validation [120/123] Loss: 0.24804  focal_loss 0.00165  dice_loss 0.24639
Epoch [22/25] Validation [121/123] Loss: 0.61190  focal_loss 0.01242  dice_loss 0.59949
Epoch [22/25] Validation [122/123] Loss: 0.54624  focal_loss 0.00031  dice_loss 0.54593
Epoch [22/25] Validation [123/123] Loss: 0.24438  focal_loss 0.00141  dice_loss 0.24297
Epoch [22/25] Validation metric {'Val/mean dice_metric': 0.8958836793899536, 'Val/TC dice_metric': 0.9184909462928772, 'Val/WT dice_metric': 0.9390375018119812, 'Val/ET dice_metric': 0.8301225304603577}
Epoch [22/25] lr = [9.549150281252633e-05, 9.549150281252633e-05] best acc: tensor([0.8925], device='cuda:0'), mean acc: tensor([0.8959], device='cuda:0'), mean class: tensor([0.9185, 0.9390, 0.8301], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [23/25] Training [1/488] Loss: 0.36591
Epoch [23/25] Training [2/488] Loss: 0.11996
Epoch [23/25] Training [3/488] Loss: 0.13423
Epoch [23/25] Training [4/488] Loss: 0.48078
Epoch [23/25] Training [5/488] Loss: 0.12220
Epoch [23/25] Training [6/488] Loss: 0.11663
Epoch [23/25] Training [7/488] Loss: 0.17760
Epoch [23/25] Training [8/488] Loss: 0.15563
Epoch [23/25] Training [9/488] Loss: 0.22747
Epoch [23/25] Training [10/488] Loss: 0.13082
Epoch [23/25] Training [11/488] Loss: 0.12012
Epoch [23/25] Training [12/488] Loss: 0.19518
Epoch [23/25] Training [13/488] Loss: 0.12499
Epoch [23/25] Training [14/488] Loss: 0.14120
Epoch [23/25] Training [15/488] Loss: 0.15633
Epoch [23/25] Training [16/488] Loss: 0.13687
Epoch [23/25] Training [17/488] Loss: 0.17533
Epoch [23/25] Training [18/488] Loss: 0.50356
Epoch [23/25] Training [19/488] Loss: 0.12675
Epoch [23/25] Training [20/488] Loss: 0.13408
Epoch [23/25] Training [21/488] Loss: 0.11975
Epoch [23/25] Training [22/488] Loss: 0.13285
Epoch [23/25] Training [23/488] Loss: 0.15280
Epoch [23/25] Training [24/488] Loss: 0.28401
Epoch [23/25] Training [25/488] Loss: 0.33893
Epoch [23/25] Training [26/488] Loss: 0.38812
Epoch [23/25] Training [27/488] Loss: 0.15637
Epoch [23/25] Training [28/488] Loss: 0.13916
Epoch [23/25] Training [29/488] Loss: 0.14143
Epoch [23/25] Training [30/488] Loss: 0.15291
Epoch [23/25] Training [31/488] Loss: 0.14124
Epoch [23/25] Training [32/488] Loss: 0.22253
Epoch [23/25] Training [33/488] Loss: 0.17873
Epoch [23/25] Training [34/488] Loss: 0.16072
Epoch [23/25] Training [35/488] Loss: 0.12391
Epoch [23/25] Training [36/488] Loss: 0.18675
Epoch [23/25] Training [37/488] Loss: 0.16478
Epoch [23/25] Training [38/488] Loss: 0.27823
Epoch [23/25] Training [39/488] Loss: 0.17015
Epoch [23/25] Training [40/488] Loss: 0.13794
Epoch [23/25] Training [41/488] Loss: 0.16441
Epoch [23/25] Training [42/488] Loss: 0.11367
Epoch [23/25] Training [43/488] Loss: 0.22332
Epoch [23/25] Training [44/488] Loss: 0.13491
Epoch [23/25] Training [45/488] Loss: 0.15439
Epoch [23/25] Training [46/488] Loss: 0.22683
Epoch [23/25] Training [47/488] Loss: 0.17448
Epoch [23/25] Training [48/488] Loss: 0.14377
Epoch [23/25] Training [49/488] Loss: 0.19939
Epoch [23/25] Training [50/488] Loss: 0.18577
Epoch [23/25] Training [51/488] Loss: 0.17942
Epoch [23/25] Training [52/488] Loss: 0.10095
Epoch [23/25] Training [53/488] Loss: 0.20657
Epoch [23/25] Training [54/488] Loss: 0.21606
Epoch [23/25] Training [55/488] Loss: 0.15837
Epoch [23/25] Training [56/488] Loss: 0.22328
Epoch [23/25] Training [57/488] Loss: 0.15274
Epoch [23/25] Training [58/488] Loss: 0.16891
Epoch [23/25] Training [59/488] Loss: 0.15037
Epoch [23/25] Training [60/488] Loss: 0.12466
Epoch [23/25] Training [61/488] Loss: 0.34469
Epoch [23/25] Training [62/488] Loss: 0.23865
Epoch [23/25] Training [63/488] Loss: 0.16293
Epoch [23/25] Training [64/488] Loss: 0.16425
Epoch [23/25] Training [65/488] Loss: 0.15182
Epoch [23/25] Training [66/488] Loss: 0.28239
Epoch [23/25] Training [67/488] Loss: 0.38350
Epoch [23/25] Training [68/488] Loss: 0.22181
Epoch [23/25] Training [69/488] Loss: 0.24523
Epoch [23/25] Training [70/488] Loss: 0.22979
Epoch [23/25] Training [71/488] Loss: 0.14292
Epoch [23/25] Training [72/488] Loss: 0.40619
Epoch [23/25] Training [73/488] Loss: 0.14839
Epoch [23/25] Training [74/488] Loss: 0.17052
Epoch [23/25] Training [75/488] Loss: 0.34709
Epoch [23/25] Training [76/488] Loss: 0.16345
Epoch [23/25] Training [77/488] Loss: 0.48579
Epoch [23/25] Training [78/488] Loss: 0.11069
Epoch [23/25] Training [79/488] Loss: 0.13398
Epoch [23/25] Training [80/488] Loss: 0.19518
Epoch [23/25] Training [81/488] Loss: 0.24265
Epoch [23/25] Training [82/488] Loss: 0.17085
Epoch [23/25] Training [83/488] Loss: 0.10565
Epoch [23/25] Training [84/488] Loss: 0.10847
Epoch [23/25] Training [85/488] Loss: 0.18718
Epoch [23/25] Training [86/488] Loss: 0.22818
Epoch [23/25] Training [87/488] Loss: 0.14116
Epoch [23/25] Training [88/488] Loss: 0.16951
Epoch [23/25] Training [89/488] Loss: 0.12928
Epoch [23/25] Training [90/488] Loss: 0.14973
Epoch [23/25] Training [91/488] Loss: 0.27977
Epoch [23/25] Training [92/488] Loss: 0.13620
Epoch [23/25] Training [93/488] Loss: 0.30541
Epoch [23/25] Training [94/488] Loss: 0.13612
Epoch [23/25] Training [95/488] Loss: 0.13055
Epoch [23/25] Training [96/488] Loss: 0.13869
Epoch [23/25] Training [97/488] Loss: 0.57804
Epoch [23/25] Training [98/488] Loss: 0.19370
Epoch [23/25] Training [99/488] Loss: 0.15120
Epoch [23/25] Training [100/488] Loss: 0.19729
Epoch [23/25] Training [101/488] Loss: 0.12079
Epoch [23/25] Training [102/488] Loss: 0.19869
Epoch [23/25] Training [103/488] Loss: 0.19833
Epoch [23/25] Training [104/488] Loss: 0.17685
Epoch [23/25] Training [105/488] Loss: 0.19371
Epoch [23/25] Training [106/488] Loss: 0.15282
Epoch [23/25] Training [107/488] Loss: 0.12068
Epoch [23/25] Training [108/488] Loss: 0.43079
Epoch [23/25] Training [109/488] Loss: 0.13967
Epoch [23/25] Training [110/488] Loss: 0.10827
Epoch [23/25] Training [111/488] Loss: 0.23184
Epoch [23/25] Training [112/488] Loss: 0.12004
Epoch [23/25] Training [113/488] Loss: 0.10408
Epoch [23/25] Training [114/488] Loss: 0.22675
Epoch [23/25] Training [115/488] Loss: 0.23161
Epoch [23/25] Training [116/488] Loss: 0.20862
Epoch [23/25] Training [117/488] Loss: 0.40644
Epoch [23/25] Training [118/488] Loss: 0.15397
Epoch [23/25] Training [119/488] Loss: 0.11198
Epoch [23/25] Training [120/488] Loss: 0.14243
Epoch [23/25] Training [121/488] Loss: 0.17440
Epoch [23/25] Training [122/488] Loss: 0.29176
Epoch [23/25] Training [123/488] Loss: 0.25753
Epoch [23/25] Training [124/488] Loss: 0.71432
Epoch [23/25] Training [125/488] Loss: 0.22748
Epoch [23/25] Training [126/488] Loss: 0.24881
Epoch [23/25] Training [127/488] Loss: 0.17287
Epoch [23/25] Training [128/488] Loss: 0.27752
Epoch [23/25] Training [129/488] Loss: 0.25804
Epoch [23/25] Training [130/488] Loss: 0.13856
Epoch [23/25] Training [131/488] Loss: 0.19370
Epoch [23/25] Training [132/488] Loss: 0.37283
Epoch [23/25] Training [133/488] Loss: 0.16277
Epoch [23/25] Training [134/488] Loss: 0.13465
Epoch [23/25] Training [135/488] Loss: 0.16233
Epoch [23/25] Training [136/488] Loss: 0.36042
Epoch [23/25] Training [137/488] Loss: 0.18195
Epoch [23/25] Training [138/488] Loss: 0.11580
Epoch [23/25] Training [139/488] Loss: 0.23014
Epoch [23/25] Training [140/488] Loss: 0.17858
Epoch [23/25] Training [141/488] Loss: 0.14090
Epoch [23/25] Training [142/488] Loss: 0.32741
Epoch [23/25] Training [143/488] Loss: 0.31320
Epoch [23/25] Training [144/488] Loss: 0.63094
Epoch [23/25] Training [145/488] Loss: 0.15287
Epoch [23/25] Training [146/488] Loss: 0.21011
Epoch [23/25] Training [147/488] Loss: 0.13688
Epoch [23/25] Training [148/488] Loss: 0.20800
Epoch [23/25] Training [149/488] Loss: 0.33044
Epoch [23/25] Training [150/488] Loss: 0.29482
Epoch [23/25] Training [151/488] Loss: 0.12426
Epoch [23/25] Training [152/488] Loss: 0.33156
Epoch [23/25] Training [153/488] Loss: 0.13300
Epoch [23/25] Training [154/488] Loss: 0.17376
Epoch [23/25] Training [155/488] Loss: 0.11224
Epoch [23/25] Training [156/488] Loss: 0.32947
Epoch [23/25] Training [157/488] Loss: 0.14644
Epoch [23/25] Training [158/488] Loss: 0.11524
Epoch [23/25] Training [159/488] Loss: 0.13618
Epoch [23/25] Training [160/488] Loss: 0.25063
Epoch [23/25] Training [161/488] Loss: 0.15205
Epoch [23/25] Training [162/488] Loss: 0.13788
Epoch [23/25] Training [163/488] Loss: 0.24181
Epoch [23/25] Training [164/488] Loss: 0.14227
Epoch [23/25] Training [165/488] Loss: 0.21331
Epoch [23/25] Training [166/488] Loss: 0.38739
Epoch [23/25] Training [167/488] Loss: 0.24100
Epoch [23/25] Training [168/488] Loss: 0.16051
Epoch [23/25] Training [169/488] Loss: 0.09735
Epoch [23/25] Training [170/488] Loss: 0.34432
Epoch [23/25] Training [171/488] Loss: 0.35049
Epoch [23/25] Training [172/488] Loss: 0.42401
Epoch [23/25] Training [173/488] Loss: 0.24275
Epoch [23/25] Training [174/488] Loss: 0.12192
Epoch [23/25] Training [175/488] Loss: 0.12895
Epoch [23/25] Training [176/488] Loss: 0.12589
Epoch [23/25] Training [177/488] Loss: 0.19954
Epoch [23/25] Training [178/488] Loss: 0.13715
Epoch [23/25] Training [179/488] Loss: 0.13374
Epoch [23/25] Training [180/488] Loss: 0.12884
Epoch [23/25] Training [181/488] Loss: 0.27868
Epoch [23/25] Training [182/488] Loss: 0.14959
Epoch [23/25] Training [183/488] Loss: 0.16872
Epoch [23/25] Training [184/488] Loss: 0.33359
Epoch [23/25] Training [185/488] Loss: 0.15499
Epoch [23/25] Training [186/488] Loss: 0.15229
Epoch [23/25] Training [187/488] Loss: 0.19589
Epoch [23/25] Training [188/488] Loss: 0.16135
Epoch [23/25] Training [189/488] Loss: 0.12666
Epoch [23/25] Training [190/488] Loss: 0.48017
Epoch [23/25] Training [191/488] Loss: 0.20006
Epoch [23/25] Training [192/488] Loss: 0.27799
Epoch [23/25] Training [193/488] Loss: 0.16229
Epoch [23/25] Training [194/488] Loss: 0.44132
Epoch [23/25] Training [195/488] Loss: 0.12673
Epoch [23/25] Training [196/488] Loss: 0.29932
Epoch [23/25] Training [197/488] Loss: 0.30278
Epoch [23/25] Training [198/488] Loss: 0.22799
Epoch [23/25] Training [199/488] Loss: 0.13220
Epoch [23/25] Training [200/488] Loss: 0.21742
Epoch [23/25] Training [201/488] Loss: 0.14979
Epoch [23/25] Training [202/488] Loss: 0.17052
Epoch [23/25] Training [203/488] Loss: 0.18630
Epoch [23/25] Training [204/488] Loss: 0.20153
Epoch [23/25] Training [205/488] Loss: 0.33308
Epoch [23/25] Training [206/488] Loss: 0.15744
Epoch [23/25] Training [207/488] Loss: 0.14971
Epoch [23/25] Training [208/488] Loss: 0.48100
Epoch [23/25] Training [209/488] Loss: 0.15138
Epoch [23/25] Training [210/488] Loss: 0.13868
Epoch [23/25] Training [211/488] Loss: 0.30723
Epoch [23/25] Training [212/488] Loss: 0.20859
Epoch [23/25] Training [213/488] Loss: 0.11208
Epoch [23/25] Training [214/488] Loss: 0.12133
Epoch [23/25] Training [215/488] Loss: 0.21117
Epoch [23/25] Training [216/488] Loss: 0.13457
Epoch [23/25] Training [217/488] Loss: 0.20792
Epoch [23/25] Training [218/488] Loss: 0.12836
Epoch [23/25] Training [219/488] Loss: 0.16909
Epoch [23/25] Training [220/488] Loss: 0.12140
Epoch [23/25] Training [221/488] Loss: 0.14596
Epoch [23/25] Training [222/488] Loss: 0.12211
Epoch [23/25] Training [223/488] Loss: 0.20324
Epoch [23/25] Training [224/488] Loss: 0.44052
Epoch [23/25] Training [225/488] Loss: 0.26485
Epoch [23/25] Training [226/488] Loss: 0.44190
Epoch [23/25] Training [227/488] Loss: 0.14113
Epoch [23/25] Training [228/488] Loss: 0.15513
Epoch [23/25] Training [229/488] Loss: 0.22714
Epoch [23/25] Training [230/488] Loss: 0.15336
Epoch [23/25] Training [231/488] Loss: 0.16715
Epoch [23/25] Training [232/488] Loss: 0.22078
Epoch [23/25] Training [233/488] Loss: 0.12482
Epoch [23/25] Training [234/488] Loss: 0.11639
Epoch [23/25] Training [235/488] Loss: 0.70762
Epoch [23/25] Training [236/488] Loss: 0.23012
Epoch [23/25] Training [237/488] Loss: 0.24816
Epoch [23/25] Training [238/488] Loss: 0.12455
Epoch [23/25] Training [239/488] Loss: 0.12665
Epoch [23/25] Training [240/488] Loss: 0.11198
Epoch [23/25] Training [241/488] Loss: 0.39225
Epoch [23/25] Training [242/488] Loss: 0.38859
Epoch [23/25] Training [243/488] Loss: 0.17749
Epoch [23/25] Training [244/488] Loss: 0.18363
Epoch [23/25] Training [245/488] Loss: 0.17596
Epoch [23/25] Training [246/488] Loss: 0.12394
Epoch [23/25] Training [247/488] Loss: 0.10517
Epoch [23/25] Training [248/488] Loss: 0.16982
Epoch [23/25] Training [249/488] Loss: 0.14918
Epoch [23/25] Training [250/488] Loss: 0.15561
Epoch [23/25] Training [251/488] Loss: 0.13687
Epoch [23/25] Training [252/488] Loss: 0.12752
Epoch [23/25] Training [253/488] Loss: 0.30465
Epoch [23/25] Training [254/488] Loss: 0.18576
Epoch [23/25] Training [255/488] Loss: 0.16629
Epoch [23/25] Training [256/488] Loss: 0.17465
Epoch [23/25] Training [257/488] Loss: 0.14208
Epoch [23/25] Training [258/488] Loss: 0.23756
Epoch [23/25] Training [259/488] Loss: 0.30682
Epoch [23/25] Training [260/488] Loss: 0.13933
Epoch [23/25] Training [261/488] Loss: 0.16176
Epoch [23/25] Training [262/488] Loss: 0.44089
Epoch [23/25] Training [263/488] Loss: 0.21323
Epoch [23/25] Training [264/488] Loss: 0.19820
Epoch [23/25] Training [265/488] Loss: 0.40712
Epoch [23/25] Training [266/488] Loss: 0.21053
Epoch [23/25] Training [267/488] Loss: 0.13355
Epoch [23/25] Training [268/488] Loss: 0.59321
Epoch [23/25] Training [269/488] Loss: 0.24059
Epoch [23/25] Training [270/488] Loss: 0.36699
Epoch [23/25] Training [271/488] Loss: 0.14018
Epoch [23/25] Training [272/488] Loss: 0.15150
Epoch [23/25] Training [273/488] Loss: 0.18258
Epoch [23/25] Training [274/488] Loss: 0.34457
Epoch [23/25] Training [275/488] Loss: 0.12603
Epoch [23/25] Training [276/488] Loss: 0.18445
Epoch [23/25] Training [277/488] Loss: 0.13073
Epoch [23/25] Training [278/488] Loss: 0.16089
Epoch [23/25] Training [279/488] Loss: 0.11436
Epoch [23/25] Training [280/488] Loss: 0.29492
Epoch [23/25] Training [281/488] Loss: 0.41357
Epoch [23/25] Training [282/488] Loss: 0.17623
Epoch [23/25] Training [283/488] Loss: 0.71028
Epoch [23/25] Training [284/488] Loss: 0.31113
Epoch [23/25] Training [285/488] Loss: 0.47803
Epoch [23/25] Training [286/488] Loss: 0.18900
Epoch [23/25] Training [287/488] Loss: 0.19858
Epoch [23/25] Training [288/488] Loss: 0.24479
Epoch [23/25] Training [289/488] Loss: 0.23686
Epoch [23/25] Training [290/488] Loss: 0.65420
Epoch [23/25] Training [291/488] Loss: 0.14883
Epoch [23/25] Training [292/488] Loss: 0.16728
Epoch [23/25] Training [293/488] Loss: 0.15748
Epoch [23/25] Training [294/488] Loss: 0.14760
Epoch [23/25] Training [295/488] Loss: 0.12617
Epoch [23/25] Training [296/488] Loss: 0.12468
Epoch [23/25] Training [297/488] Loss: 0.13181
Epoch [23/25] Training [298/488] Loss: 0.46142
Epoch [23/25] Training [299/488] Loss: 0.13812
Epoch [23/25] Training [300/488] Loss: 0.16432
Epoch [23/25] Training [301/488] Loss: 0.14928
Epoch [23/25] Training [302/488] Loss: 0.31646
Epoch [23/25] Training [303/488] Loss: 0.11912
Epoch [23/25] Training [304/488] Loss: 0.46382
Epoch [23/25] Training [305/488] Loss: 0.18297
Epoch [23/25] Training [306/488] Loss: 0.11120
Epoch [23/25] Training [307/488] Loss: 0.23628
Epoch [23/25] Training [308/488] Loss: 0.33632
Epoch [23/25] Training [309/488] Loss: 0.21155
Epoch [23/25] Training [310/488] Loss: 0.10802
Epoch [23/25] Training [311/488] Loss: 0.17393
Epoch [23/25] Training [312/488] Loss: 0.17504
Epoch [23/25] Training [313/488] Loss: 0.38991
Epoch [23/25] Training [314/488] Loss: 0.46984
Epoch [23/25] Training [315/488] Loss: 0.13992
Epoch [23/25] Training [316/488] Loss: 0.19908
Epoch [23/25] Training [317/488] Loss: 0.17793
Epoch [23/25] Training [318/488] Loss: 0.15721
Epoch [23/25] Training [319/488] Loss: 0.26351
Epoch [23/25] Training [320/488] Loss: 0.28700
Epoch [23/25] Training [321/488] Loss: 0.13522
Epoch [23/25] Training [322/488] Loss: 0.13738
Epoch [23/25] Training [323/488] Loss: 0.25256
Epoch [23/25] Training [324/488] Loss: 0.21736
Epoch [23/25] Training [325/488] Loss: 0.12104
Epoch [23/25] Training [326/488] Loss: 0.19857
Epoch [23/25] Training [327/488] Loss: 0.13837
Epoch [23/25] Training [328/488] Loss: 0.11227
Epoch [23/25] Training [329/488] Loss: 0.19541
Epoch [23/25] Training [330/488] Loss: 0.16160
Epoch [23/25] Training [331/488] Loss: 0.16060
Epoch [23/25] Training [332/488] Loss: 0.39057
Epoch [23/25] Training [333/488] Loss: 0.13844
Epoch [23/25] Training [334/488] Loss: 0.15633
Epoch [23/25] Training [335/488] Loss: 0.18127
Epoch [23/25] Training [336/488] Loss: 0.17632
Epoch [23/25] Training [337/488] Loss: 0.17306
Epoch [23/25] Training [338/488] Loss: 0.14864
Epoch [23/25] Training [339/488] Loss: 0.17241
Epoch [23/25] Training [340/488] Loss: 0.13232
Epoch [23/25] Training [341/488] Loss: 0.21312
Epoch [23/25] Training [342/488] Loss: 0.23412
Epoch [23/25] Training [343/488] Loss: 0.13551
Epoch [23/25] Training [344/488] Loss: 0.19415
Epoch [23/25] Training [345/488] Loss: 0.14550
Epoch [23/25] Training [346/488] Loss: 0.30179
Epoch [23/25] Training [347/488] Loss: 0.31310
Epoch [23/25] Training [348/488] Loss: 0.24937
Epoch [23/25] Training [349/488] Loss: 0.14483
Epoch [23/25] Training [350/488] Loss: 0.23972
Epoch [23/25] Training [351/488] Loss: 0.14181
Epoch [23/25] Training [352/488] Loss: 0.33387
Epoch [23/25] Training [353/488] Loss: 0.24494
Epoch [23/25] Training [354/488] Loss: 0.19233
Epoch [23/25] Training [355/488] Loss: 0.36686
Epoch [23/25] Training [356/488] Loss: 0.13296
Epoch [23/25] Training [357/488] Loss: 0.24882
Epoch [23/25] Training [358/488] Loss: 0.32919
Epoch [23/25] Training [359/488] Loss: 0.24732
Epoch [23/25] Training [360/488] Loss: 0.18934
Epoch [23/25] Training [361/488] Loss: 0.22765
Epoch [23/25] Training [362/488] Loss: 0.19394
Epoch [23/25] Training [363/488] Loss: 0.17866
Epoch [23/25] Training [364/488] Loss: 0.31242
Epoch [23/25] Training [365/488] Loss: 0.51675
Epoch [23/25] Training [366/488] Loss: 0.14744
Epoch [23/25] Training [367/488] Loss: 0.15671
Epoch [23/25] Training [368/488] Loss: 0.10526
Epoch [23/25] Training [369/488] Loss: 0.11242
Epoch [23/25] Training [370/488] Loss: 0.15504
Epoch [23/25] Training [371/488] Loss: 0.18939
Epoch [23/25] Training [372/488] Loss: 0.24023
Epoch [23/25] Training [373/488] Loss: 0.12806
Epoch [23/25] Training [374/488] Loss: 0.12817
Epoch [23/25] Training [375/488] Loss: 0.34355
Epoch [23/25] Training [376/488] Loss: 0.27260
Epoch [23/25] Training [377/488] Loss: 0.27262
Epoch [23/25] Training [378/488] Loss: 0.18131
Epoch [23/25] Training [379/488] Loss: 0.13135
Epoch [23/25] Training [380/488] Loss: 0.21806
Epoch [23/25] Training [381/488] Loss: 0.13406
Epoch [23/25] Training [382/488] Loss: 0.20227
Epoch [23/25] Training [383/488] Loss: 0.20664
Epoch [23/25] Training [384/488] Loss: 0.13779
Epoch [23/25] Training [385/488] Loss: 0.33506
Epoch [23/25] Training [386/488] Loss: 0.11455
Epoch [23/25] Training [387/488] Loss: 0.13488
Epoch [23/25] Training [388/488] Loss: 0.18884
Epoch [23/25] Training [389/488] Loss: 0.11738
Epoch [23/25] Training [390/488] Loss: 0.14646
Epoch [23/25] Training [391/488] Loss: 0.24646
Epoch [23/25] Training [392/488] Loss: 0.26573
Epoch [23/25] Training [393/488] Loss: 0.23796
Epoch [23/25] Training [394/488] Loss: 0.16561
Epoch [23/25] Training [395/488] Loss: 0.13397
Epoch [23/25] Training [396/488] Loss: 0.18780
Epoch [23/25] Training [397/488] Loss: 0.24514
Epoch [23/25] Training [398/488] Loss: 0.30235
Epoch [23/25] Training [399/488] Loss: 0.21923
Epoch [23/25] Training [400/488] Loss: 0.13097
Epoch [23/25] Training [401/488] Loss: 0.12464
Epoch [23/25] Training [402/488] Loss: 0.20712
Epoch [23/25] Training [403/488] Loss: 0.16163
Epoch [23/25] Training [404/488] Loss: 0.12417
Epoch [23/25] Training [405/488] Loss: 0.25953
Epoch [23/25] Training [406/488] Loss: 0.18344
Epoch [23/25] Training [407/488] Loss: 0.13566
Epoch [23/25] Training [408/488] Loss: 0.44645
Epoch [23/25] Training [409/488] Loss: 0.23992
Epoch [23/25] Training [410/488] Loss: 0.57613
Epoch [23/25] Training [411/488] Loss: 0.16512
Epoch [23/25] Training [412/488] Loss: 0.29105
Epoch [23/25] Training [413/488] Loss: 0.15792
Epoch [23/25] Training [414/488] Loss: 0.15900
Epoch [23/25] Training [415/488] Loss: 0.18529
Epoch [23/25] Training [416/488] Loss: 0.40214
Epoch [23/25] Training [417/488] Loss: 0.23391
Epoch [23/25] Training [418/488] Loss: 0.21935
Epoch [23/25] Training [419/488] Loss: 0.17348
Epoch [23/25] Training [420/488] Loss: 0.13409
Epoch [23/25] Training [421/488] Loss: 0.26242
Epoch [23/25] Training [422/488] Loss: 0.11123
Epoch [23/25] Training [423/488] Loss: 0.11992
Epoch [23/25] Training [424/488] Loss: 0.25029
Epoch [23/25] Training [425/488] Loss: 0.28645
Epoch [23/25] Training [426/488] Loss: 0.16293
Epoch [23/25] Training [427/488] Loss: 0.10052
Epoch [23/25] Training [428/488] Loss: 0.21342
Epoch [23/25] Training [429/488] Loss: 0.13839
Epoch [23/25] Training [430/488] Loss: 0.14462
Epoch [23/25] Training [431/488] Loss: 0.35584
Epoch [23/25] Training [432/488] Loss: 0.12627
Epoch [23/25] Training [433/488] Loss: 0.24741
Epoch [23/25] Training [434/488] Loss: 0.19345
Epoch [23/25] Training [435/488] Loss: 0.34571
Epoch [23/25] Training [436/488] Loss: 0.19922
Epoch [23/25] Training [437/488] Loss: 0.18460
Epoch [23/25] Training [438/488] Loss: 0.16912
Epoch [23/25] Training [439/488] Loss: 0.11881
Epoch [23/25] Training [440/488] Loss: 0.19000
Epoch [23/25] Training [441/488] Loss: 0.28373
Epoch [23/25] Training [442/488] Loss: 0.18520
Epoch [23/25] Training [443/488] Loss: 0.16681
Epoch [23/25] Training [444/488] Loss: 0.19406
Epoch [23/25] Training [445/488] Loss: 0.18664
Epoch [23/25] Training [446/488] Loss: 0.31253
Epoch [23/25] Training [447/488] Loss: 0.28257
Epoch [23/25] Training [448/488] Loss: 0.17726
Epoch [23/25] Training [449/488] Loss: 0.11644
Epoch [23/25] Training [450/488] Loss: 0.15998
Epoch [23/25] Training [451/488] Loss: 0.47356
Epoch [23/25] Training [452/488] Loss: 0.10991
Epoch [23/25] Training [453/488] Loss: 0.25929
Epoch [23/25] Training [454/488] Loss: 0.14720
Epoch [23/25] Training [455/488] Loss: 0.30295
Epoch [23/25] Training [456/488] Loss: 0.18899
Epoch [23/25] Training [457/488] Loss: 0.14010
Epoch [23/25] Training [458/488] Loss: 0.17526
Epoch [23/25] Training [459/488] Loss: 0.13517
Epoch [23/25] Training [460/488] Loss: 0.22759
Epoch [23/25] Training [461/488] Loss: 0.11957
Epoch [23/25] Training [462/488] Loss: 0.24316
Epoch [23/25] Training [463/488] Loss: 0.13877
Epoch [23/25] Training [464/488] Loss: 0.11434
Epoch [23/25] Training [465/488] Loss: 0.50264
Epoch [23/25] Training [466/488] Loss: 0.13039
Epoch [23/25] Training [467/488] Loss: 0.29756
Epoch [23/25] Training [468/488] Loss: 0.29356
Epoch [23/25] Training [469/488] Loss: 0.20934
Epoch [23/25] Training [470/488] Loss: 0.13859
Epoch [23/25] Training [471/488] Loss: 0.36600
Epoch [23/25] Training [472/488] Loss: 0.16658
Epoch [23/25] Training [473/488] Loss: 0.28908
Epoch [23/25] Training [474/488] Loss: 0.45589
Epoch [23/25] Training [475/488] Loss: 0.12800
Epoch [23/25] Training [476/488] Loss: 0.20087
Epoch [23/25] Training [477/488] Loss: 0.14961
Epoch [23/25] Training [478/488] Loss: 0.30925
Epoch [23/25] Training [479/488] Loss: 0.38631
Epoch [23/25] Training [480/488] Loss: 0.20624
Epoch [23/25] Training [481/488] Loss: 0.34443
Epoch [23/25] Training [482/488] Loss: 0.11120
Epoch [23/25] Training [483/488] Loss: 0.13773
Epoch [23/25] Training [484/488] Loss: 0.28516
Epoch [23/25] Training [485/488] Loss: 0.18787
Epoch [23/25] Training [486/488] Loss: 0.24081
Epoch [23/25] Training [487/488] Loss: 0.15125
Epoch [23/25] Training [488/488] Loss: 0.10760
Epoch [23/25] Training metric {'Train/mean dice_metric': 0.8996238708496094, 'Train/TC dice_metric': 0.9251013398170471, 'Train/WT dice_metric': 0.9417776465415955, 'Train/ET dice_metric': 0.831992506980896}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [23/25] Validation [1/123] Loss: 0.20626  focal_loss 0.00183  dice_loss 0.20443
Epoch [23/25] Validation [2/123] Loss: 0.37997  focal_loss 0.00155  dice_loss 0.37842
Epoch [23/25] Validation [3/123] Loss: 0.18842  focal_loss 0.00138  dice_loss 0.18703
Epoch [23/25] Validation [4/123] Loss: 0.27293  focal_loss 0.00135  dice_loss 0.27158
Epoch [23/25] Validation [5/123] Loss: 0.34807  focal_loss 0.01087  dice_loss 0.33720
Epoch [23/25] Validation [6/123] Loss: 0.34222  focal_loss 0.00167  dice_loss 0.34055
Epoch [23/25] Validation [7/123] Loss: 0.35431  focal_loss 0.00053  dice_loss 0.35378
Epoch [23/25] Validation [8/123] Loss: 0.34789  focal_loss 0.00128  dice_loss 0.34661
Epoch [23/25] Validation [9/123] Loss: 0.27215  focal_loss 0.00132  dice_loss 0.27083
Epoch [23/25] Validation [10/123] Loss: 0.46940  focal_loss 0.00255  dice_loss 0.46685
Epoch [23/25] Validation [11/123] Loss: 0.49132  focal_loss 0.00192  dice_loss 0.48940
Epoch [23/25] Validation [12/123] Loss: 0.21552  focal_loss 0.00136  dice_loss 0.21416
Epoch [23/25] Validation [13/123] Loss: 0.20204  focal_loss 0.00307  dice_loss 0.19897
Epoch [23/25] Validation [14/123] Loss: 0.24282  focal_loss 0.00120  dice_loss 0.24162
Epoch [23/25] Validation [15/123] Loss: 0.35736  focal_loss 0.00134  dice_loss 0.35602
Epoch [23/25] Validation [16/123] Loss: 0.47036  focal_loss 0.00199  dice_loss 0.46837
Epoch [23/25] Validation [17/123] Loss: 0.48464  focal_loss 0.00146  dice_loss 0.48318
Epoch [23/25] Validation [18/123] Loss: 0.32152  focal_loss 0.00187  dice_loss 0.31966
Epoch [23/25] Validation [19/123] Loss: 0.28838  focal_loss 0.00267  dice_loss 0.28571
Epoch [23/25] Validation [20/123] Loss: 0.44774  focal_loss 0.00057  dice_loss 0.44716
Epoch [23/25] Validation [21/123] Loss: 0.33123  focal_loss 0.00069  dice_loss 0.33054
Epoch [23/25] Validation [22/123] Loss: 0.62875  focal_loss 0.00730  dice_loss 0.62146
Epoch [23/25] Validation [23/123] Loss: 0.19975  focal_loss 0.00149  dice_loss 0.19826
Epoch [23/25] Validation [24/123] Loss: 0.29501  focal_loss 0.00245  dice_loss 0.29256
Epoch [23/25] Validation [25/123] Loss: 0.35101  focal_loss 0.00355  dice_loss 0.34746
Epoch [23/25] Validation [26/123] Loss: 0.20873  focal_loss 0.00139  dice_loss 0.20734
Epoch [23/25] Validation [27/123] Loss: 0.24646  focal_loss 0.00206  dice_loss 0.24440
Epoch [23/25] Validation [28/123] Loss: 0.49620  focal_loss 0.00338  dice_loss 0.49282
Epoch [23/25] Validation [29/123] Loss: 0.33779  focal_loss 0.00130  dice_loss 0.33649
Epoch [23/25] Validation [30/123] Loss: 0.25602  focal_loss 0.00377  dice_loss 0.25225
Epoch [23/25] Validation [31/123] Loss: 0.20053  focal_loss 0.00131  dice_loss 0.19922
Epoch [23/25] Validation [32/123] Loss: 0.30870  focal_loss 0.00322  dice_loss 0.30547
Epoch [23/25] Validation [33/123] Loss: 0.35204  focal_loss 0.00147  dice_loss 0.35058
Epoch [23/25] Validation [34/123] Loss: 0.29158  focal_loss 0.00122  dice_loss 0.29036
Epoch [23/25] Validation [35/123] Loss: 0.23254  focal_loss 0.00098  dice_loss 0.23156
Epoch [23/25] Validation [36/123] Loss: 0.26634  focal_loss 0.00085  dice_loss 0.26548
Epoch [23/25] Validation [37/123] Loss: 0.37865  focal_loss 0.00386  dice_loss 0.37480
Epoch [23/25] Validation [38/123] Loss: 0.22078  focal_loss 0.00115  dice_loss 0.21963
Epoch [23/25] Validation [39/123] Loss: 0.21321  focal_loss 0.00128  dice_loss 0.21194
Epoch [23/25] Validation [40/123] Loss: 0.31581  focal_loss 0.00074  dice_loss 0.31507
Epoch [23/25] Validation [41/123] Loss: 0.21392  focal_loss 0.00174  dice_loss 0.21218
Epoch [23/25] Validation [42/123] Loss: 0.19254  focal_loss 0.00106  dice_loss 0.19148
Epoch [23/25] Validation [43/123] Loss: 0.27399  focal_loss 0.00809  dice_loss 0.26590
Epoch [23/25] Validation [44/123] Loss: 0.51649  focal_loss 0.00432  dice_loss 0.51216
Epoch [23/25] Validation [45/123] Loss: 0.30609  focal_loss 0.00119  dice_loss 0.30490
Epoch [23/25] Validation [46/123] Loss: 0.33658  focal_loss 0.00244  dice_loss 0.33414
Epoch [23/25] Validation [47/123] Loss: 0.30371  focal_loss 0.00122  dice_loss 0.30250
Epoch [23/25] Validation [48/123] Loss: 0.42951  focal_loss 0.00486  dice_loss 0.42465
Epoch [23/25] Validation [49/123] Loss: 0.21464  focal_loss 0.00108  dice_loss 0.21355
Epoch [23/25] Validation [50/123] Loss: 0.21165  focal_loss 0.00177  dice_loss 0.20988
Epoch [23/25] Validation [51/123] Loss: 0.40963  focal_loss 0.01094  dice_loss 0.39869
Epoch [23/25] Validation [52/123] Loss: 0.22936  focal_loss 0.00072  dice_loss 0.22864
Epoch [23/25] Validation [53/123] Loss: 0.28916  focal_loss 0.00077  dice_loss 0.28840
Epoch [23/25] Validation [54/123] Loss: 0.33730  focal_loss 0.00110  dice_loss 0.33621
Epoch [23/25] Validation [55/123] Loss: 0.28877  focal_loss 0.00123  dice_loss 0.28754
Epoch [23/25] Validation [56/123] Loss: 0.23022  focal_loss 0.00220  dice_loss 0.22802
Epoch [23/25] Validation [57/123] Loss: 0.30132  focal_loss 0.00169  dice_loss 0.29964
Epoch [23/25] Validation [58/123] Loss: 0.26580  focal_loss 0.00235  dice_loss 0.26344
Epoch [23/25] Validation [59/123] Loss: 0.61188  focal_loss 0.00899  dice_loss 0.60288
Epoch [23/25] Validation [60/123] Loss: 0.25752  focal_loss 0.00310  dice_loss 0.25442
Epoch [23/25] Validation [61/123] Loss: 0.60984  focal_loss 0.00162  dice_loss 0.60822
Epoch [23/25] Validation [62/123] Loss: 0.49217  focal_loss 0.00817  dice_loss 0.48400
Epoch [23/25] Validation [63/123] Loss: 0.37596  focal_loss 0.00117  dice_loss 0.37479
Epoch [23/25] Validation [64/123] Loss: 0.38790  focal_loss 0.00633  dice_loss 0.38157
Epoch [23/25] Validation [65/123] Loss: 0.23868  focal_loss 0.00089  dice_loss 0.23779
Epoch [23/25] Validation [66/123] Loss: 0.24924  focal_loss 0.00113  dice_loss 0.24811
Epoch [23/25] Validation [67/123] Loss: 0.40835  focal_loss 0.00706  dice_loss 0.40129
Epoch [23/25] Validation [68/123] Loss: 0.36296  focal_loss 0.00088  dice_loss 0.36208
Epoch [23/25] Validation [69/123] Loss: 0.39302  focal_loss 0.00674  dice_loss 0.38628
Epoch [23/25] Validation [70/123] Loss: 0.32194  focal_loss 0.00169  dice_loss 0.32025
Epoch [23/25] Validation [71/123] Loss: 0.22991  focal_loss 0.00071  dice_loss 0.22920
Epoch [23/25] Validation [72/123] Loss: 0.21306  focal_loss 0.00135  dice_loss 0.21171
Epoch [23/25] Validation [73/123] Loss: 0.32890  focal_loss 0.00386  dice_loss 0.32504
Epoch [23/25] Validation [74/123] Loss: 0.33422  focal_loss 0.00421  dice_loss 0.33001
Epoch [23/25] Validation [75/123] Loss: 0.26384  focal_loss 0.00113  dice_loss 0.26271
Epoch [23/25] Validation [76/123] Loss: 0.51878  focal_loss 0.00581  dice_loss 0.51297
Epoch [23/25] Validation [77/123] Loss: 0.37374  focal_loss 0.00109  dice_loss 0.37265
Epoch [23/25] Validation [78/123] Loss: 0.27552  focal_loss 0.00133  dice_loss 0.27419
Epoch [23/25] Validation [79/123] Loss: 0.31422  focal_loss 0.00108  dice_loss 0.31315
Epoch [23/25] Validation [80/123] Loss: 0.22451  focal_loss 0.00226  dice_loss 0.22224
Epoch [23/25] Validation [81/123] Loss: 0.26261  focal_loss 0.00159  dice_loss 0.26103
Epoch [23/25] Validation [82/123] Loss: 0.21686  focal_loss 0.00080  dice_loss 0.21605
Epoch [23/25] Validation [83/123] Loss: 0.37930  focal_loss 0.00966  dice_loss 0.36964
Epoch [23/25] Validation [84/123] Loss: 0.26387  focal_loss 0.00117  dice_loss 0.26270
Epoch [23/25] Validation [85/123] Loss: 0.35560  focal_loss 0.00657  dice_loss 0.34904
Epoch [23/25] Validation [86/123] Loss: 0.23257  focal_loss 0.00104  dice_loss 0.23153
Epoch [23/25] Validation [87/123] Loss: 0.22429  focal_loss 0.00259  dice_loss 0.22171
Epoch [23/25] Validation [88/123] Loss: 0.24807  focal_loss 0.00149  dice_loss 0.24658
Epoch [23/25] Validation [89/123] Loss: 0.20684  focal_loss 0.00188  dice_loss 0.20496
Epoch [23/25] Validation [90/123] Loss: 0.30645  focal_loss 0.00190  dice_loss 0.30455
Epoch [23/25] Validation [91/123] Loss: 0.23537  focal_loss 0.00093  dice_loss 0.23444
Epoch [23/25] Validation [92/123] Loss: 0.19765  focal_loss 0.00112  dice_loss 0.19654
Epoch [23/25] Validation [93/123] Loss: 0.21600  focal_loss 0.00122  dice_loss 0.21477
Epoch [23/25] Validation [94/123] Loss: 0.34416  focal_loss 0.00155  dice_loss 0.34261
Epoch [23/25] Validation [95/123] Loss: 0.25624  focal_loss 0.00216  dice_loss 0.25408
Epoch [23/25] Validation [96/123] Loss: 0.32985  focal_loss 0.00154  dice_loss 0.32831
Epoch [23/25] Validation [97/123] Loss: 0.61284  focal_loss 0.00906  dice_loss 0.60378
Epoch [23/25] Validation [98/123] Loss: 0.32396  focal_loss 0.00109  dice_loss 0.32287
Epoch [23/25] Validation [99/123] Loss: 0.32006  focal_loss 0.00061  dice_loss 0.31945
Epoch [23/25] Validation [100/123] Loss: 0.34287  focal_loss 0.00088  dice_loss 0.34199
Epoch [23/25] Validation [101/123] Loss: 0.30206  focal_loss 0.00129  dice_loss 0.30077
Epoch [23/25] Validation [102/123] Loss: 0.33354  focal_loss 0.00051  dice_loss 0.33303
Epoch [23/25] Validation [103/123] Loss: 0.48797  focal_loss 0.00104  dice_loss 0.48692
Epoch [23/25] Validation [104/123] Loss: 0.41943  focal_loss 0.00521  dice_loss 0.41422
Epoch [23/25] Validation [105/123] Loss: 0.20759  focal_loss 0.00275  dice_loss 0.20485
Epoch [23/25] Validation [106/123] Loss: 0.23814  focal_loss 0.00082  dice_loss 0.23732
Epoch [23/25] Validation [107/123] Loss: 0.52479  focal_loss 0.00268  dice_loss 0.52211
Epoch [23/25] Validation [108/123] Loss: 0.23151  focal_loss 0.00053  dice_loss 0.23098
Epoch [23/25] Validation [109/123] Loss: 0.21896  focal_loss 0.00475  dice_loss 0.21422
Epoch [23/25] Validation [110/123] Loss: 0.35396  focal_loss 0.00230  dice_loss 0.35166
Epoch [23/25] Validation [111/123] Loss: 0.38111  focal_loss 0.00316  dice_loss 0.37795
Epoch [23/25] Validation [112/123] Loss: 0.31804  focal_loss 0.00069  dice_loss 0.31735
Epoch [23/25] Validation [113/123] Loss: 0.28190  focal_loss 0.00160  dice_loss 0.28029
Epoch [23/25] Validation [114/123] Loss: 0.32805  focal_loss 0.00400  dice_loss 0.32405
Epoch [23/25] Validation [115/123] Loss: 0.27881  focal_loss 0.00513  dice_loss 0.27369
Epoch [23/25] Validation [116/123] Loss: 0.26346  focal_loss 0.00045  dice_loss 0.26301
Epoch [23/25] Validation [117/123] Loss: 0.27671  focal_loss 0.00103  dice_loss 0.27568
Epoch [23/25] Validation [118/123] Loss: 0.18396  focal_loss 0.00159  dice_loss 0.18237
Epoch [23/25] Validation [119/123] Loss: 0.21423  focal_loss 0.00121  dice_loss 0.21302
Epoch [23/25] Validation [120/123] Loss: 0.24463  focal_loss 0.00176  dice_loss 0.24287
Epoch [23/25] Validation [121/123] Loss: 0.62764  focal_loss 0.01630  dice_loss 0.61134
Epoch [23/25] Validation [122/123] Loss: 0.53978  focal_loss 0.00030  dice_loss 0.53947
Epoch [23/25] Validation [123/123] Loss: 0.23836  focal_loss 0.00132  dice_loss 0.23703
Epoch [23/25] Validation metric {'Val/mean dice_metric': 0.8977617621421814, 'Val/TC dice_metric': 0.9214134216308594, 'Val/WT dice_metric': 0.9401533603668213, 'Val/ET dice_metric': 0.8317184448242188}
Epoch [23/25] lr = [5.449673790581611e-05, 5.449673790581611e-05] best acc: tensor([0.8959], device='cuda:0'), mean acc: tensor([0.8978], device='cuda:0'), mean class: tensor([0.9214, 0.9402, 0.8317], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [24/25] Training [1/488] Loss: 0.33378
Epoch [24/25] Training [2/488] Loss: 0.28651
Epoch [24/25] Training [3/488] Loss: 0.24146
Epoch [24/25] Training [4/488] Loss: 0.18830
Epoch [24/25] Training [5/488] Loss: 0.20882
Epoch [24/25] Training [6/488] Loss: 0.13665
Epoch [24/25] Training [7/488] Loss: 0.13131
Epoch [24/25] Training [8/488] Loss: 0.11336
Epoch [24/25] Training [9/488] Loss: 0.15634
Epoch [24/25] Training [10/488] Loss: 0.11121
Epoch [24/25] Training [11/488] Loss: 0.15286
Epoch [24/25] Training [12/488] Loss: 0.18231
Epoch [24/25] Training [13/488] Loss: 0.22962
Epoch [24/25] Training [14/488] Loss: 0.12231
Epoch [24/25] Training [15/488] Loss: 0.22923
Epoch [24/25] Training [16/488] Loss: 0.15841
Epoch [24/25] Training [17/488] Loss: 0.13106
Epoch [24/25] Training [18/488] Loss: 0.13829
Epoch [24/25] Training [19/488] Loss: 0.15601
Epoch [24/25] Training [20/488] Loss: 0.28373
Epoch [24/25] Training [21/488] Loss: 0.14731
Epoch [24/25] Training [22/488] Loss: 0.17357
Epoch [24/25] Training [23/488] Loss: 0.16206
Epoch [24/25] Training [24/488] Loss: 0.18259
Epoch [24/25] Training [25/488] Loss: 0.14663
Epoch [24/25] Training [26/488] Loss: 0.22301
Epoch [24/25] Training [27/488] Loss: 0.16671
Epoch [24/25] Training [28/488] Loss: 0.17732
Epoch [24/25] Training [29/488] Loss: 0.39250
Epoch [24/25] Training [30/488] Loss: 0.28274
Epoch [24/25] Training [31/488] Loss: 0.18199
Epoch [24/25] Training [32/488] Loss: 0.29135
Epoch [24/25] Training [33/488] Loss: 0.63042
Epoch [24/25] Training [34/488] Loss: 0.12810
Epoch [24/25] Training [35/488] Loss: 0.18123
Epoch [24/25] Training [36/488] Loss: 0.19137
Epoch [24/25] Training [37/488] Loss: 0.11278
Epoch [24/25] Training [38/488] Loss: 0.16034
Epoch [24/25] Training [39/488] Loss: 0.28387
Epoch [24/25] Training [40/488] Loss: 0.24797
Epoch [24/25] Training [41/488] Loss: 0.24460
Epoch [24/25] Training [42/488] Loss: 0.27663
Epoch [24/25] Training [43/488] Loss: 0.23648
Epoch [24/25] Training [44/488] Loss: 0.20118
Epoch [24/25] Training [45/488] Loss: 0.09895
Epoch [24/25] Training [46/488] Loss: 0.16324
Epoch [24/25] Training [47/488] Loss: 0.12525
Epoch [24/25] Training [48/488] Loss: 0.27447
Epoch [24/25] Training [49/488] Loss: 0.20417
Epoch [24/25] Training [50/488] Loss: 0.33073
Epoch [24/25] Training [51/488] Loss: 0.19928
Epoch [24/25] Training [52/488] Loss: 0.12717
Epoch [24/25] Training [53/488] Loss: 0.13795
Epoch [24/25] Training [54/488] Loss: 0.17147
Epoch [24/25] Training [55/488] Loss: 0.46090
Epoch [24/25] Training [56/488] Loss: 0.21624
Epoch [24/25] Training [57/488] Loss: 0.15158
Epoch [24/25] Training [58/488] Loss: 0.50088
Epoch [24/25] Training [59/488] Loss: 0.16297
Epoch [24/25] Training [60/488] Loss: 0.22384
Epoch [24/25] Training [61/488] Loss: 0.11918
Epoch [24/25] Training [62/488] Loss: 0.34767
Epoch [24/25] Training [63/488] Loss: 0.12522
Epoch [24/25] Training [64/488] Loss: 0.21073
Epoch [24/25] Training [65/488] Loss: 0.13061
Epoch [24/25] Training [66/488] Loss: 0.28523
Epoch [24/25] Training [67/488] Loss: 0.15303
Epoch [24/25] Training [68/488] Loss: 0.36844
Epoch [24/25] Training [69/488] Loss: 0.23820
Epoch [24/25] Training [70/488] Loss: 0.18591
Epoch [24/25] Training [71/488] Loss: 0.20861
Epoch [24/25] Training [72/488] Loss: 0.23818
Epoch [24/25] Training [73/488] Loss: 0.13845
Epoch [24/25] Training [74/488] Loss: 0.17399
Epoch [24/25] Training [75/488] Loss: 0.19184
Epoch [24/25] Training [76/488] Loss: 0.30105
Epoch [24/25] Training [77/488] Loss: 0.13257
Epoch [24/25] Training [78/488] Loss: 0.11289
Epoch [24/25] Training [79/488] Loss: 0.37446
Epoch [24/25] Training [80/488] Loss: 0.12169
Epoch [24/25] Training [81/488] Loss: 0.20595
Epoch [24/25] Training [82/488] Loss: 0.15085
Epoch [24/25] Training [83/488] Loss: 0.15165
Epoch [24/25] Training [84/488] Loss: 0.44731
Epoch [24/25] Training [85/488] Loss: 0.14508
Epoch [24/25] Training [86/488] Loss: 0.20696
Epoch [24/25] Training [87/488] Loss: 0.42129
Epoch [24/25] Training [88/488] Loss: 0.36434
Epoch [24/25] Training [89/488] Loss: 0.19387
Epoch [24/25] Training [90/488] Loss: 0.31565
Epoch [24/25] Training [91/488] Loss: 0.13125
Epoch [24/25] Training [92/488] Loss: 0.30826
Epoch [24/25] Training [93/488] Loss: 0.23198
Epoch [24/25] Training [94/488] Loss: 0.10637
Epoch [24/25] Training [95/488] Loss: 0.12200
Epoch [24/25] Training [96/488] Loss: 0.14732
Epoch [24/25] Training [97/488] Loss: 0.16338
Epoch [24/25] Training [98/488] Loss: 0.33442
Epoch [24/25] Training [99/488] Loss: 0.13051
Epoch [24/25] Training [100/488] Loss: 0.18043
Epoch [24/25] Training [101/488] Loss: 0.12813
Epoch [24/25] Training [102/488] Loss: 0.45620
Epoch [24/25] Training [103/488] Loss: 0.29439
Epoch [24/25] Training [104/488] Loss: 0.15077
Epoch [24/25] Training [105/488] Loss: 0.16083
Epoch [24/25] Training [106/488] Loss: 0.13848
Epoch [24/25] Training [107/488] Loss: 0.10675
Epoch [24/25] Training [108/488] Loss: 0.18976
Epoch [24/25] Training [109/488] Loss: 0.12499
Epoch [24/25] Training [110/488] Loss: 0.18837
Epoch [24/25] Training [111/488] Loss: 0.13764
Epoch [24/25] Training [112/488] Loss: 0.19983
Epoch [24/25] Training [113/488] Loss: 0.12251
Epoch [24/25] Training [114/488] Loss: 0.53355
Epoch [24/25] Training [115/488] Loss: 0.14653
Epoch [24/25] Training [116/488] Loss: 0.19455
Epoch [24/25] Training [117/488] Loss: 0.13987
Epoch [24/25] Training [118/488] Loss: 0.39214
Epoch [24/25] Training [119/488] Loss: 0.13352
Epoch [24/25] Training [120/488] Loss: 0.45453
Epoch [24/25] Training [121/488] Loss: 0.14367
Epoch [24/25] Training [122/488] Loss: 0.50169
Epoch [24/25] Training [123/488] Loss: 0.24536
Epoch [24/25] Training [124/488] Loss: 0.18994
Epoch [24/25] Training [125/488] Loss: 0.20465
Epoch [24/25] Training [126/488] Loss: 0.19991
Epoch [24/25] Training [127/488] Loss: 0.21768
Epoch [24/25] Training [128/488] Loss: 0.23935
Epoch [24/25] Training [129/488] Loss: 0.40061
Epoch [24/25] Training [130/488] Loss: 0.10781
Epoch [24/25] Training [131/488] Loss: 0.36338
Epoch [24/25] Training [132/488] Loss: 0.71349
Epoch [24/25] Training [133/488] Loss: 0.24056
Epoch [24/25] Training [134/488] Loss: 0.34235
Epoch [24/25] Training [135/488] Loss: 0.13297
Epoch [24/25] Training [136/488] Loss: 0.25303
Epoch [24/25] Training [137/488] Loss: 0.15322
Epoch [24/25] Training [138/488] Loss: 0.11833
Epoch [24/25] Training [139/488] Loss: 0.22450
Epoch [24/25] Training [140/488] Loss: 0.13616
Epoch [24/25] Training [141/488] Loss: 0.21051
Epoch [24/25] Training [142/488] Loss: 0.14700
Epoch [24/25] Training [143/488] Loss: 0.30854
Epoch [24/25] Training [144/488] Loss: 0.16195
Epoch [24/25] Training [145/488] Loss: 0.16870
Epoch [24/25] Training [146/488] Loss: 0.14760
Epoch [24/25] Training [147/488] Loss: 0.17137
Epoch [24/25] Training [148/488] Loss: 0.20805
Epoch [24/25] Training [149/488] Loss: 0.24235
Epoch [24/25] Training [150/488] Loss: 0.13965
Epoch [24/25] Training [151/488] Loss: 0.14056
Epoch [24/25] Training [152/488] Loss: 0.10827
Epoch [24/25] Training [153/488] Loss: 0.42087
Epoch [24/25] Training [154/488] Loss: 0.15988
Epoch [24/25] Training [155/488] Loss: 0.29596
Epoch [24/25] Training [156/488] Loss: 0.13090
Epoch [24/25] Training [157/488] Loss: 0.29858
Epoch [24/25] Training [158/488] Loss: 0.13325
Epoch [24/25] Training [159/488] Loss: 0.32199
Epoch [24/25] Training [160/488] Loss: 0.49129
Epoch [24/25] Training [161/488] Loss: 0.22213
Epoch [24/25] Training [162/488] Loss: 0.16374
Epoch [24/25] Training [163/488] Loss: 0.23363
Epoch [24/25] Training [164/488] Loss: 0.18112
Epoch [24/25] Training [165/488] Loss: 0.30605
Epoch [24/25] Training [166/488] Loss: 0.12939
Epoch [24/25] Training [167/488] Loss: 0.71179
Epoch [24/25] Training [168/488] Loss: 0.18582
Epoch [24/25] Training [169/488] Loss: 0.29445
Epoch [24/25] Training [170/488] Loss: 0.14534
Epoch [24/25] Training [171/488] Loss: 0.20306
Epoch [24/25] Training [172/488] Loss: 0.24743
Epoch [24/25] Training [173/488] Loss: 0.13609
Epoch [24/25] Training [174/488] Loss: 0.11233
Epoch [24/25] Training [175/488] Loss: 0.12932
Epoch [24/25] Training [176/488] Loss: 0.23450
Epoch [24/25] Training [177/488] Loss: 0.18272
Epoch [24/25] Training [178/488] Loss: 0.12594
Epoch [24/25] Training [179/488] Loss: 0.13598
Epoch [24/25] Training [180/488] Loss: 0.34320
Epoch [24/25] Training [181/488] Loss: 0.15078
Epoch [24/25] Training [182/488] Loss: 0.14845
Epoch [24/25] Training [183/488] Loss: 0.19336
Epoch [24/25] Training [184/488] Loss: 0.14696
Epoch [24/25] Training [185/488] Loss: 0.17531
Epoch [24/25] Training [186/488] Loss: 0.11037
Epoch [24/25] Training [187/488] Loss: 0.15877
Epoch [24/25] Training [188/488] Loss: 0.25962
Epoch [24/25] Training [189/488] Loss: 0.32914
Epoch [24/25] Training [190/488] Loss: 0.12749
Epoch [24/25] Training [191/488] Loss: 0.17427
Epoch [24/25] Training [192/488] Loss: 0.21808
Epoch [24/25] Training [193/488] Loss: 0.28346
Epoch [24/25] Training [194/488] Loss: 0.19359
Epoch [24/25] Training [195/488] Loss: 0.26138
Epoch [24/25] Training [196/488] Loss: 0.11405
Epoch [24/25] Training [197/488] Loss: 0.12364
Epoch [24/25] Training [198/488] Loss: 0.15604
Epoch [24/25] Training [199/488] Loss: 0.15507
Epoch [24/25] Training [200/488] Loss: 0.24086
Epoch [24/25] Training [201/488] Loss: 0.13710
Epoch [24/25] Training [202/488] Loss: 0.22193
Epoch [24/25] Training [203/488] Loss: 0.13745
Epoch [24/25] Training [204/488] Loss: 0.28104
Epoch [24/25] Training [205/488] Loss: 0.13380
Epoch [24/25] Training [206/488] Loss: 0.13940
Epoch [24/25] Training [207/488] Loss: 0.21825
Epoch [24/25] Training [208/488] Loss: 0.46272
Epoch [24/25] Training [209/488] Loss: 0.22304
Epoch [24/25] Training [210/488] Loss: 0.15606
Epoch [24/25] Training [211/488] Loss: 0.16128
Epoch [24/25] Training [212/488] Loss: 0.19018
Epoch [24/25] Training [213/488] Loss: 0.19503
Epoch [24/25] Training [214/488] Loss: 0.13504
Epoch [24/25] Training [215/488] Loss: 0.19920
Epoch [24/25] Training [216/488] Loss: 0.17557
Epoch [24/25] Training [217/488] Loss: 0.22827
Epoch [24/25] Training [218/488] Loss: 0.12262
Epoch [24/25] Training [219/488] Loss: 0.17037
Epoch [24/25] Training [220/488] Loss: 0.16811
Epoch [24/25] Training [221/488] Loss: 0.14327
Epoch [24/25] Training [222/488] Loss: 0.13095
Epoch [24/25] Training [223/488] Loss: 0.18905
Epoch [24/25] Training [224/488] Loss: 0.14758
Epoch [24/25] Training [225/488] Loss: 0.17209
Epoch [24/25] Training [226/488] Loss: 0.22857
Epoch [24/25] Training [227/488] Loss: 0.15888
Epoch [24/25] Training [228/488] Loss: 0.10821
Epoch [24/25] Training [229/488] Loss: 0.17669
Epoch [24/25] Training [230/488] Loss: 0.13280
Epoch [24/25] Training [231/488] Loss: 0.22299
Epoch [24/25] Training [232/488] Loss: 0.26743
Epoch [24/25] Training [233/488] Loss: 0.22561
Epoch [24/25] Training [234/488] Loss: 0.29054
Epoch [24/25] Training [235/488] Loss: 0.30242
Epoch [24/25] Training [236/488] Loss: 0.14402
Epoch [24/25] Training [237/488] Loss: 0.12924
Epoch [24/25] Training [238/488] Loss: 0.16009
Epoch [24/25] Training [239/488] Loss: 0.11097
Epoch [24/25] Training [240/488] Loss: 0.24723
Epoch [24/25] Training [241/488] Loss: 0.19897
Epoch [24/25] Training [242/488] Loss: 0.17468
Epoch [24/25] Training [243/488] Loss: 0.16760
Epoch [24/25] Training [244/488] Loss: 0.36034
Epoch [24/25] Training [245/488] Loss: 0.39062
Epoch [24/25] Training [246/488] Loss: 0.27024
Epoch [24/25] Training [247/488] Loss: 0.12738
Epoch [24/25] Training [248/488] Loss: 0.11741
Epoch [24/25] Training [249/488] Loss: 0.14477
Epoch [24/25] Training [250/488] Loss: 0.14144
Epoch [24/25] Training [251/488] Loss: 0.13646
Epoch [24/25] Training [252/488] Loss: 0.63536
Epoch [24/25] Training [253/488] Loss: 0.40906
Epoch [24/25] Training [254/488] Loss: 0.24012
Epoch [24/25] Training [255/488] Loss: 0.15789
Epoch [24/25] Training [256/488] Loss: 0.22213
Epoch [24/25] Training [257/488] Loss: 0.33148
Epoch [24/25] Training [258/488] Loss: 0.15553
Epoch [24/25] Training [259/488] Loss: 0.15739
Epoch [24/25] Training [260/488] Loss: 0.29519
Epoch [24/25] Training [261/488] Loss: 0.16492
Epoch [24/25] Training [262/488] Loss: 0.15876
Epoch [24/25] Training [263/488] Loss: 0.50252
Epoch [24/25] Training [264/488] Loss: 0.25295
Epoch [24/25] Training [265/488] Loss: 0.20225
Epoch [24/25] Training [266/488] Loss: 0.15660
Epoch [24/25] Training [267/488] Loss: 0.40438
Epoch [24/25] Training [268/488] Loss: 0.15815
Epoch [24/25] Training [269/488] Loss: 0.23484
Epoch [24/25] Training [270/488] Loss: 0.19638
Epoch [24/25] Training [271/488] Loss: 0.12294
Epoch [24/25] Training [272/488] Loss: 0.12738
Epoch [24/25] Training [273/488] Loss: 0.12822
Epoch [24/25] Training [274/488] Loss: 0.48255
Epoch [24/25] Training [275/488] Loss: 0.14760
Epoch [24/25] Training [276/488] Loss: 0.21346
Epoch [24/25] Training [277/488] Loss: 0.16551
Epoch [24/25] Training [278/488] Loss: 0.11875
Epoch [24/25] Training [279/488] Loss: 0.29017
Epoch [24/25] Training [280/488] Loss: 0.23172
Epoch [24/25] Training [281/488] Loss: 0.15679
Epoch [24/25] Training [282/488] Loss: 0.60227
Epoch [24/25] Training [283/488] Loss: 0.11641
Epoch [24/25] Training [284/488] Loss: 0.19041
Epoch [24/25] Training [285/488] Loss: 0.19707
Epoch [24/25] Training [286/488] Loss: 0.11471
Epoch [24/25] Training [287/488] Loss: 0.10871
Epoch [24/25] Training [288/488] Loss: 0.12334
Epoch [24/25] Training [289/488] Loss: 0.17784
Epoch [24/25] Training [290/488] Loss: 0.15364
Epoch [24/25] Training [291/488] Loss: 0.22460
Epoch [24/25] Training [292/488] Loss: 0.35511
Epoch [24/25] Training [293/488] Loss: 0.14976
Epoch [24/25] Training [294/488] Loss: 0.14769
Epoch [24/25] Training [295/488] Loss: 0.23708
Epoch [24/25] Training [296/488] Loss: 0.18261
Epoch [24/25] Training [297/488] Loss: 0.13508
Epoch [24/25] Training [298/488] Loss: 0.11853
Epoch [24/25] Training [299/488] Loss: 0.12648
Epoch [24/25] Training [300/488] Loss: 0.13090
Epoch [24/25] Training [301/488] Loss: 0.13426
Epoch [24/25] Training [302/488] Loss: 0.13783
Epoch [24/25] Training [303/488] Loss: 0.23776
Epoch [24/25] Training [304/488] Loss: 0.16845
Epoch [24/25] Training [305/488] Loss: 0.42301
Epoch [24/25] Training [306/488] Loss: 0.12613
Epoch [24/25] Training [307/488] Loss: 0.70625
Epoch [24/25] Training [308/488] Loss: 0.16818
Epoch [24/25] Training [309/488] Loss: 0.31240
Epoch [24/25] Training [310/488] Loss: 0.19129
Epoch [24/25] Training [311/488] Loss: 0.14066
Epoch [24/25] Training [312/488] Loss: 0.13323
Epoch [24/25] Training [313/488] Loss: 0.11456
Epoch [24/25] Training [314/488] Loss: 0.19917
Epoch [24/25] Training [315/488] Loss: 0.09696
Epoch [24/25] Training [316/488] Loss: 0.20247
Epoch [24/25] Training [317/488] Loss: 0.25996
Epoch [24/25] Training [318/488] Loss: 0.13577
Epoch [24/25] Training [319/488] Loss: 0.16098
Epoch [24/25] Training [320/488] Loss: 0.12534
Epoch [24/25] Training [321/488] Loss: 0.17268
Epoch [24/25] Training [322/488] Loss: 0.11019
Epoch [24/25] Training [323/488] Loss: 0.35448
Epoch [24/25] Training [324/488] Loss: 0.28504
Epoch [24/25] Training [325/488] Loss: 0.24495
Epoch [24/25] Training [326/488] Loss: 0.17689
Epoch [24/25] Training [327/488] Loss: 0.25106
Epoch [24/25] Training [328/488] Loss: 0.22373
Epoch [24/25] Training [329/488] Loss: 0.21309
Epoch [24/25] Training [330/488] Loss: 0.32777
Epoch [24/25] Training [331/488] Loss: 0.12462
Epoch [24/25] Training [332/488] Loss: 0.11921
Epoch [24/25] Training [333/488] Loss: 0.24029
Epoch [24/25] Training [334/488] Loss: 0.29110
Epoch [24/25] Training [335/488] Loss: 0.20699
Epoch [24/25] Training [336/488] Loss: 0.14919
Epoch [24/25] Training [337/488] Loss: 0.45026
Epoch [24/25] Training [338/488] Loss: 0.19183
Epoch [24/25] Training [339/488] Loss: 0.16875
Epoch [24/25] Training [340/488] Loss: 0.14909
Epoch [24/25] Training [341/488] Loss: 0.10535
Epoch [24/25] Training [342/488] Loss: 0.23837
Epoch [24/25] Training [343/488] Loss: 0.12824
Epoch [24/25] Training [344/488] Loss: 0.13517
Epoch [24/25] Training [345/488] Loss: 0.15266
Epoch [24/25] Training [346/488] Loss: 0.21242
Epoch [24/25] Training [347/488] Loss: 0.18688
Epoch [24/25] Training [348/488] Loss: 0.19506
Epoch [24/25] Training [349/488] Loss: 0.17444
Epoch [24/25] Training [350/488] Loss: 0.12440
Epoch [24/25] Training [351/488] Loss: 0.13633
Epoch [24/25] Training [352/488] Loss: 0.50571
Epoch [24/25] Training [353/488] Loss: 0.11059
Epoch [24/25] Training [354/488] Loss: 0.13711
Epoch [24/25] Training [355/488] Loss: 0.30911
Epoch [24/25] Training [356/488] Loss: 0.17496
Epoch [24/25] Training [357/488] Loss: 0.33044
Epoch [24/25] Training [358/488] Loss: 0.13746
Epoch [24/25] Training [359/488] Loss: 0.19496
Epoch [24/25] Training [360/488] Loss: 0.38316
Epoch [24/25] Training [361/488] Loss: 0.13599
Epoch [24/25] Training [362/488] Loss: 0.39515
Epoch [24/25] Training [363/488] Loss: 0.13200
Epoch [24/25] Training [364/488] Loss: 0.35346
Epoch [24/25] Training [365/488] Loss: 0.21424
Epoch [24/25] Training [366/488] Loss: 0.17922
Epoch [24/25] Training [367/488] Loss: 0.21001
Epoch [24/25] Training [368/488] Loss: 0.17877
Epoch [24/25] Training [369/488] Loss: 0.12576
Epoch [24/25] Training [370/488] Loss: 0.11198
Epoch [24/25] Training [371/488] Loss: 0.16329
Epoch [24/25] Training [372/488] Loss: 0.27249
Epoch [24/25] Training [373/488] Loss: 0.12732
Epoch [24/25] Training [374/488] Loss: 0.23947
Epoch [24/25] Training [375/488] Loss: 0.56141
Epoch [24/25] Training [376/488] Loss: 0.14425
Epoch [24/25] Training [377/488] Loss: 0.22120
Epoch [24/25] Training [378/488] Loss: 0.29433
Epoch [24/25] Training [379/488] Loss: 0.30250
Epoch [24/25] Training [380/488] Loss: 0.14195
Epoch [24/25] Training [381/488] Loss: 0.23043
Epoch [24/25] Training [382/488] Loss: 0.14858
Epoch [24/25] Training [383/488] Loss: 0.24738
Epoch [24/25] Training [384/488] Loss: 0.13168
Epoch [24/25] Training [385/488] Loss: 0.18562
Epoch [24/25] Training [386/488] Loss: 0.11026
Epoch [24/25] Training [387/488] Loss: 0.23793
Epoch [24/25] Training [388/488] Loss: 0.10590
Epoch [24/25] Training [389/488] Loss: 0.16054
Epoch [24/25] Training [390/488] Loss: 0.37506
Epoch [24/25] Training [391/488] Loss: 0.14027
Epoch [24/25] Training [392/488] Loss: 0.14349
Epoch [24/25] Training [393/488] Loss: 0.12697
Epoch [24/25] Training [394/488] Loss: 0.37688
Epoch [24/25] Training [395/488] Loss: 0.23215
Epoch [24/25] Training [396/488] Loss: 0.09795
Epoch [24/25] Training [397/488] Loss: 0.41844
Epoch [24/25] Training [398/488] Loss: 0.15242
Epoch [24/25] Training [399/488] Loss: 0.29965
Epoch [24/25] Training [400/488] Loss: 0.15028
Epoch [24/25] Training [401/488] Loss: 0.17116
Epoch [24/25] Training [402/488] Loss: 0.50499
Epoch [24/25] Training [403/488] Loss: 0.14128
Epoch [24/25] Training [404/488] Loss: 0.17056
Epoch [24/25] Training [405/488] Loss: 0.24466
Epoch [24/25] Training [406/488] Loss: 0.18496
Epoch [24/25] Training [407/488] Loss: 0.28767
Epoch [24/25] Training [408/488] Loss: 0.35545
Epoch [24/25] Training [409/488] Loss: 0.14809
Epoch [24/25] Training [410/488] Loss: 0.15931
Epoch [24/25] Training [411/488] Loss: 0.16067
Epoch [24/25] Training [412/488] Loss: 0.13913
Epoch [24/25] Training [413/488] Loss: 0.20483
Epoch [24/25] Training [414/488] Loss: 0.12487
Epoch [24/25] Training [415/488] Loss: 0.13144
Epoch [24/25] Training [416/488] Loss: 0.12078
Epoch [24/25] Training [417/488] Loss: 0.47242
Epoch [24/25] Training [418/488] Loss: 0.30232
Epoch [24/25] Training [419/488] Loss: 0.13769
Epoch [24/25] Training [420/488] Loss: 0.11986
Epoch [24/25] Training [421/488] Loss: 0.18079
Epoch [24/25] Training [422/488] Loss: 0.39216
Epoch [24/25] Training [423/488] Loss: 0.16867
Epoch [24/25] Training [424/488] Loss: 0.13728
Epoch [24/25] Training [425/488] Loss: 0.29540
Epoch [24/25] Training [426/488] Loss: 0.16923
Epoch [24/25] Training [427/488] Loss: 0.11859
Epoch [24/25] Training [428/488] Loss: 0.34155
Epoch [24/25] Training [429/488] Loss: 0.17783
Epoch [24/25] Training [430/488] Loss: 0.17129
Epoch [24/25] Training [431/488] Loss: 0.15321
Epoch [24/25] Training [432/488] Loss: 0.13091
Epoch [24/25] Training [433/488] Loss: 0.11008
Epoch [24/25] Training [434/488] Loss: 0.10079
Epoch [24/25] Training [435/488] Loss: 0.47014
Epoch [24/25] Training [436/488] Loss: 0.10235
Epoch [24/25] Training [437/488] Loss: 0.28971
Epoch [24/25] Training [438/488] Loss: 0.23183
Epoch [24/25] Training [439/488] Loss: 0.17932
Epoch [24/25] Training [440/488] Loss: 0.32386
Epoch [24/25] Training [441/488] Loss: 0.32460
Epoch [24/25] Training [442/488] Loss: 0.16724
Epoch [24/25] Training [443/488] Loss: 0.17236
Epoch [24/25] Training [444/488] Loss: 0.39305
Epoch [24/25] Training [445/488] Loss: 0.17760
Epoch [24/25] Training [446/488] Loss: 0.13235
Epoch [24/25] Training [447/488] Loss: 0.13102
Epoch [24/25] Training [448/488] Loss: 0.11920
Epoch [24/25] Training [449/488] Loss: 0.29180
Epoch [24/25] Training [450/488] Loss: 0.13635
Epoch [24/25] Training [451/488] Loss: 0.12976
Epoch [24/25] Training [452/488] Loss: 0.12498
Epoch [24/25] Training [453/488] Loss: 0.16474
Epoch [24/25] Training [454/488] Loss: 0.41737
Epoch [24/25] Training [455/488] Loss: 0.14681
Epoch [24/25] Training [456/488] Loss: 0.20127
Epoch [24/25] Training [457/488] Loss: 0.13479
Epoch [24/25] Training [458/488] Loss: 0.14848
Epoch [24/25] Training [459/488] Loss: 0.11243
Epoch [24/25] Training [460/488] Loss: 0.10880
Epoch [24/25] Training [461/488] Loss: 0.11726
Epoch [24/25] Training [462/488] Loss: 0.16446
Epoch [24/25] Training [463/488] Loss: 0.22749
Epoch [24/25] Training [464/488] Loss: 0.13800
Epoch [24/25] Training [465/488] Loss: 0.15635
Epoch [24/25] Training [466/488] Loss: 0.13223
Epoch [24/25] Training [467/488] Loss: 0.11772
Epoch [24/25] Training [468/488] Loss: 0.30447
Epoch [24/25] Training [469/488] Loss: 0.11626
Epoch [24/25] Training [470/488] Loss: 0.38097
Epoch [24/25] Training [471/488] Loss: 0.24857
Epoch [24/25] Training [472/488] Loss: 0.12375
Epoch [24/25] Training [473/488] Loss: 0.11013
Epoch [24/25] Training [474/488] Loss: 0.17876
Epoch [24/25] Training [475/488] Loss: 0.16950
Epoch [24/25] Training [476/488] Loss: 0.14728
Epoch [24/25] Training [477/488] Loss: 0.18878
Epoch [24/25] Training [478/488] Loss: 0.31178
Epoch [24/25] Training [479/488] Loss: 0.13096
Epoch [24/25] Training [480/488] Loss: 0.13431
Epoch [24/25] Training [481/488] Loss: 0.13349
Epoch [24/25] Training [482/488] Loss: 0.11140
Epoch [24/25] Training [483/488] Loss: 0.18761
Epoch [24/25] Training [484/488] Loss: 0.14971
Epoch [24/25] Training [485/488] Loss: 0.17553
Epoch [24/25] Training [486/488] Loss: 0.16706
Epoch [24/25] Training [487/488] Loss: 0.16314
Epoch [24/25] Training [488/488] Loss: 0.13759
Epoch [24/25] Training metric {'Train/mean dice_metric': 0.9015452265739441, 'Train/TC dice_metric': 0.9261516332626343, 'Train/WT dice_metric': 0.9431659579277039, 'Train/ET dice_metric': 0.8353179693222046}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [24/25] Validation [1/123] Loss: 0.20201  focal_loss 0.00164  dice_loss 0.20037
Epoch [24/25] Validation [2/123] Loss: 0.38429  focal_loss 0.00189  dice_loss 0.38240
Epoch [24/25] Validation [3/123] Loss: 0.18428  focal_loss 0.00129  dice_loss 0.18299
Epoch [24/25] Validation [4/123] Loss: 0.27219  focal_loss 0.00147  dice_loss 0.27073
Epoch [24/25] Validation [5/123] Loss: 0.35364  focal_loss 0.01020  dice_loss 0.34344
Epoch [24/25] Validation [6/123] Loss: 0.36304  focal_loss 0.00252  dice_loss 0.36052
Epoch [24/25] Validation [7/123] Loss: 0.35669  focal_loss 0.00058  dice_loss 0.35611
Epoch [24/25] Validation [8/123] Loss: 0.34177  focal_loss 0.00125  dice_loss 0.34053
Epoch [24/25] Validation [9/123] Loss: 0.27158  focal_loss 0.00142  dice_loss 0.27016
Epoch [24/25] Validation [10/123] Loss: 0.48249  focal_loss 0.00299  dice_loss 0.47951
Epoch [24/25] Validation [11/123] Loss: 0.50470  focal_loss 0.00237  dice_loss 0.50233
Epoch [24/25] Validation [12/123] Loss: 0.21090  focal_loss 0.00121  dice_loss 0.20969
Epoch [24/25] Validation [13/123] Loss: 0.19943  focal_loss 0.00268  dice_loss 0.19674
Epoch [24/25] Validation [14/123] Loss: 0.24120  focal_loss 0.00132  dice_loss 0.23988
Epoch [24/25] Validation [15/123] Loss: 0.36148  focal_loss 0.00150  dice_loss 0.35998
Epoch [24/25] Validation [16/123] Loss: 0.45564  focal_loss 0.00203  dice_loss 0.45361
Epoch [24/25] Validation [17/123] Loss: 0.49252  focal_loss 0.00168  dice_loss 0.49084
Epoch [24/25] Validation [18/123] Loss: 0.32966  focal_loss 0.00231  dice_loss 0.32735
Epoch [24/25] Validation [19/123] Loss: 0.28667  focal_loss 0.00258  dice_loss 0.28409
Epoch [24/25] Validation [20/123] Loss: 0.45340  focal_loss 0.00070  dice_loss 0.45271
Epoch [24/25] Validation [21/123] Loss: 0.33097  focal_loss 0.00076  dice_loss 0.33021
Epoch [24/25] Validation [22/123] Loss: 0.61744  focal_loss 0.00831  dice_loss 0.60913
Epoch [24/25] Validation [23/123] Loss: 0.19500  focal_loss 0.00126  dice_loss 0.19374
Epoch [24/25] Validation [24/123] Loss: 0.29917  focal_loss 0.00299  dice_loss 0.29618
Epoch [24/25] Validation [25/123] Loss: 0.36440  focal_loss 0.00462  dice_loss 0.35979
Epoch [24/25] Validation [26/123] Loss: 0.20322  focal_loss 0.00113  dice_loss 0.20210
Epoch [24/25] Validation [27/123] Loss: 0.24377  focal_loss 0.00236  dice_loss 0.24141
Epoch [24/25] Validation [28/123] Loss: 0.52171  focal_loss 0.00403  dice_loss 0.51768
Epoch [24/25] Validation [29/123] Loss: 0.34362  focal_loss 0.00160  dice_loss 0.34203
Epoch [24/25] Validation [30/123] Loss: 0.25031  focal_loss 0.00344  dice_loss 0.24687
Epoch [24/25] Validation [31/123] Loss: 0.19599  focal_loss 0.00111  dice_loss 0.19487
Epoch [24/25] Validation [32/123] Loss: 0.31348  focal_loss 0.00377  dice_loss 0.30972
Epoch [24/25] Validation [33/123] Loss: 0.35598  focal_loss 0.00180  dice_loss 0.35418
Epoch [24/25] Validation [34/123] Loss: 0.30670  focal_loss 0.00205  dice_loss 0.30465
Epoch [24/25] Validation [35/123] Loss: 0.22903  focal_loss 0.00091  dice_loss 0.22812
Epoch [24/25] Validation [36/123] Loss: 0.26256  focal_loss 0.00079  dice_loss 0.26177
Epoch [24/25] Validation [37/123] Loss: 0.37410  focal_loss 0.00310  dice_loss 0.37100
Epoch [24/25] Validation [38/123] Loss: 0.21978  focal_loss 0.00117  dice_loss 0.21861
Epoch [24/25] Validation [39/123] Loss: 0.20868  focal_loss 0.00114  dice_loss 0.20754
Epoch [24/25] Validation [40/123] Loss: 0.31460  focal_loss 0.00078  dice_loss 0.31382
Epoch [24/25] Validation [41/123] Loss: 0.21639  focal_loss 0.00226  dice_loss 0.21413
Epoch [24/25] Validation [42/123] Loss: 0.18840  focal_loss 0.00091  dice_loss 0.18749
Epoch [24/25] Validation [43/123] Loss: 0.28878  focal_loss 0.01138  dice_loss 0.27740
Epoch [24/25] Validation [44/123] Loss: 0.58162  focal_loss 0.00702  dice_loss 0.57460
Epoch [24/25] Validation [45/123] Loss: 0.30557  focal_loss 0.00107  dice_loss 0.30451
Epoch [24/25] Validation [46/123] Loss: 0.33432  focal_loss 0.00224  dice_loss 0.33208
Epoch [24/25] Validation [47/123] Loss: 0.30286  focal_loss 0.00139  dice_loss 0.30147
Epoch [24/25] Validation [48/123] Loss: 0.45358  focal_loss 0.00628  dice_loss 0.44730
Epoch [24/25] Validation [49/123] Loss: 0.21185  focal_loss 0.00108  dice_loss 0.21077
Epoch [24/25] Validation [50/123] Loss: 0.20692  focal_loss 0.00161  dice_loss 0.20531
Epoch [24/25] Validation [51/123] Loss: 0.40569  focal_loss 0.01095  dice_loss 0.39475
Epoch [24/25] Validation [52/123] Loss: 0.22652  focal_loss 0.00073  dice_loss 0.22579
Epoch [24/25] Validation [53/123] Loss: 0.28775  focal_loss 0.00082  dice_loss 0.28694
Epoch [24/25] Validation [54/123] Loss: 0.33585  focal_loss 0.00116  dice_loss 0.33469
Epoch [24/25] Validation [55/123] Loss: 0.28571  focal_loss 0.00127  dice_loss 0.28444
Epoch [24/25] Validation [56/123] Loss: 0.23574  focal_loss 0.00287  dice_loss 0.23288
Epoch [24/25] Validation [57/123] Loss: 0.29608  focal_loss 0.00120  dice_loss 0.29488
Epoch [24/25] Validation [58/123] Loss: 0.25869  focal_loss 0.00196  dice_loss 0.25673
Epoch [24/25] Validation [59/123] Loss: 0.64612  focal_loss 0.00980  dice_loss 0.63632
Epoch [24/25] Validation [60/123] Loss: 0.25397  focal_loss 0.00284  dice_loss 0.25114
Epoch [24/25] Validation [61/123] Loss: 0.59843  focal_loss 0.00152  dice_loss 0.59691
Epoch [24/25] Validation [62/123] Loss: 0.49687  focal_loss 0.00746  dice_loss 0.48941
Epoch [24/25] Validation [63/123] Loss: 0.38460  focal_loss 0.00156  dice_loss 0.38304
Epoch [24/25] Validation [64/123] Loss: 0.39405  focal_loss 0.00721  dice_loss 0.38683
Epoch [24/25] Validation [65/123] Loss: 0.23639  focal_loss 0.00089  dice_loss 0.23550
Epoch [24/25] Validation [66/123] Loss: 0.24784  focal_loss 0.00120  dice_loss 0.24665
Epoch [24/25] Validation [67/123] Loss: 0.41519  focal_loss 0.00826  dice_loss 0.40693
Epoch [24/25] Validation [68/123] Loss: 0.36582  focal_loss 0.00103  dice_loss 0.36479
Epoch [24/25] Validation [69/123] Loss: 0.40162  focal_loss 0.00785  dice_loss 0.39378
Epoch [24/25] Validation [70/123] Loss: 0.32531  focal_loss 0.00201  dice_loss 0.32329
Epoch [24/25] Validation [71/123] Loss: 0.22801  focal_loss 0.00074  dice_loss 0.22727
Epoch [24/25] Validation [72/123] Loss: 0.20523  focal_loss 0.00108  dice_loss 0.20415
Epoch [24/25] Validation [73/123] Loss: 0.32988  focal_loss 0.00457  dice_loss 0.32531
Epoch [24/25] Validation [74/123] Loss: 0.34747  focal_loss 0.00509  dice_loss 0.34237
Epoch [24/25] Validation [75/123] Loss: 0.26267  focal_loss 0.00109  dice_loss 0.26157
Epoch [24/25] Validation [76/123] Loss: 0.51325  focal_loss 0.00637  dice_loss 0.50688
Epoch [24/25] Validation [77/123] Loss: 0.37747  focal_loss 0.00128  dice_loss 0.37618
Epoch [24/25] Validation [78/123] Loss: 0.27580  focal_loss 0.00152  dice_loss 0.27428
Epoch [24/25] Validation [79/123] Loss: 0.31851  focal_loss 0.00133  dice_loss 0.31717
Epoch [24/25] Validation [80/123] Loss: 0.21860  focal_loss 0.00200  dice_loss 0.21660
Epoch [24/25] Validation [81/123] Loss: 0.26338  focal_loss 0.00171  dice_loss 0.26167
Epoch [24/25] Validation [82/123] Loss: 0.21077  focal_loss 0.00064  dice_loss 0.21013
Epoch [24/25] Validation [83/123] Loss: 0.37560  focal_loss 0.01065  dice_loss 0.36495
Epoch [24/25] Validation [84/123] Loss: 0.26121  focal_loss 0.00123  dice_loss 0.25999
Epoch [24/25] Validation [85/123] Loss: 0.36690  focal_loss 0.00808  dice_loss 0.35882
Epoch [24/25] Validation [86/123] Loss: 0.23174  focal_loss 0.00113  dice_loss 0.23061
Epoch [24/25] Validation [87/123] Loss: 0.22176  focal_loss 0.00228  dice_loss 0.21948
Epoch [24/25] Validation [88/123] Loss: 0.24679  focal_loss 0.00167  dice_loss 0.24511
Epoch [24/25] Validation [89/123] Loss: 0.20163  focal_loss 0.00160  dice_loss 0.20004
Epoch [24/25] Validation [90/123] Loss: 0.30790  focal_loss 0.00206  dice_loss 0.30584
Epoch [24/25] Validation [91/123] Loss: 0.23291  focal_loss 0.00098  dice_loss 0.23192
Epoch [24/25] Validation [92/123] Loss: 0.19321  focal_loss 0.00094  dice_loss 0.19227
Epoch [24/25] Validation [93/123] Loss: 0.21185  focal_loss 0.00116  dice_loss 0.21068
Epoch [24/25] Validation [94/123] Loss: 0.34360  focal_loss 0.00174  dice_loss 0.34186
Epoch [24/25] Validation [95/123] Loss: 0.25529  focal_loss 0.00220  dice_loss 0.25309
Epoch [24/25] Validation [96/123] Loss: 0.35108  focal_loss 0.00273  dice_loss 0.34835
Epoch [24/25] Validation [97/123] Loss: 0.62644  focal_loss 0.01179  dice_loss 0.61464
Epoch [24/25] Validation [98/123] Loss: 0.33052  focal_loss 0.00141  dice_loss 0.32911
Epoch [24/25] Validation [99/123] Loss: 0.32049  focal_loss 0.00068  dice_loss 0.31981
Epoch [24/25] Validation [100/123] Loss: 0.34574  focal_loss 0.00103  dice_loss 0.34471
Epoch [24/25] Validation [101/123] Loss: 0.30489  focal_loss 0.00152  dice_loss 0.30338
Epoch [24/25] Validation [102/123] Loss: 0.33614  focal_loss 0.00060  dice_loss 0.33554
Epoch [24/25] Validation [103/123] Loss: 0.46970  focal_loss 0.00106  dice_loss 0.46864
Epoch [24/25] Validation [104/123] Loss: 0.42094  focal_loss 0.00566  dice_loss 0.41529
Epoch [24/25] Validation [105/123] Loss: 0.20212  focal_loss 0.00239  dice_loss 0.19973
Epoch [24/25] Validation [106/123] Loss: 0.23528  focal_loss 0.00083  dice_loss 0.23445
Epoch [24/25] Validation [107/123] Loss: 0.54318  focal_loss 0.00362  dice_loss 0.53956
Epoch [24/25] Validation [108/123] Loss: 0.22693  focal_loss 0.00044  dice_loss 0.22650
Epoch [24/25] Validation [109/123] Loss: 0.21217  focal_loss 0.00409  dice_loss 0.20809
Epoch [24/25] Validation [110/123] Loss: 0.36015  focal_loss 0.00264  dice_loss 0.35751
Epoch [24/25] Validation [111/123] Loss: 0.38431  focal_loss 0.00356  dice_loss 0.38074
Epoch [24/25] Validation [112/123] Loss: 0.31562  focal_loss 0.00062  dice_loss 0.31500
Epoch [24/25] Validation [113/123] Loss: 0.27969  focal_loss 0.00172  dice_loss 0.27796
Epoch [24/25] Validation [114/123] Loss: 0.32244  focal_loss 0.00460  dice_loss 0.31784
Epoch [24/25] Validation [115/123] Loss: 0.27878  focal_loss 0.00483  dice_loss 0.27396
Epoch [24/25] Validation [116/123] Loss: 0.26128  focal_loss 0.00047  dice_loss 0.26082
Epoch [24/25] Validation [117/123] Loss: 0.27454  focal_loss 0.00109  dice_loss 0.27345
Epoch [24/25] Validation [118/123] Loss: 0.17871  focal_loss 0.00145  dice_loss 0.17726
Epoch [24/25] Validation [119/123] Loss: 0.20851  focal_loss 0.00104  dice_loss 0.20748
Epoch [24/25] Validation [120/123] Loss: 0.24072  focal_loss 0.00163  dice_loss 0.23909
Epoch [24/25] Validation [121/123] Loss: 0.64321  focal_loss 0.01891  dice_loss 0.62430
Epoch [24/25] Validation [122/123] Loss: 0.55000  focal_loss 0.00038  dice_loss 0.54962
Epoch [24/25] Validation [123/123] Loss: 0.23322  focal_loss 0.00119  dice_loss 0.23202
Epoch [24/25] Validation metric {'Val/mean dice_metric': 0.8987221717834473, 'Val/TC dice_metric': 0.9216349720954895, 'Val/WT dice_metric': 0.9408448934555054, 'Val/ET dice_metric': 0.8336867690086365}
Epoch [24/25] lr = [2.4471741852423235e-05, 2.4471741852423235e-05] best acc: tensor([0.8978], device='cuda:0'), mean acc: tensor([0.8987], device='cuda:0'), mean class: tensor([0.9216, 0.9408, 0.8337], device='cuda:0')
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [25/25] Training [1/488] Loss: 0.17673
Epoch [25/25] Training [2/488] Loss: 0.17470
Epoch [25/25] Training [3/488] Loss: 0.13388
Epoch [25/25] Training [4/488] Loss: 0.17342
Epoch [25/25] Training [5/488] Loss: 0.39829
Epoch [25/25] Training [6/488] Loss: 0.15217
Epoch [25/25] Training [7/488] Loss: 0.12378
Epoch [25/25] Training [8/488] Loss: 0.46702
Epoch [25/25] Training [9/488] Loss: 0.50342
Epoch [25/25] Training [10/488] Loss: 0.12238
Epoch [25/25] Training [11/488] Loss: 0.16576
Epoch [25/25] Training [12/488] Loss: 0.15116
Epoch [25/25] Training [13/488] Loss: 0.16093
Epoch [25/25] Training [14/488] Loss: 0.47507
Epoch [25/25] Training [15/488] Loss: 0.16551
Epoch [25/25] Training [16/488] Loss: 0.16540
Epoch [25/25] Training [17/488] Loss: 0.31655
Epoch [25/25] Training [18/488] Loss: 0.21723
Epoch [25/25] Training [19/488] Loss: 0.13564
Epoch [25/25] Training [20/488] Loss: 0.11596
Epoch [25/25] Training [21/488] Loss: 0.12597
Epoch [25/25] Training [22/488] Loss: 0.12740
Epoch [25/25] Training [23/488] Loss: 0.22779
Epoch [25/25] Training [24/488] Loss: 0.12432
Epoch [25/25] Training [25/488] Loss: 0.11168
Epoch [25/25] Training [26/488] Loss: 0.26651
Epoch [25/25] Training [27/488] Loss: 0.41748
Epoch [25/25] Training [28/488] Loss: 0.37868
Epoch [25/25] Training [29/488] Loss: 0.10997
Epoch [25/25] Training [30/488] Loss: 0.24508
Epoch [25/25] Training [31/488] Loss: 0.14640
Epoch [25/25] Training [32/488] Loss: 0.48537
Epoch [25/25] Training [33/488] Loss: 0.17186
Epoch [25/25] Training [34/488] Loss: 0.11784
Epoch [25/25] Training [35/488] Loss: 0.14741
Epoch [25/25] Training [36/488] Loss: 0.29961
Epoch [25/25] Training [37/488] Loss: 0.14208
Epoch [25/25] Training [38/488] Loss: 0.15259
Epoch [25/25] Training [39/488] Loss: 0.23573
Epoch [25/25] Training [40/488] Loss: 0.13846
Epoch [25/25] Training [41/488] Loss: 0.11779
Epoch [25/25] Training [42/488] Loss: 0.11806
Epoch [25/25] Training [43/488] Loss: 0.20263
Epoch [25/25] Training [44/488] Loss: 0.22888
Epoch [25/25] Training [45/488] Loss: 0.13045
Epoch [25/25] Training [46/488] Loss: 0.38431
Epoch [25/25] Training [47/488] Loss: 0.22824
Epoch [25/25] Training [48/488] Loss: 0.16572
Epoch [25/25] Training [49/488] Loss: 0.15695
Epoch [25/25] Training [50/488] Loss: 0.21462
Epoch [25/25] Training [51/488] Loss: 0.17171
Epoch [25/25] Training [52/488] Loss: 0.25010
Epoch [25/25] Training [53/488] Loss: 0.23484
Epoch [25/25] Training [54/488] Loss: 0.10145
Epoch [25/25] Training [55/488] Loss: 0.12214
Epoch [25/25] Training [56/488] Loss: 0.14272
Epoch [25/25] Training [57/488] Loss: 0.14969
Epoch [25/25] Training [58/488] Loss: 0.41502
Epoch [25/25] Training [59/488] Loss: 0.28949
Epoch [25/25] Training [60/488] Loss: 0.21127
Epoch [25/25] Training [61/488] Loss: 0.50150
Epoch [25/25] Training [62/488] Loss: 0.13727
Epoch [25/25] Training [63/488] Loss: 0.13077
Epoch [25/25] Training [64/488] Loss: 0.25028
Epoch [25/25] Training [65/488] Loss: 0.24907
Epoch [25/25] Training [66/488] Loss: 0.34176
Epoch [25/25] Training [67/488] Loss: 0.20090
Epoch [25/25] Training [68/488] Loss: 0.16164
Epoch [25/25] Training [69/488] Loss: 0.16347
Epoch [25/25] Training [70/488] Loss: 0.71135
Epoch [25/25] Training [71/488] Loss: 0.12388
Epoch [25/25] Training [72/488] Loss: 0.17329
Epoch [25/25] Training [73/488] Loss: 0.13487
Epoch [25/25] Training [74/488] Loss: 0.21482
Epoch [25/25] Training [75/488] Loss: 0.12376
Epoch [25/25] Training [76/488] Loss: 0.12143
Epoch [25/25] Training [77/488] Loss: 0.19102
Epoch [25/25] Training [78/488] Loss: 0.18939
Epoch [25/25] Training [79/488] Loss: 0.18130
Epoch [25/25] Training [80/488] Loss: 0.15613
Epoch [25/25] Training [81/488] Loss: 0.18706
Epoch [25/25] Training [82/488] Loss: 0.13037
Epoch [25/25] Training [83/488] Loss: 0.14466
Epoch [25/25] Training [84/488] Loss: 0.14438
Epoch [25/25] Training [85/488] Loss: 0.27356
Epoch [25/25] Training [86/488] Loss: 0.23480
Epoch [25/25] Training [87/488] Loss: 0.12595
Epoch [25/25] Training [88/488] Loss: 0.20318
Epoch [25/25] Training [89/488] Loss: 0.18402
Epoch [25/25] Training [90/488] Loss: 0.16054
Epoch [25/25] Training [91/488] Loss: 0.12061
Epoch [25/25] Training [92/488] Loss: 0.14326
Epoch [25/25] Training [93/488] Loss: 0.13684
Epoch [25/25] Training [94/488] Loss: 0.15969
Epoch [25/25] Training [95/488] Loss: 0.11758
Epoch [25/25] Training [96/488] Loss: 0.13049
Epoch [25/25] Training [97/488] Loss: 0.20800
Epoch [25/25] Training [98/488] Loss: 0.09658
Epoch [25/25] Training [99/488] Loss: 0.10935
Epoch [25/25] Training [100/488] Loss: 0.14309
Epoch [25/25] Training [101/488] Loss: 0.14520
Epoch [25/25] Training [102/488] Loss: 0.58324
Epoch [25/25] Training [103/488] Loss: 0.28503
Epoch [25/25] Training [104/488] Loss: 0.13329
Epoch [25/25] Training [105/488] Loss: 0.13202
Epoch [25/25] Training [106/488] Loss: 0.36558
Epoch [25/25] Training [107/488] Loss: 0.11008
Epoch [25/25] Training [108/488] Loss: 0.19031
Epoch [25/25] Training [109/488] Loss: 0.32818
Epoch [25/25] Training [110/488] Loss: 0.31236
Epoch [25/25] Training [111/488] Loss: 0.13396
Epoch [25/25] Training [112/488] Loss: 0.15680
Epoch [25/25] Training [113/488] Loss: 0.10054
Epoch [25/25] Training [114/488] Loss: 0.14893
Epoch [25/25] Training [115/488] Loss: 0.13416
Epoch [25/25] Training [116/488] Loss: 0.23263
Epoch [25/25] Training [117/488] Loss: 0.19604
Epoch [25/25] Training [118/488] Loss: 0.30459
Epoch [25/25] Training [119/488] Loss: 0.11948
Epoch [25/25] Training [120/488] Loss: 0.15407
Epoch [25/25] Training [121/488] Loss: 0.16184
Epoch [25/25] Training [122/488] Loss: 0.14603
Epoch [25/25] Training [123/488] Loss: 0.14610
Epoch [25/25] Training [124/488] Loss: 0.23987
Epoch [25/25] Training [125/488] Loss: 0.13985
Epoch [25/25] Training [126/488] Loss: 0.30199
Epoch [25/25] Training [127/488] Loss: 0.19409
Epoch [25/25] Training [128/488] Loss: 0.38049
Epoch [25/25] Training [129/488] Loss: 0.19466
Epoch [25/25] Training [130/488] Loss: 0.12617
Epoch [25/25] Training [131/488] Loss: 0.10612
Epoch [25/25] Training [132/488] Loss: 0.31655
Epoch [25/25] Training [133/488] Loss: 0.11281
Epoch [25/25] Training [134/488] Loss: 0.29643
Epoch [25/25] Training [135/488] Loss: 0.29729
Epoch [25/25] Training [136/488] Loss: 0.18109
Epoch [25/25] Training [137/488] Loss: 0.34099
Epoch [25/25] Training [138/488] Loss: 0.29868
Epoch [25/25] Training [139/488] Loss: 0.12496
Epoch [25/25] Training [140/488] Loss: 0.38944
Epoch [25/25] Training [141/488] Loss: 0.13420
Epoch [25/25] Training [142/488] Loss: 0.21628
Epoch [25/25] Training [143/488] Loss: 0.39873
Epoch [25/25] Training [144/488] Loss: 0.16377
Epoch [25/25] Training [145/488] Loss: 0.15259
Epoch [25/25] Training [146/488] Loss: 0.19160
Epoch [25/25] Training [147/488] Loss: 0.17692
Epoch [25/25] Training [148/488] Loss: 0.19365
Epoch [25/25] Training [149/488] Loss: 0.12079
Epoch [25/25] Training [150/488] Loss: 0.24845
Epoch [25/25] Training [151/488] Loss: 0.14993
Epoch [25/25] Training [152/488] Loss: 0.17185
Epoch [25/25] Training [153/488] Loss: 0.37463
Epoch [25/25] Training [154/488] Loss: 0.12326
Epoch [25/25] Training [155/488] Loss: 0.20741
Epoch [25/25] Training [156/488] Loss: 0.21616
Epoch [25/25] Training [157/488] Loss: 0.17746
Epoch [25/25] Training [158/488] Loss: 0.13912
Epoch [25/25] Training [159/488] Loss: 0.27339
Epoch [25/25] Training [160/488] Loss: 0.12641
Epoch [25/25] Training [161/488] Loss: 0.38879
Epoch [25/25] Training [162/488] Loss: 0.17687
Epoch [25/25] Training [163/488] Loss: 0.13268
Epoch [25/25] Training [164/488] Loss: 0.24111
Epoch [25/25] Training [165/488] Loss: 0.25090
Epoch [25/25] Training [166/488] Loss: 0.22688
Epoch [25/25] Training [167/488] Loss: 0.22619
Epoch [25/25] Training [168/488] Loss: 0.23408
Epoch [25/25] Training [169/488] Loss: 0.11994
Epoch [25/25] Training [170/488] Loss: 0.13731
Epoch [25/25] Training [171/488] Loss: 0.14951
Epoch [25/25] Training [172/488] Loss: 0.26702
Epoch [25/25] Training [173/488] Loss: 0.21222
Epoch [25/25] Training [174/488] Loss: 0.12735
Epoch [25/25] Training [175/488] Loss: 0.13961
Epoch [25/25] Training [176/488] Loss: 0.13294
Epoch [25/25] Training [177/488] Loss: 0.12188
Epoch [25/25] Training [178/488] Loss: 0.38189
Epoch [25/25] Training [179/488] Loss: 0.14557
Epoch [25/25] Training [180/488] Loss: 0.39772
Epoch [25/25] Training [181/488] Loss: 0.33137
Epoch [25/25] Training [182/488] Loss: 0.11411
Epoch [25/25] Training [183/488] Loss: 0.18622
Epoch [25/25] Training [184/488] Loss: 0.17437
Epoch [25/25] Training [185/488] Loss: 0.14643
Epoch [25/25] Training [186/488] Loss: 0.14655
Epoch [25/25] Training [187/488] Loss: 0.27794
Epoch [25/25] Training [188/488] Loss: 0.18324
Epoch [25/25] Training [189/488] Loss: 0.13094
Epoch [25/25] Training [190/488] Loss: 0.40657
Epoch [25/25] Training [191/488] Loss: 0.16100
Epoch [25/25] Training [192/488] Loss: 0.14694
Epoch [25/25] Training [193/488] Loss: 0.20577
Epoch [25/25] Training [194/488] Loss: 0.16659
Epoch [25/25] Training [195/488] Loss: 0.14550
Epoch [25/25] Training [196/488] Loss: 0.27372
Epoch [25/25] Training [197/488] Loss: 0.50568
Epoch [25/25] Training [198/488] Loss: 0.22225
Epoch [25/25] Training [199/488] Loss: 0.12221
Epoch [25/25] Training [200/488] Loss: 0.34202
Epoch [25/25] Training [201/488] Loss: 0.20864
Epoch [25/25] Training [202/488] Loss: 0.33707
Epoch [25/25] Training [203/488] Loss: 0.23478
Epoch [25/25] Training [204/488] Loss: 0.16262
Epoch [25/25] Training [205/488] Loss: 0.10822
Epoch [25/25] Training [206/488] Loss: 0.15593
Epoch [25/25] Training [207/488] Loss: 0.24569
Epoch [25/25] Training [208/488] Loss: 0.30851
Epoch [25/25] Training [209/488] Loss: 0.12557
Epoch [25/25] Training [210/488] Loss: 0.13593
Epoch [25/25] Training [211/488] Loss: 0.13123
Epoch [25/25] Training [212/488] Loss: 0.14369
Epoch [25/25] Training [213/488] Loss: 0.33204
Epoch [25/25] Training [214/488] Loss: 0.19155
Epoch [25/25] Training [215/488] Loss: 0.13784
Epoch [25/25] Training [216/488] Loss: 0.62435
Epoch [25/25] Training [217/488] Loss: 0.35343
Epoch [25/25] Training [218/488] Loss: 0.32736
Epoch [25/25] Training [219/488] Loss: 0.19949
Epoch [25/25] Training [220/488] Loss: 0.19626
Epoch [25/25] Training [221/488] Loss: 0.14497
Epoch [25/25] Training [222/488] Loss: 0.13666
Epoch [25/25] Training [223/488] Loss: 0.15068
Epoch [25/25] Training [224/488] Loss: 0.10887
Epoch [25/25] Training [225/488] Loss: 0.15346
Epoch [25/25] Training [226/488] Loss: 0.19616
Epoch [25/25] Training [227/488] Loss: 0.19501
Epoch [25/25] Training [228/488] Loss: 0.13298
Epoch [25/25] Training [229/488] Loss: 0.11864
Epoch [25/25] Training [230/488] Loss: 0.16624
Epoch [25/25] Training [231/488] Loss: 0.39174
Epoch [25/25] Training [232/488] Loss: 0.17670
Epoch [25/25] Training [233/488] Loss: 0.12712
Epoch [25/25] Training [234/488] Loss: 0.21358
Epoch [25/25] Training [235/488] Loss: 0.22467
Epoch [25/25] Training [236/488] Loss: 0.72072
Epoch [25/25] Training [237/488] Loss: 0.12835
Epoch [25/25] Training [238/488] Loss: 0.13724
Epoch [25/25] Training [239/488] Loss: 0.11728
Epoch [25/25] Training [240/488] Loss: 0.11192
Epoch [25/25] Training [241/488] Loss: 0.14041
Epoch [25/25] Training [242/488] Loss: 0.23167
Epoch [25/25] Training [243/488] Loss: 0.14968
Epoch [25/25] Training [244/488] Loss: 0.48205
Epoch [25/25] Training [245/488] Loss: 0.18845
Epoch [25/25] Training [246/488] Loss: 0.13500
Epoch [25/25] Training [247/488] Loss: 0.28933
Epoch [25/25] Training [248/488] Loss: 0.11456
Epoch [25/25] Training [249/488] Loss: 0.11808
Epoch [25/25] Training [250/488] Loss: 0.29411
Epoch [25/25] Training [251/488] Loss: 0.18028
Epoch [25/25] Training [252/488] Loss: 0.24011
Epoch [25/25] Training [253/488] Loss: 0.11001
Epoch [25/25] Training [254/488] Loss: 0.13652
Epoch [25/25] Training [255/488] Loss: 0.30808
Epoch [25/25] Training [256/488] Loss: 0.09590
Epoch [25/25] Training [257/488] Loss: 0.28301
Epoch [25/25] Training [258/488] Loss: 0.15392
Epoch [25/25] Training [259/488] Loss: 0.10744
Epoch [25/25] Training [260/488] Loss: 0.15483
Epoch [25/25] Training [261/488] Loss: 0.15818
Epoch [25/25] Training [262/488] Loss: 0.16752
Epoch [25/25] Training [263/488] Loss: 0.29940
Epoch [25/25] Training [264/488] Loss: 0.14720
Epoch [25/25] Training [265/488] Loss: 0.12677
Epoch [25/25] Training [266/488] Loss: 0.19268
Epoch [25/25] Training [267/488] Loss: 0.20364
Epoch [25/25] Training [268/488] Loss: 0.16046
Epoch [25/25] Training [269/488] Loss: 0.14718
Epoch [25/25] Training [270/488] Loss: 0.15745
Epoch [25/25] Training [271/488] Loss: 0.18504
Epoch [25/25] Training [272/488] Loss: 0.29222
Epoch [25/25] Training [273/488] Loss: 0.13809
Epoch [25/25] Training [274/488] Loss: 0.21992
Epoch [25/25] Training [275/488] Loss: 0.15364
Epoch [25/25] Training [276/488] Loss: 0.13776
Epoch [25/25] Training [277/488] Loss: 0.17246
Epoch [25/25] Training [278/488] Loss: 0.46293
Epoch [25/25] Training [279/488] Loss: 0.28515
Epoch [25/25] Training [280/488] Loss: 0.37256
Epoch [25/25] Training [281/488] Loss: 0.17506
Epoch [25/25] Training [282/488] Loss: 0.13639
Epoch [25/25] Training [283/488] Loss: 0.27192
Epoch [25/25] Training [284/488] Loss: 0.10940
Epoch [25/25] Training [285/488] Loss: 0.13563
Epoch [25/25] Training [286/488] Loss: 0.17949
Epoch [25/25] Training [287/488] Loss: 0.17814
Epoch [25/25] Training [288/488] Loss: 0.10905
Epoch [25/25] Training [289/488] Loss: 0.23958
Epoch [25/25] Training [290/488] Loss: 0.15936
Epoch [25/25] Training [291/488] Loss: 0.13192
Epoch [25/25] Training [292/488] Loss: 0.23907
Epoch [25/25] Training [293/488] Loss: 0.16065
Epoch [25/25] Training [294/488] Loss: 0.14656
Epoch [25/25] Training [295/488] Loss: 0.20342
Epoch [25/25] Training [296/488] Loss: 0.13116
Epoch [25/25] Training [297/488] Loss: 0.29282
Epoch [25/25] Training [298/488] Loss: 0.14809
Epoch [25/25] Training [299/488] Loss: 0.12639
Epoch [25/25] Training [300/488] Loss: 0.24543
Epoch [25/25] Training [301/488] Loss: 0.10278
Epoch [25/25] Training [302/488] Loss: 0.15652
Epoch [25/25] Training [303/488] Loss: 0.35466
Epoch [25/25] Training [304/488] Loss: 0.70564
Epoch [25/25] Training [305/488] Loss: 0.37851
Epoch [25/25] Training [306/488] Loss: 0.15353
Epoch [25/25] Training [307/488] Loss: 0.13489
Epoch [25/25] Training [308/488] Loss: 0.17540
Epoch [25/25] Training [309/488] Loss: 0.14015
Epoch [25/25] Training [310/488] Loss: 0.17953
Epoch [25/25] Training [311/488] Loss: 0.28578
Epoch [25/25] Training [312/488] Loss: 0.41253
Epoch [25/25] Training [313/488] Loss: 0.18404
Epoch [25/25] Training [314/488] Loss: 0.14060
Epoch [25/25] Training [315/488] Loss: 0.17386
Epoch [25/25] Training [316/488] Loss: 0.47638
Epoch [25/25] Training [317/488] Loss: 0.13000
Epoch [25/25] Training [318/488] Loss: 0.23707
Epoch [25/25] Training [319/488] Loss: 0.15860
Epoch [25/25] Training [320/488] Loss: 0.36377
Epoch [25/25] Training [321/488] Loss: 0.19942
Epoch [25/25] Training [322/488] Loss: 0.13694
Epoch [25/25] Training [323/488] Loss: 0.28401
Epoch [25/25] Training [324/488] Loss: 0.11554
Epoch [25/25] Training [325/488] Loss: 0.55644
Epoch [25/25] Training [326/488] Loss: 0.23652
Epoch [25/25] Training [327/488] Loss: 0.66224
Epoch [25/25] Training [328/488] Loss: 0.23137
Epoch [25/25] Training [329/488] Loss: 0.15650
Epoch [25/25] Training [330/488] Loss: 0.19608
Epoch [25/25] Training [331/488] Loss: 0.11080
Epoch [25/25] Training [332/488] Loss: 0.16036
Epoch [25/25] Training [333/488] Loss: 0.23057
Epoch [25/25] Training [334/488] Loss: 0.20690
Epoch [25/25] Training [335/488] Loss: 0.34288
Epoch [25/25] Training [336/488] Loss: 0.18805
Epoch [25/25] Training [337/488] Loss: 0.16841
Epoch [25/25] Training [338/488] Loss: 0.32607
Epoch [25/25] Training [339/488] Loss: 0.14681
Epoch [25/25] Training [340/488] Loss: 0.25807
Epoch [25/25] Training [341/488] Loss: 0.12696
Epoch [25/25] Training [342/488] Loss: 0.13514
Epoch [25/25] Training [343/488] Loss: 0.21988
Epoch [25/25] Training [344/488] Loss: 0.26158
Epoch [25/25] Training [345/488] Loss: 0.19547
Epoch [25/25] Training [346/488] Loss: 0.29036
Epoch [25/25] Training [347/488] Loss: 0.23995
Epoch [25/25] Training [348/488] Loss: 0.44532
Epoch [25/25] Training [349/488] Loss: 0.20561
Epoch [25/25] Training [350/488] Loss: 0.12302
Epoch [25/25] Training [351/488] Loss: 0.11929
Epoch [25/25] Training [352/488] Loss: 0.23346
Epoch [25/25] Training [353/488] Loss: 0.24132
Epoch [25/25] Training [354/488] Loss: 0.22368
Epoch [25/25] Training [355/488] Loss: 0.19611
Epoch [25/25] Training [356/488] Loss: 0.38239
Epoch [25/25] Training [357/488] Loss: 0.31143
Epoch [25/25] Training [358/488] Loss: 0.29582
Epoch [25/25] Training [359/488] Loss: 0.38287
Epoch [25/25] Training [360/488] Loss: 0.14832
Epoch [25/25] Training [361/488] Loss: 0.10267
Epoch [25/25] Training [362/488] Loss: 0.13023
Epoch [25/25] Training [363/488] Loss: 0.12801
Epoch [25/25] Training [364/488] Loss: 0.23104
Epoch [25/25] Training [365/488] Loss: 0.14778
Epoch [25/25] Training [366/488] Loss: 0.13401
Epoch [25/25] Training [367/488] Loss: 0.31044
Epoch [25/25] Training [368/488] Loss: 0.32453
Epoch [25/25] Training [369/488] Loss: 0.12537
Epoch [25/25] Training [370/488] Loss: 0.12808
Epoch [25/25] Training [371/488] Loss: 0.19056
Epoch [25/25] Training [372/488] Loss: 0.22418
Epoch [25/25] Training [373/488] Loss: 0.30147
Epoch [25/25] Training [374/488] Loss: 0.12315
Epoch [25/25] Training [375/488] Loss: 0.21097
Epoch [25/25] Training [376/488] Loss: 0.11394
Epoch [25/25] Training [377/488] Loss: 0.37140
Epoch [25/25] Training [378/488] Loss: 0.18046
Epoch [25/25] Training [379/488] Loss: 0.23841
Epoch [25/25] Training [380/488] Loss: 0.18902
Epoch [25/25] Training [381/488] Loss: 0.28245
Epoch [25/25] Training [382/488] Loss: 0.15317
Epoch [25/25] Training [383/488] Loss: 0.15093
Epoch [25/25] Training [384/488] Loss: 0.11848
Epoch [25/25] Training [385/488] Loss: 0.16003
Epoch [25/25] Training [386/488] Loss: 0.16194
Epoch [25/25] Training [387/488] Loss: 0.10732
Epoch [25/25] Training [388/488] Loss: 0.23533
Epoch [25/25] Training [389/488] Loss: 0.39132
Epoch [25/25] Training [390/488] Loss: 0.11104
Epoch [25/25] Training [391/488] Loss: 0.13651
Epoch [25/25] Training [392/488] Loss: 0.18182
Epoch [25/25] Training [393/488] Loss: 0.16968
Epoch [25/25] Training [394/488] Loss: 0.14940
Epoch [25/25] Training [395/488] Loss: 0.25891
Epoch [25/25] Training [396/488] Loss: 0.12944
Epoch [25/25] Training [397/488] Loss: 0.23694
Epoch [25/25] Training [398/488] Loss: 0.17994
Epoch [25/25] Training [399/488] Loss: 0.22268
Epoch [25/25] Training [400/488] Loss: 0.18050
Epoch [25/25] Training [401/488] Loss: 0.24896
Epoch [25/25] Training [402/488] Loss: 0.16863
Epoch [25/25] Training [403/488] Loss: 0.16873
Epoch [25/25] Training [404/488] Loss: 0.12243
Epoch [25/25] Training [405/488] Loss: 0.16443
Epoch [25/25] Training [406/488] Loss: 0.46742
Epoch [25/25] Training [407/488] Loss: 0.13927
Epoch [25/25] Training [408/488] Loss: 0.13335
Epoch [25/25] Training [409/488] Loss: 0.14461
Epoch [25/25] Training [410/488] Loss: 0.20609
Epoch [25/25] Training [411/488] Loss: 0.16848
Epoch [25/25] Training [412/488] Loss: 0.52568
Epoch [25/25] Training [413/488] Loss: 0.23923
Epoch [25/25] Training [414/488] Loss: 0.23551
Epoch [25/25] Training [415/488] Loss: 0.10576
Epoch [25/25] Training [416/488] Loss: 0.18111
Epoch [25/25] Training [417/488] Loss: 0.13675
Epoch [25/25] Training [418/488] Loss: 0.30439
Epoch [25/25] Training [419/488] Loss: 0.13727
Epoch [25/25] Training [420/488] Loss: 0.15786
Epoch [25/25] Training [421/488] Loss: 0.29637
Epoch [25/25] Training [422/488] Loss: 0.35458
Epoch [25/25] Training [423/488] Loss: 0.10938
Epoch [25/25] Training [424/488] Loss: 0.11307
Epoch [25/25] Training [425/488] Loss: 0.15267
Epoch [25/25] Training [426/488] Loss: 0.33938
Epoch [25/25] Training [427/488] Loss: 0.17445
Epoch [25/25] Training [428/488] Loss: 0.20721
Epoch [25/25] Training [429/488] Loss: 0.14065
Epoch [25/25] Training [430/488] Loss: 0.09728
Epoch [25/25] Training [431/488] Loss: 0.17954
Epoch [25/25] Training [432/488] Loss: 0.11274
Epoch [25/25] Training [433/488] Loss: 0.20936
Epoch [25/25] Training [434/488] Loss: 0.19470
Epoch [25/25] Training [435/488] Loss: 0.16494
Epoch [25/25] Training [436/488] Loss: 0.16693
Epoch [25/25] Training [437/488] Loss: 0.16992
Epoch [25/25] Training [438/488] Loss: 0.13419
Epoch [25/25] Training [439/488] Loss: 0.12760
Epoch [25/25] Training [440/488] Loss: 0.12396
Epoch [25/25] Training [441/488] Loss: 0.17275
Epoch [25/25] Training [442/488] Loss: 0.11187
Epoch [25/25] Training [443/488] Loss: 0.13262
Epoch [25/25] Training [444/488] Loss: 0.12384
Epoch [25/25] Training [445/488] Loss: 0.13937
Epoch [25/25] Training [446/488] Loss: 0.12658
Epoch [25/25] Training [447/488] Loss: 0.11285
Epoch [25/25] Training [448/488] Loss: 0.13752
Epoch [25/25] Training [449/488] Loss: 0.27379
Epoch [25/25] Training [450/488] Loss: 0.12485
Epoch [25/25] Training [451/488] Loss: 0.20153
Epoch [25/25] Training [452/488] Loss: 0.10918
Epoch [25/25] Training [453/488] Loss: 0.18040
Epoch [25/25] Training [454/488] Loss: 0.17988
Epoch [25/25] Training [455/488] Loss: 0.15834
Epoch [25/25] Training [456/488] Loss: 0.21930
Epoch [25/25] Training [457/488] Loss: 0.10660
Epoch [25/25] Training [458/488] Loss: 0.17426
Epoch [25/25] Training [459/488] Loss: 0.44106
Epoch [25/25] Training [460/488] Loss: 0.12926
Epoch [25/25] Training [461/488] Loss: 0.44471
Epoch [25/25] Training [462/488] Loss: 0.35342
Epoch [25/25] Training [463/488] Loss: 0.10538
Epoch [25/25] Training [464/488] Loss: 0.11616
Epoch [25/25] Training [465/488] Loss: 0.19218
Epoch [25/25] Training [466/488] Loss: 0.12048
Epoch [25/25] Training [467/488] Loss: 0.15336
Epoch [25/25] Training [468/488] Loss: 0.12915
Epoch [25/25] Training [469/488] Loss: 0.23505
Epoch [25/25] Training [470/488] Loss: 0.17420
Epoch [25/25] Training [471/488] Loss: 0.20497
Epoch [25/25] Training [472/488] Loss: 0.19210
Epoch [25/25] Training [473/488] Loss: 0.20052
Epoch [25/25] Training [474/488] Loss: 0.13204
Epoch [25/25] Training [475/488] Loss: 0.20752
Epoch [25/25] Training [476/488] Loss: 0.27683
Epoch [25/25] Training [477/488] Loss: 0.30407
Epoch [25/25] Training [478/488] Loss: 0.22053
Epoch [25/25] Training [479/488] Loss: 0.31327
Epoch [25/25] Training [480/488] Loss: 0.20057
Epoch [25/25] Training [481/488] Loss: 0.19235
Epoch [25/25] Training [482/488] Loss: 0.16817
Epoch [25/25] Training [483/488] Loss: 0.39092
Epoch [25/25] Training [484/488] Loss: 0.13061
Epoch [25/25] Training [485/488] Loss: 0.12250
Epoch [25/25] Training [486/488] Loss: 0.16372
Epoch [25/25] Training [487/488] Loss: 0.19082
Epoch [25/25] Training [488/488] Loss: 0.45240
Epoch [25/25] Training metric {'Train/mean dice_metric': 0.9025055170059204, 'Train/TC dice_metric': 0.9282965064048767, 'Train/WT dice_metric': 0.943570077419281, 'Train/ET dice_metric': 0.835649847984314}
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
True
1
NVIDIA GeForce RTX 2060
Epoch [25/25] Validation [1/123] Loss: 0.20365  focal_loss 0.00182  dice_loss 0.20183
Epoch [25/25] Validation [2/123] Loss: 0.37396  focal_loss 0.00143  dice_loss 0.37254
Epoch [25/25] Validation [3/123] Loss: 0.18590  focal_loss 0.00138  dice_loss 0.18453
Epoch [25/25] Validation [4/123] Loss: 0.26880  focal_loss 0.00132  dice_loss 0.26748
Epoch [25/25] Validation [5/123] Loss: 0.34545  focal_loss 0.01079  dice_loss 0.33467
Epoch [25/25] Validation [6/123] Loss: 0.33835  focal_loss 0.00167  dice_loss 0.33668
Epoch [25/25] Validation [7/123] Loss: 0.35203  focal_loss 0.00053  dice_loss 0.35150
Epoch [25/25] Validation [8/123] Loss: 0.34848  focal_loss 0.00133  dice_loss 0.34715
Epoch [25/25] Validation [9/123] Loss: 0.26940  focal_loss 0.00123  dice_loss 0.26818
Epoch [25/25] Validation [10/123] Loss: 0.46713  focal_loss 0.00255  dice_loss 0.46458
Epoch [25/25] Validation [11/123] Loss: 0.45211  focal_loss 0.00167  dice_loss 0.45044
Epoch [25/25] Validation [12/123] Loss: 0.21473  focal_loss 0.00138  dice_loss 0.21336
Epoch [25/25] Validation [13/123] Loss: 0.20476  focal_loss 0.00329  dice_loss 0.20147
Epoch [25/25] Validation [14/123] Loss: 0.24017  focal_loss 0.00136  dice_loss 0.23881
Epoch [25/25] Validation [15/123] Loss: 0.35545  focal_loss 0.00126  dice_loss 0.35419
Epoch [25/25] Validation [16/123] Loss: 0.43998  focal_loss 0.00162  dice_loss 0.43837
Epoch [25/25] Validation [17/123] Loss: 0.48094  focal_loss 0.00146  dice_loss 0.47948
Epoch [25/25] Validation [18/123] Loss: 0.32172  focal_loss 0.00191  dice_loss 0.31981
Epoch [25/25] Validation [19/123] Loss: 0.28558  focal_loss 0.00269  dice_loss 0.28289
Epoch [25/25] Validation [20/123] Loss: 0.44176  focal_loss 0.00055  dice_loss 0.44121
Epoch [25/25] Validation [21/123] Loss: 0.33039  focal_loss 0.00070  dice_loss 0.32968
Epoch [25/25] Validation [22/123] Loss: 0.62961  focal_loss 0.00730  dice_loss 0.62232
Epoch [25/25] Validation [23/123] Loss: 0.19825  focal_loss 0.00155  dice_loss 0.19669
Epoch [25/25] Validation [24/123] Loss: 0.29316  focal_loss 0.00248  dice_loss 0.29068
Epoch [25/25] Validation [25/123] Loss: 0.34428  focal_loss 0.00338  dice_loss 0.34090
Epoch [25/25] Validation [26/123] Loss: 0.20714  focal_loss 0.00146  dice_loss 0.20568
Epoch [25/25] Validation [27/123] Loss: 0.24646  focal_loss 0.00223  dice_loss 0.24423
Epoch [25/25] Validation [28/123] Loss: 0.48908  focal_loss 0.00324  dice_loss 0.48584
Epoch [25/25] Validation [29/123] Loss: 0.33719  focal_loss 0.00146  dice_loss 0.33573
Epoch [25/25] Validation [30/123] Loss: 0.25151  focal_loss 0.00369  dice_loss 0.24781
Epoch [25/25] Validation [31/123] Loss: 0.19934  focal_loss 0.00137  dice_loss 0.19797
Epoch [25/25] Validation [32/123] Loss: 0.30318  focal_loss 0.00315  dice_loss 0.30003
Epoch [25/25] Validation [33/123] Loss: 0.34479  focal_loss 0.00129  dice_loss 0.34350
Epoch [25/25] Validation [34/123] Loss: 0.29076  focal_loss 0.00138  dice_loss 0.28937
Epoch [25/25] Validation [35/123] Loss: 0.22894  focal_loss 0.00098  dice_loss 0.22796
Epoch [25/25] Validation [36/123] Loss: 0.26381  focal_loss 0.00088  dice_loss 0.26293
Epoch [25/25] Validation [37/123] Loss: 0.37258  focal_loss 0.00365  dice_loss 0.36893
Epoch [25/25] Validation [38/123] Loss: 0.21511  focal_loss 0.00109  dice_loss 0.21402
Epoch [25/25] Validation [39/123] Loss: 0.21194  focal_loss 0.00134  dice_loss 0.21060
Epoch [25/25] Validation [40/123] Loss: 0.31194  focal_loss 0.00069  dice_loss 0.31125
Epoch [25/25] Validation [41/123] Loss: 0.20901  focal_loss 0.00157  dice_loss 0.20744
Epoch [25/25] Validation [42/123] Loss: 0.19228  focal_loss 0.00119  dice_loss 0.19110
Epoch [25/25] Validation [43/123] Loss: 0.27889  focal_loss 0.00996  dice_loss 0.26893
Epoch [25/25] Validation [44/123] Loss: 0.52558  focal_loss 0.00449  dice_loss 0.52110
Epoch [25/25] Validation [45/123] Loss: 0.30313  focal_loss 0.00122  dice_loss 0.30191
Epoch [25/25] Validation [46/123] Loss: 0.33379  focal_loss 0.00254  dice_loss 0.33125
Epoch [25/25] Validation [47/123] Loss: 0.29765  focal_loss 0.00111  dice_loss 0.29655
Epoch [25/25] Validation [48/123] Loss: 0.42300  focal_loss 0.00466  dice_loss 0.41834
Epoch [25/25] Validation [49/123] Loss: 0.21249  focal_loss 0.00112  dice_loss 0.21137
Epoch [25/25] Validation [50/123] Loss: 0.21007  focal_loss 0.00185  dice_loss 0.20823
Epoch [25/25] Validation [51/123] Loss: 0.40047  focal_loss 0.01052  dice_loss 0.38995
Epoch [25/25] Validation [52/123] Loss: 0.22562  focal_loss 0.00066  dice_loss 0.22496
Epoch [25/25] Validation [53/123] Loss: 0.28482  focal_loss 0.00073  dice_loss 0.28409
Epoch [25/25] Validation [54/123] Loss: 0.32505  focal_loss 0.00083  dice_loss 0.32422
Epoch [25/25] Validation [55/123] Loss: 0.28409  focal_loss 0.00115  dice_loss 0.28294
Epoch [25/25] Validation [56/123] Loss: 0.23281  focal_loss 0.00252  dice_loss 0.23029
Epoch [25/25] Validation [57/123] Loss: 0.29989  focal_loss 0.00186  dice_loss 0.29802
Epoch [25/25] Validation [58/123] Loss: 0.27174  focal_loss 0.00250  dice_loss 0.26924
Epoch [25/25] Validation [59/123] Loss: 0.61728  focal_loss 0.00838  dice_loss 0.60890
Epoch [25/25] Validation [60/123] Loss: 0.25501  focal_loss 0.00320  dice_loss 0.25181
Epoch [25/25] Validation [61/123] Loss: 0.60794  focal_loss 0.00168  dice_loss 0.60626
Epoch [25/25] Validation [62/123] Loss: 0.48784  focal_loss 0.00781  dice_loss 0.48004
Epoch [25/25] Validation [63/123] Loss: 0.37037  focal_loss 0.00113  dice_loss 0.36923
Epoch [25/25] Validation [64/123] Loss: 0.38570  focal_loss 0.00633  dice_loss 0.37937
Epoch [25/25] Validation [65/123] Loss: 0.23682  focal_loss 0.00090  dice_loss 0.23592
Epoch [25/25] Validation [66/123] Loss: 0.24682  focal_loss 0.00114  dice_loss 0.24568
Epoch [25/25] Validation [67/123] Loss: 0.42212  focal_loss 0.00945  dice_loss 0.41267
Epoch [25/25] Validation [68/123] Loss: 0.35745  focal_loss 0.00080  dice_loss 0.35665
Epoch [25/25] Validation [69/123] Loss: 0.39773  focal_loss 0.00722  dice_loss 0.39051
Epoch [25/25] Validation [70/123] Loss: 0.31491  focal_loss 0.00153  dice_loss 0.31338
Epoch [25/25] Validation [71/123] Loss: 0.22651  focal_loss 0.00070  dice_loss 0.22581
Epoch [25/25] Validation [72/123] Loss: 0.21057  focal_loss 0.00137  dice_loss 0.20920
Epoch [25/25] Validation [73/123] Loss: 0.32572  focal_loss 0.00386  dice_loss 0.32186
Epoch [25/25] Validation [74/123] Loss: 0.32875  focal_loss 0.00397  dice_loss 0.32479
Epoch [25/25] Validation [75/123] Loss: 0.26218  focal_loss 0.00125  dice_loss 0.26092
Epoch [25/25] Validation [76/123] Loss: 0.51730  focal_loss 0.00574  dice_loss 0.51156
Epoch [25/25] Validation [77/123] Loss: 0.36512  focal_loss 0.00096  dice_loss 0.36416
Epoch [25/25] Validation [78/123] Loss: 0.27084  focal_loss 0.00120  dice_loss 0.26964
Epoch [25/25] Validation [79/123] Loss: 0.30800  focal_loss 0.00096  dice_loss 0.30704
Epoch [25/25] Validation [80/123] Loss: 0.22308  focal_loss 0.00236  dice_loss 0.22072
Epoch [25/25] Validation [81/123] Loss: 0.25374  focal_loss 0.00127  dice_loss 0.25247
Epoch [25/25] Validation [82/123] Loss: 0.21599  focal_loss 0.00090  dice_loss 0.21509
Epoch [25/25] Validation [83/123] Loss: 0.37299  focal_loss 0.01034  dice_loss 0.36265
Epoch [25/25] Validation [84/123] Loss: 0.26087  focal_loss 0.00113  dice_loss 0.25974
Epoch [25/25] Validation [85/123] Loss: 0.36238  focal_loss 0.00767  dice_loss 0.35471
Epoch [25/25] Validation [86/123] Loss: 0.22974  focal_loss 0.00101  dice_loss 0.22873
Epoch [25/25] Validation [87/123] Loss: 0.22468  focal_loss 0.00274  dice_loss 0.22194
Epoch [25/25] Validation [88/123] Loss: 0.24451  focal_loss 0.00146  dice_loss 0.24304
Epoch [25/25] Validation [89/123] Loss: 0.20536  focal_loss 0.00197  dice_loss 0.20338
Epoch [25/25] Validation [90/123] Loss: 0.30055  focal_loss 0.00193  dice_loss 0.29862
Epoch [25/25] Validation [91/123] Loss: 0.23201  focal_loss 0.00094  dice_loss 0.23107
Epoch [25/25] Validation [92/123] Loss: 0.19539  focal_loss 0.00120  dice_loss 0.19419
Epoch [25/25] Validation [93/123] Loss: 0.21350  focal_loss 0.00123  dice_loss 0.21228
Epoch [25/25] Validation [94/123] Loss: 0.33976  focal_loss 0.00145  dice_loss 0.33830
Epoch [25/25] Validation [95/123] Loss: 0.25423  focal_loss 0.00218  dice_loss 0.25206
Epoch [25/25] Validation [96/123] Loss: 0.34873  focal_loss 0.00258  dice_loss 0.34615
Epoch [25/25] Validation [97/123] Loss: 0.61070  focal_loss 0.00931  dice_loss 0.60139
Epoch [25/25] Validation [98/123] Loss: 0.31735  focal_loss 0.00096  dice_loss 0.31639
Epoch [25/25] Validation [99/123] Loss: 0.31396  focal_loss 0.00054  dice_loss 0.31342
Epoch [25/25] Validation [100/123] Loss: 0.33583  focal_loss 0.00079  dice_loss 0.33504
Epoch [25/25] Validation [101/123] Loss: 0.29626  focal_loss 0.00115  dice_loss 0.29511
Epoch [25/25] Validation [102/123] Loss: 0.32929  focal_loss 0.00047  dice_loss 0.32882
Epoch [25/25] Validation [103/123] Loss: 0.47902  focal_loss 0.00100  dice_loss 0.47803
Epoch [25/25] Validation [104/123] Loss: 0.41880  focal_loss 0.00514  dice_loss 0.41366
Epoch [25/25] Validation [105/123] Loss: 0.20590  focal_loss 0.00284  dice_loss 0.20306
Epoch [25/25] Validation [106/123] Loss: 0.23519  focal_loss 0.00078  dice_loss 0.23441
Epoch [25/25] Validation [107/123] Loss: 0.52509  focal_loss 0.00305  dice_loss 0.52204
Epoch [25/25] Validation [108/123] Loss: 0.22870  focal_loss 0.00056  dice_loss 0.22814
Epoch [25/25] Validation [109/123] Loss: 0.22045  focal_loss 0.00512  dice_loss 0.21533
Epoch [25/25] Validation [110/123] Loss: 0.35664  focal_loss 0.00254  dice_loss 0.35410
Epoch [25/25] Validation [111/123] Loss: 0.37337  focal_loss 0.00298  dice_loss 0.37039
Epoch [25/25] Validation [112/123] Loss: 0.31552  focal_loss 0.00073  dice_loss 0.31479
Epoch [25/25] Validation [113/123] Loss: 0.28017  focal_loss 0.00165  dice_loss 0.27852
Epoch [25/25] Validation [114/123] Loss: 0.31838  focal_loss 0.00417  dice_loss 0.31421
Epoch [25/25] Validation [115/123] Loss: 0.27620  focal_loss 0.00488  dice_loss 0.27133
Epoch [25/25] Validation [116/123] Loss: 0.25986  focal_loss 0.00043  dice_loss 0.25943
Epoch [25/25] Validation [117/123] Loss: 0.27365  focal_loss 0.00101  dice_loss 0.27264
Epoch [25/25] Validation [118/123] Loss: 0.18220  focal_loss 0.00162  dice_loss 0.18058
Epoch [25/25] Validation [119/123] Loss: 0.21386  focal_loss 0.00135  dice_loss 0.21252
Epoch [25/25] Validation [120/123] Loss: 0.24023  focal_loss 0.00161  dice_loss 0.23862
Epoch [25/25] Validation [121/123] Loss: 0.62690  focal_loss 0.01598  dice_loss 0.61091
Epoch [25/25] Validation [122/123] Loss: 0.55887  focal_loss 0.00038  dice_loss 0.55849
Epoch [25/25] Validation [123/123] Loss: 0.23766  focal_loss 0.00137  dice_loss 0.23630
Epoch [25/25] Validation metric {'Val/mean dice_metric': 0.9004503488540649, 'Val/TC dice_metric': 0.924568772315979, 'Val/WT dice_metric': 0.9415337443351746, 'Val/ET dice_metric': 0.8352484703063965}
Epoch [25/25] lr = [6.15582970243117e-06, 6.15582970243117e-06] best acc: tensor([0.8987], device='cuda:0'), mean acc: tensor([0.9005], device='cuda:0'), mean class: tensor([0.9246, 0.9415, 0.8352], device='cuda:0')
best dice mean acc: tensor([0.9005], device='cuda:0')
best dice accs: tensor([0.9246, 0.9415, 0.8352], device='cuda:0')
PS D:\Luisa\luisa\Slim-UNETR-nuevo\Slim-UNETR-main>